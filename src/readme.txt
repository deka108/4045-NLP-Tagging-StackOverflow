+=========================+
| Data Collection Process |
+=========================+
1. Dependencies:
	1.1 Python Requests library
	1.2 StackExchange API: https://api.stackexchange.com/2.2

2. Download Data Set
	run python filter.py
	-- this will generate top 100 question threads (including answers) for every half year from 2011-2015 in JSON format.

3. Select posts for the experiment. The selected posts are put under api_mention/ directory. 

+===============+
| Preprocessing |
+===============+
	At root folder:
		* Run preprocess.bat

	It will populate api_preprocessed/ with preprocessed post in text files for each half year from 2011-2015.

+===================+
| Statistic Process |
+===================+
1.	Dependencies:
	1.1 pandas library, by running command pip install pandas
	1.2 matplotlib library, by running command pip install matlplotlib
	
2.	At root folder:
	2.1	Run statistic_new.py after running preprocess.bat
		--this will create histogram for answers' distribution, length of post, number of thread files to Stat_API/ 

+==================+
| Stemming Process |
+==================+
1.	Dependencies:
	1.1 Snowball stemmer, from nltk library, by running command pip install snowballstemmer
	1.2 stopwords, from nltk library, by running command nltk.download('stopwords') in the script
	
2.	At root folder:
		*Run stemming.py after running preprocess.bat
		-- this will create files for most frequent word rank to Stat_API/
		-- for ranking before stemming, change the input after inside the script into False
		-- otherwise, keep after equals to True for ranking after stemming 

+=====================+
| POS Tagging Process |
+=====================+
1.	Dependencies:
	1.1 nltk library, by running command pip install nltk
	
2.	At root\pos_tagging folder:
		*Run pos_tag.py
		--read 10 randomly selected sentences in sentence.txt
		--this will create a file containing POS tagging result (result.txt)

+========================+
| The Annotation Process |
+========================+
Using Brat annotation tool:
1. Dependencies:
	1.1 Git clone from https://github.com/nlplab/brat
	1.2 Use python2, Brat tool is implemented using Python 2.7.11

2. Setup:
	2.1 Copy brat files under brat/tools/ under cloned brat repository,
		eg: brat/tools/* is copied into cloned-brat-repo/tools

		There are two files available in this folder:
		- BIOtostandoff_utf8.py -> converts BIO labels into ann format of BRAT
		- anntoconll_utf8.py -> converts ann labels into tab separated BIO format

	2.2 Similarly, copy all brat files under data/ into the cloned brat repository,
		eg: brat/data is copied under cloned-brat-repo/data

		There are three subdirectories exist in this folder:
		- stackoverflow: contains the original preprocessed text files and the manual api annotation

		- classifier: contains 4 text files and the predicted annotation labels generated by the classifier corresponding to the 4-fold test data

		- gold: contains 4 text files and the gold standard for the annotation labels (manually annotated by humans) corresponding to the 4-fold test data

	2.3. Run cloned-brat-repo/.install.sh
	2.4. Run python2 standalone.py to run the server:
		python2 standalone.py [optional-port-number]
		
		Default port number is 8001

3. Annotation
	3.1. Open chrome, navigate to localhost:8001, access to StackOverflow collection and choose a text data
		http://localhost:8001/index.xhtml#/stackoverflow/
		
	3.2. Annotate the api mention in the text
	3.3. Run ./anntoconll_utf8.sh to convert the brat .ann files to .conll and generates tokenize words with their respective BIO tags. Conll file is  a tabbed separated file consist of key term in the first column and the I, O, B tags in the second column. This conll file is ready to be used by the Stanford NER classifier.

+==========+
| Training |
+==========+
	Requirements:
		* JDK 1.8
		* Stanford NER (http://nlp.stanford.edu/software/CRF-NER.shtml#Download)

	- Windows
		At root folder:
			* Run split_all.bat: aggregate all the text files, shuffle them and splits them into 4 folds
			* Run train.bat
			* Run test.bat

+======================+
| Evaluation Analysis  | 
+======================+
	Results and confusion matrices can be found in:
		* %ROOT%\train\result-0.tsv
		* %ROOT%\train\score-0.txt

		* %ROOT%\train\result-1.tsv
		* %ROOT%\train\score-1.txt

		* %ROOT%\train\result-2.tsv
		* %ROOT%\train\score-2.txt

		* %ROOT%\train\result-3.tsv
		* %ROOT%\train\score-3.txt

	result-*.tsv contains list of tokens with gold standard annotation and predicted annotation
	score-*.txt contains the confusion matrix for respective fold


Diff and Compare the Classification Results on Brat
	1. Run Brat Server
	2. Open http://localhost:8001/diff.xhtml#/gold/test-0?diff=/classifier
	The right side will show the Gold Standard annotation and the left side will show the Classifier annotation results
