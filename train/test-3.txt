Question - 26791441 , answer - 26791724 Use the replaceEach ( ) method from Apache Commons StringUtils : StringUtils . replaceEach ( args )

Question - 12468764 , answer - 24537575 I ' ve found a very nice and concise solution , especially useful when you cannot modify enum classes as it was in my case . Then you should provide a custom ObjectMapper with a certain feature enabled . Those features are available since Jackson 1 . 6 . So you only need to write toString ( args ) method in your enum . # pre There are more enum - related features available , see here : # a # a

Question - 29140402 , answer - 38628203 In intellij you can auto generate toString method by pressing alt + inset and then selecting toString ( ) here is an out put for a test class : # pre As you can see , it generates a String by concatenating , several attributes of the class , for primitives it will print their values and for reference types it will use their class type ( in this case to string method of Test2 ) .

Question - 12552863 , answer - 16229988 My solution is to do a " extract method " refactoring , as following : # pre printToFile can be written either # pre or # pre For class lib designers , I will suggest them extend the AutoClosable interface with an additional method to suppress the close . In this case we can then manually control the close behavior . For language designers , the lesson is that adding a new feature could mean adding a lot others . In this Java case , obviously ARM feature will work better with a resource ownership transfer mechanism . UPDATE Originally the code above requires @ SuppressWarning since the BufferedWriter inside the function requires close ( args ) . As suggested by a comment , if flush ( args ) to be called before close the writer , we need to do so before any return ( implicit or explicit ) statements inside the try block . There is currently no way to ensure the caller doing this I think , so this must be documented for writeFileWriter . UPDATE AGAIN The above update makes @ SuppressWarning unnecessary since it require the function to return the resource to the caller , so itself does not necessary being closed . Unfortunately , this pull us back to the beginning of the situation : the warning is now moved back to the caller side . So to properly solve this , we need a customised AutoClosable that whenever it closes , the underline BufferedWriter shall be flush ( args ) ed . Actually , this shows us another way to bypass the warning , since the BufferWriter is never closed in either way .

Question - 7283338 , answer - 7283475 Because any particular implementation of Set may or may not be random access . You can always get an iterator and step through the Set , using the iterators ' next ( args ) method to return the result you want once you find the equal element . This works regardless of the implementation . If the implementation is NOT random access ( picture a linked - list backed Set ) , a get ( args ) method in the interface would be deceptive , since it would have to iterate the collection to find the element to return , and a get ( args ) would seem to imply this would be necessary , that the Set could jump directly to the element to get . contains ( args ) may or may not have to do the same thing , of course , depending on the implementation , but the name doesn ' t seem to lend itself to the same sort of misunderstandings .

Question - 16148575 , answer - 16148647 Please use HashMap < T > myMap = new HashMap < T > ( args ) ;

Question - 19416644 , answer - 19416665 One simple way is to use Float . NaN : # pre # pre You can do the same with Double . NaN . From JLS ยง 15 . 21 . 1 . Numerical Equality Operators = = and ! = : # blockquote

Question - 20945049 , answer - 20959594 String is immutable , but through reflection you ' re allowed to change the String class . You ' ve just redefined the String class as mutable in real - time . You could redefine methods to be public or private or static if you wanted .

Question - 5868369 , answer - 31265714 In Java 8 , there is also an alternative to using Files . lines ( ) . If your input source isn ' t a file but something more abstract like a Reader or an InputStream , you can stream the lines via the BufferedReader s lines ( args ) method . For example : # pre will call processLine ( args ) for each input line read by the BufferedReader .

Question - 10796160 , answer - 21025279 Use proper escaping : string . split ( args ) Or the helper Regexp . quote ( args ) which has been created for exactly this purpose : string . split ( args ) which works with arbitrary input strings . Very useful when you need to quote / escape user input .

Question - 12552863 , answer - 18496449 The first style is the one suggested by Oracle . BufferedWriter doesn ' t throw checked exceptions , so if any exception is thrown , the program is not expected to recover from it , making resource recover mostly moot . Mostly because it could happen in a thread , with the thread dieing but the program still continuing - - say , there was a temporary memory outage that wasn ' t long enough to seriously impair the rest of the program . It ' s a rather corner case , though , and if it happens often enough to make resource leak a problem , the try - with - resources is the least of your problems .

Question - 20877086 , answer - 20877283 The Integer class has a static cache , that stores 256 special Integer objects - one for every value between - 128 and 127 . With that in mind , consider the difference between these three . new Integer ( args ) ; This ( obviously ) makes a brand new Integer object . Integer . parseInt ( args ) ; This returns an int primitive value after parsing the String . Integer . valueOf ( args ) ; This is more complex than the others . It starts off by parsing the String . Then , if the value is between - 128 and 127 , it returns the corresponding object from the static cache . If the value is outside of this range , then it invokes new Integer ( args ) and passes in the value , so that you get a new object . Now , consider the three expressions in the question . Integer . valueOf ( args ) = = Integer . valueOf ( args ) ; This returns true , because the Integer whose value is 127 is retrieved twice from the static cache , and compared to itself . There ' s only one Integer object involved , so this returns true . Integer . valueOf ( args ) = = Integer . valueOf ( args ) ; This returns false , because 128 is not in the static cache . So a new Integer is created for each side of the equality . Since there are two different Integer objects , and = = for objects only returns true if both sides are the exact same object , this is going to be false . Integer . parseInt ( args ) = = Integer . valueOf ( args ) ; This is comparing the primitive int value 128 on the left , with a newly created Integer object on the right . But because it doesn ' t make sense to compare an int to an Integer , Java will auto - unbox the Integer before doing the comparison ; so you end up comparing an int to an int . Since the primitive 128 is equal to itself , this returns true .

Question - 29095967 , answer - 29097694 Please do not vote . I do not have enough place to explain this in comments . This is a solution with a Stream and a foreach but this is strictly equivalent to Alexis ' s solution or a foreach loop ( and less clear , and I could not get rid of the copy constructor ) : # pre I understand that you want to find a more elegant solution with Java 8 but I truly think that it has not been designed for this case . And as said by Mr spoon , highly prefer the naive way in this case .

Question - 14014086 , answer - 20784007 Ken ' s answer is basically right but I ' d like to chime in on the " why would you want to use one over the other ? " part of your question . Basics The base interface you choose for your repository has two main purposes . First , you allow the Spring Data repository infrastructure to find your interface and trigger the proxy creation so that you inject instances of the interface into clients . The second purpose is to pull in as much functionality as needed into the interface without having to declare extra methods . The common interfaces The Spring Data core library ships with two base interfaces that expose a dedicated set of functionalities : # li CrudRepository - CRUD methods # li PagingAndSortingRepository - methods for pagination and sorting ( extends CrudRepository ) Store - specific interfaces The individual store modules ( e . g . for JPA or MongoDB ) expose store - specific extensions of these base interfaces to allow access to store - specific functionality like flushing or dedicated batching that take some store specifics into account . An example for this is deleteInBatch ( args ) of JpaRepository which is different from delete ( args ) as it uses a query to delete the given entities which is more performant but comes with the side effect of not triggering the JPA - defined cascades ( as the spec defines it ) . We generally recommend not to use these base interfaces as they expose the underlying persistence technology to the clients and thus tighten the coupling between them and the repository . Plus , you get a bit away from the original definition of a repository which is basically " a collection of entities " . So if you can , stay with PagingAndSortingRepository . Custom repository base interfaces The downside of directly depending on one of the provided base interfaces is two - fold . Both of them might be considered as theoretical but I think they ' re important to be aware of : # li Depending on a a Spring Data repository interface couples your repository interface to the library . I don ' t think this is a particular issue as you ' ll probably use abstractions like Page or Pageable in your code anyway . Spring Data is not any different from any other general purpose library like commons - lang or Guava . As long as it provides reasonable benefit , it ' s just fine . # li By extending e . g . CrudRepository , you expose a complete set of persistence method at once . This is probably fine in most circumstances as well but you might run into situations where you ' d like to gain more fine - grained control over the methods expose , e . g . to create a ReadOnlyRepository that doesn ' t include the save ( args ) and delete ( args ) methods of CrudRepository . The solution to both of these downsides is to craft your own base repository interface or even a set of them . In a lot of applications we ' ve seen something like this : # pre The first repository interface is some general purpose base interface that actually only fixes point 1 but also ties the ID type to be Long for consistency . The second interface usually has all the find โฆ ( โฆ ) methods copied from CrudRepository and PagingAndSortingRepository but does not expose the manipulating ones . Read more on that approach in the reference documentation . Summary - tl ; dr The repository abstraction allows you to pickt the base repository totally driven by you architectural and functional needs . Use the ones provided out of the box if they suit , craft your own repository base interfaces if necessary . Stay away from the store specific repository interfaces unless unavoidable .

Question - 8777257 , answer - 8777312 Arrays inherit equals ( args ) from Object and hence compare only returns true if comparing an array against itself . On the other hand , Arrays . equals compares the elements of the arrays . This snippet elucidates the difference : # pre See also Arrays . equals ( ) . Another static method there may also be of interest : Arrays . deepEquals ( ) .

Question - 14491966 , answer - 14495128 If the Math . Random ( args ) function calls the operating system to get the time of day , then you cannot compare it to your function . Your function is a PRNG , whereas that function is striving for real random numbers . Apples and oranges . Your PRNG may be fast , but it does not have enough state information to achieve a long period before it repeats ( and its logic is not sophisticated enough to even achieve the periods that are possible with that much state information ) . Period is the length of the sequence before your PRNG begins to repeat itself . This happens as soon as the PRNG machine makes a state transition to a state which is identical to some past state . From there , it will repeat the transitions which began in that state . Another problem with PRNG ' s can be a low number of unique sequences , as well as degenerate convergence on a particular sequence which repeats . There can also be undesirable patterns . For instance , suppose that a PRNG looks fairly random when the numbers are printed in decimal , but an inspection of the values in binary shows that bit 4 is simply toggling between 0 and 1 on each call . Oops ! Take a look at the Mersenne Twister and other algorithms . There are ways to strike a balance between the period length and CPU cycles . One basic approach ( used in the Mersenne Twister ) is to cycle around in the state vector . That is to say , when a number is being generated , it is not based on the entire state , just on a few words from the state array subject to a few bit operations . But at each step , the algorithm also moves around in the array , scrambling the contents a little bit at a time .

Question - 22740464 , answer - 22741520 Unfortunately this answer is probably of little or no help whatsoever , but I did a forensics analysis of the Java Lambda Mailing list to see if I could find the cause of this design . This is what I found out . In the beginning there was an instance method for Stream . concat ( Stream ) In the mailing list I can clearly see the method was originally implemented as an instance method , as you can read in this thread by Paul Sandoz , about the concat operation . In it they discuss the issues that could arise from those cases in which the stream could be infinite and what concatenation would mean in those cases , but I do not think that was the reason for the modification . You see in this other thread that some early users of the JDK 8 questioned about the behavior of the concat instance method when used with null arguments . This other thread reveals , though , that the design of the concat method was under discussion . Refactored to Streams . concat ( Stream , Stream ) But without any explanation , suddenly , the methods were changed to static methods , as you can see in this thread about combining streams . This is perhaps the only mail thread that sheds a bit of light about this change , but it was not clear enough for me to determine the reason for the refactoring . But we can see they did a commit in which they suggested to move the concat method out of Stream and into the helper class Streams . Refactored to Stream . concat ( Stream , Stream ) Later , it was moved again from Streams to Stream , but yet again , no explanation for that . So , bottom line , the reason for the design is not entirely clear for me and I could not find a good explanation . I guess you could still ask the question in the mailing list . Some Alternatives for Stream Concatenation This other thread by Michael Hixson discusses / asks about other ways to combine / concat streams # blockquote

Question - 15156857 I have a method with a void return type . It can also throw a number of exceptions so I ' d like to test those exceptions being thrown . All attempts have failed with the same reason : # blockquote Any ideas how I can get the method to throw a specified exception ? doThrow ( args ) . when ( args ) ;

Question - 5455794 , answer - 5455820 How about replaceAll ( args ) . Refer here .

Question - 13604703 , answer - 13604748 Lambdas are purely a call - site construct : the recipient of the lambda does not need to know that a Lambda is involved , instead it accepts an Interface with the appropriate method . In other words , you define or use a functional interface ( i . e . an interface with a single method ) that accepts and returns exactly what you want . For this Java 8 comes with a set of commonly - used interface types in java . util . function ( thanks to Maurice Naftalin for the hint about the JavaDoc ) . For this specific use case there ' s java . util . function . IntBinaryOperator with a single int applyAsInt ( int left , int right ) method , so you could write your method like this : # pre But you can just as well define your own interface and use it like this : # pre Using your own interface has the advantage that you can have names that more clearly indicate the intent .

Question - 16635398 , answer - 22502206 When reading this question one can get the impression , that Iterable # forEach in combination with lambda expressions is a shortcut / replacement for writing a traditional for - each loop . This is simply not true . This code from the OP : joins . forEach ( args ) ; is not intended as a shortcut for writing # pre and should certainly not be used in this way . Instead it is intended as a shortcut ( although it is not exactly the same ) for writing # pre And it is as a replacement for the following Java 7 code : # pre Replacing the body of a loop with a functional interface , as in the examples above , makes your code more explicit : You are saying that ( 1 ) the body of the loop does not affect the surrounding code and control flow , and ( 2 ) the body of the loop may be replaced with a different implementation of the function , without affecting the surrounding code . Not being able to access non final variables of the outer scope is not a deficit of functions / lambdas , it is a feature that distinguishes the semantics of Iterable # forEach from the semantics of a traditional for - each loop . Once one gets used to the syntax of Iterable # forEach , it makes the code more readable , because you immediately get this additional information about the code . Traditional for - each loops will certainly stay good practice ( to avoid the overused term " best practice " ) in Java . But this doesn ' t mean , that Iterable # forEach should be considered bad practice or bad style . It is always good practice , to use the right tool for doing the job , and this includes mixing traditional for - each loops with Iterable # forEach , where it makes sense . Since the downsides of Iterable # forEach have already been discussed in this thread , here are some reasons , why you might probably want to use Iterable # forEach : # li To make your code more explicit : As described above , Iterable # forEach can make your code more explicit and readable in some situations . # li To make your code more extensible and maintainable : Using a function as the body of a loop allows you to replace this function with different implementations ( see Strategy Pattern ) . You could e . g . easily replace the lambda expression with a method call , that may be overwritten by sub - classes : joins . forEach ( args ) ; Then you could provide default strategies using an enum , that implements the functional interface . This not only makes your code more extensible , it also increases maintainability because it decouples the loop implementation from the loop declaration . # li To make your code more debuggable : Seperating the loop implementation from the declaration can also make debugging more easy , because you could have a specialized debug implementation , that prints out debug messages , without the need to clutter your main code with if ( args ) System . out . println ( args ) . The debug implementation could e . g . be a delegate , that decorates the actual function implementation . # li To optimize performance - critical code : Contrary to some of the assertions in this thread , Iterable # forEach does already provide better performance than a traditional for - each loop , at least when using ArrayList and running Hotspot in " - client " mode . While this performance boost is small and negligible for most use cases , there are situations , where this extra performance can make a difference . E . g . library maintainers will certainly want to evaluate , if some of their existing loop implementations should be replaced with Iterable # forEach . To back this statement up with facts , I have done some micro - benchmarks with Caliper . Here is the test code ( latest Caliper from git is needed ) : # pre And here are the results : # li Results for - client # li Results for - server When running with " - client " , Iterable # forEach outperforms the traditional for loop over an ArrayList , but is still slower than directly iterating over an array . When running with " - server " , the performance of all approaches is about the same . # li To provide optional support for parallel execution : It has already been said here , that the possibility to execute the functional interface of Iterable # forEach in parallel using streams , is certainly an important aspect . Since Collection # parallelStream ( args ) does not guarantee , that the loop is actually executed in parallel , one must consider this an optional feature . By iterating over your list with list . parallelStream ( args ) . forEach ( args ) ; , you explicitly say : This loop supports parallel execution , but it does not depend on it . Again , this is a feature and not a deficit ! By moving the decision for parallel execution away from your actual loop implementation , you allow optional optimization of your code , without affecting the code itself , which is a good thing . Also , if the default parallel stream implementation does not fit your needs , no one is preventing you from providing your own implementation . You could e . g . provide an optimized collection depending on the underlying operating system , on the size of the collection , on the number of cores , and on some preference settings : # pre The nice thing here is , that your loop implementation doesn ' t need to know or care about these details .

Question - 4812570 , answer - 21765043 You can use the ExceptionUtils . getStackTrace ( args ) ; from Apache Commons 3 class org . apache . commons . lang3 . exception . ExceptionUtils . # a

Question - 6608795 I wonder what the difference is between Class . getResource ( args ) and ClassLoader . getResource ( args ) ? edit : I especially want to know if any caching is involved on file / directory level . As in " are directory listings cached in the Class version ? " AFAIK the following should essentially do the same , but they are not : # pre I discovered this when fiddling with some report generation code that creates a new file in WEB - INF / classes / from an existing file in that directory . When using the method from Class , I could find files that were there at deployment using getClass ( args ) . getResource ( args ) , but when trying to fetch the newly created file , I recieved a null object . Browsing the directory clearly shows that the new file is there . The filenames were prepended with a forward slash as in " / myFile . txt " . The ClassLoader version of getResource ( args ) on the other hand did find the generated file . From this experience it seems that there is some kind of caching of the directory listing going on . Am I right , and if so , where is this documented ? From the API docs on Class . getResource ( args ) # blockquote To me , this reads " Class . getResource is really calling its own classloader ' s getResource ( ) " . Which would be the same as doing getClass ( args ) . getClassLoader ( args ) . getResource ( args ) . But it is obviously not . Could someone please provide me with some illumination into this matter ?

Question - 30581531 What is the maximum number of parameters that a method in Java can have and why ? I am using Java 1 . 8 on a 64 - bit Windows system . All the answers on StackOverflow about this say that the technical limit is 255 parameters without specifying why . To be precise , 255 for static and 254 for non - static ( this will be the 255th in this case ) methods . I thought this could be specified in some sort of specification and that this was simply a statically defined maximum number of parameters allowed . But this was only valid for int and all 4 - bytes types . I did some tests with long parameters , and I was only able to declare 127 parameters in that case . With String parameters , the allowed number i deduced from testing is 255 ( it may be because the reference size is 4 bytes in Java ? ) . But since I am using a 64 - bit system , references size should be 8 bytes wide and so with String parameters the maximum allowed number should be 127 , similar to long types . How does this limit is exactly applied ? Does the limit have anything to do with the stack size of the method ? Note : I am not really going to use these many parameters in any method , but this question is only to clarify the exact behavior .

Question - 5455794 , answer - 5455809 st . replaceAll ( args ) removes all whitespaces and non - visible characters ( e . g . , tab , \ n ) . st . replaceAll ( args ) and st . replaceAll ( args ) produce the same result . The second regex is 20 % faster than the first one , but as the number consecutive spaces increases , the first one performs better than the second one . Assign the value to a variable , if not used directly : st = st . replaceAll ( args )

Question - 31445024 I ' m trying to determine whether the following statements are guaranteed to be true : # pre I ' ve always assumed that autoboxing was equivalent to calling valueOf ( args ) on the corresponding type . Every discussion that I ' ve seen on the topic seems to support my assumption . But all I could find in the JLS was the following ( ยง 5 . 1 . 7 ) : # blockquote That describes behavior identical to that of valueOf ( args ) . But there doesn ' t seem to be any guarantee that valueOf ( args ) is actually invoked , meaning there could theoretically be an implementation that keeps a separate , dedicated cache for autoboxed values . In such a case , there might not be identity equality between cached autoboxed values and regular cached boxed values . Oracle ' s autoboxing tutorial states matter - of - factly that li . add ( args ) is compiled to li . add ( args ) , where i is an int . But I don ' t know whether the tutorial should be considered an authoritative source .

Question - 22725537 , answer - 27215810 A slightly shorter version using reduce : things . stream ( args ) . map ( args ) . reduce ( args ) ; You could also move the reduce function to a static utility method and then it becomes : . reduce ( args ) ;

Question - 14534767 , answer - 14534791 Escape should be done with \ , not / . So r . append ( args ) ; or r . append ( args ) ; will work ( StringBuilder has overloaded methods for char and String type ) .

Question - 4709175 , answer - 4709892 Something none of the other answers have covered that make enums particularly powerful are the ability to have template methods . Methods can be part of the base enum and overridden by each type . And , with the behavior attached to the enum , it often eliminates the need for if - else constructs or switch statements as this blog post demonstrates - where enum . method ( args ) does what originally would be executed inside the conditional . The same example also shows the use of static imports with enums as well producing much cleaner DSL like code . Some other interesting qualities include the fact that enums provide implementation for equals ( args ) , toString ( args ) and hashCode ( args ) and implement Serializable and Comparable . For a complete rundown of all that enums have to offer I highly recommend Bruce Eckel ' s Thinking in Java 4th edition which devotes an entire chapter to the topic . Particularly illuminating are the examples involving a Rock , Paper , Scissors ( i . e . RoShamBo ) game as enums .

Question - 23699371 In Java 8 how can I filter a collection using the Stream API by checking the distinctness of a property of each object ? For example I have a list of Person object and I want to remove people with the same name , persons . stream ( args ) . distinct ( args ) ; Will use the default equality check for a Person object , so I need something like , persons . stream ( args ) . distinct ( args ) ; Unfortunately the distinct ( args ) method has no such overload . Without modifying the equality check inside the Person class is it possible to do this succinctly ?

Question - 4871051 , answer - 27760556 System . getProperty ( args )

Question - 13102045 , answer - 24907860 Instead of input . nextLine ( args ) use input . next ( args ) , that should solve the problem . Modified code : # pre

Question - 7032070 , answer - 7032137 Unless there is a specific optimization that checks if the argument passed to removeAll ( args ) is the collection itself ( and I highly doubt that such an optimization is there ) it will be significantly slower than a simple . clear ( args ) . Apart from that ( and at least equally important ) : arraylist . removeAll ( args ) is just obtuse , confusing code . It is a very backwards way of saying " clear this collection " . What advantage would it have over the very understandable arraylist . clear ( args ) ?

Question - 9749746 How do atomic / volatile / synchronized work internally ? What is the difference between the following code blocks ? Code 1 # pre Code 2 # pre Code 3 # pre Does volatile work in the following way ? Is # pre equivalent to # pre I think that two threads cannot enter a synchronized block at the same time . . . am I right ? If this is true then how does atomic . incrementAndGet ( args ) work without synchronized ? And is it thread - safe ? And what is the difference between internal reading and writing to volatile variables / atomic variables ? I read in some article that the thread has a local copy of the variables - what is that ?

Question - 21242110 What is the best way to convert a java . util . Date object to the new JDK 8 / JSR - 310 java . time . LocalDate ? # pre

Question - 5243754 , answer - 34295445 request . getParameter ( ) We use request . getParameter ( args ) to extract request parameters ( i . e . data sent by posting a html form ) . The request . getParameter ( args ) always returns String value and the data come from client . request . getAttribute ( ) We use request . getAttribute ( args ) to get an object added to the request scope on the server side i . e . using request . setAttribute ( args ) . You can add any type of object you like here , Strings , Custom objects , in fact any object . You add the attribute to the request and forward the request to another resource , the client does not know about this . So all the code handling this would typically be in JSP / servlets . You can use request . setAttribute ( args ) to add extra - information and forward / redirect the current request to another resource . For example , consider about first . jsp , # pre and second . jsp : # pre From your browser , run first . jsp ? CLIENT = you and the output on your browser is # pre The basic difference between getAttribute ( args ) and getParameter ( args ) is that the first method extracts a ( serialized ) Java object and the other provides a String value . For both cases a name is given so that its value ( be it string or a java bean ) can be looked up and extracted .

Question - 5011932 I am storing a SQL query in my strings . xml file and I want to use String . Format to build the final string in code . The SELECT statement uses a like , something like this : SELECT Field1 , Field2 FROM mytable WHERE Field1 LIKE ' % something % ' In order to format that I replace ' something ' with % 1 $ s so it becomes : SELECT Field1 , Field2 FROM mytable WHERE Field1 LIKE \ ' % % 1 $ s % \ ' I escape the single quotes with the backslash . However I am not able to escape the % sign . How can I include a like statement in my strings . xml file ?

Question - 9297899 We can determine the length of an ArrayList < T > using its public method size ( args ) , like # pre Similarly we can determine the length of an Array object using the length property # pre Whereas the size ( args ) method of ArrayList is defined inside the ArrayList class , where is this length property of Array defined ?

Question - 24603186 In Java 8 , the Collection interface was extended with two methods that return Stream < T > : stream ( args ) , which returns a sequential stream , and parallelStream ( args ) , which returns a possibly - parallel stream . Stream itself also has a parallel ( args ) method that returns an equivalent parallel stream ( either mutating the current stream to be parallel or creating a new stream ) . The duplication has obvious disadvantages : # li It ' s confusing . A question asks whether calling both parallelStream ( ) . parallel ( ) is necessary to be sure the stream is parallel , given that parallelStream ( ) may return a sequential stream . Why does parallelStream ( ) exist if it can ' t make a guarantee ? The other way around is also confusing - - if parallelStream ( ) returns a sequential stream , there ' s probably a reason ( e . g . , an inherently sequential data structure for which parallel streams are a performance trap ) ; what should Stream . parallel ( ) do for such a stream ? ( UnsupportedOperationException is not allowed by parallel ( ) ' s specification . ) # li Adding methods to an interface risks conflicts if an existing implementation has a similarly - named method with an incompatible return type . Adding parallelStream ( ) in addition to stream ( ) doubles the risk for little gain . ( Note that parallelStream ( ) was at one point just named parallel ( ) , though I don ' t know if it was renamed to avoid name clashes or for another reason . ) Why does Collection . parallelStream ( ) exist when calling Collection . stream ( ) . parallel ( ) does the same thing ?

Question - 31922866 , answer - 31923042 The pattern with Optional is for one to avoid returning null . It ' s still perfectly possible to pass in null to a method . While these aren ' t really official yet , you can use JSR - 308 style annotations to indicate whether or not you accept null values into the function . Note that you ' d have to have the right tooling to actually identify it , and it ' d provide more of a static check than an enforceable runtime policy , but it would help . public int calculateSomething ( args ) { }

Question - 29229373 , answer - 29230939 When looking into the implementation ( ReferencePipeline . java ) we see the method [ link ] # pre which will be invoke for findFirst operation . The special thing to take care about is the sink . cancellationRequested ( args ) which allows to end the loop on the first match . Compare to [ link ] # pre The method for advancing one item ends up calling forEach on the sub - stream without any possibility for earlier termination and the comment at the beginning of the flatMap method even tells about this absent feature . Since this is more than just an optimization thing as it implies that the code simply breaks when the sub - stream is infinite , I hope that the developers soon prove that they โ can do better than this โ โฆ To illustrate the implications , while Stream . iterate ( args ) . findFirst ( args ) works as expected , Stream . of ( args ) . flatMap ( args ) . findFirst ( args ) will end up in an infinite loop . Regarding the specification , most of it can be found in the chapter โ Stream operations and pipelines โ of the package specification : # blockquote It โ s clear that a short - circuiting operation doesn โ t guaranty a finite time termination , e . g . when a filter doesn โ t match any item the processing can โ t complete , but an implementation which doesn โ t support any termination in finite time by simply ignoring the short - circuiting nature of an operation is far off the specification .

Question - 14846920 , answer - 14846964 For one , you can get away with reference sharing . A new HashMap ( args ) etc will require an allocated object , and possibly some extra elements to hold the data , but you only need one copy of an immutable empty collection ( list , set , map , or any other such ) . This makes it an obvious choice when a method you ' re calling needs to accept a Map but does not need to edit it . I suggest checking out Josh Bloch ' s Effective Java , which lists some very nice attributes of immutable objects ( including thread safety ) .

Question - 20358883 , answer - 31965160 With Java 8 Streams : Stream . of ( args ) . collect ( args ) or if you need a set : Stream . of ( args ) . collect ( args )

Question - 8725387 , answer - 8725453 Since all lists are already " sorted " by the order the items were added ( FIFO ordering ) , you can " resort " them with another ordering , including the natural ordering of elements , using java . util . Collections . sort ( args ) . EDIT : Lists as data structures are based in what is interesting is the ordering in which the items where inserted . Sets do not have that information . If you want to order by addition time , use List . If you want to order by other criteria , use SortedSet .

Question - 31445024 , answer - 31871515 Autoboxing is absolutely implemented using valueOf ( args ) . . . in the OpenJDK . If that ' s your implementation , read on . . . if not , skip to below . # pre Java documentation states that Boolean . valueOf ( args ) always returns Boolean . TRUE or Boolean . FALSE , therefore your reference comparisons in these cases will succeed . ( ( Integer ) 1 ) = = Integer . valueOf ( args ) For this particular example , under the OpenJDK implementation with default settings , it will probably work by virtue of the fact that you picked a value < 128 which is cached at startup ( although this can be overridden as a commandline arg ) . It may also work for larger values if it ' s frequently used enough to be cached . Unless you ' re working under " safe " assumptions about the Integer cache , don ' t expect the reference comparison to be an equality . Long , Short , Character and Byte incidentally implement this caching too , but unlike Integer , it ' s not tunable . Byte will always work if you ' re comparing autobox / valueOf ( args ) references since obviously , you can ' t go out of range . Float and Double will unsurprisingly always create a new instance . Now , in purely generic terms ? See this section of the JLS - you MUST be given equal references for boolean and any int or char within the - 128 to 127 range . There are no guarantees for anything else .

Question - 5868369 , answer - 32542424 What you can do is scan the entire text using Scanner and go through the text line by line . Of course you should import the following : # pre Scanner basically scans all the text . The while loop is used to traverse through the entire text . The . hasNextLine ( args ) function is a boolean that returns true if there are still more lines in the text . The . nextLine ( args ) function gives you an entire line as a String which you can then use the way you want . Try System . out . println ( args ) to print the text . Side Note : . txt is the file type text .

Question - 22409102 , answer - 22501695 The approach used by Math . min is similar to what Jesper proposes but a little clearer : # pre

Question - 8275499 , answer - 8275761 getClass ( args ) method is defined in Object class with the following signature : # blockquote Since it is not defined as static , you can not call it within a static code block . See these answers for more information : Q1 , Q2 , Q3 . If you ' re in a static context , then you have to use the class literal expression to get the Class , so you basically have to do like : # blockquote This type of expression is called Class Literals and they are explained in Java Language Specification Book as follows : # blockquote You can also find information about this subject on API documentation for Class .

Question - 24511052 I am looking for a concise way to convert an Iterator to a Stream or more specifically to " view " the iterator as a stream . For performance reason , I would like to avoid a copy of the iterator in a new list : # pre Based on the some suggestions in the comments , I have also tried to use Stream . generate : # pre However , I get a NoSuchElementException ( since there is no invocation of hasNext ) # pre I have looked at StreamSupport and Collections but I didn ' t find anything .

Question - 14602062 , answer - 14602155 From the documentation of String . split ( String regex ) : # blockquote So you will have to use the two argument version String . split ( String regex , int limit ) with a negative value : String [ ] split = data . split ( args ) ; Doc : # blockquote This will not leave out any empty elements , including the trailing ones .

Question - 20331163 , answer - 20331323 Another way of doing that is : String date = dateAndTime . substring ( args ) ; I ' m not exactly certain , but I think this might be faster / use less memory than using the . split ( args ) method .

Question - 28459498 , answer - 28460301 Stream s are built around Spliterator s which are stateful , mutable objects . They don โ t have a โ reset โ action and in fact , requiring to support such rewind action would โ take away much power โ . How would Random . ints ( ) be supposed to handle such a request ? On the other hand , for Stream s which have a retraceable origin , it is easy to construct an equivalent Stream to be used again . Just put the steps made to construct the Stream into a reusable method . Keep in mind that repeating these steps is not an expensive operation as all these steps are lazy operations ; the actual work starts with the terminal operation and depending on the actual terminal operation entirely different code might get executed . It would be up to you , the writer of such a method , to specify what calling the method twice implies : does it reproduce exactly the same sequence , as streams created for an unmodified array or collection do , or does it produce a stream with a similar semantics but different elements like a stream of random ints or a stream of console input lines , etc . By the way , to avoid confusion , a terminal operation consumes the Stream which is distinct from closing the Stream as calling close ( args ) on the stream does ( which is required for streams having associated resources like , e . g . produced by Files . lines ( args ) ) . It seems that a lot of confusion stems from misguiding comparison of IEnumerable with Stream . An IEnumerable represents the ability to provide an actual IEnumerator , so its like an Iterable in Java . In contrast , a Stream is a kind of iterator and comparable to an IEnumerator so it โ s wrong to claim that this kind of data type can be used multiple times in . NET , the support for IEnumerator . Reset is optional . The examples discussed here rather use the fact that an IEnumerable can be used to fetch new IEnumerator s and that works with Java โ s Collection s as well ; you can get a new Stream . If the Java developers decided to add the Stream operations to Iterable directly , with intermediate operations returning another Iterable , it was really comparable and it could work the same way . However , the developers decided against it and the decision is discussed in this question . The biggest point is the confusion about eager Collection operations and lazy Stream operations . By looking at the . NET API , I ( yes , personally ) find it justified . While it looks reasonable looking at IEnumerable alone , a particular Collection will have lots of methods manipulating the Collection directly and lots of methods returning a lazy IEnumerable , while the particular nature of a method isn โ t always intuitively recognizable . The worst example I found ( within the few minutes I looked at it ) is List . Reverse ( ) whose name matches exactly the name of the inherited ( is this the right terminus for extension methods ? ) Enumerable . Reverse ( ) while having an entirely contradicting behavior . Of course , these are two distinct decisions . The first one to make Stream a type distinct from Iterable / Collection and the second to make Stream a kind of one time iterator rather than another kind of iterable . But these decision were made together and it might be the case that separating these two decision never was considered . It wasn โ t created with being comparable to . NET โ s in mind . The actual API design decision was to add an improved type of iterator , the Spliterator . Spliterator s can be provided by the old Iterable s ( which is the way how these were retrofitted ) or entirely new implementations . Then , Stream was added as a high - level front - end to the rather low level Spliterator s . That โ s it . You may discuss about whether a different design would be better , but that โ s not productive , it won โ t change , given the way they are designed now . There is another implementation aspect you have to consider . Stream s are not immutable data structures . Each intermediate operation may return a new Stream instance encapsulating the old one but it may also manipulate its own instance instead and return itself ( that doesn โ t preclude doing even both for the same operation ) . Commonly known examples are operations like parallel or unordered which do not add another step but manipulate the entire pipeline ) . Having such a mutable data structure and attempts to reuse ( or even worse , using it multiple times at the same time ) doesn โ t play well โฆ For completeness , here is your quicksort example translated to the Java Stream API . It shows that it does not really โ take away much power โ . # pre It can be used like # pre You can write it even more compact as # pre

Question - 25441088 , answer - 25441208 I think you ' re just looking for the overload which takes another Collector to specify what to do with each group . . . and then Collectors . counting ( args ) to do the counting : # pre Result : { Hello = 2 , World = 1 } ( There ' s also the possibility of using groupingByConcurrent for more efficiency . Something to bear in mind for your real code , if it would be safe in your context . )

Question - 20129762 In Java 8 we have the class Stream < T > , which curiously have a method Iterator < T > iterator ( args ) So you would expect it to implement interface Iterable < T > , which requires exactly this method , but that ' s not the case . When I want to iterate over a Stream using a foreach loop , I have to do something like # pre Am I missing something here ?

Question - 11408427 , answer - 11408477 The + operator is usually replaced by a StringBuilder at compile time . Check this answer for more details on that matter .

Question - 27845223 I ' m looking at a piece of Java code right now , and it takes a path as a String and gets its URL using URL resource = ClassLoader . getSystemClassLoader ( args ) . getResource ( args ) ; , then calls String path = resource . getPath ( args ) and finally executes new File ( args ) ; . Oh , and there are also calls to URL url = resource . toURI ( args ) ; and String file = resource . getFile ( args ) . I ' m totally confused right now - mostly because of the terminology , I guess . Can someone please walk me through the differences , or provide a few links to Dummy - proof material ? Especially URI to URL and Resource to File ? To me , it feels like they should be the same thing , respectively . . . The difference between getFile ( args ) and getPath ( args ) is explained here : What ' s the difference between url . getFile ( ) and getpath ( ) ? ( Interestingly they both seem to return Strings , which probably adds a whole lot to my state of mind . . . ) Now , if I have a locator that references a class or package in a jar file , will those two ( i . e . path an file strings ) differ ? resource . toString ( args ) would give you jar : file : / C : / path / to / my . jar ! / com / example / , after all ( note the exclamation mark ) . Is the difference between URI and URL in Java that the former doesn ' t encode spaces ? Cf . Files , URIs , and URLs conflicting in Java ( This answer explains the general , conceptual difference between the two terms fairly well : URIs identify and URLs locate ; ) Lastly - and most importantly - why do I need File object ; why isn ' t a Resource ( URL ) enough ? ( And is there a Resource object ? ) Sorry if this question is a bit unorganized ; it just reflects the confusion I have . . . : )

Question - 32046078 I have a server side implemented in Scala and React / Flux based front end . My services return Futures and they are handled within Scalatra ' s AsyncResult for JSON responses . For isomorphic / server side rendering setup I did not want to change services to be blocking so I started with Scala Future - > java . util . function . Function conversion shown here . But the dispatcher in Flux would like to have JS Promise . So far I found only rather complicated sounding way around this Slides 68 - 81 Is there any recommended way to deal with this Scala Future - > JS Promise conversion ?

Question - 15430247 , answer - 15432106 This is to avoid possible efforts for reallocation for every single object . int newCapacity = ( oldCapacity * 3 ) / 2 + 1 ; internally new Object [ ] is created . JVM needs effort to create new Object [ ] when you add element in the arraylist . If you don ' t have above code ( any algo you think ) for reallocation then every time when you invoke arraylist . add ( args ) then new Object [ ] has to be created which is pointless and we are loosing time for increasing size by 1 for each and every objects to be added . So it is better to increase size of Object [ ] with following formula . ( JSL has used forcasting formula given below for dynamically growing arraylist instead of growing by 1 every time . Because to grow it takes effort by JVM ) int newCapacity = ( oldCapacity * 3 ) / 2 + 1 ;

Question - 28584669 , answer - 28588854 The correct answer is a simple " because the standard ( and the docs ) say so " . But I ' m not gonna be cynical because it ' s obvious that ' s not what you are after . In addition to the other answers here , I ' ll try to relate the infinities to saturating arithmetic . Other answers have already stated that the reason the comparisons on NaNs result in true , so I ' m not gonna beat a dead horse . Let ' s say I have a saturating integer that represents grayscale colors . Why am I using saturating arithmetic ? Because anything brighter than white is still white , and anything darker than black is still black ( except orange ) . That means BLACK - x = = BLACK and WHITE + x = = WHITE . Makes sense ? Now , let ' s say we want to represent those grayscale colors with a ( signed ) 1s complement 8 - bit integer where BLACK = = - 127 and WHITE = = 127 . Why 1s complement ? Because it gives us a signed zero like IEEE 754 floating point . And , because we are using saturating arithmetic , - 127 - x = = - 127 and 127 + x = = 127 . How does this relate to floating point infinities ? Replace the integer with floating point , BLACK with NEGATIVE _ INFINITY , and WHITE with POSITIVE _ INFINITY and what do you get ? NEGATIVE _ INFINITY - x = = NEGATIVE _ INFINITY and POSITIVE _ INFINITY + x = = POSITIVE _ INFINITY . Since you used POSITIVE _ INFINITY , I ' ll use it also . First we need a class to represent our saturating integer - based color ; let ' s call it SaturatedColor and assume it works like any other integer in Java . Now , let ' s take your code and replace double with our own SaturatedColor and Double . POSITIVE _ INFINITY with SaturatedColor . WHITE : # pre As we established above , SaturatedColor . WHITE ( just WHITE above ) is 127 , so let ' s do that here : # pre Now we take the System . out . println statements you used and replace a and b with their value ( values ? ) : # pre It should be obvious what this will print .

Question - 29262002 , answer - 29262511 The first case is ok because you are invoking a " special " method ( a constructor ) and you are no actually taking the created object . Just to make it more clear , I ' ll put the optional braces in your lambdas : # pre And more clear , I ' ll translate that to the older notation : # pre In the first case you are executing a constructor , but you are NOT returning the created object , in the second case you are attempting to return a String value , but your method in your interface BiConsumer returns void , hence the compiler error .

Question - 8894258 , answer - 22676782 Despite @ Saint Hill ' s answer if you consider the time complexity of str . toCharArray ( ) , the first one is faster even for very large strings . You can run the code below to see it for yourself . # pre output : # pre

Question - 14534767 , answer - 33687544 For HTML response below code can be used bufString . append ( args ) ;

Question - 5374311 , answer - 17909134 I can see many answers showing how to solve problem , but only Stephen ' s answer is trying to explain why problem occurs so I will try to add something more on this subject . It is a story about possible reasons why Object [ ] toArray wasn ' t changed to T [ ] toArray where generics ware introduced to Java . Why String [ ] stockArr = ( String [ ] ) stock _ list . toArray ( args ) ; wont work ? In Java , generic type exists at compile - time only . At runtime information about generic type ( like in your case < String > ) is removed and replaced with Object type ( take a look at type erasure ) . That is why at runtime toArray ( args ) have no idea about what precise type to use to create new array , so it uses Object as safest type , because each class extends Object so it can safely store instance of any class . Now the problem is that you can ' t cast instance of Object [ ] to String [ ] . Why ? Take a look at this example ( lets assume that class B extends A ) : # pre Although such code will compile , at runtime we will see thrown ClassCastException because instance held by reference a is not actually of type B ( or its subtypes ) . Why is this problem ( why this exception needs to be cast ) ? One of the reasons is that B could have new methods / fields which A doesn ' t , so it is possible that someone will try to use these new members via b reference even if held instance doesn ' t have ( doesn ' t support ) them . In other words we could end up trying to use data which doesn ' t exist , which could lead to many problems . So to prevent such situation JVM throws exception , and stop further potentially dangerous code . You could ask now " So why aren ' t we stopped even earlier ? Why code involving such casting is even compilable ? Shouldn ' t compiler stop it ? " . Answer is : no because compiler can ' t know for sure what is the actual type of instance held by a reference , and there is a chance that it will hold instance of class B which will support interface of b reference . Take a look at this example : # pre Now lets go back to your arrays . As you see in question , we can ' t cast instance of Object [ ] array to more precise type String [ ] like # pre Here problem is a little different . Now we are sure that String [ ] array will not have additional fields or methods because every array support only : # li [ ] operator , # li length filed , # li methods inherited from Object supertype , So it is not arrays interface which is making it impossible . Problem is that Object [ ] array beside Strings can store any objects ( for instance Integers ) so it is possible that one beautiful day we will end up with trying to invoke method like strArray [ i ] . substring ( args ) on instance of Integer which doesn ' t have such method . So to make sure that this situation will never happen , in Java array references can hold only # li instances of array of same type as reference ( reference String [ ] strArr can hold String [ ] ) # li instances of array of subtype ( Object [ ] can hold String [ ] because String is subtype of Object ) , but can ' t hold # li array of supertype of type of array from reference ( String [ ] can ' t hold Object [ ] ) # li array of type which is not related to type from reference ( Integer [ ] can ' t hold String [ ] ) In other words something like this is OK # pre You could say that one way to resolve this problem is to find at runtime most common type between all list elements and create array of that type , but this wont work in situations where all elements of list will be of one type derived from generic one . Take a look # pre now most common type is B , not A so toArray ( args ) A [ ] arr = elements . toArray ( args ) ; would return array of B class new B [ ] . Problem with this array is that while compiler would allow you to edit its content by adding new A ( args ) element to it , you would get ArrayStoreException because B [ ] array can hold only elements of class B or its subclass , to make sure that all elements will support interface of B , but instance of A may not have all methods / fields of B . So this solution is not perfect . Best solution to this problem is explicitly tell what type of array toArray ( args ) should be returned by passing this type as method argument like String [ ] arr = list . toArray ( args ) ; or String [ ] arr = list . toArray ( args ) ; / / if size of array is smaller then list it will be automatically adjusted .

Question - 11408427 , answer - 11408526 Let ' s look at the following simple expressions in Java # pre The compiler converts StringLiteral + x ; into a StringBuilder internally and uses . append ( args ) to " add " the integer to the string . 5 . 1 . 11 . String Conversion # blockquote 15 . 18 . 1 . # blockquote The optimized version will not actually do a full wrapped String conversion first . This is a good illustration of an optimized version used by the compiler , albeit without the conversion of a primitive , where you can see the compiler changing things into a StringBuilder in the background : # a This java code : # pre Generates this - see how the two concatenation styles lead to the very same bytecode : # pre Looking at the example above and how the byte code based on the source code in the given example is generated , you will be able to notice that the compiler has internally transformed the following statement cip + ciop ; into new StringBuilder ( args ) . append ( args ) . toString ( args ) ; In other words , the operator + in string concatenation is effectively a shorthand for the more verbose StringBuilder idiom .

Question - 24885223 I don ' t know whether I am asking the right question . I was exploring RecyclerView and I was surprised to see that RecyclerView does not have onItemClickListener ( args ) . Because RecyclerView extends # blockquote and ListView extends # blockquote . However I solved my problem by writing onClick in my RecyclerView . Adapter : # pre But still I want to know why Google removed onItemClickListener ( args ) ? Is there a performance issue or something else ?

Question - 7032070 , answer - 7032208 clear ( args ) will go through the underlying Array and set each entry to null ; removeAll ( args ) will go through the ArrayList checking for collection and remove ( args ) it if it exists . I would imagine that clear ( args ) is way faster then removeAll because it ' s not comparing , etc .

Question - 29494800 , answer - 29495113 # blockquote ( Object ) newType = = ( Object ) Object [ ] . class It is checking whether variable newType holds a reference to an instance of java . lang . Class representing type Object [ ] . The casts are unneeded . # blockquote As far as I can tell , Array . newInstance ( args ) could be used in both cases , but non - reflective ordinary array construction is likely a bit faster . Thus , I suppose that Object [ ] is called out as a special case for performance reasons , but I have no idea whether that case is exercised frequently enough for the optimization to be important . # blockquote Integer [ ] nums = Arrays . copyOf ( args ) You should use it when you need to copy an array to an array with a possibly different ( but compatible ) element type , especially when the element types are not statically known . If you know you want the copy to have the same element type as the original , then it ' s easier to use the original array ' s clone ( args ) method .

Question - 22725537 , answer - 36334855 As my previous answer appeared not to be very popular , I will give this another go . A short answer : You are mostly on a right track . The shortest code to get to your desired output I could come up with is this : things . stream ( args ) . map ( args ) . filter ( args ) . findFirst ( args ) . flatMap ( args ) ; This will fit all your requirements : # li It will find first response that resolves to a nonempty Optional < T > # li It calls this : : resolve lazily as needed # li this : : resolve will not be called after first non - empty result # li It will return Optional < T > Longer answer The only modification compared to OP initial version was that I removed . map ( args ) before call to . findFirst ( args ) and added . flatMap ( args ) as the last call in the chain . This has a nice effect of getting rid of the double - Optional , whenever stream finds an actual result . You can ' t really go any shorter than this in Java . The alternative snippet of code using the more conventional for loop technique is going to be about same number of lines of code and have more or less same order and number of operations you need to perform : # li Calling this . resolve , # li filtering based on Optional . isPresent # li returning the result and # li some way of dealing with negative result ( when nothing was found ) Just to prove that my solution works as advertised , I wrote a small test program : # pre ( It does have few extra lines for debugging and verifying that only as many calls to resolve as needed . . . ) Executing this on a command line , I got the following results : # pre

Question - 15202997 , answer - 15203417 If you ' re unsure about something , try writing a test first . I did this : # pre Prints : # pre There ' s an empty line in the last block where getSimpleName returns an empty string . The upshot looking at this is : # li the name is the name that you ' d use to dynamically load the class with , for example , a call to Class . forName with the default ClassLoader . # li the canonical name is the name that would be used in an import statement and uniquely identifies the class . Might be useful during toString or logging operations . # li the simple name loosely identifies the class , again might be useful during toString or logging operations but is not guaranteed to be unique .

Question - 31270759 Exceptions , especially checked ones , can severely interrupt the flow of program logic when the FP idiom is used in Java 8 . Here is an arbitrary example : # pre The above code breaks when there ' s an exception for an unparseable string . But say I just want to replace that with a default value , much like I can with Optional : Stream . of ( args ) . forEach ( args ) ; Of course , this still fails because Optional only handles null s . I would like something as follows : Stream . of ( args ) . forEach ( args ) ; Note : this is a self - answered question .

Question - 15430247 , answer - 15446006 I actually wrote a blog post on the topic 2 months ago . The article is for C # ' s List < T > but Java ' s ArrayList has a very similar implementation . Since ArrayList is implemented using a dynamic array , it increases in size on demand . So the reason for the capacity constructor is for optimisation purposes . When one of these resizings operation occurs , the ArrayList copies the contents of the array into a new array that is twice the capacity of the old one . This operation runs in O ( n ) time . Example Here is an example of how the ArrayList would increase in size : # pre So the list starts with a capacity of 10 , when the 11th item is added it is increase by 50 % + 1 to 16 . On the 17th item the ArrayList is increased again to 25 and so on . Now consider the example where we ' re creating a list where the desired capacity is already known as 1000000 . Creating the ArrayList without the size constructor will call ArrayList . add 1000000 times which takes O ( 1 ) normally or O ( n ) on resize . # blockquote Compare this using the constructor and then calling ArrayList . add which is guaranteed to run in O ( 1 ) . # blockquote Java vs C # Java is as above , starting at 10 and increasing each resize at 50 % + 1 . C # starts at 4 and increases much more aggressively , doubling at each resize . The 1000000 adds example from above for C # uses 3097084 operations . References # li My blog post on C # ' s List < T > # li Java ' s ArrayList source code

Question - 8894258 , answer - 8894356 Looks like niether is faster or slower # pre For long strings I ' ll chose the first one . Why copy around long strings ? Documentations says : # blockquote / / Edit 1 I ' ve changed the test to trick JIT optimisation . / / Edit 2 Repeat test 10 times to let JVM warm up . / / Edit 3 Conclusions : First of all str . toCharArray ( args ) ; copies entire string in memory . It can be memory consuming for long strings . Method String . charAt ( args ) looks up char in char array inside String class checking index before . It looks like for short enough Strings first method ( i . e . chatAt method ) is a bit slower due to this index check . But if the String is long enough , copying whole char array gets slower , and the first method is faster . The longer the string is , the slower toCharArray performs . Try to change limit in for ( args ) loop to see it . If we let JVM warm up code runs faster , but proportions are the same . After all it ' s just micro - optimisation .

Question - 5192512 , answer - 5192545 Edit Updated to bring in feedback . So two ways that work : # li Use StringBulderObj . setLength ( args ) . # li Allocate a new one instead of clearing the buffer

Question - 30081520 , answer - 30081600 From Objects . equals ( ) : return ( args ) | | ( a ! = null & & a . equals ( args ) ) ; Very simple , self - explaining and elegant .

Question - 31170459 I was testing boundary conditions on some code involving a BigDecimal , and I noticed that when a BigDecimal is initialized with the String StringLiteral it behaves unexpectedly . It seems to have a value between 0 and 1e - 2147483647 . When I try calling intValue ( args ) , I get a NegativeArraySizeException . I should note that 2147483647 is the max value of an integer on my system . Am I doing something wrong , or is this a problem with BigDecimal ? # pre

Question - 32164385 , answer - 32164423 # blockquote The only way is to read the code unfortunately . # blockquote The common convention is to pass an object which cannot be modified , using a wrapper if needed . This ensure the class cannot modify the object . List < T > readOnly = Collections . unmodifiableList ( args ) ; If the object is Cloneable , you can also use clone ( args ) but another common approach is to use a copy . List < T > readOnly = new ArrayList < T > ( args ) ; If you care about such behaviour , unit tests can show whether a method modifies an object or not . If you have unit tests already , it is usually one or two lines extra to check for this .

Question - 25606833 , answer - 25757572 There are several issues here . # li Any solution based on reading lines is going to process each character twice . Compilers for example don ' t do this , they read one character at a time and despatch on it directly . # li Any solution based on readLine ( args ) is going to create Strings . # li You are using different buffer sizes . # li You are using different I / O technologies . # li In some cases you are using character conversion , while in others you aren ' t . # li You ' re over - analyzing the file . You don ' t really care where the white space is , or how much of it there is , as long as it separates the numbers from each other . My solution : # pre

Question - 29815636 , answer - 29815698 The first form is called Javadoc . You use this when you ' re writing formal APIs for your code , which are generated by the javadoc tool . For an example , the Java 7 API page uses Javadoc and was generated by that tool . Some common elements you ' d see in Javadoc include : # li @ param : this is used to indicate what parameters are being passed to a method , and what value they ' re expected to have # li @ return : this is used to indicate what result the method is going to give back # li @ throws : this is used to indicate that a method throws an exception or error in case of certain input # li @ since : this is used to indicate the earliest Java version this class or function was available in As an example , here ' s Javadoc for the compare method of Integer : # pre The second form is a block ( multi - line ) comment . You use this if you want to have multiple lines in a comment . I will say that you ' d only want to use the latter form sparingly ; that is , you don ' t want to overburden your code with block comments that don ' t describe what behaviors the method / complex function is supposed to have . Since Javadoc is the more descriptive of the two , and you can generate actual documentation as a result of using it , using Javadoc would be more preferable to simple block comments .

Question - 5243754 , answer - 13612866 It is crucial to know that attributes are not parameters . The return type for attributes is an Object , whereas the return type for a parameter is a String . When calling the getAttribute ( args ) method , bear in mind that the attributes must be cast . Additionally , there is no servlet specific attributes , and there are no session parameters . This post is written with the purpose to connect on @ Bozho ' s response , as additional information that can be useful for other people .

Question - 13102045 , answer - 22593693 There seem to be many questions about this issue with java . util . Scanner . I think a more readable / idiomatic solution would be to call scanner . skip ( args ) to drop any newline characters after calling nextInt ( args ) .

Question - 4812570 , answer - 4812585 You have to use getStackTrace ( args ) method instead of printStackTrace ( args ) . Here is a good example : # pre

Question - 10904911 , answer - 10904956 What you want is the Arrays . toString ( args ) method : # pre There is a static Arrays . toString helper method for every different primitive java type ; the one for int [ ] says this : # blockquote

Question - 23453287 One of the most useful features of Java 8 are the new default methods on interfaces . There are essentially two reasons ( there may be others ) why they have been introduced : # li Providing actual default implementations . Example : Iterator . remove ( ) # li Allowing for JDK API evolution . Example : Iterable . forEach ( ) From an API designer ' s perspective , I would have liked to be able to use other modifiers on interface methods , e . g . final . This would be useful when adding convenience methods , preventing " accidental " overrides in implementing classes : # pre The above is already common practice if Sender were a class : # pre Now , default and final are obviously contradicting keywords , but the default keyword itself would not have been strictly required , so I ' m assuming that this contradiction is deliberate , to reflect the subtle differences between " class methods with body " ( just methods ) and " interface methods with body " ( default methods ) , i . e . differences which I have not yet understood . At some point of time , support for modifiers like static and final on interface methods was not yet fully explored , citing Brian Goetz : # blockquote Since that time in late 2011 , obviously , support for static methods in interfaces was added . Clearly , this added a lot of value to the JDK libraries themselves , such as with Comparator . comparing ( ) . Question : What is the reason final ( and also static final ) never made it to Java 8 interfaces ?

Question - 15655012 , answer - 15655071 If you make foo static , you must initialize it in the class constructor ( or inline where you define it ) like the following examples . Class constructor ( not instance ) : # pre Inline : private static final List foo = new ArrayList ( args ) ; The problem here is not how the final modifier works , but rather how the static modifier works . The final modifier enforces an initialization of your reference by the time the call to your constructor completes ( i . e . you must initialize it in the constructor ) . When you initialize an attribute in - line , it gets initialized before the code you have defined for the constructor is run , so you get the following outcomes : # li if foo is static , foo = new ArrayList ( args ) will be executed before the static { } constructor you have defined for your class is executed # li if foo is not static , foo = new ArrayList ( args ) will be executed before your constructor is run When you do not initilize an attribute in - line , the final modifier enforces that you initialize it and that you must do so in the constructor . If you also have a static modifier , the constructor you will have to initialize the attribute in is the class ' initialization block : static { } . The error you get in your code is from the fact that static { } is run when the class is loaded , before the time you instantiate an object of that class . Thus , you will have not initialized foo when the class is created . Think of the static { } block as a constructor for an object of type Class . This is where you must do the initialization of your static final class attributes ( if not done inline ) . Side note : The final modifier assures const - ness only for primitive types and references . When you declare a final object , what you get is a final reference to that object , but the object itself is not constant . What you are really achieving when declaring a final attribute is that , once you declare an object for your specific purpose ( like the final List that you have declared ) , that and only that object will be used for that purpose : you will not be able to change List foo to another List , but you can still alter your List by adding / removing items ( the List you are using will be the same , only with its contents altered ) .

Question - 6992608 , answer - 26764904 As pointed by this the best way to obtain a concurrency - able HashSet is by means of Collections . synchronizedSet ( args ) Set s = Collections . synchronizedSet ( args ) ; This worked for me and I haven ' t seen anybody really pointing to it . EDIT This is less efficient than the currently aproved solution , as Eugene points out , since it just wraps your set into a synchronized decorator , while a ConcurrentHashMap actually implements low - level concurrency and it can back your Set just as fine . So thanks to Mr . Stepanenkov for making that clear . # a

Question - 8275499 , answer - 17397548 As for the code example in the question , the standard solution is to reference the class explicitly by its name , and it is even possible to do without getClassLoader ( args ) call : # pre This approach still has a back side that it is not very safe against copy / paste errors in case you need to replicate this code to a number of similar classes . And as for the exact question in the headline , there is a trick posted in the adjacent thread : Class currentClass = new Object ( args ) { } . getClass ( args ) . getEnclosingClass ( args ) ; It uses a nested anonymous Object subclass to get hold of the execution context . This trick has a benefit of being copy / paste safe . . . It may be also worth noting that if this snippet is shaped as a static method of some base class , then currenClass value will always be a reference to that base class rather than to any subclass that may be using that method .

Question - 9749746 , answer - 9749864 You are specifically asking about how they internally work , so here you are : No synchronization # pre It basically reads value from memory , increments it and puts back to memory . This works in single thread but nowadays , in the era of multi - core , multi - CPU , multi - level caches it won ' t work correctly . First of all it introduces race condition ( several threads can read the value at the same time ) , but also visibility problems . The value might only be stored in " local " CPU memory ( some cache ) and not be visible for other CPUs / cores ( and thus - threads ) . This is why many refer to local copy of a variable in a thread . It is very unsafe . Consider this popular but broken thread - stopping code : # pre Add volatile to stopped variable and it works fine - if any other thread modifies stopped variable via pleaseStop ( args ) method , you are guaranteed to see that change immediately in working thread ' s while ( args ) loop . BTW this is not a good way to interrupt a thread either , see : How to stop a thread that is running forever without any use and Stopping a specific java thread . AtomicInteger # pre The AtomicInteger class uses CAS ( compare - and - swap ) low - level CPU operations ( no synchronization needed ! ) They allow you to modify a particular variable only if the present value is equal to something else ( and is returned successfully ) . So when you execute getAndIncrement ( args ) it actually runs in a loop ( simplified real implementation ) : # pre So basically : read ; try to store incremented value ; if not successful ( the value is no longer equal to current ) , read and try again . The compareAndSet ( args ) is implemented in native code ( assembly ) . volatile without synchronization # pre This code is not correct . It fixes the visibility issue ( volatile makes sure other threads can see change made to counter ) but still has a race condition . This has been explained multiple times : pre / post - incrementation is not atomic . The only side effect of volatile is " flushing " caches so that all other parties see the freshest version of the data . This is too strict in most situations ; that is why volatile is not default . volatile without synchronization ( 2 ) # pre The same problem as above , but even worse because i is not private . The race condition is still present . Why is it a problem ? If , say , two threads run this code simultaneously , the output might be + 5 or + 10 . However , you are guaranteed to see the change . Multiple independent synchronized # pre Surprise , this code is incorrect as well . In fact , it is completely wrong . First of all you are synchronizing on i , which is about to be changed ( moreover , i is a primitive , so I guess you are synchronizing on a temporary Integer created via autoboxing . . . ) Completely flawed . You could also write : # pre No two threads can enter the same synchronized block with the same lock . In this case ( and similarly in your code ) the lock object changes upon every execution , so synchronized effectively has no effect . Even if you have used a final variable ( or this ) for synchronization , the code is still incorrect . Two threads can first read i to temp synchronously ( having the same value locally in temp ) , then the first assigns a new value to i ( say , from 1 to 6 ) and the other one does the same thing ( from 1 to 6 ) . The synchronization must span from reading to assigning a value . Your first synchronization has no effect ( reading an int is atomic ) and the second as well . In my opinion , these are the correct forms : # pre

Question - 12317668 According to the JLS , an int array should be filled by zeros just after initialization . However , I am faced with a situation where it is not . Such a behavior occurs first in JDK 7u4 and also occurs in all later updates ( I use 64 - bit implementation ) . The following code throws exception : # pre The exception occurs after the JVM performs compilation of the code block and does not arise with - Xint flag . Additionally , the Arrays . fill ( args ) statement ( as all other statements in this code ) is necessary , and the exception does not occurs if it is absent . It is clear that this possible bug is bounded with some JVM optimization . Any ideas for the reason of such a behavior ? Update : I see this behavior on HotSpot 64 - bit server VM , Java version from 1 . 7 . 0 _ 04 to 1 . 7 . 0 _ 10 on Gentoo Linux , Debian Linux ( both kernel 3 . 0 version ) and MacOS Lion . This error can always be reproduced with the code above . I did not test this problem with a 32 - bit JDK or on Windows . I already sent a bug report to the Oracle ( bug id 7196857 ) and it will appear in public Oracle bug database in few days . Update : Oracle published this bug at their public bug database : # a

Question - 30125296 , answer - 30125487 I suggest 2 more options : # pre The second one uses Collectors . summingInt ( ) collector . Besides , Java 8 introduces a very effective LongAdder accumulator designed to speed - up summarizing in parallel streams and multi - thread environments . Here , it may be used as follows : # pre

Question - 31922866 , answer - 31923227 Optionals aren ' t designed for this purpose , as explained nicely by Brian Goetz . You can always use @ Nullable to denote that a method argument can be null . Using an optional does not really enable you to write your method logic more neatly .

Question - 31419029 , answer - 31419047 An empty HashMap object is much smaller than an array of 2000 Object references . Even though you pass 2000 to the initialCapacity parameter of the HashMap constructor , it ' s not actually creating 2000 spaces for objects yet .

Question - 14491966 , answer - 14526729 The real problem with this is that it ' s output histogram is dependent on the initial seed far to much - much of the time it will end up with a near uniform output but a lot of the time will have distinctly un - uniform output . Inspired by this article about how bad php ' s rand ( ) function is , I made some random matrix images using QuickRandom and System . Random . This run shows how sometimes the seed can have a bad effect ( in this case favouring lower numbers ) where as System . Random is pretty uniform . QuickRandom # img System . Random # img Even Worse If we initialise QuickRandom as new QuickRandom ( args ) we get this image : # img The Code # pre

Question - 5031614 , answer - 5032837 If you want to use equals ( args ) / hashCode ( args ) for your Sets , in the sense that the same entity can only be in there once , then there is only one option : Option 2 . That ' s because a primary key for an entity by definition never changes ( if somebody indeed updates it , it ' s not the same entity anymore ) You should take that literally : Since your equals ( args ) / hashCode ( args ) are based on the primary key , you must not use these methods , until the primary key is set . So you shouldn ' t put entities in the set , until they ' re assigned a primary key . ( Yes , UUIDs and similar concepts may help to assign primary keys early . ) Now , it ' s theoretically also possible to achieve that with Option 3 , even though so - called " business - keys " have the nasty drawback that they can change : " All you ' ll have to do is delete the already inserted entities from the set ( s ) , and re - insert them . " That is true - but it also means , that in a distributed system , you ' ll have to make sure , that this is done absolutely everywhere the data has been inserted to ( and you ' ll have to make sure , that the update is performed , before other things occur ) . You ' ll need a sophisticated update mechanism , especially if some remote systems aren ' t currently reachable . . . Option 1 can only be used , if all the objects in your sets are from the same Hibernate session . The Hibernate documentation makes this very clear in chapter 13 . 1 . 3 . Considering object identity : # blockquote It continues to argue in favor of Option 3 : # blockquote This is true , if you # li cannot assign the id early ( e . g . by using UUIDs ) # li and yet you absolutely want to put your objects in sets while they ' re in transient state . Otherwise , you ' re free to choose Option 2 . Then it mentions the need for a relative stability : # blockquote This is correct . The practical problem I see with this is : If you can ' t guarantee absolute stability , how will you be able to guarantee stability " as long as the objects are in the same Set " . I can imagine some special cases ( like using sets only for a conversation and then throwing it away ) , but I would question the general practicability of this . Short version : # li Option 1 can only be used with objects within a single session . # li If you can , use Option 2 . ( Assign PK as early as possible , because you can ' t use the objects in sets until the PK is assigned . ) # li If you can guarantee relative stability , you can use Option 3 . But be careful with this .

Question - 5175728 , answer - 5175771 Have a look at the Date class . There ' s also the newer Calendar class which is the preferred method of doing many date / time operations ( a lot of the methods on Date have been deprecated . ) If you just want the current date , then either create a new Date object or call Calendar . getInstance ( args ) ; .

Question - 31696485 , answer - 31696584 Your question is based on assumption that the code which may throw NullPointerException is worse than the code which may not . This assumption is wrong . If you expect that your foobar is never null due to the program logic , it ' s much better to use Optional . of ( args ) as you will see a NullPointerException which will indicate that your program has a bug . If you use Optional . ofNullable ( args ) and the foobar happens to be null due to the bug , then your program will silently continue working incorrectly , which may be a bigger disaster . This way an error may occur much later and it would be much harder to understand at which point it went wrong .

Question - 24649842 What ' s the main difference between scheduleAtFixedRate and scheduleWithFixedDelay methods of ScheduledExecutorService ? # pre they print exact the same time , seems they are executed at exact the same interval .

Question - 22561614 , answer - 22561853 Let me explain what is happening here , because it isn ' t obvious ! First , Stream . max ( ) accepts an instance of Comparator so that items in the stream can be compared against each other to find the minimum or maximum , in some optimal order that you don ' t need to worry too much about . So the question is , of course , why is Integer : : max accepted ? After all it ' s not a comparator ! The answer is in the way that the new lambda functionality works in Java 8 . It relies on a concept which is informally known as " single abstract method " interfaces , or " SAM " interfaces . The idea is that any interface with one abstract method can be automatically implemented by any lambda - or method reference - whose method signature is a match for the one method on the interface . So examining the Comparator interface ( simple version ) : # pre If a method is looking for a Comparator < T > , then it ' s essentially looking for this signature : int xxx ( args ) ; I use " xxx " because the method name is not used for matching purposes . Therefore , both Integer . min ( args ) and Integer . max ( args ) are close enough that autoboxing will allow this to appear as a Comparator < T > in a method context .

Question - 15430247 , answer - 25757711 ArrayList shrinks or expands dynamically . This is a effective but costly operation , if you know size of your array will be fixed then its better to mention the size of the array , If you don ' t , new array will be created at each insertion and reallocation will be done for each element . this will cost you . ensureCapacity ( args ) this method help to avoid reallocations and helps increase size of arraylist . trimToSize ( args ) this is reverse used to shrink size Arraylist has 3 constructors : # li ArrayList ( ) - builds empty ArrayList # li ArrayList ( Collection c ) - builds a ArrayList initialized with elements of collection c . # li ArrayList ( int capacity ) - builds an ArrayList with specified initial capacity .

Question - 28770822 I understand the use of the @ Native annotation . # blockquote However , while reading the java source code I noticed that in the class Integer and Long the SIZE constant is @ Native while it is not for the Float , Byte , Double , Short and Character . Note that the SIZE constant represents the number of bits used to represent the actual value . # pre Edit : I just noticed that this also applies for MAX _ VALUE and MIN _ VALUE of the same classes . Edit 2 : I had spare time to do some research on this , and looking at the header files of the Long , Float etc . classes I had hope to figure out that the constants were not present in the other headers , but unfortunately they are . # pre Why is the SIZE constant only @ Native for Integer and Long ?

Question - 21105403 I ' ve written a factory to produce java . sql . Connection objects : # pre I ' d like to validate the parameters passed to DriverManager . getConnection , but I don ' t know how to mock a static method . I ' m using JUnit 4 and Mockito for my test cases . Is there a good way to mock / verify this specific use - case ?

Question - 27430092 , answer - 27449187 The standard use case for BigInteger . isProbablePrime ( int ) is in cryptography . Specifically , certain cryptographic algorithms , such as RSA , require randomly chosen large primes . Importantly , however , these algorithms don ' t really require these numbers to be guaranteed to be prime โ they just need to be prime with a very high probability . How high is very high ? Well , in a crypto application , one would typically call . isProbablePrime ( args ) with an argument somewhere between 128 and 256 . Thus , the probability of a non - prime number passing such a test is less than one in 2 128 or 2 256 . Let ' s put that in perspective : if you had 10 billion computers , each generating 10 billion probable prime numbers per second ( which would mean less than one clock cycle per number on any modern CPU ) , and the primality of those numbers was tested with . isProbablePrime ( args ) , you would , on average , expect one non - prime number to slip in once in every 100 billion years . That is , that would be the case , if those 10 billion computers could somehow all run for hundreds of billions of years without experiencing any hardware failures . In practice , though , it ' s a lot more likely for a random cosmic ray to strike your computer at just the right time and place to flip the return value of . isProbablePrime ( args ) from false to true , without causing any other detectable effects , than it is for a non - prime number to actually pass the probabilistic primality test at that certainty level . Of course , the same risk of random cosmic rays and other hardware faults also applies to deterministic primality tests like AKS . Thus , in practice , even these tests have a ( very small ) baseline false positive rate due to random hardware failures ( not to mention all other possible sources of errors , such as implementation bugs ) . Since it ' s easy to push the intrinsic false positive rate of the Miller โ Rabin primality test used by . isProbablePrime ( args ) far below this baseline rate , simply by repeating the test sufficiently many times , and since , even repeated so many times , the Miller โ Rabin test is still much faster in practice than the best known deterministic primality tests like AKS , it remains the standard primality test for cryptographic applications . ( Besides , even if you happened to accidentally select a strong pseudoprime as one of the factors of your RSA modulus , it would not generally lead to a catastrophic failure . Typically , such pseudoprimes would be products of two ( or rarely more ) primes of approximately half the length , which means that you ' d end up with a multi - prime RSA key . As long as none of the factors were too small ( and if they were , the primality test should ' ve caught them ) , the RSA algorithm will still work just fine , and the key , although somewhat weaker against certain types of attacks than normal RSA keys of the same length , should still be reasonably secure if you didn ' t needlessly skimp on the key length . )

Question - 29328785 # pre Compile > javac BigDecimalTest . java Execute > java BigDecimalTest Output # pre The value of z . toString ( args ) in the output is correct 4 . 883242e + 888 / 7 . 115109e + 302 = 6 . 863200e + 585 as is the value of y . toString ( args ) , but notice that the value given for x . toString ( args ) is completely wrong . Why is this ? Strangely , if the scale ( i . e . desired decimal places ) of the result of the division is changed BigDecimal z = x . divide ( args ) ; then x . toString ( args ) will produce the correct value for x . Or , if the operands are swapped BigDecimal z = y . divide ( args ) ; then x . toString ( args ) will also then produce the correct value . Or , if the exponent of x is changed from e + 888 to e . g . e + 878 then x . toString ( args ) will be correct . Or , if another x . toString ( args ) call is added above the divide operation , then both x . toString ( args ) calls will produce the correct value ! On the machine I ' m testing this , Windows 7 64 bit , the behaviour is the same using java 7 and 8 , both 32bit and 64 bit versions , but testing online at # a produces different results for java 7 and java 8 . Using java 7 , the value of x is given correctly : # a , but using java 8 its value is incorrect : # a . Also , this behaviour is not unique to this particular value of x , as calling toString on other BigDecimals with more than about 1500 digits after passing them as the first operand to a divide operation will also produce incorrect values . What is the explanation for this ? The divide operation seems to be mutating the value produced by subsequent toString calls on its operands . Does this happen on your platform ? Edit : The issue seems to be with the java 8 runtime only , as the above program compiled with java 7 produces correct output when executed with the java 7 runtime , but incorrect output when executed with the java 8 runtime . Edit : I ' ve tested with the early access jre1 . 8 . 0 _ 60 and the bug does not appear , and according to Marco13 ' s answer it was fixed in build 51 . The Oracle JDK 8 product binaries are only at update 40 though so it may be some time before the fixed versions are widely used .

Question - 30727515 , answer - 30739477 Since this hasn โ t addressed yet , here an explanation , why the translation of Unicode escapes happens before any other source code processing : The idea behind it was that it allows lossless translations of Java source code between different character encodings . Today , there is widespread Unicode support , and this doesn โ t look like a problem , but back then it wasn โ t easy for a developer from a western country to receive some source code from his Asian colleague containing Asian characters , make some changes ( including compiling and testing it ) and sending the result back , all without damaging something . So , Java source code can be written in any encoding and allows a wide range of characters within identifiers , character and String literals and comments . Then , in order to transfer it losslessly , all characters not supported by the target encoding are replaced by their Unicode escapes . This is a reversible process and the interesting point is that the translation can be done by a tool which doesn โ t need to know anything about the Java source code syntax as the translation rule is not dependent on it . This works as the translation to their actual Unicode characters inside the compiler happens independently to the Java source code syntax as well . It implies that you can perform an arbitrary number of translation steps in both directions without ever changing the meaning of the source code . This is the reason for another weird feature which hasn โ t even mentioned : the \ uuuuuuxxxx syntax : When a translation tool is escaping characters and encounters a sequence that is already an escaped sequence , it should insert an additional u into the sequence , converting \ ucafe to \ uucafe . The meaning doesn โ t change , but when converting into the other direction , the tool should just remove one u and replace only sequences containing a single u by their Unicode characters . That way , even Unicode escapes are retained in their original form when converting back and forth . I guess , no - one ever used that feature โฆ

Question - 20945049 We all know that String is immutable in Java , but check the following code : # pre Why does this program operate like this ? And why is the value of s1 and s2 changed , but not s3 ?

Question - 31922866 , answer - 39005452 The best post I ' ve seen on the topic was written by Daniel Olszewski and can be found at # a . While others mention when you should or should not use Optional , this post actually explains why . Cross - posting here in case the link goes down : # blockquote

Question - 8579657 , answer - 26159918 invoke run ( args ) is executing on the calling thread , like any other method call . whereas Thread . start ( args ) creates a new thread . invoking run ( args ) is a programmatic bug .

Question - 10066590 With Mockito , I want to verify ( args ) a method call with byte [ ] in its argument list , but I didn ' t find how to write this . myMethod ( args ) I just want something like anyByteArray ( args ) , how to do that with Mockito ?

Question - 5031614 , answer - 26826084 # li If you have a business key , then you should use that for equals / hashCode . # li If you don ' t have a business key , you should not leave it with the default Object equals and hashCode implementations because that does not work after you merge and entity . # li You can use the entity identifier as suggested in this post . The only catch is that you need to use a hashCode implementation that always return the same value , like this : # pre

Question - 6667243 , answer - 6667310 You can use Mode . mode1 . name ( args ) however you often don ' t need to do this . Mode mode = System . out . println ( args ) ;

Question - 30888581 , answer - 30897102 Once given more thought In hindsight it sounds like they were looking for the execute around pattern . They ' re usually used to do things like enforce closing of streams . This is also more relevant due to this line : # blockquote The idea is you give the thing that does the " executing around " some class to do somethings with . You ' ll probably use Runnable but it ' s not necessary . ( Runnable makes the most sense and you ' ll see why soon . ) In your StopWatch class add some method like this # pre You would then call it like this # pre This makes it fool proof . You don ' t have to worry about handling stop before start or people forgetting to call one and not the other , etc . The reason Runnable is nice is because # li Standard java class , not your own or third party # li End users can put whatever they need in the Runnable to be done . ( If you were using it to enforce stream closing then you could put the actions that need to be done with a database connection inside so the end user doesn ' t need to worry about how to open and close it and you simultaneously force them to close it properly . ) If you wanted , you could make some StopWatchWrapper instead leave StopWatch unmodified . You could also make measureAction ( args ) not return a time and make getTime ( args ) public instead . The Java 8 way to calling it is even simpler # pre # blockquote Original answer # blockquote To me something like this seems to be good . # pre The reason I believe this to be good is the recording is during object creation so it can ' t be forgotten or done out of order ( can ' t call stop ( args ) method if it doesn ' t exist ) . One flaw is probably the naming of stop ( args ) . At first I thought maybe lap ( args ) but that usually implies a restarting or some sort ( or at least recording since last lap / start ) . Perhaps read ( args ) would be better ? This mimics the action of looking at the time on a stop watch . I chose stop ( args ) to keep it similar to the original class . The only thing I ' m not 100 % sure about is how to get the time . To be honest that seems to be a more minor detail . As long as both . . . in the above code obtain current time the same way it should be fine .

Question - 9297899 , answer - 25816501 Even though this is not a direct answer to the question , it is an addition to the . length vs . size ( args ) argument . I was researching something related to this question so when I came across it I noticed that the definition ( s ) provided here # blockquote is not " exactly " correct . The field length contains the number of available places to put a component , not the number of components present in the array . So it represents the total available memory allocated to that array , not how much of that memory is filled . # img Example : # pre Output : # pre However , the . size ( args ) property of the ArrayList does give the number of elements in the list : # pre Output : # pre

Question - 9481865 , answer - 33093380 You may try isReachable ( args ) method of InetAddress class to figure out which IP address is your real publicly available IP address . I think other type of addresses ( site local , link local ) are not reachable from outside . # pre

Question - 8172420 , answer - 15633542 Nice question . I ' ve got of the following five 6 methods to do it . # pre # blockquote String . valueOf ( args ) invokes new String ( args ) , which in turn sets the value char array . # pre On the other hand String . valueOf ( args ) invokes the following package private constructor . # pre Source code from String . java in Java 8 source code # blockquote # li Java : : How to convert primitive char to String in Java # li How to convert Char to String in Java with Example

Question - 8894258 In Java , what would the fastest way to iterate over all the chars in a String , this : # pre Or this : # pre EDIT : What I ' d like to know is if the cost of repeatedly calling the charAt method during a long iteration ends up being either less than or greater than the cost of performing a single call to toCharArray at the beginning and then directly accessing the array during the iteration . It ' d be great if someone could provide a robust benchmark for different string lengths , having in mind JIT warm - up time , JVM start - up time , etc . and not just the difference between two calls to System . currentTimeMillis ( args ) .

Question - 20129762 , answer - 20130131 There are already people asked the same on the mailing list โบ . The main reason is Iterable also has a re - iterable semantic , while Stream is not . # blockquote

Question - 12552863 , answer - 12665271 Here ' s my take on the alternatives : 1 ) # pre For me , the best thing coming to Java from traditional C + + 15 years ago was that you could trust your program . Even if things are in the muck and going wrong , which they often do , I want the rest of the code to be on best behaviour and smelling of roses . Indeed , the BufferedWriter might throw an exception here . Running out of memory wouldn ' t be unusual , for instance . For other decorators , do you know which of the java . io wrapper classes throw a checked exception from their constructors ? I don ' t . Doesn ' t do code understandability much good if you rely upon that sort of obscure knowledge . Also there ' s the " destruction " . If there is an error condition , then you probably don ' t want to be flushing rubbish to a file that needs deleting ( code for that not shown ) . Although , of course , deleting the file is also another interesting operation to do as error handling . Generally you want finally blocks to be as short and reliable as possible . Adding flushes does not help this goal . For many releases some of the buffering classes in the JDK had a bug where an exception from flush within close caused close on the decorated object not be called . Whilst that has been fixed for some time , expect it from other implementations . 2 ) # pre We ' re still flushing in the implicit finally block ( now with repeated close - this gets worse as you add more decorators ) , but the construction is safe and we have to implicit finally blocks so even a failed flush doesn ' t prevent resource release . 3 ) # pre There ' s a bug here . Should be : # pre Some poorly implemented decorators are in fact resource and will need to be closed reliably . Also some streams may need to be closed in a particular way ( perhaps they are doing compression and need to write bits to finish off , and can ' t just flush everything . Verdict Although 3 is a technically superior solution , software development reasons make 2 the better choice . However , try - with - resource is still an inadequate fix and you should stick with the Execute Around idiom , which should have a clearer syntax with closures in Java SE 8 .

Question - 17828584 , answer - 17836189 I think the others have done a good job at explaining why cnt > 0 , but there ' s not enough details regarding why cnt = 4 , and why cnt varies so widely among different settings . I will attempt to fill that void here . Let # li X be the total stack size # li M be the stack space used when we enter main the first time # li R be the stack space increase each time we enter into main # li P be the stack space necessary to run System . out . println When we first get into main , the space left over is X - M . Each recursive call takes up R more memory . So for 1 recursive call ( 1 more than original ) , the memory use is M + R . Suppose that StackOverflowError is thrown after C successful recursive calls , that is , M + C * R < = X and M + C * ( R + 1 ) > X . At the time of the first StackOverflowError , there ' s X - M - C * R memory left . To be able to run System . out . prinln , we need P amount of space left on the stack . If it so happens that X - M - C * R > = P , then 0 will be printed . If P requires more space , then we remove frames from the stack , gaining R memory at the cost of cnt + + . When println is finally able to run , X - M - ( C - cnt ) * R > = P . So if P is large for a particular system , then cnt will be large . Let ' s look at this with some examples . Example 1 : Suppose # li X = 100 # li M = 1 # li R = 2 # li P = 1 Then C = floor ( ( X - M ) / R ) = 49 , and cnt = ceiling ( ( P - ( X - M - C * R ) ) / R ) = 0 . Example 2 : Suppose that # li X = 100 # li M = 1 # li R = 5 # li P = 12 Then C = 19 , and cnt = 2 . Example 3 : Suppose that # li X = 101 # li M = 1 # li R = 5 # li P = 12 Then C = 20 , and cnt = 3 . Example 4 : Suppose that # li X = 101 # li M = 2 # li R = 5 # li P = 12 Then C = 19 , and cnt = 2 . Thus , we see that both the system ( M , R , and P ) and the stack size ( X ) affects cnt . As a side note , it does not matter how much space catch requires to start . As long as there is not enough space for catch , then cnt will not increase , so there are no external effects . EDIT I take back what I said about catch . It does play a role . Suppose it requires T amount of space to start . cnt starts to increment when the leftover space is greater than T , and println runs when the leftover space is greater than T + P . This adds an extra step to the calculations and further muddies up the already muddy analysis . EDIT I finally found time to run some experiments to back up my theory . Unfortunately , the theory doesn ' t seem to match up with the experiments . What actually happens is very different . Experiment setup : Ubuntu 12 . 04 server with default java and default - jdk . Xss starting at 70 , 000 at 1 byte increments to 460 , 000 . The results are available at : # a I ' ve created another version where every repeated data point is removed . In other words , only points that are different from the previous are shown . This makes it easier to see anomalies . # a

Question - 31471444 , answer - 31476657 From Class NumberUtils you ' ll see it ' s defined as : # pre So , you ' ll see that INTEGER _ ONE is not the same as 1 . It ' s an object that ' s already been constructed for you . So , if we ' re needing an instance of Integer ( args ) , rather than create your own , you can reuse the one from the library saving time and memory . It really depends on your application , if you indeed what the int version of 1 , then , you ' d probably be better of using that instead of this Integer class .

Question - 18263489 , answer - 29873100 It isn ' t pretty , but String . valueOf ( args ) allows you to use a null String in a switch . If it finds null , it converts it to StringLiteral , otherwise it just returns the same String you passed it . If you don ' t handle StringLiteral explicitly , then it will go to default . The only caveat is that there is no way of distinguishing between the String StringLiteral and an actual null String . # pre

Question - 32312876 , answer - 32313069 This is possible using the mergeFunction parameter of Collectors . toMap ( keyMapper , valueMapper , mergeFunction ) : # pre mergeFunction is a function that operates on two values associated with the same key . adress1 corresponds to the first address that was encountered when collecting elements and adress2 corresponds to the second address encountered : this lambda just tells to keep the first address and ignores the second .

Question - 5374311 , answer - 5374346 What is happening is that stock _ list . toArray ( args ) is creating an Object [ ] rather than a String [ ] and hence the typecast is failing . The correct code would be : String [ ] stockArr = stockList . toArray ( args ) ; or even String [ ] stockArr = stockList . toArray ( args ) ; For more details , refer to the javadocs for the two overloads of List . toArray . ( From a technical perspective , the reason for this API behaviour / design is that an implementation of the List < T > . toArray ( args ) method has no information of what the < T > is at runtime . All it knows is that the raw element type is Object . By contrast , in the other case , the array parameter gives the base type of the array . ( If the supplied array is big enough , it is used . Otherwise a new array of the same type and a larger size will be allocated and returned as the result . )

Question - 29183904 I used to define a set of related constants like Bundle keys together in an interface like below : # pre This provides me a nicer way to group related constants together and used them by making a static import ( not implements ) . I know Android framework also uses the constants in same way like Toast . LENTH _ LONG , View . GONE . However , I often feel that the Java Enums provide much better and powerful way to represent the constant . But is there a performence issue in using enums on Android ? With a bit of research I ended up in confusion . From this question " Avoid Enums Where You Only Need Ints โ removed from Android ' s performance tips ? it ' s clear that Google has removed " Avoid enums " from its performance tips , but from it ' s official training docs Be aware of memory overhead section it clearly says : " Enums often require more than twice as much memory as static constants . You should strictly avoid using enums on Android . " Is this still holds good ? ( say in Java versions after 1 . 6 ) One more issue that I observed is to send enums across intents using Bundle I should send them by serializing ( i . e putSerializable ( args ) , that I think an expensive operation compared to primitive putString ( args ) method , eventhough enums provides it for free ) . Can someone please clarify which one is the best way to represent the same in Android ? Should I strictly avoid using enums on Android ?

Question - 31471444 , answer - 31471520 org . apache . commons . lang . math . NumberUtils . INTEGER _ ONE it gives you a final static Integer object rather than primitive int 1 , and as it is final static it acts as a constant and can be used in comparison of Integer objects because will always return same instance . So in the above scenario it might not look fit but somewhere if you are using it while comparison , it for sure has impact . Moreover , as much as we can , should prefer the use of constants over hardcoded beacuse : # li It can make your code easily maintainable . If any situation occurs in future for change , you can change only at a single place . # li The code looks cleaner & more readable .

Question - 20358883 , answer - 29784337 The other answers all use Arrays . asList ( args ) , which returns an unmodifiable list ( an UnsupportedOperationException is thrown if you try to add or remove an element ) . To get a mutable list you can wrap the returned list in a new ArrayList as a couple of answers point out , but a cleaner solution is to use Guava ' s Lists . newArrayList ( ) ( available since at least Guava 10 , released in 2011 ) . For example : Lists . newArrayList ( args ) ;

Question - 8275499 , answer - 8275508 Just use TheClassName . class instead of getClass ( args ) .

Question - 31202946 , answer - 31203218 You can of course choose to shoot yourself in the foot , but that doesn ' t mean you must . # blockquote Because the recommended way to create a start a thread is not to subclass Thread . The recommended way is to define a Runnable , and pass it as argument to the Thread constructor : # pre # blockquote Yes and no . You can ' t replace the implementation of start ( ) by your own implementation , but you can do additional things in start ( ) if you want : # pre That said , if Java was redesigned from scratch today , there is a good chance the design would be different . Remember that this class dates from Java 1 . 0 , and is still backward - compatible .

Question - 15430247 , answer - 15430259 If you know in advance what the size of the ArrayList is going to be , it is more efficient to specify the initial capacity . If you don ' t do this , the internal array will have to be repeatedly reallocated as the list grows . The larger the final list , the more time you save by avoiding the reallocations . That said , even without pre - allocation , inserting n elements at the back of an ArrayList is guaranteed to take total O ( args ) time . In other words , appending an element is an amortized constant - time operation . This is achieved by having each reallocation increase the size of the array exponentially , typically by a factor of 1 . 5 . With this approach , the total number of operations can be shown to be O ( n ) .

Question - 22561614 , answer - 22561687 This works because Integer : : min resolves to an implementation of the Comparable < T > interface . The method reference of Integer : : min resolves to Integer . min ( args ) , resolved to IntBinaryOperator , and presumably autoboxing occurs somewhere making it a BinaryOperator < T > . And the min ( args ) resp max ( args ) methods of the Stream < T > ask the Comparable < T > interface to be implemented . Now this resolves to the single method Integer compareTo ( args ) . Which is of type BinaryOperator < T > . And thus the magic has happened as both methods are a BinaryOperator < T > .

Question - 32820722 , answer - 32820940 An IntFunction < T > is a function int - > R . An IntUnaryOperator is a function int - > int . Thus an IntFunction < T > is a function that takes an int as parameter and return a function that takes an int as parameter and return an int . # pre Maybe it is more clear if you use anonymous classes to " decompose " the lambda : # pre

Question - 32693704 , answer - 32745612 For me , the reason is a likely performance inprovement , at a negligible cost in terms of code clarity . Note that the implementation of the fill method is trivial , a simple for - loop setting each array element to null . So , replacing a call to it with the actual implementation does not cause any significant degradation in the clarity / conciseness of the caller method . The potential performance benefits are not so insignificant , if you consider everything that is involved : # li There will be no need for the JVM to resolve the Arrays class , plus loading and initializing it if needed . This is a non - trivial process where the JVM performs several steps . Firstly , it checks the class loader to see if the class is already loaded , and this happens every time a method is called ; there are optimizations involved here , of course , but it still takes some effort . If the class is not loaded , the JVM will need to go through the expensive process of loading it , verifying the bytecode , resolving other necessary dependencies , and finally performing static initialization of the class ( which can be arbitrarily expensive ) . Given that HashMap is such a core class , and that Arrays is such a huge class ( 3600 + lines ) , avoiding these costs may add up to noticeable savings . # li Since there is no Arrays . fill ( args ) method call , the JVM won ' t have to decide whether / when to inline the method into the caller ' s body . Since HashMap # clear ( args ) tends to get called a lot , the JVM will eventually perform the inlining , which requires JIT recompilation of the clear method . With no method calls , clear will always run at top - speed ( once initially JITed ) . Another benefit of no longer calling methods in Arrays is that it simplifies the dependency graph inside the java . util package , since one dependency is removed .

Question - 31188231 , answer - 31188818 Ironically default methods in interfaces were introduced to allow existing libraries using those interfaces not to break , while introducing massive new functionality in the interfaces . ( backward compatibility . ) Conflicts like that sort method might arise . Something to pay for the extra functionality . In your case also something to investigate ( should new functionality be used instead ? ) . Java forward compatibility breaks are little , more in its typing system , which was constantly enlarged . First with generic types and now with inferred types from functional interfaces . From version to version and from compiler to compiler there were slight differences .

Question - 10827872 , answer - 10827945 The replace ( args ) method is overloaded to accept both a primitive char and a CharSequence as arguments . Now as far as the performance is concerned , the replace ( args ) method is a bit faster than replaceAll ( args ) because the later first compiles the regex pattern and then matches before finally replacing whereas the former simply matches for the provided argument and replaces . Since we know the regex pattern matching is a bit more complex and consequently slower , then preferring replace ( args ) over replaceAll ( args ) is suggested whenever possible . For example , for simple substitutions like you mentioned , it is better to use : replace ( args ) ; instead of : replaceAll ( args ) ; Note : the above conversion method arguments are system - dependent .

Question - 25903137 , answer - 25905196 Here are some variations on Sotirios Delimanolis ' answer , which was pretty good to begin with ( + 1 ) . Consider the following : # pre A couple points here . First is the use of wildcards in the generics ; this makes the function somewhat more flexible . A wildcard would be necessary if , for example , you wanted the output map to have a key that ' s a superclass of the input map ' s key : # pre ( There is also an example for the map ' s values , but it ' s really contrived , and I admit that having the bounded wildcard for Y only helps in edge cases . ) A second point is that instead of running the stream over the input map ' s entrySet , I ran it over the keySet . This makes the code a little cleaner , I think , at the cost of having to fetch values out of the map instead of from the map entry . Incidentally , I initially had key - > key as the first argument to toMap ( args ) and this failed with a type inference error for some reason . Changing it to ( X key ) - > key worked , as did Function . identity ( args ) . Still another variation is as follows : # pre This uses Map . forEach ( args ) instead of streams . This is even simpler , I think , because it dispenses with the collectors , which are somewhat clumsy to use with maps . The reason is that Map . forEach ( args ) gives the key and value as separate parameters , whereas the stream has only one value - - and you have to choose whether to use the key or the map entry as that value . On the minus side , this lacks the rich , streamy goodness of the other approaches . : - )

Question - 13950338 , answer - 17066803 Grant Vibration Permission Before you start implementing any vibration code , you have to give your application the permission to vibrate : < uses - permission android : name = StringLiteral / > Make sure to include this line in your AndroidManifest . xml file . Import the Vibration Library Most IDEs will do this for you , but here is the import statement if yours doesn ' t : import android . os . Vibrator ; Make sure this in the activity where you want the vibration to occur . How to Vibrate for a Given Time In most circumstances , you ' ll be wanting to vibrate the device for a short , predetermined amount of time . You can achieve this by using the vibrate ( args ) method . Here is a quick example : # pre That ' s it , simple ! How to Vibrate Indefinitely It may be the case that you want the device to continue vibrating indefinitely . For this , we use the vibrate ( args ) method : # pre When you ' re ready to stop the vibration , just call the cancel ( args ) method : v . cancel ( args ) ; How to use Vibration Patterns If you want a more bespoke vibration , you can attempt to create your own vibration patterns : # pre More Complex Vibrations There are multiple SDKs that offer a more comprehensive range of haptic feedback . One that I use for special effects is Immersion ' s Haptic Development Platform for Android . Troubleshooting If your device won ' t vibrate , first make sure that it can vibrate : # pre Secondly , please ensure that you ' ve given your application the permission to vibrate ! Refer back to the first point .

Question - 13291076 , answer - 13291108 Use name ( args ) when you want to make a comparison or use the hardcoded value for some internal use in your code . Use toString ( args ) when you want to present information to a user ( including a developper looking at a log ) . Never rely in your code on toString ( args ) giving a specific value . Never test it against a specific string . If your code breaks when someone correctly changes the toString ( args ) return , then it was already broken . From the javadoc ( emphasis mine ) : # blockquote

Question - 20358883 , answer - 31931870 Collections . singletonList ( args )

Question - 26318569 , answer - 26319364 You ' re nesting mocking inside of mocking . You ' re calling getSomeList ( args ) , which does some mocking , before you ' ve finished the mocking for MyMainModel . Mockito doesn ' t like it when you do this . Replace # pre with # pre To understand why this causes a problem , you need to know a little about how Mockito works , and also be aware in what order expressions and statements are evaluated in Java . Mockito can ' t read your source code , so in order to figure out what you are asking it to do , it relies a lot on static state . When you call a method on a mock object , Mockito records the details of the call in an internal list of invocations . The when method reads the last of these invocations off the list and records this invocation in the OngoingStubbing object it returns . The line Mockito . when ( args ) . thenReturn ( args ) ; causes the following interactions with Mockito : # li Mock method mainModel . getList ( args ) is called , # li Static method when is called , # li Method thenReturn is called on the OngoingStubbing object returned by the when method . The thenReturn method can then instruct the mock it received via the OngoingStubbing method to handle any suitable call to the getList method to return someModelList . In fact , as Mockito can ' t see your code , you can also write your mocking as follows : # pre This style is somewhat less clear to read , especially since in this case the null has to be casted , but it generates the same sequence of interactions with Mockito and will achieve the same result as the line above . However , the line Mockito . when ( args ) . thenReturn ( args ) ; causes the following interactions with Mockito : # li Mock method mainModel . getList ( args ) is called , # li Static method when is called , # li A new mock of SomeModel is created ( inside getSomeList ( args ) ) , # li Mock method model . getName ( args ) is called , At this point Mockito gets confused . It thought you were mocking mainModel . getList ( args ) , but now you ' re telling it you want to mock the model . getName ( args ) method . To Mockito , it looks like you ' re doing the following : # pre This looks silly to Mockito as it can ' t be sure what you ' re doing with mainModel . getList ( args ) . Note that we did not get to the thenReturn method call , as the JVM needs to evaluate the parameters to this method before it can call the method . In this case , this means calling the getSomeList ( args ) method . Generally it is a bad design decision to rely on static state , as Mockito does , because it can lead to cases where the Principle of Least Astonishment is violated . However , Mockito ' s design does make for clear and expressive mocking , even if it leads to astonishment sometimes . Finally , recent versions of Mockito add an extra line to the error message above . This extra line indicates you may be in the same situation as this question : # blockquote

Question - 27683759 , answer - 27684042 In a nutshell , this creates an empty , immutable list of strings . Let ' s look at the expression bit by bit . Collections is the name of a class . From the Javadoc : # blockquote emptyList ( ) is the name of a static method defined in the Collections class ( Javadoc ) . It is a generic method , and the < String > in Collections . < String > emptyList ( args ) specifies the generic type argument . The method returns a List < T > , which in this case is List < T > : a list of strings . More specifically , it returns an empty , immutable list of strings .

Question - 28319064 , answer - 28319221 Don ' t worry about any performance differences , they ' re going to be minimal in this case normally . Method 2 is preferable because # li it doesn ' t require mutating a collection that exists outside the lambda expression , # li it ' s more readable because the different steps that are performed in the collection pipeline are written sequentially ( first a filter operation , then a map operation , then collecting the result ) , ( for more info on the benefits of collection pipelines , see Martin Fowler ' s excellent article ) # li you can easily change the way values are collected by replacing the Collector that is used . In some cases you may need to write your own Collector , but then the benefit is that you can easily reuse that .

Question - 6841333 If I run the following program , which parses two date strings referencing times one second apart and compares them : # pre The output is : 353 Why is ld4 - ld3 not 1 ( as I would expect from the one - second difference in the times ) , but 353 ? If I change the dates to times one second later : # pre Then ld4 - ld3 will be 1 . Java version : # pre Timezone ( TimeZone . getDefault ( args ) ) : # pre

Question - 15202997 , answer - 37603567 this is best document I found describing getName ( ) , getSimpleName ( ) , getCanonicalName ( ) # a # pre

Question - 7693324 , answer - 7693341 To convert a String to a Long ( object ) , use Long . valueOf ( args ) . longValue ( args ) ; See link

Question - 12539365 , answer - 12562433 This is great question ! I think the root cause of it is the following , we are using JUnit not only for unit testing . So the question should be splited up : # li Should I use Mockito . verify ( ) in my integration ( or any other higher - than - unit testing ) testing ? # li Should I use Mockito . verify ( ) in my black - box unit - testing ? # li Should I use Mockito . verify ( ) in my white - box unit - testing ? so if we will ignore higher - than - unit testing , the question can be rephrased " Using white - box unit - testing with Mockito . verify ( ) creates great couple between unit test and my could implementation , can I make some " grey - box " unit - testing and what rules of thumb I should use for this " . Now , let ' s go through all of this step - by - step . * - Should I use Mockito . verify ( ) in my integration ( or any other higher - than - unit testing ) testing ? * I think the answer is clearly no , moreover you shouldn ' t use mocks for this . Your test should be as close to real application as possible . You are testing complete use case , not isolated part of the application . * black - box vs white - box unit - testing black - box state If you are using white - box approach what is you really doing , you ' re testing the behaviour of your unit . In this approach calling to Mockito . verify ( ) is essential , you should verify that your unit behaves as you ' re expecting to . rules of thumbs for grey - box - testing The problem with white - box testing is it creates a high coupling . One possible solution is to do grey - box - testing , not white - box - testing . This is sort of combination of black & white box testing . You are really testing the behaviour of your unit like in white - box testing , but in general you make it implementation - agnostic when possible . When it is possible , you will just make a check like in black - box case , just asserts that output is what is your expected to be . So , the essence of your question is when it is possible . This is really hard . I don ' t have a good example , but I can give you to examples . In the case that was mentioned above with equals ( ) vs equalsIgnoreCase ( ) you shouldn ' t call Mockito . verify ( ) , just assert the output . If you couldn ' t do it , break down your code to the smaller unit , until you can do it . On the other hand , suppose you have some @ Service and you are writting @ Web - Service that is essentially wrapper upon your @ Service - it delegates all calls to the @ Service ( and making some extra error handling ) . In this case calling to Mockito . verify ( ) is essential , you shouldn ' t duplicate all of your checks that you did for the @ Serive , verifying that you ' re calling to @ Service with correct parammeter list is sufficient .

Question - 32175145 , answer - 32175175 Note that a . b and c are instances of primitive wrapper classes ( such as Integer , Double , etc . . . ) . These classes are final and cannot be extended , so you can ' t override their equals implementation . Therefore a . equals ( args ) will always return true , since those classes implement equals properly .

Question - 6652687 # blockquote Is there a convenience method to strip any leading or trailing spaces from a Java String ? Something like : # pre Result : no spaces : keep this myString . replace ( args ) would replace the space between keep and this . Thanks

Question - 18532488 , answer - 24296741 Here ' s another technique I ran across the other day : Collections . nCopies ( args ) . stream ( args ) . forEach ( args ) ; The Collections . nCopies call creates a List containing n copies of whatever value you provide . In this case it ' s the boxed Integer value 1 . Of course it doesn ' t actually create a list with n elements ; it creates a " virtualized " list that contains only the value and the length , and any call to get within range just returns the value . The nCopies method has been around since the Collections Framework was introduced way back in JDK 1 . 2 . Of course , the ability to create a stream from its result was added in Java SE 8 . Big deal , another way to do the same thing in about the same number of lines . However , this technique is faster than the IntStream . generate and IntStream . iterate approaches , and surprisingly , it ' s also faster than the IntStream . range approach . For iterate and generate the result is perhaps not too surprising . The streams framework ( really , the Spliterators for these streams ) is built on the assumption that the lambdas will potentially generate different values each time , and that they will generate an unbounded number of results . This makes parallel splitting particularly difficult . The iterate method is also problematic for this case because each call requires the result of the previous one . So the streams using generate and iterate don ' t do very well for generating repeated constants . The relatively poor performance of range is surprising . This too is virtualized , so the elements don ' t actually all exist in memory , and the size is known up front . This should make for a fast and easily parallelizable spliterator . But it surprisingly didn ' t do very well . Perhaps the reason is that range has to compute a value for each element of the range and then call a function on it . But this function just ignores its input and returns a constant , so I ' m surprised this isn ' t inlined and killed . The Collections . nCopies technique has to do boxing / unboxing in order to handle the values , since there are no primitive specializations of List . Since the value is the same every time , it ' s basically boxed once and that box is shared by all n copies . I suspect boxing / unboxing is highly optimized , even intrinsified , and it can be inlined well . Here ' s the code : # pre And here are the JMH results : ( 2 . 8GHz Core2Duo ) # pre There is a fair amount of variance in the ncopies version , but overall it seems comfortably 20x faster than the range version . ( I ' d be quite willing to believe that I ' ve done something wrong , though . ) I ' m surprised at how well the nCopies technique works . Internally it doesn ' t do very much special , with the stream of the virtualized list simply being implemented using IntStream . range ! I had expected that it would be necessary to create a specialized spliterator to get this to go fast , but it already seems to be pretty good .

Question - 4818699 , answer - 4819109 If you look at the methods AtomicInteger has , you ' ll notice that they tend to correspond to common operations on ints . For instance : # pre is the thread - safe version of this : # pre The methods map like this : + + i is i . incrementAndGet ( args ) i + + is i . getAndIncrement ( args ) - - i is i . decrementAndGet ( args ) i - - is i . getAndDecrement ( args ) i = x is i . set ( args ) x = i is x = i . get ( args ) There are other convenience methods as well , like compareAndSet or addAndGet

Question - 18448671 , answer - 26937769 Though one answer is accepted and this is an old one , I thought posting this answer as it does not use Iterator # pre

Question - 8777257 , answer - 8777311 The Arrays . equals ( args ) : check if both arrays contain the same number of elements , and all corresponding pairs of elements in the two arrays are equal . The array1 . equals ( args ) : compare the object to another object and return true only if the reference of the two object are equal as in the Object . equals ( args )

Question - 33635717 I ' m reading up about Java streams and discovering new things as I go along . One of the new things I found was the peek ( args ) function . Almost everything I ' ve read on peek says it should be used to debug your Streams . What if I had a Stream where each Account has a username , password field and a login ( ) and loggedIn ( ) method . I also have Consumer < T > login = account - > account . login ( args ) ; and Predicate < T > loggedIn = account - > account . loggedIn ( args ) ; Why would this be so bad ? # pre Now as far as I can tell this does exactly what it ' s intended to do . It ; # li Takes a list of accounts # li Tries to log in to each account # li Filters out any account which aren ' t logged in # li Collects the logged in accounts into a new list What is the downside of doing something like this ? Any reason I shouldn ' t proceed ? Lastly , if not this solution then what ? The original version of this used the . filter ( ) method as follows ; # pre

Question - 28276423 , answer - 28276493 You can close the outer most stream , in fact you don ' t need to retain all the streams wrapped and you can use Java 7 try - with - resources . # pre If you subscribe to YAGNI , or you - aint - gonna - need - it , you should be only adding code you actually need . You shouldn ' t be adding code you imagine you might need but in reality doesn ' t do anything useful . Take this example and imagine what could possibly go wrong if you didn ' t do this and what the impact would be ? # pre Lets start with FileOutputStream which calls open to do all the real work . / * * * Opens a file , with the specified name , for overwriting or appending . * @ param name name of file to be opened * @ param append whether the file is to be opened in append mode * / private native void open ( args ) throws FileNotFoundException ; If the file is not found , there is no underlying resource to close , so closing it won ' t make any difference . If The file exists , it should be throwing a FileNotFoundException . So there is nothing to be gained by trying to close the resource from this line alone . The reason you need to close the file is when the file is opened successfully , but you later get an error . Lets look at the next stream GZIPOutputStream There is code which can throw an exception # pre This writes the header of the file . Now it would be very unusual for you to be able to open a file for writing but not be able to write even 8 bytes to it , but lets imagine this could happen and we don ' t close the file afterwards . What does happen to a file if it is not closed ? You don ' t get any unflushed writes , they are discarded and in this case , there is no successfully written bytes to the stream which isn ' t buffered at this point anyway . But a file which is not closed doesn ' t live forever , instead FileOutputStream has # pre If you don ' t close a file at all , it gets closed anyway , just not immediately ( and like I said , data which is left in a buffer will be lost this way , but there is none at this point ) What is the consequence of not closing the file immediately ? Under normal conditions , you potentially lose some data , and you potentially run out of file descriptors . But if you have a system where you can create files but you can ' t write anything to them , you have a bigger problem . i . e . it hard to imagine why you are repeatedly trying to create this file despite the fact you are failing . Both OutputStreamWriter and BufferedWriter don ' t throw IOException in their constructors , so it not clear what problem they would cause . In The case of BufferedWriter , you could get an OutOfMemoryError . In this case it will immediately trigger a GC , which as we have seen will close the file anyway .

Question - 5071040 , answer - 5071064 There are multiple ways : # li String . valueOf ( args ) ( my preference ) # li StringLiteral + number ( I don ' t know how the compiler handles it , perhaps it is as efficient as the above ) # li Integer . toString ( args )

Question - 18777989 , answer - 18778228 You made a good summery of the practical differences in use and implementation but did not say anything about the difference in meaning . An interface is a description of the behaviour an implementing class will have . The implementing class ensures , that it will have these methods that can be used on it . It is basically a contract or a promise the class has to make . An abstract class is a basis for different subclasses that share behaviour which does not need to be repeatedly be created . Subclasses must complete the behaviour and have the option to override predefine behaviour ( as long as it is not defined as final or private ) . You will find good examples in the java . util package which includes interfaces like List and abstract classes like AbstractList which already implements the interface . The official documentation describes the AbstractList as follows : # blockquote

Question - 32323081 I have a question regarding Java 8 inference with respect to lambdas and their related exception signatures . If I define some method foo : # pre then I get the nice and concise semantic of being able to write foo ( args ) ; in most cases for a given T . However , in this example , if my getTheT operation declares that it throws Exception , my foo method which takes a Supplier no longer compiles : the Supplier method signature for get doesn ' t throw exceptions . It seems like a decent way to get around this would be to overload foo to accept either option , with the overloaded definition being : # pre where ThrowingSupplier is defined as # pre In this way , we have one Supplier type which throws exceptions and one which doesn ' t . The desired syntax would be something like this : # pre However , this causes issues due to the lambda type being ambiguous ( presumably unable to resolve between Supplier and ThrowingSupplier ) . Doing an explicit cast a la foo ( args ) ; would work , but it gets rid of most of the conciseness of the desired syntax . I guess the underlying question is : if the Java compiler is able to resolve the fact that one of my lambdas is incompatible due to it throwing an exception in the Supplier - only case , why isn ' t it able to use that same information to derive the type of the lambda in the secondary , type - inference case ? Any information or resources which anyone could point me to would likewise be much appreciated , as I ' m just not too sure where to look for more information on the matter . Thanks !

Question - 9481865 , answer - 9482369 This could be a bit tricky in the most general case . On the face of it , InetAddress . getLocalHost ( args ) should give you the IP address of this host . The problem is that a host could have lots of network interfaces , and an interface could be bound to more than one IP address . And to top that , not all IP addresses will be reachable outside of your machine or your LAN . For example , they could be IP addresses for virtual network devices , private network IP addresses , and so on . What this means is that the IP address returned by InetAddress . getLocalHost ( args ) might not be the right one to use . How can you deal with this ? # li One approach is to use NetworkInterface . getNetworkInterfaces ( args ) to get all of the known network interfaces on the host , and then iterate over each NI ' s addresses . # li Another approach is to ( somehow ) get the externally advertized FQDN for the host , and use InetAddress . getByName ( args ) to look up the primary IP address . ( But how do you get it , and how do you deal with a DNS - based load balancer ? ) # li A variation of the previous is to get the preferred FQDN from a config file or a command line parameter . # li Another variation is to get the preferred IP address from a config file or a command line parameter . In summary , InetAddress . getLocalHost ( args ) will typically work , but you may need to provide an alternative method for the cases where your code is run in an environment with " complicated " networking . # blockquote # li Any address in the range 127 . xxx . xxx . xxx is a " loopback " address . It is only visible to " this " host . # li Any address in the range 192 . 168 . xxx . xxx is a private ( aka site local ) IP address . These are reserved for use within an organization . The same applies to 10 . xxx . xxx . xxx addresses , and 172 . 16 . xxx . xxx through 172 . 31 . xxx . xxx . # li Addresses in the range 169 . 254 . xxx . xxx are link local IP addresses . These are reserved for use on a single network segment . # li Addresses in the range 224 . xxx . xxx . xxx through 239 . xxx . xxx . xxx are multicast addresses . # li The address 255 . 255 . 255 . 255 is the broadcast address . # li Anything else should be a valid public point - to - point IPv4 address . In fact , the InetAddress API provides methods for testing for loopback , link local , site local , multicast and broadcast addresses . You can use these to sort out which of the IP addresses you get back is most appropriate .

Question - 10827872 , answer - 22578124 Old thread I know but I am sort of new to Java and discover one of it ' s strange things . I have used String . replaceAll ( args ) but get unpredictable results . Something like this mess up the string : sUrl = sUrl . replaceAll ( args ) . replaceAll ( args ) ; So I designed this function to get around the weird problem : # pre Which make you able to do : # pre

Question - 5585779 , answer - 35834484 Integer . decode You can also use public static Integer decode ( args ) throws NumberFormatException . It also works for base 8 and 16 : # pre If you want to get int instead of Integer you can use : # li Unboxing : int val = Integer . decode ( args ) ; # li intValue ( args ) : Integer . decode ( args ) . intValue ( args ) ;

Question - 29945627 , answer - 29945754 The lambda : ( ) - > { System . out . println ( args ) ; } ; actually represents an implementation for an interface like : # pre which is completely different than the one you ' ve defined . That ' s why you get an error . Since you can ' t extend your @ FunctionalInterface , nor introduce a brand new one , then I think you don ' t have much options . You can use the Optional < T > interfaces to denote that some of the values ( return type or method parameter ) is missing , though . However , this won ' t make the lambda body simpler .

Question - 17489250 , answer - 17489453 Java treats String as a special class , you can initialize in both ways # li Directly assigning literal String a = StringLiteral ; # li As other Objects using new keyword String a = new String ( args ) ; You need to take special care when you wants to compare with = = sign : # pre That is because in first case the objects a and b are kept in something called literal pool and they both are referencing same object so they are equal in both ways . But in second case a and b references different objects like when we initialize any other objects . so they are unequal when compared with = = operator whereas they are equal in values .

Question - 31202946 , answer - 31203252 # blockquote This question actually boils down to the fact that you should always prefer composition over inheritance . If the Thread class was declared as abstract , the language would have to provide another class that extended from it which programmers could use to create a Thread . Your question would then be about why this class that extends from Thread is not abstract . If the language did not provide another class that extends from Thread , programmers would have to create their own class that extend s from Thread and override the run ( args ) method . # blockquote The only possible explanation I can give is that the developers of the language saw some use - cases for overriding start when the class was introduced to the JDK . The first version of Java that I used was 1 . 5 and I personally have not come across a use - case where I found the need to override start . As JB Nizet stated in his answer # blockquote

Question - 33147339 , answer - 33147762 I found this explanation : # blockquote In Java 6 , if you use the API as : # pre And newCount overflows ( this becomes negative ) , if ( args ) will return false and you may mistakenly assume that the ArrayList was increased by len .

Question - 8189466 , answer - 8189786 Here ' s why : As it is says in the Javadoc : # blockquote This check is done in the next ( args ) method of the iterator ( as you can see by the stacktrace ) . But we will reach the next ( args ) method only if hasNext ( args ) delivered true , which is what is called by the for each to check if the boundary is met . In your remove method , when hasNext ( args ) checks if it needs to return another element , it will see that it returned two elements , and now after one element was removed the list only contains two elements . So all is peachy and we are done with iterating . The check for concurrent modifications does not occur , as this is done in the next ( args ) method which is never called . Next we get to the second loop . After we remove the second number the hasNext method will check again if can return more values . It has returned two values already , but the list now only contains one . But the code here is : # pre 1 ! = 2 , so we continue to the next ( args ) method , which now realizes that someone has been messing with the list and fires the exception . Hope that clears your question up .

Question - 32714194 String is a special case in Java . It ' s a class , which I can examine in the source code , but it also has its own infix operator + , which seems to be syntactic sugar for StringBuilder . For example , StringLiteral + yourName ; could become new StringBuilder ( args ) . append ( args ) . append ( args ) . toString ( args ) ; There are no user - defined operators in Java , so where is + specified for String ? Could the same mechanism be used to make additional operators , such as for vectors ?

Question - 21375659 , answer - 21375716 String is immutable irrespective of how it is instantiated 1 ) Short answer is yes , new String ( args ) is immutable too . Because every possible mutable operation ( like replace , toLowerCase etcetra ) that you perform on String does not affect the original String instance and returns you a new instance . You may check this in Javadoc for String . Each public method of String that is exposed returns a new String instance and does not alter the present instance on which you called the method . This is very helpful in Multi - threaded environment as you don ' t have to think about mutability ( someone will change the value ) every time you pass or share the String around . String can easily be the most used data type , so the designers have blessed us all to not think about mutability everytime and saved us a lot of pain . Immutability allowed String pool or caching It is because of immutability property that the internal pool of string was possible , as when same String value is required at some other place then that immutable reference is returned . If String would have been mutable then it would not have been possible to share String s like this to save memory . String immutablity was not because of pooling , but immutability has more benefits attached to it . String interning or pooling is an example of Flyweight Design pattern 2 ) Yes it will be interned like any other String as a blank String is also as much a String as other String instances . References : # li Immutability benefits of String

Question - 29922296 I ' m wondering what the best way is in Java 8 to work with all the values of an enum . Specifically when you need to get all the values and add it to somewhere , for example , supposing that we have the following enum : # pre I could of course do the following : # pre But , I could also add the following method to the enum definition : # pre And then replace the for from above with : Letter . stream ( args ) . forEach ( args ) ; Is this approach OK or does it have some fault in design or performance ? Moreover , why don ' t enums have a stream ( ) method ?

Question - 29262002 , answer - 29262126 The JLS specify that # blockquote Now let ' s see that in detail , Since your takeBiConsumer method is of void type , the lambda receiving new String ( args ) will interpret it as a block like # pre which is valid in a void , hence the first case compile . However , in the case where the lambda is - > StringLiteral , a block such as # pre is not valid syntax in java . Therefore the only thing to do with " hi " is to try and return it . # pre which is not valid in a void and explain the error message # pre For a better understanding , note that if you change the type of takeBiConsumer to a String , - > StringLiteral will be valid as it will simply try to directly return the string . Note that at first I tought the error was caused by the lambda being in a wrong invocation context , so I ' ll share this possibility with the community : JLS 15 . 27 # blockquote However in our case , we are in an invocation context which is correct .

Question - 7569335 , answer - 39329245 As others have pointed out the preferred way is to use : new StringBuilder ( args ) . reverse ( args ) . toString ( args ) but if you want to implement this by youself , i ' am afraid that the rest of responses have flaws . The reason is that String represent a list of Unicode points , encoded in a char [ ] array according to the variable - length encoding : UTF - 16 . This means some code points use a single element of the array ( one code unit ) but others use two of them , so there might be pairs of characters that must be treated as a single unit ( consecutive " high " and " low " surrogates ) # pre

Question - 8579657 , answer - 8579702 If you just invoke run ( args ) directly , it ' s executed on the calling thread , just like any other method call . Thread . start ( args ) is required to actually create a new thread so that the runnable ' s run method is executed in parallel .

Question - 5673260 , answer - 5673356 # pre Generally speaking , when you have response . getOutputStream ( args ) , you can write anything there . You can pass this output stream as a place to put generated PDF to your generator . Also , if you know what file type you are sending , you can set response . setContentType ( args ) ;

Question - 31270759 , answer - 31270760 Presented below is the full code of the Exceptional class . It has a quite large API which is a pure extension of the Optional API so it can be a drop - in replacement for it in any existing code โ except that it isn ' t a subtype of the final Optional class . The class can be seen as being in the same relationship with the Try monad as Optional is with the Maybe monad : it draws inspiration from it , but is adapted to the Java idiom ( such as actually throwing exceptions , even from non - terminal operations ) . These are some key guidelines followed by the class : # li as opposed to the monadic approach , doesn ' t ignore Java ' s exception mechanism ; # li instead it relieves the impedance mismatch between exceptions and higher - order functions ; # li exception handling not statically typesafe ( due to sneaky throwing ) , but always safe at runtime ( never swallows an exception except on explicit request ) . The class tries to cover all the typical ways to handle an exception : # li recover with some handling code which provides a substitute value ; # li flatRecover which , analogous to flatMap , allows to return a new Exceptional instance which will be unwrapped and the state of the current instance suitably updated ; # li propagate an exception , throwing it from the Exceptional expression and making the propagate call declare this exception type ; # li propagate it after wrapping into another exception ( translate it ) ; # li handle it , resulting in an empty Exceptional ; # li as a special case of handling , swallow it with an empty handler block . The propagate approach allows one to selectively pick which checked exceptions he wants to expose from his code . Exceptions which remain unhandled at the time a terminal operation is called ( like get ) will be sneakily thrown without declaration . This is often considered as an advanced and dangerous approach , but is nevertheless often employed as a way to somewhat alleviate the nuisance of checked exceptions in combination with lambda shapes which do not declare them . The Exceptional class hopes to offer a cleaner and more selective alternative to sneaky throw . # pre # pre # pre

Question - 8725387 , answer - 8725550 Think of it like this : the List interface has methods like add ( args ) , set ( args ) . The contract is that once you added an element at position X you will find it there unless you add or remove elements before it . If any list implementation would store elements in some order other than based on the index , the above list methods would make no sense .

Question - 6271417 , answer - 6271460 The " $ 1 " is not " useless non - sense " . If your class is anonymous , a number is appended . If you don ' t want the class itself , but its declaring class , then you can use getEnclosingClass ( args ) . For example : # pre You can move that in some static utility method . But note that this is not the current class name . The anonymous class is different class than its enclosing class . The case is similar for inner classes .

Question - 20945049 , answer - 21008747 [ Disclaimer this is a deliberately opinionated style of answer as I feel a more " don ' t do this at home kids " answer is warranted ] The sin is the line field . setAccessible ( args ) ; which says to violate the public api by allowing access to a private field . Thats a giant security hole which can be locked down by configuring a security manager . The phenomenon in the question are implementation details which you would never see when not using that dangerous line of code to violate the access modifiers via reflection . Clearly two ( normally ) immutable strings can share the same char array . Whether a substring shares the same array depends on whether it can and whether the developer thought to share it . Normally these are invisible implementation details which you should not have to know unless you shoot the access modifier through the head with that line of code . It is simply not a good idea to rely upon such details which cannot be experienced without violating the access modifiers using reflection . The owner of that class only supports the normal public API and is free to make implementation changes in the future . Having said all that the line of code is really very useful when you have a gun held you your head forcing you to do such dangerous things . Using that back door is usually a code smell that you need to upgrade to better library code where you don ' t have to sin . Another common use of that dangerous line of code is to write a " voodoo framework " ( orm , injection container , . . . ) . Many folks get religious about such frameworks ( both for and against them ) so I will avoid inviting a flame war by saying nothing other than the vast majority of programmers don ' t have to go there .

Question - 19235606 , answer - 19235857 Spliterator basically means " splittable Iterator " . Single thread can traverse / process the entire Spliterator itself , but the Spliterator also has a method trySplit ( args ) which will " split off " a section for someone else ( typically , another thread ) to process - - leaving the current spliterator with less work . Collector combines the specification of a reduce function ( of map - reduce fame ) , with an initial value , and a value to combine two results ( thus enabling results from Spliterated streams of work , to be combined . ) For example , the most basic Collector would have an initial vaue of 0 , add an integer onto an existing result , and would ' combine ' two results by adding them . Thus summing a spliterated stream of integers . See : # li Spliterator . trySplit ( ) # li Collector < T , A , R >

Question - 18092160 Why were 181783497276652981 and 8682522807148012 chosen in Random . java ? Here ' s the relevant source code from Java SE JDK 1 . 7 : # pre So , invoking new Random ( args ) without any seed parameter takes the current " seed uniquifier " and XORs it with System . nanoTime ( args ) . Then it uses 181783497276652981 to create another seed uniquifier to be stored for the next time new Random ( args ) is called . The literals 181783497276652981L and 8682522807148012L are not placed in constants , but they don ' t appear anywhere else . At first the comment gives me an easy lead . Searching online for that article yields the actual article . 8682522807148012 doesn ' t appear in the paper , but 181783497276652981 does appear - - as a substring of another number , 1181783497276652981 , which is 181783497276652981 with a 1 prepended . The paper claims that 1181783497276652981 is a number that yields good " merit " for a linear congruential generator . Was this number simply mis - copied into Java ? Does 181783497276652981 have an acceptable merit ? And why was 8682522807148012 chosen ? Searching online for either number yields no explanation , only this page that also notices the dropped 1 in front of 181783497276652981 . Could other numbers have been chosen that would have worked as well as these two numbers ? Why or why not ?

Question - 28818506 I ' ve been working with the new Optional type in Java 8 , and I ' ve come across what seems like a common operation that isn ' t supported functionally : an " orElseOptional " Consider the following pattern : # pre There are many forms of this pattern , but it boils down to wanting an " orElse " on an optional that takes a function producing a new optional , called only if the current one does not exist . It ' s implementation would look like this : # pre I ' m curious if there ' s a reason such a method doesn ' t exist , if I ' m just using Optional in an unintended way , and what other ways people have come up with to deal with this case . I should say that I think that solutions involving custom utility classes / methods aren ' t elegant because people working with my code won ' t necessarily know they exist . Also , if anyone knows , will such a method be included in JDK 9 , and where might I propose such a method ? This seems like a pretty glaring omission to the API to me .

Question - 32175145 , answer - 32182250 Integer a . equals ( a ) can return false But you have to be really evil and use reflections and Multithreading : If you run this code , there is a chance that a racing condition can change the internal Value of myInt while the comparision takes place . If you want to simulate this condition , just set a breakpoint inside of Integer . intValue ( args ) run the code in debug and hit continue . This will create a delay which creates the race condition artificially and the console will return false . # pre

Question - 27747562 , answer - 27747702 A List < T > could very well be an Item . See for example : # pre A cast tells the compiler : " I know you can ' t be sure that this is a object of type Item , but I know better than you , so please compile " . The compiler will only refuse to compile that if it ' s impossible for the returned object to be an instance of Item ( like , for example , Integer can ' t ever be a String ) At runtime , the type of the actual object returned by the method will be checked , and if it ' s not actually an object of type Item , you ' ll get a ClassCastException .

Question - 16635398 , answer - 16636899 I feel that I need to extend my comment a bit . . . About paradigm \ style That ' s probably the most notable aspect . FP became popular due to what you can get avoiding side - effects . I won ' t delve deep into what pros \ cons you can get from this , since this is not related to the question . However , I will say that the iteration using Iterable . forEach is inspired by FP and rather result of bringing more FP to Java ( ironically , I ' d say that there is no much use for forEach in pure FP , since it does nothing except introducing side - effects ) . In the end I would say that it is rather a matter of taste \ style \ paradigm you are currently writing in . About parallelism . From performance point of view there is no promised notable benefits from using Iterable . forEach over foreach ( . . . ) . According to official docs on Iterable . forEach : # blockquote . . . i . e . docs pretty much clear that there will be no implicit parallelism . Adding one would be LSP violation . Now , there are " parallell collections " that are promised in Java 8 , but to work with those you need to me more explicit and put some extra care to use them ( see mschenk74 ' s answer for example ) . BTW : in this case Stream . forEach will be used , and it doesn ' t guarantee that actual work will be done in parallell ( depends on underlying collection ) . UPDATE : might be not that obvious and a little stretched at a glance but there is another facet of style and readability perspective . First of all - plain old forloops are plain and old . Everybody already knows them . Second , and more important - you probably want to use Iterable . forEach only with one - liner lambdas . If " body " gets heavier - they tend to be not - that readable . You have 2 options from here - use inner classes ( yuck ) or use plain old forloop . People often gets annoyed when they see the same things ( iteratins over collections ) being done various vays / styles in the same codebase , and this seems to be the case . Again , this might or might not be an issue . Depends on people working on code .

Question - 19418427 , answer - 19418553 If you take a look at this methods # pre and its decompiled with javap - c ClassWithTheseMethods versions you will see # pre and # pre So if Strings are not final compiler will have to use StringBuilder to concatenate str1 and str2 so String concat = str1 + str2 ; will be compiled to String concat = new StringBuilder ( args ) . append ( args ) . toString ( args ) ; which means that concat will be created at runtime so will not come from String pool . Also if Strings are final then compiler can assume that they will never change so instead of using StringBuilder it can safely concatenate its values so String concat = str1 + str2 ; can be changed to String concat = StringLiteral + StringLiteral ; and concatenated into String concat = StringLiteral ; which means that concate will become sting literal which will be interned in string pool and then compared with same string literal from that pool in if statement .

Question - 31445024 , answer - 31760309 Until the language specification mentions it , it is not guaranteed that autoboxing is equivalent to a call to the static valueOf methods . It is an implementation aspect , not part of the boxing conversion specification . An implementation is theoretically free to use another mechanism as long as it conforms to the rule you mentioned from the JLS . In practice , there are many Sun JDK bug reports ( e . g . JDK - 4990346 and JDK - 6628737 ) that clearly imply that when autoboxing was introduced in Java 5 , the intention was having the compiler to rely on valueOf as stated in JDK - 6628737 : # blockquote But that ' s only for javac , not necessarily all compilers .

Question - 15621083 I am working on some Java code which needs to be highly optimized as it will run in hot functions that are invoked at many points in my main program logic . Part of this code involves multiplying double variables by 10 raised to arbitrary non - negative int exponent s . One fast way ( edit : but not the fastest possible , see Update 2 below ) to get the multiplied value is to switch on the exponent : # pre The commented ellipses above indicate that the case int constants continue incrementing by 1 , so there are really 19 case s in the above code snippet . Since I wasn ' t sure whether I would actually need all the powers of 10 in case statements 10 thru 18 , I ran some microbenchmarks comparing the time to complete 10 million operations with this switch statement versus a switch with only case s 0 thru 9 ( with the exponent limited to 9 or less to avoid breaking the pared - down switch ) . I got the rather surprising ( to me , at least ! ) result that the longer switch with more case statements actually ran faster . On a lark , I tried adding even more case s which just returned dummy values , and found that I could get the switch to run even faster with around 22 - 27 declared case s ( even though those dummy cases are never actually hit while the code is running ) . ( Again , case s were added in a contiguous fashion by incrementing the prior case constant by 1 . ) These execution time differences are not very significant : for a random exponent between 0 and 10 , the dummy padded switch statement finishes 10 million executions in 1 . 49 secs versus 1 . 54 secs for the unpadded version , for a grand total savings of 5ns per execution . So , not the kind of thing that makes obsessing over padding out a switch statement worth the effort from an optimization standpoint . But I still just find it curious and counter - intuitive that a switch doesn ' t become slower ( or perhaps at best maintain constant O ( 1 ) time ) to execute as more case s are added to it . # img These are the results I obtained from running with various limits on the randomly - generated exponent values . I didn ' t include the results all the way down to 1 for the exponent limit , but the general shape of the curve remains the same , with a ridge around the 12 - 17 case mark , and a valley between 18 - 28 . All tests were run in JUnitBenchmarks using shared containers for the random values to ensure identical testing inputs . I also ran the tests both in order from longest switch statement to shortest , and vice - versa , to try and eliminate the possibility of ordering - related test problems . I ' ve put my testing code up on a github repo if anyone wants to try to reproduce these results . So , what ' s going on here ? Some vagaries of my architecture or micro - benchmark construction ? Or is the Java switch really a little faster to execute in the 18 to 28 case range than it is from 11 up to 17 ? github test repo " switch - experiment " UPDATE : I cleaned up the benchmarking library quite a bit and added a text file in / results with some output across a wider range of possible exponent values . I also added an option in the testing code not to throw an Exception from default , but this doesn ' t appear to affect the results . UPDATE 2 : Found some pretty good discussion of this issue from back in 2009 on the xkcd forum here : # a . The OP ' s discussion of using Array . binarySearch ( args ) gave me the idea for a simple array - based implementation of the exponentiation pattern above . There ' s no need for the binary search since I know what the entries in the array are . It appears to run about 3 times faster than using switch , obviously at the expense of some of the control flow that switch affords . That code has been added to the github repo also .

Question - 31922866 , answer - 31923211 This advice is a variant of the " be as unspecific as possible regarding inputs and as specific as possible regarding outputs " rule of thumb . Usually if you have a method that takes a plain non - null value , you can map it over the Optional , so the plain version is strictly more unspecific regarding inputs . However there are a bunch of possible reasons why you would want to require an Optional argument nonetheless : # li you want your function to be used in conjunction with another API that returns an Optional # li Your function should return something other than an empty Optional if the given value is empty # li You think Optional is so awesome that whoever uses your API should be required to learn about it ; - )

