Question-13102045, answer-7056786
It's because when you enter a number then press Enter , input.nextInt(args) consumes only the number, not the "end of line". When input.nextLine(args) executes, it consumes the "end of line" still in the buffer from the first input. Instead, use input.nextLine(args) immediately after input.nextInt(args)

Question-6470651, answer-6470695
A simple thing to do is to use a HashSet with an incorrect (or non-existent) hashCode(args) or equals(args) , and then keep adding "duplicates". Instead of ignoring duplicates as it should, the set will only ever grow and you won't be able to remove them. If you want these bad keys/elements to hang around you can use a static field like #pre

Question-10827872, answer-10827900
In java.lang.String , the replace method either takes a pair of char's or a pair of CharSequence 's (of which String is a subclass, so it'll happily take a pair of String's). The replace method will replace all occurrences of a char or CharSequence . On the other hand, both String arguments to replaceFirst and replaceAll are regular expressions (regex). Using the wrong function can lead to subtle bugs.

Question-17489250, answer-17489394
It's a feature of the Java language. String literals in the source code is given special treatment. The language spec, here , simply says that a string literal is of String type

Question-21163108, answer-22269778
There actually is a trick how to execute a parallel operation in a specific fork-join pool. If you execute it as a task in a fork-join pool, it stays there and does not use the common one. #pre The trick is based on ForkJoinTask.fork which specifies: "Arranges to asynchronously execute this task in the pool the current task is running in, if applicable, or using the ForkJoinPool.commonPool() if not inForkJoinPool()"

Question-10786042, answer-25735202
You need to first create a URI like: #pre Then convert that Uri to ASCII string: urlStr=uri.toASCIIString(args); Now your url string is completely encoded first we did simple url encoding and then we converted it to ASCII String to make sure no character outside US-ASCII are remaining in string. This is exactly how browsers do.

Question-31445024, answer-31445150
I first tought your question was a dupe of What code does the compiler generate for autoboxing? However, after your comment on @ElliottFrisch I realized it was different : #blockquote For other readers, assume that "behaves that way" means using valueOf . Remember that there are multiples compilers for Java. To be "legal" they must follow the contract given in the JLS . Therefore, as long as all the rules here are respected, there is no guarantee of how autoboxing is internally implemented. But I don't see any reason to not use valueOf , specially that it uses the cached values and is the recommended way as per this article by Joseph D. Darcy.

Question-20331163, answer-20331323
Another way of doing that is: String date = dateAndTime.substring(args); I'm not exactly certain, but I think this might be faster/use less memory than using the .split(args) method.

Question-32356762
Is there a good reason that the Collections.list() method in the java.utils package returns an ArrayList<T> instead of List<T> ? Obviously an ArrayList is a List , but I'm under the impression that it's generally good practice to return the interface type instead of implementation type.

Question-28276423, answer-28276498
Assuming all the streams get created okay, yes, just closing bw is fine with those stream implementations ; but that's a big assumption. I'd use try-with-resources ( tutorial ) so that any issues constructing the subsequent streams that throw exceptions don't leave the previous streams hanging, and so you don't have to rely on the stream implementation having the call to close the underlying stream: #pre Note you no longer call close at all. Important note : To have try-with-resources close them, you must assign the streams to variables as you open them, you cannot use nesting. If you use nesting, an exception during construction of one of the later streams (say, GZIPOutputStream ) will leave any stream constructed by the nested calls inside it open. From JLS §14.20.3 : #blockquote Note the word "variables" (my emphasis) . E.g., don't do this: #pre ...because an exception from the GZIPOutputStream(OutputStream) constructor (which says it may throw IOException , and writes a header to the underlying stream) would leave the FileOutputStream open. Since some resources have constructors that may throw and others don't, it's a good habit to just list them separately. We can double-check our interpretation of that JLS section with this program: #pre ...which has the output: #pre Note that there are no calls to close there. If we fix main : #pre then we get the appropriate close calls: #pre (Yes, two calls to InnerMost#close is correct; one is from Middle , the other from try-with-resources.)

Question-14491966, answer-14492043
'Random' is more than just about getting numbers.... what you have is pseudo-random If pseudo-random is good enough for your purposes, then sure, it's way faster (and XOR+Bitshift will be faster than what you have) Rolf Edit: OK, after being too hasty in this answer, let me answer the real reason why your code is faster: From the JavaDoc for Math.Random() #blockquote This is likely why your code is faster.

Question-27504925
The Java language specification specifies that #blockquote So, considering arrays are objects — why did the Java designers make the decision not to allow inherit and override from it, for example, toString() or equals(args) ? The current syntax wouldn't allow creating anonymous classes with an array as the base class, but I don't think that was the reason for their decision.

Question-8579657, answer-13134221
Actually Thread.start(args) creates a new thread and have its own execution scenario. Thread.start(args) calls the run(args) method asynchronously,which changes the state of new Thread to Runnable. But Thread.run(args) does not create any new thread. Instead it execute the run method in the current running thread synchronously. If you are using Thread.run(args) then you are not using the features of multi threading at all.

Question-8777257, answer-8777312
Arrays inherit equals(args) from Object and hence compare only returns true if comparing an array against itself. On the other hand, Arrays.equals compares the elements of the arrays. This snippet elucidates the difference: #pre See also Arrays.equals() . Another static method there may also be of interest: Arrays.deepEquals() .

Question-23114015, answer-23177907
This was not an omission; there was detailed discussion on the EG list in June of 2013. The definitive discussion of the Expert Group is rooted at this thread . While it seemed "obvious" (even to the Expert Group, initially) that stream(args) seemed to make sense on Iterable , the fact that Iterable was so general became a problem, because the obvious signature: Stream<T> stream(args) was not always what you were going to want. Some things that were Iterable<T> would rather have their stream method return an IntStream , for example. But putting the stream(args) method this high up in the hierarchy would make that impossible. So instead, we made it really easy to make a Stream from an Iterable , by providing a spliterator(args) method. The implementation of stream(args) in Collection is just: #pre Any client can get the stream they want from an Iterable with: Stream s = StreamSupport.stream(args); In the end we concluded that adding stream(args) to Iterable would be a mistake.

Question-31445024, answer-31760309
Until the language specification mentions it, it is not guaranteed that autoboxing is equivalent to a call to the static valueOf methods. It is an implementation aspect, not part of the boxing conversion specification. An implementation is theoretically free to use another mechanism as long as it conforms to the rule you mentioned from the JLS. In practice, there are many Sun JDK bug reports (e.g. JDK-4990346 and JDK-6628737 ) that clearly imply that when autoboxing was introduced in Java 5, the intention was having the compiler to rely on valueOf as stated in JDK-6628737 : #blockquote But that's only for javac, not necessarily all compilers.

Question-31419029
I've tried to build my own Map to increase the performance for a special environment, and I realized something pretty interesting: Creating a new Hashmap<T>(args) is faster than new Object[2000] - no matter in which order I execute these commands. That's pretty confusing to me, esp. because the Hashmap constructor contains a table = new Entry[capacity] , according to this . Is there something wrong with my testbench? #pre I'd love to see the results of testing on another computer. I've got no clue why creating a HashMap is 10 times faster than creating a Object[] .

Question-13659217, answer-13659231
You can't see this method in javadoc because it's added by the compiler. Documented in three places : #li Enum Types , The Java Tutorials #blockquote #li Enum.valueOf class (The special implicit values method is mentioned in description of valueOf method) #blockquote #li Enum Types, Section 8.9 , Java Language Specification The values function simply list all values of the enumeration.

Question-20358883, answer-31931870
Collections.singletonList(args)

Question-8157755, answer-8157791
If you want the value you are assigning in the constructor, you need to add a method in the enum definition to return that value. If you want a unique number that represent the enum value, you can use ordinal(args) .

Question-18571223, answer-18571352
You can use String.getBytes(args) which returns the byte[] array.

Question-8725387, answer-8725470
List iterators guarantee first and foremost that you get the list's elements in the internal order of the list (aka. insertion order ). More specifically it is in the order you've inserted the elements or on how you've manipulated the list. Sorting can be seen as a manipulation of the data structure, and there are several ways to sort the list. I'll order the ways in the order of usefulness as I personally see it: 1. Consider using Set or Bag collections instead NOTE: I put this option at the top because this is what you normally want to do anyway. A sorted set automatically sorts the collection at insertion , meaning that it does the sorting while you add elements into the collection. It also means you don't need to manually sort it. Furthermore if you are sure that you don't need to worry about (or have) duplicate elements then you can use the TreeSet<T> instead. It implements SortedSet and NavigableSet interfaces and works as you'd probably expect from a list: #pre If you don't want the natural ordering you can use the constructor parameter that takes a Comparator<T> . Alternatively you can use Multisets (also known as Bags ) , that is a Set that allows duplicate elements, instead and there are third party implementations of them. Most notably from the Guava libraries there is a TreeMultiset , that works a lot like the TreeSet . 2. Sort your list with Collections.sort(args) As mentioned above, sorting of List s is an manipulation of the data structure. So for situations where you need "one source of truth" that will be sorted in a variety of ways then sorting it manually is the way to go. You can sort your list with the java.util.Collections.sort() method. Here is a code sample on how: #pre Using comparators One clear benefit is that you may use Comparator in the sort method. Java also provides some implementations for the Comparator such as the Collator which is useful for locale sensitive sorting strings. Here is one example: #pre Sorting in concurrent environments Do note though that using the sort method is not friendly in concurrent environments, since the collection instance will be manipulated, and you should consider using immutable collections instead. This is something Guava provides in the Ordering class and is a simple one-liner: List<T> sorted = Ordering.natural(args).sortedCopy(args); 3. Wrap your list with java.util.PriorityQueue Though there is no sorted list in Java there is however a sorted queue which would probably work just as well for you. It is the java.util.PriorityQueue class. Nico Haase linked in the comments to a related question that also answers this. In a sorted collection you most likely don't want to manipulate the internal data structure which is why PriorityQueue doesn't implement the List interface (because that would give you direct access to it's elements). Caveat on the PriorityQueue iterator The PriorityQueue class implements the Iterable<T> and Collection<T> interfaces so it can be iterated as usual. However the iterator is not guaranteed to return elements in the sorted order. Instead (as Alderath points out in the comments) you need to poll(args) the queue until empty. Note that you can convert a list to a priority queue via the constructor that takes any collection : #pre 4. Write your own SortedList class NOTE: You shouldn't have to do this. You can write your own List class that sorts each time you add a new element. This can get rather computation heavy depending on your implementation and is pointless , unless you want to do it as an exercise, because of two main reasons: #li It breaks the contract that List<T> interface has, because the add methods should ensure that the element will reside in the index that the user specifies. #li Why reinvent the wheel? You should be using the TreeSet or Multisets instead as pointed out in the first point above. However if you want to do it as an exercise here is a code sample to get you started, it uses the AbstractList abstract class: #pre Note that if you haven't overridden the methods you need, then the default implementations from AbstractList will throw UnsupportedOperationException s.

Question-31922866, answer-31923042
The pattern with Optional is for one to avoid returning null . It's still perfectly possible to pass in null to a method. While these aren't really official yet, you can use JSR-308 style annotations to indicate whether or not you accept null values into the function. Note that you'd have to have the right tooling to actually identify it, and it'd provide more of a static check than an enforceable runtime policy, but it would help. public int calculateSomething(args) {}

Question-22725537
The new Java 8 stream framework and friends make for some very concise java code, but I have come across a seemingly-simple situation that is tricky to do concisely. Consider a List<T> things and method Optional<T> resolve(args) . I want to map the Thing s to Optional<T> s and get the first Other . The obvious solution would be to use things.stream(args).flatMap(args).findFirst(args) , but flatMap requires that you return a stream, and Optional doesn't have a stream(args) method (or is it a Collection or provide a method to convert it to or view it as a Collection ). The best I can come up with is this: things.stream(args) .map(args) .filter(args) .map(args) .findFirst(args); But that seems awfully long-winded for what seems like a very common case. Anyone have a better idea?

Question-21163108, answer-34930831
To measure the actual number of used threads, you can check Thread.activeCount(args) : #pre This can produce on a 4-core CPU an output like: #pre Without .parallel(args) it gives: #pre

Question-6667243
What is the best way to use the values stored in an Enum as String literals? For example: #pre Then later I could use Mode.mode1 to return its string representation as mode1 . Without having to keep calling Mode.model.toString(args) .

Question-26318569
I am getting following exception while running the tests. I am using Mockito for mocking. The hints mentioned by Mockito library are not helping. #pre Test Code from DomainTestFactory. When I run the following test, I see the exception #pre

Question-9297899
We can determine the length of an ArrayList<T> using its public method size(args) , like #pre Similarly we can determine the length of an Array object using the length property #pre Whereas the size(args) method of ArrayList is defined inside the ArrayList class, where is this length property of Array defined?

Question-31471444, answer-31471530
You should not. The INTEGER_ONE name is no more meaningful than 1. If however this value has some other meaning (for example, month in the year), then using a constant (like Calendar.FEBRUARY ) will make your code clearer. I can guess that this constant in Commons Math library was created in Java 1.4 when there were no Integer cache and autoboxing, so it had sense in terms that you may reuse the same Integer object (not primitive int ) in different places to save memory. So it was added for performance reasons, not for code clarity. Now it's obsolete: even if you need an Integer object, you can use Integer.valueOf(args) or implicit autoboxing and get the cached one.

Question-29691513, answer-29727412
The JLS describes a few special behaviors of what it calls constant variables , which are final variables (whether static or not) which are initialized with constant expressions of String or primitive type. Constant variables have a major difference with respect to binary compatibility: the values of constant variables become part of the class's API, as far as the compiler is concerned. An example: #pre Here, XFOO is a "constant variable" and YFOO is not, but they are otherwise equivalent. Class Z prints out each of them. Compile those classes, then disassemble them with javap -v X Y Z , and here is the output: Class X: #pre Class Y: #pre Class Z: #pre Things to notice in the disassembly, which tell you the differences between X and Y run deeper than syntactic sugar: #li XFOO has a ConstantValue attribute, signifying that its value is a compile-time constant. Whereas YFOO does not, and uses a static block with a putstatic instruction to initialize the value at runtime. #li The String constant StringLiteral has become part of class Z 's constant pool , but StringLiteral has not. #li Z.main uses the ldc (load constant) instruction to load StringLiteral onto the stack directly from its own constant pool, but it uses a getstatic instruction to load the value of Y.YFOO . Other differences you will find: #li If you change the value of XFOO and recompile X.java but not Z.java , you have a problem: class Z is still using the old value. If you change the value of YFOO and recompile Y.java , class Z uses the new value whether you recompile Z.java or not. #li If you delete the X.class file entirely, class Z still runs correctly. Z has no runtime dependency on X . Whereas if you delete the Y.class file, class Z fails to initialize with a ClassNotFoundException: Y . #li If you generate documentation for the classes with javadoc, the "Constant Field Values" page will document the value of XFOO , but not the value of YFOO . The JLS describes the above effects constant variables have on compiled class files in §13.1.3 : #blockquote And in §13.4.9 : #blockquote The upshot is that if your public library exposes any constant variables, you must never change their values if your new library version is otherwise supposed to be compatible with code compiled against old versions of the library. It won't necessarily cause an error, but the existing code will probably malfunction since it will have outdated ideas about the values of constants. (If your new library version needs for classes which use it to be recompiled anyway, then changing constants doesn't cause this problem.) Thus, initializing a constant with a block gives you more freedom to change its value, because it prevents the compiler embedding the value into other classes.

Question-28584669, answer-28584932
Your reasoning is that Double.POSITIVE_INFINITY should not be equal to itself because it is “likely” to have been obtained as the result of a loss of accuracy. This line of reasoning applies to all of floating-point. Any finite value can be obtained as the result of an inaccurate operation. That did not push the IEEE 754 standardization committee to define == as always evaluating to false for finite values, so why should infinities be different? As defined, == is useful for people who understand what it does (that is, test the floating-point values that have been obtained , and certainly not the values that should have been obtained with real computations). For anyone who understands that, and you need to understand it to use floating-point even for computations that do not involve infinity, having Double.POSITIVE_INFINITY == Double.POSITIVE_INFINITY evaluate to true is convenient, if only to test if the floating-point result of a floating-point computation is Double.POSITIVE_INFINITY . That leaves the question of why NaN can afford to have special behavior, and infinities should follow the same general principles as finite values. NaN is different from infinities: the underlying principle of the IEEE 754 standard is that values are exactly what they are, but the result of an operation can be approximated with respect to the real result, and in this case, the resulting floating-point value is obtained according to the rounding mode. Forget for an instant that 1.0 / 0.0 is defined as +inf, which is an annoyance in this discussion. Think for the moment of Double.POSITIVE_INFINITY only as the result of operations such as 1.0e100 / 1.0e-300 or Double.MAX_VALUE + Double.MAX_VALUE . For these operations, +inf is the closest approximation of the real result, just like for operations that produce a finite result. By contrast, NaN is the result you obtain when the operation doesn't make sense. It is defensible to have NaN behave specially, but inf is just an approximation of all the values too large to represent. In reality, 1.0 / 0.0 also produces +inf, but that should be considered an exception. It would have been just as coherent to define the result of that operation as NaN, but defining it as +inf was more convenient in the implementation of some algorithms. An example is provided page 10 in Kahan's notes . More details than most will wish for are in the article “Branch Cuts for Complex Elementary Functions, or Much Ado About Nothing's Sign Bit” . I would also interpret the existence in IEEE 754 of a “division by zero” flag separate from the NaN flag as recognition that the user may want to treat division by zero specially although it is not defined as producing NaN.

Question-27908213, answer-27908302
With strings you're going to want to use the equals method of Strings. That aside, you already have the enum that you could compare with the equality operator. Under what scenario would this arise? That being said, yes, the .equals method will return true if they are the same. I'm not sure about equality operator, and without looking it up, I can tell you that it's poor programming to use it if it is.

Question-23653778, answer-25564062
Try OnStart(args) method and just use View view = getView(args).findViewById(args); or Declare any View using getView(args).findViewById method in onStart(args) Declare click listener on view by anyView.setOnClickListener(args);

Question-28671903, answer-28672583
The behaviour is (somewhat) documented in the javadoc : #blockquote What this means in practice, when you call source.removeAll(args); : #li if the removals collection is of a smaller size than source , the remove method of HashSet is called, which is fast. #li if the removals collection is of equal or larger size than the source , then removals.contains is called, which is slow for an ArrayList. Quick fix: Collection<T> removals = new HashSet<T>(args); Note that there is an open bug that is very similar to what you describe. The bottom line seems to be that it is probably a poor choice but can't be changed because it is documented in the javadoc. For reference, this is the code of removeAll (in Java 8 - haven't checked other versions): #pre

Question-32175145, answer-32175175
Note that a . b and c are instances of primitive wrapper classes (such as Integer, Double, etc...). These classes are final and cannot be extended, so you can't override their equals implementation. Therefore a.equals(args) will always return true, since those classes implement equals properly.

Question-31316581, answer-31327420
If type inference produces a single upper bound for a type variable, typically the upper bound is chosen as the solution. For example, if T<<Number , the solution is T=Number . Although Integer , Float etc. could also satisfy the constraint, there's no good reason to choose them over Number . That was also the case for throws T in java 5-7: T<<Throwable => T=Throwable . (Sneaky throw solutions all had explicit <RuntimeException> type arguments, otherwise <Throwable> is inferred.) In java8, with the introduction of lambda, this becomes problematic. Consider this case #pre If we invoke with an empty lambda, what would T be inferred as? invoke(args); The only constraint on T is an upper bound Throwable . In earlier stage of java8, T=Throwable would be inferred. See this report I filed. But that is pretty silly, to infer Throwable , a checked exception, out of an empty block. A solution was proposed in the report (which is apparently adopted by JLS) - #pre i.e. if the upper bound is Exception or Throwable , choose RuntimeException as the solution. In this case, there is a good reason to choose a particular subtype of the upper bound.

Question-27683759, answer-27684040
That line creates an empty list of strings by calling a static method with a generic type parameter. Inside the Collections class, there is a static method emptyList declared like: #pre This has a generic type parameter T . We call call this method by using: List<T> list = Collections.emptyList(args); and T is infered to be a String because of the type of list . We can also specify the type of T by putting it in angle brackets when calling emptyList . This may be needed if we want a more specific type than is inferred: List<T> list = Collections.<String>emptyList(args); emptyList<T>(args) is not correct because that placement is only valid when creating instances of generic classes, not calling methods. When using new there are two possible type parameters, the ones before the class name are for the constructor only, and the ones after the class name are for the whole instance, so with the class: #pre We can call its constructor where A is String and B is Integer like: MyClass<T> a = new<T>MyClass<T>(args); or by using type inference: MyClass<T> a = new MyClass<T>(args); See also: #li Generic Methods #li Type Inference

Question-20331163
I have a string " 11/15/2013 08:00:00 ", I want to format it to " 11/15/2013 ", what is the correct DateTimeFormatter pattern? I've tried many and googled and still unable to find the correct pattern. edit: I am looking for Joda-Time DateTimeFormatter , not Java's SimpleDateFormat..

Question-28770822, answer-28816219
Looking at the issue and fix, it looks like this has been done to resolve a handling of a header file generation for special classes in jigsaw Jigsaw is a module system designated to use in Java SE Platform and JDK. More details here Here is a corresponding changeset . You can see a comment, #blockquote From the changeset I see that for the sake of purpose in addition to java.lang.Integer and java.lang.Long , also some properties in java.net.SocketOptions , sun.nio.ch.IOStatus , java.io.FileSystem have been changed to @Native . So I assume only those were needed to solve the dependency with jigsaw.

Question-10827872, answer-30749407
replace(args) method doesn't uses regex pattern whereas replaceAll(args) method uses regex pattern. So replace(args) performs faster than replaceAll(args) .

Question-24676877, answer-24681959
I have a few points to add to Brian Goetz' excellent answer . It's quite common to return a Stream from a "getter" style method call. See the Stream usage page in the Java 8 javadoc and look for "methods... that return Stream" for the packages other than java.util.Stream . These methods are usually on classes that represent or can contain multiple values or aggregations of something. In such cases, APIs typically have returned collections or arrays of them. For all the reasons that Brian noted in his answer, it's very flexible to add Stream-returning methods here. Many of these classes have collections- or array-returning methods already, because the classes predate the Streams API. If you're designing a new API, and it makes sense to provide Stream-returning methods, it might not be necessary to add collection-returning methods as well. Brian mentioned the cost of "materializing" the values into a collection. To amplify this point, there are actually two costs here: the cost of storing values in the collection (memory allocation and copying) and also the cost of creating the values in the first place. The latter cost can often be reduced or avoided by taking advantage of a Stream's laziness-seeking behavior. A good example of this are the APIs in java.nio.file.Files : #pre Not only does readAllLines have to hold the entire file contents in memory in order to store it into the result list, it also has to read the file to the very end before it returns the list. The lines method can return almost immediately after it has performed some setup, leaving file reading and line breaking until later when it's necessary -- or not at all. This is a huge benefit, if for example, the caller is interested only in the first ten lines: List<T> firstTen = Files.lines(args).limit(args).collect(args); Of course considerable memory space can be saved if the caller filters the stream to return only lines matching a pattern, etc. An idiom that seems to be emerging is to name stream-returning methods after the plural of the name of the things that it represents or contains, without a get prefix. Also, while stream(args) is a reasonable name for a stream-returning method when there is only one possible set of values to be returned, sometimes there are classes that have aggregations of multiple types of values. For example, suppose you have some object that contains both attributes and elements. You might provide two stream-returning APIs: #pre

Question-22463062
Java 8 added a new API for working with dates and times (JSR 310). I have date and time as string (e.g. StringLiteral ). How can I obtain a LocalDateTime instance from the given string? After I finished working with the LocalDateTime object: How can I then convert the LocalDateTime instance back to a string with the same format as shown above?

Question-16148575, answer-16148593
Use Integer instead. HashMap<T> myMap = new HashMap<T>(args); Java will automatically autobox your int primitive values to Integer objects. Read more about autoboxing from Oracle Java documentations.

Question-8777257, answer-8777311
The Arrays.equals(args) : check if both arrays contain the same number of elements, and all corresponding pairs of elements in the two arrays are equal. The array1.equals(args) : compare the object to another object and return true only if the reference of the two object are equal as in the Object.equals(args)

Question-5243754, answer-5243798
#li getParameter(args) returns http request parameters. Those passed from the client to the server. For example http://example.com/servlet?parameter=1 . Can only return String #li getAttribute(args) is for server-side usage only - you fill the request with attributes that you can use within the same request. For example - you set an attribute in a servlet, and read it from a JSP. Can be used for any object, not just string.

Question-32294367, answer-32378895
#blockquote Yes and No. I explain: #li Referring to shared memory: Different threads in a Java process share the whole heap, therefore threads can interact in a huge number of planned and unplanned ways. However objects in the stack (e.g. a context you pass down to called method) or a ThreadLocal are their own thread's (unless they start sharing references). #li Crashing: If a thread crashes in Java (a Throwable is propagated into Thread.run(args) , or something gets looped or blocked), that mishap might not affect other threads (e.g. a pool of connections in a server will continue to operate). However as different threads interact. Other threads will easily get stranded if one of them ends abnormally (e.g. one thread trying to read from an empty pipe from another thread which did not close its end). So unless the developers are highly paranoid careful, it is very likely that side effects will occur. I doubt that any other paradigm intends threads to operate as totally independent islands. They must share information and coordinate somehow. And then there will be the chance to mess things up. It is just they will take a more defensive approach that "gives you less rope to hang yourself" (same idiom as with pointers).

Question-18723596, answer-18723666
You can cast null to any reference type without getting any exception. println method does not throw null pointer because it first checks whether the object is null or not. If null then it simply prints the string StringLiteral . Otherwise it will call the toString method of that object. Adding more details: Internally print methods call String.valueOf(args) method on the input object. And in valueOf method, this check helps to avoid null pointer excpeiton: return(args) ? StringLiteral : obj.toString(args); For rest of your confusion, calling any method on a null object should throw a null pointer exception, if not a special case.

Question-32334319
I am using JDK-8 (x64). For Arrays.sort I found the following in the Java documentation: #blockquote For Collections.sort I found this: #blockquote If Collections.sort uses an array, why doesn't it just call Arrays.sort or use dual-pivot QuickSort ? Why use Mergesort ?

Question-6802483, answer-6802523
There is no direct way to do this - Java has no Map literals (yet - I think they were proposed for Java 8). Some people like this: #pre This creates an anonymous subclass of HashMap, whose instance initializer puts these values. (By the way, a map can't contain twice the same value, your second put will overwrite the first one. I'll use different values for the next examples.) The normal way would be this (for a local variable): #pre If your test map is an instance variable, put the initialization in a constructor or instance initializer: #pre If your test map is a class variable, put the initialization in a static initializer: #pre If you want your map to never change, you should after the initialization wrap your map by Collections.unmodifiableMap(args) . You can do this in a static initializer too: #pre (I'm not sure if you can now make test final ... try it out and report here.)

Question-28459498, answer-28459604
Background While the question appears simple, the actual answer requires some background to make sense. If you want to skip to the conclusion, scroll down... Pick your comparison point - Basic functionality Using basic concepts, C#'s IEnumerable concept is more closely related to Java's Iterable , which is able to create as many Iterators as you want. IEnumerables create IEnumerators . Java's Iterable create Iterators The history of each concept is similar, in that both IEnumerable and Iterable have a basic motivation to allow 'for-each' style looping over the members of data collections. That's an oversimplification as they both allow more than just that, and they also arrived at that stage via different progressions, but it is a significant common feature regardless. Let's compare that feature: in both languages, if a class implements the IEnumerable / Iterable , then that class must implement at least a single method (for C#, it's GetEnumerator and for Java it's iterator(args) ). In each case, the instance returned from that ( IEnumerator / Iterator ) allows you to access the current and subsequent members of the data. This feature is used in the for-each language syntax. Pick your comparison point - Enhanced functionality IEnumerable in C# has been extended to allow a number of other language features ( mostly related to Linq ). Features added include selections, projections, aggregations, etc. These extensions have a strong motivation from use in set-theory, similar to SQL and Relational Database concepts. Java 8 has also had functionality added to enable a degree of functional programming using Streams and Lambdas. Note that Java 8 streams are not primarily motivated by set theory, but by functional programming. Regardless, there are a lot of parallels. So, this is the second point. The enhancements made to C# were implemented as an enhancement to the IEnumerable concept. In Java, though, the enhancements made were implemented by creating new base concepts of Lambdas and Streams, and then also creating a relatively trivial way to convert from Iterators and Iterables to Streams, and visa-versa. So, comparing IEnumerable to Java's Stream concept is incomplete. You need to compare it to the combined Streams and Collections API's in Java. In Java, Streams are not the same as Iterables, or Iterators Streams are not designed to solve problems the same way that iterators are: #li Iterators are a way of describing the sequence of data. #li Streams are a way of describing a sequence of data transformations. With an Iterator , you get a data value, process it, and then get another data value. With Streams, you chain a sequence of functions together, then you feed an input value to the stream, and get the output value from the combined sequence. Note, in Java terms, each function is encapsulated in a single Stream instance. The Streams API allows you to link a sequence of Stream instances in a way that chains a sequence of transformation expressions. In order to complete the Stream concept, you need a source of data to feed the stream, and a terminal function that consumes the stream. The way you feed values in to the stream may in fact be from an Iterable , but the Stream sequence itself is not an Iterable , it is a compound function. A Stream is also intended to be lazy, in the sense that it only does work when you request a value from it. Note these significant assumptions and features of Streams: #li A Stream in Java is a transformation engine, it transforms a data item in one state, to being in another state. #li streams have no concept of the data order or position, the simply transform whatever they are asked to. #li streams can be supplied with data from many sources, including other streams, Iterators, Iterables, Collections, #li you cannot "reset" a stream, that would be like "reprogramming the transformation". Resetting the data source is probably what you want. #li there is logically only 1 data item 'in flight' in the stream at any time (unless the stream is a parallel stream, at which point, there is 1 item per thread). This is independent of the data source which may have more than the current items 'ready' to be supplied to the stream, or the stream collector which may need to aggregate and reduce multiple values. #li Streams can be unbound (infinite), limited only by the data source, or collector (which can be infinite too). #li Streams are 'chainable', the output of filtering one stream, is another stream. Values input to and transformed by a stream can in turn be supplied to another stream which does a different transformation. The data, in its transformed state flows from one stream to the next. You do not need to intervene and pull the data from one stream and plug it in to the next. C# Comparison When you consider that a Java Stream is just a part of a supply, stream, and collect system, and that Streams and Iterators are often used together with Collections, then it is no wonder that it is hard to relate to the same concepts which are almost all embedded in to a single IEnumerable concept in C#. Parts of IEnumerable (and close related concepts) are apparent in all of the Java Iterator, Iterable, Lambda, and Stream concepts. There are small things that the Java concepts can do that are harder in IEnumerable, and visa-versa. Conclusion #li There's no design problem here, just a problem in matching concepts between the languages. #li Streams solve problems in a different way #li Streams add functionality to Java (they add a different way of doing things, they do not take functionality away) Adding Streams gives you more choices when solving problems, which is fair to classify as 'enhancing power', not 'reducing', 'taking away', or 'restricting' it. Why are Java Streams once-off? This question is misguided, because streams are function sequences, not data. Depending on the data source that feeds the stream, you can reset the data source, and feed the same, or different stream. Unlike C#'s IEnumerable, where an execution pipeline can be executed as many times as we want, in Java a stream can be 'iterated' only once. Comparing an IEnumerable to a Stream is misguided. The context you are using to say IEnumerable can be executed as many times as you want, is best compared to Java Iterables , which can be iterated as many times as you want. A Java Stream represents a subset of the IEnumerable concept, and not the subset that supplies data, and thus cannot be 'rerun'. Any call to a terminal operation closes the stream, rendering it unusable. This 'feature' takes away a lot of power. The first statement is true, in a sense. The 'takes away power' statement is not. You are still comparing Streams it IEnumerables. The terminal operation in the stream is like a 'break' clause in a for loop. You are always free to have another stream, if you want, and if you can re-supply the data you need. Again, if you consider the IEnumerable to be more like an Iterable , for this statement, Java does it just fine. I imagine the reason for this is not technical. What were the design considerations behind this strange restriction? The reason is technical, and for the simple reason that a Stream a subset of what think it is. The stream subset does not control the data supply, so you should reset the supply, not the stream. In that context, it is not so strange. QuickSort example Your quicksort example has the signature: IEnumerable<T> QuickSort(args) You are treating the input IEnumerable as a data source: IEnumerable<T> lt = ints.Where(args); Additionally, return value is IEnumerable too, which is a supply of data, and since this is a Sort operation, the order of that supply is significant. If you consider the Java Iterable class to be the appropriate match for this, specifically the List specialization of Iterable , since List is a supply of data which has a guaranteed order or iteration, then the equivalent Java code to your code would be: #pre Note there is a bug (which I have reproduced), in that the sort does not handle duplicate values gracefully, it is a 'unique value' sort. Also note how the Java code uses data source ( List ), and stream concepts at different point, and that in C# those two 'personalities' can be expressed in just IEnumerable . Also, although I have use List as the base type, I could have used the more general Collection , and with a small iterator-to-Stream conversion, I could have used the even more general Iterable

Question-21947452
I generated two matrices of 1000 x 1000 : First Matrix: O and # . Second Matrix: O and B . Using the following code, the first matrix took 8.52 seconds to complete: #pre With this code, the second matrix took 259.152 seconds to complete: #pre What is the reason behind the dramatically different run times? As suggested in the comments, printing only System.out.print(args); takes 7.8871 seconds, whereas System.out.print(args); gives still printing... . As others who pointed out that it works for them normally, I tried Ideone.com for instance, and both pieces of code execute at the same speed. Test Conditions: #li I ran this test from Netbeans 7.2, with the output into its console #li I used System.nanoTime(args) for measurements

Question-24885223
I don't know whether I am asking the right question. I was exploring RecyclerView and I was surprised to see that RecyclerView does not have onItemClickListener(args) . Because RecyclerView extends #blockquote and ListView extends #blockquote . However I solved my problem by writing onClick in my RecyclerView.Adapter : #pre But still I want to know why Google removed onItemClickListener(args) ? Is there a performance issue or something else?

Question-14846920, answer-14846964
For one, you can get away with reference sharing. A new HashMap(args) etc will require an allocated object, and possibly some extra elements to hold the data, but you only need one copy of an immutable empty collection (list, set, map, or any other such). This makes it an obvious choice when a method you're calling needs to accept a Map but does not need to edit it. I suggest checking out Josh Bloch's Effective Java , which lists some very nice attributes of immutable objects (including thread safety).

Question-24609564, answer-24609841
If you will read comment above the code, It is mentioned that... If the caller is not a ForkJoinTask , this method is behaviorally equivalent to #pre So it is just another form to implement above code in else part...!! In Style notes it is mentioned that, #blockquote And if you will see implementation of ManagedLocker#isReleasable , It is updating the lock and returns true if blocking is unnecessary. Interpretation : Blank while loops are used to provide an interrupt until some condition reset to true/false. Here, do { } while(args) is a blocker/interrupt until blocker.block(args) will be true when blocker.isReleasable(args) is false . Loop will continue execution while blocker is not releasable ( !blocker.isReleasable(args) ) and blocker is not blocked !! Execution will be out of loop as soon as blocker.block(args) will set to true. Note that, do{ } while(args) does not update CAS variable, but it guarantee that program will wait until variable gets updated (force to wait until variable gets updated).

Question-17489250, answer-17489410
Java String is Special #blockquote For example #pre #img Note : String literals are stored in a common pool. This facilitates sharing of storage for strings with the same contents to conserve storage. String objects allocated via new operator are stored in the heap , and there is no sharing of storage for the same contents.

Question-33477695, answer-33477803
The java.time API in general does have nanosecond precision. For example: #pre Output: 2015-11-02T12:38:00,123456789+0000 However, it's the clock value returned by OffsetDateTime.now(args) which is returning a value which only has milliseconds. From Clock implementation in Java 8: #blockquote So there's nothing inherently imprecise here - just the default implementation of Clock using System.currentTimeMillis(args) . You could potentially create your own more precise subclass. However, you should note that adding more precision without adding more accuracy probably isn't terribly useful. (There are times when it might be, admittedly...)

Question-28671903
I have a set – a HashSet I want to remove some items from it… none of the items in the "removals" collection will be in the original set. I specify the size of the "source" set and the size of the "removals" collection on the command line, and build both of them. The source set contains only non-negative integers; the removals set contains only negative integers. I measure how long it takes to remove all the elements using System.currentTimeMillis(), which isn’t the world most accurate stopwatch but is more than adequate in this case, as you’ll see. Here’s the code: #pre Let’s start off by giving it an easy job: a source set of 100 items, and 100 to remove: #pre Okay, That's fast as I expected. Next i tried source of one million items and 300,000 items to remove? #pre That still seems pretty speedy. Now make it a bit easier – 300,000 source items and 300,000 removals: #pre Nearly three minutes? Really confused !! can some one explain why this is happening.

Question-10977992
#pre We can use Iterator to traverse a Set or a List or a Map . But ListIterator can only be used to traverse a List , it can't traverse a Set . Why? I know that the main difference is that with iterator we can travel in only one direction but with ListIterator we can travel both directions. Are there any other differences? And any advantages of ListIterator over Iterator ?

Question-8725387, answer-8725518
Because the concept of a List is incompatible with the concept of an automatically sorted collection. The point of a List is that after calling list.add(args) , a call to list.get(args) will return elem . With an auto-sorted list, the element could end up in an arbitrary position.

Question-32323081, answer-32323641
First of all, you don' have to overload :D - overloading is never a necessity; use 2 different method names, e.g. foo and fooX Secondly, I don't see why you need 2 methods here. If you want to handle checked and unchecked exceptions differently, it can be done at runtime. To achieve "exception transparency", you can do #pre Finally, disambiguity can be achieved throw lambda return type; the compiler uses the return type as if using an argument type for choosing the most specific method. This gives us the idea to wrap the value together with the exception type, as Result<T> , a "monad" as they say. #pre

Question-11411022, answer-34052602
The best way is the clearest way: * Thread.currentThread(args) == Looper.getMainLooper(args).getThread(args) Or, if the runtime platform is API level 23 (Marshmallow 6.0) or higher: Looper.getMainLooper(args).isCurrentThread(args) See the Looper API . Note that calling Looper.getMainLooper(args) involves synchonization (see the source ). You might want to avoid the overhead by storing the return value and reusing it. * credit greg7gkb

Question-9297899, answer-25816501
Even though this is not a direct answer to the question, it is an addition to the .length vs .size(args) argument. I was researching something related to this question so when I came across it I noticed that the definition(s) provided here #blockquote is not "exactly" correct. The field length contains the number of available places to put a component, not the number of components present in the array. So it represents the total available memory allocated to that array, not how much of that memory is filled. #img Example: #pre Output: #pre However, the .size(args) property of the ArrayList does give the number of elements in the list: #pre Output: #pre

Question-32475166, answer-32476850
When you think about the type of the operands, the problem becomes more apparent: this.method != null ? this.method : this.constructor has as type the most specialized common type of both the operands, i.e. the most specialized type common to both this.method and this.constructor . In Java 7 this is java.lang.reflect.Member , however the Java 8 class library introduces a new type java.lang.reflect.Executable which is more specialized than the generic Member . Hence with a Java 8 class library the result type of the ternary expression is Executable rather than Member . Some (pre-release) versions of the Java 8 compiler seem to have produced an explicit reference to Executable inside generated code when compiling the ternary operator. This would trigger a class load, and thus in turn a ClassNotFoundException at runtime when running with a class library < JDK 8, because Executable only exists for JDK ≥ 8. As noted by Tagir Valeev in this answer , this is actually a bug in pre-release versions of JDK 8 and has since been fixed, so both the if-else workaround and the explanatory comment are now obsolete. Additional note: One might come to the conclusion that this compiler bug was present before Java 8. However, the byte code generated for the ternary by OpenJDK 7 is the same as the byte code generated by OpenJDK 8. In fact, the type of the expression goes completely unmentioned at runtime, the code is really only test, branch, load, return without any additional checks going on. So rest assured that this is not a problem (anymore) and indeed seems to have been a temporary problem during development of Java 8.

Question-12539365
I write jUnit test cases for 3 purposes: #li To ensure that my code satisfies all of the required functionality, under all (or most of) the input combinations/values. #li To ensure that I can change the implementation, and rely on JUnit test cases to tell me that all my functionality is still satisfied. #li As a documentation of all the use cases my code handles, and act as a spec for refactoring - should the code ever need to be rewritten. (Refactor the code, and if my jUnit tests fail - you probably missed some use case). I do not understand why or when Mockito.verify(args) should be used. When I see verify(args) being called, it is telling me that my jUnit is becoming aware of the implementation. (Thus changing my implementation would break my jUnits, even though my functionality was unaffected). I'm looking for: #li What should be the guidelines for appropriate usage of Mockito.verify(args) ? #li Is it fundamentally correct for jUnits to be aware of, or tightly coupled to, the implementation of the class under test?

Question-6470651, answer-6540248
Below there will be a non-obvious case where Java leaks, besides the standard case of forgotten listeners, static references, bogus/modifiable keys in hashmaps, or just threads stuck without any chance to end their life-cycle. #li File.deleteOnExit(args) - always leaks the string, if the string is a substring, the leak is even worse (the underlying char[] is also leaked) - in Java 7 substring also copies the char[] , so the later doesn't apply ; @Daniel, no needs for votes, though. I'll concentrate on threads to show the danger of unmanaged threads mostly, don't wish to even touch swing. #li Runtime.addShutdownHook and not remove... and then even with removeShutdownHook due to a bug in ThreadGroup class regarding unstarted threads it may not get collected, effectively leak the ThreadGroup. JGroup has the leak in GossipRouter. #li Creating, but not starting, a Thread goes into the same category as above. #li Creating a thread inherits the ContextClassLoader and AccessControlContext , plus the ThreadGroup and any InheritedThreadLocal , all those references are potential leaks, along with the entire classes loaded by the classloader and all static references, and ja-ja. The effect is especially visible with the entire j.u.c.Executor framework that features a super simple ThreadFactory interface, yet most developers have no clue of the lurking danger. Also a lot of libraries do start threads upon request (way too many industry popular libraries). #li ThreadLocal caches; those are evil in many cases. I am sure everyone has seen quite a bit of simple caches based on ThreadLocal, well the bad news: if the thread keeps going more than expected the life the context ClassLoader, it is a pure nice little leak. Do not use ThreadLocal caches unless really needed. #li Calling ThreadGroup.destroy(args) when the ThreadGroup has no threads itself, but it still keeps child ThreadGroups. A bad leak that will prevent the ThreadGroup to remove from its parent, but all the children become un-enumerateable. #li Using WeakHashMap and the value (in)directly references the key. This is a hard one to find without a heap dump. That applies to all extended Weak/SoftReference that might keep a hard reference back to the guarded object. #li Using java.net.URL with the HTTP(S) protocol and loading the resource from(!). This one is special, the KeepAliveCache creates a new thread in the system ThreadGroup which leaks the current thread's context classloader. The thread is created upon the first request when no alive thread exists, so either you may get lucky or just leak. The leak is already fixed in Java 7 and the code that creates thread properly removes the context classloader. There are few more cases ( like ImageFetcher , also fixed ) of creating similar threads. #li Using InflaterInputStream passing new java.util.zip.Inflater(args) in the constructor ( PNGImageDecoder for instance) and not calling end(args) of the inflater. Well, if you pass in the constructor with just new , no chance... And yes, calling close(args) on the stream does not close the inflater if it's manually passed as constructor parameter. This is not a true leak since it'd be released by the finalizer... when it deems it necessary. Till that moment it eats native memory so badly it can cause Linux oom_killer to kill the process with impunity. The main issue is that finalization in Java is very unreliable and G1 made it worse till 7.0.2. Moral of the story: release native resources as soon as you can; the finalizer is just too poor. #li The same case with java.util.zip.Deflater . This one is far worse since Deflater is memory hungry in Java, i.e. always uses 15 bits (max) and 8 memory levels (9 is max) allocating several hundreds KB of native memory. Fortunately, Deflater is not widely used and to my knowledge JDK contains no misuses. Always call end(args) if you manually create a Deflater or Inflater . The best part of the last two: you can't find them via normal profiling tools available. (I can add some more time wasters I have encountered upon request.) Good luck and stay safe; leaks are evil!

Question-5011932
I am storing a SQL query in my strings.xml file and I want to use String.Format to build the final string in code. The SELECT statement uses a like, something like this: SELECT Field1, Field2 FROM mytable WHERE Field1 LIKE '%something%' In order to format that I replace 'something' with %1$s so it becomes: SELECT Field1, Field2 FROM mytable WHERE Field1 LIKE \'%%1$s%\' I escape the single quotes with the backslash. However I am not able to escape the % sign. How can I include a like statement in my strings.xml file?

Question-8172420, answer-8172444
Try this: Character.toString(args) or just this: aChar + StringLiteral

Question-22182669, answer-22223113
The most common cause of StackOverFlowError is excessively deep or infinite recursion. For instance: #pre In Java: There are two areas in memory the heap and stack. The stack memory is used to store local variables and function call, while heap memory is used to store objects in Java. If there is no memory left in stack for storing function call or local variable, JVM will throw java.lang.StackOverFlowError while if there is no more heap space for creating object, JVM will throw java.lang.OutOfMemoryError

Question-15430247, answer-15430259
If you know in advance what the size of the ArrayList is going to be, it is more efficient to specify the initial capacity. If you don't do this, the internal array will have to be repeatedly reallocated as the list grows. The larger the final list, the more time you save by avoiding the reallocations. That said, even without pre-allocation, inserting n elements at the back of an ArrayList is guaranteed to take total O(args) time. In other words, appending an element is an amortized constant-time operation. This is achieved by having each reallocation increase the size of the array exponentially, typically by a factor of 1.5 . With this approach, the total number of operations can be shown to be O(n) .

Question-31170459
I was testing boundary conditions on some code involving a BigDecimal , and I noticed that when a BigDecimal is initialized with the String StringLiteral it behaves unexpectedly. It seems to have a value between 0 and 1e-2147483647 . When I try calling intValue(args) , I get a NegativeArraySizeException . I should note that 2147483647 is the max value of an integer on my system. Am I doing something wrong, or is this a problem with BigDecimal ? #pre

Question-28584669, answer-28588854
The correct answer is a simple "because the standard (and the docs ) say so". But I'm not gonna be cynical because it's obvious that's not what you are after. In addition to the other answers here, I'll try to relate the infinities to saturating arithmetic. Other answers have already stated that the reason the comparisons on NaNs result in true , so I'm not gonna beat a dead horse. Let's say I have a saturating integer that represents grayscale colors. Why am I using saturating arithmetic? Because anything brighter than white is still white, and anything darker than black is still black (except orange ). That means BLACK - x == BLACK and WHITE + x == WHITE . Makes sense? Now, let's say we want to represent those grayscale colors with a (signed) 1s complement 8-bit integer where BLACK == -127 and WHITE == 127 . Why 1s complement? Because it gives us a signed zero like IEEE 754 floating point . And, because we are using saturating arithmetic, -127 - x == -127 and 127 + x == 127 . How does this relate to floating point infinities? Replace the integer with floating point, BLACK with NEGATIVE_INFINITY , and WHITE with POSITIVE_INFINITY and what do you get? NEGATIVE_INFINITY - x == NEGATIVE_INFINITY and POSITIVE_INFINITY + x == POSITIVE_INFINITY . Since you used POSITIVE_INFINITY , I'll use it also. First we need a class to represent our saturating integer-based color; let's call it SaturatedColor and assume it works like any other integer in Java. Now, let's take your code and replace double with our own SaturatedColor and Double.POSITIVE_INFINITY with SaturatedColor.WHITE : #pre As we established above, SaturatedColor.WHITE (just WHITE above) is 127 , so let's do that here: #pre Now we take the System.out.println statements you used and replace a and b with their value (values?): #pre It should be obvious what this will print.

Question-16252269, answer-30210459
Collections.sort allows you to pass an instance of a Comparator which defines the sorting logic. So instead of sorting the list in natural order and then reversing it, one can simply pass Collections.reverseOrder(args) to sort in order to sort the list in reverse order: #pre As mentioned by @Marco13, apart from being more idiomatic (and possibly more efficient), using the reverse order comparator makes sure that the sort is stable (meaning that the order of elements will not be changed when they are equal according to the comparator, whereas reversing will change the order)

Question-5031614, answer-5032837
If you want to use equals(args)/hashCode(args) for your Sets, in the sense that the same entity can only be in there once, then there is only one option: Option 2. That's because a primary key for an entity by definition never changes (if somebody indeed updates it, it's not the same entity anymore) You should take that literally: Since your equals(args)/hashCode(args) are based on the primary key, you must not use these methods, until the primary key is set. So you shouldn't put entities in the set, until they're assigned a primary key. (Yes, UUIDs and similar concepts may help to assign primary keys early.) Now, it's theoretically also possible to achieve that with Option 3, even though so-called "business-keys" have the nasty drawback that they can change: "All you'll have to do is delete the already inserted entities from the set(s), and re-insert them." That is true - but it also means, that in a distributed system, you'll have to make sure, that this is done absolutely everywhere the data has been inserted to (and you'll have to make sure, that the update is performed, before other things occur). You'll need a sophisticated update mechanism, especially if some remote systems aren't currently reachable... Option 1 can only be used, if all the objects in your sets are from the same Hibernate session. The Hibernate documentation makes this very clear in chapter 13.1.3. Considering object identity : #blockquote It continues to argue in favor of Option 3: #blockquote This is true, if you #li cannot assign the id early (e.g. by using UUIDs) #li and yet you absolutely want to put your objects in sets while they're in transient state. Otherwise, you're free to choose Option 2. Then it mentions the need for a relative stability: #blockquote This is correct. The practical problem I see with this is: If you can't guarantee absolute stability, how will you be able to guarantee stability "as long as the objects are in the same Set". I can imagine some special cases (like using sets only for a conversation and then throwing it away), but I would question the general practicability of this. Short version: #li Option 1 can only be used with objects within a single session. #li If you can, use Option 2. (Assign PK as early as possible, because you can't use the objects in sets until the PK is assigned.) #li If you can guarantee relative stability, you can use Option 3. But be careful with this.

Question-24649842, answer-24649939
Try adding a Thread.sleep(args); call within your run(args) method... Basically it's the difference between scheduling something based on when the previous execution ends and when it (logically) starts . For example, suppose I schedule an alarm to go off with a fixed rate of once an hour, and every time it goes off, I have a cup of coffee, which takes 10 minutes. Suppose that starts at midnight, I'd have: #pre If I schedule with a fixed delay of one hour, I'd have: #pre Which one you want depends on your task.
Question-31445024, answer-31871515
Autoboxing is absolutely implemented using valueOf(args) ...in the OpenJDK. If that's your implementation, read on... if not, skip to below. #pre Java documentation states that Boolean.valueOf(args) always returns Boolean.TRUE or Boolean.FALSE , therefore your reference comparisons in these cases will succeed. ((Integer)1) == Integer.valueOf(args) For this particular example, under the OpenJDK implementation with default settings, it will probably work by virtue of the fact that you picked a value < 128 which is cached at startup (although this can be overridden as a commandline arg). It may also work for larger values if it's frequently used enough to be cached. Unless you're working under "safe" assumptions about the Integer cache, don't expect the reference comparison to be an equality. Long , Short , Character and Byte incidentally implement this caching too, but unlike Integer , it's not tunable. Byte will always work if you're comparing autobox/ valueOf(args) references since obviously, you can't go out of range. Float and Double will unsurprisingly always create a new instance. Now, in purely generic terms? See this section of the JLS - you MUST be given equal references for boolean and any int or char within the -128 to 127 range. There are no guarantees for anything else.

Question-20331163, answer-20331241
I have a very dumb but working option. if you have the String fullDate = "11/15/2013 08:00:00"; String finalDate = fullDate.split(args)[0]; That should work easy and fast. :)

Question-22740464, answer-37436520
Just do: Stream.of(args).flatMap(args); where identity(args) is a static import of Function.identity(args) . Concatenating multiple streams into one stream is the same as flattening a stream. However, unfortunately, for some reason there is no flatten(args) method on Stream , so you have to use flatMap(args) with the identity function.
Question-13102045, answer-24907860
Instead of input.nextLine(args) use input.next(args) , that should solve the problem. Modified code: #pre

Question-29815636, answer-29815698
The first form is called Javadoc . You use this when you're writing formal APIs for your code, which are generated by the javadoc tool. For an example, the Java 7 API page uses Javadoc and was generated by that tool. Some common elements you'd see in Javadoc include: #li @param : this is used to indicate what parameters are being passed to a method, and what value they're expected to have #li @return : this is used to indicate what result the method is going to give back #li @throws : this is used to indicate that a method throws an exception or error in case of certain input #li @since : this is used to indicate the earliest Java version this class or function was available in As an example, here's Javadoc for the compare method of Integer : #pre The second form is a block (multi-line) comment. You use this if you want to have multiple lines in a comment. I will say that you'd only want to use the latter form sparingly ; that is, you don't want to overburden your code with block comments that don't describe what behaviors the method/complex function is supposed to have. Since Javadoc is the more descriptive of the two, and you can generate actual documentation as a result of using it, using Javadoc would be more preferable to simple block comments.

Question-5192512, answer-5192545
Edit Updated to bring in feedback. So two ways that work: #li Use StringBulderObj.setLength(args) . #li Allocate a new one instead of clearing the buffer

Question-7283338, answer-7283475
Because any particular implementation of Set may or may not be random access . You can always get an iterator and step through the Set, using the iterators' next(args) method to return the result you want once you find the equal element. This works regardless of the implementation. If the implementation is NOT random access (picture a linked-list backed Set), a get(args) method in the interface would be deceptive, since it would have to iterate the collection to find the element to return, and a get(args) would seem to imply this would be necessary, that the Set could jump directly to the element to get. contains(args) may or may not have to do the same thing, of course, depending on the implementation, but the name doesn't seem to lend itself to the same sort of misunderstandings.

Question-14491966
I made a class called QuickRandom , and its job is to produce random numbers quickly. It's really simple: just take the old value, multiply by a double , and take the decimal part. Here is my QuickRandom class in its entirety: #pre And here is the code I wrote to test it: #pre It is a very simple algorithm that simply multiplies the previous double by a "magic number" double. I threw it together pretty quickly, so I could probably make it better, but strangely, it seems to be working fine. This is sample output of the commented-out lines in the main method: #pre Hm. Pretty random. In fact, that would work for a random number generator in a game. Here is sample output of the non-commented out part: #pre Wow! It performs almost 4 times faster than Math.random . I remember reading somewhere that Math.random used System.nanoTime(args) and tons of crazy modulus and division stuff. Is that really necessary? My algorithm performs a lot faster and it seems pretty random. I have two questions: #li Is my algorithm "good enough" (for, say, a game, where really random numbers aren't too important)? #li Why does Math.random do so much when it seems just simple multiplication and cutting out the decimal will suffice?

Question-4871051, answer-20810612
I'm on Linux and get same result for both of these approaches: #pre Paths.get("") docs System.getProperty("user.dir") docs

Question-5439529, answer-5439600
As an alternative to trying to parse the string and catching NumberFormatException , you could use a regex; e.g. #pre This is likely to be faster, especially if you precompile and reuse the regex. However, the catch is that Integer.parseInt(args) will still fail if str represents a number that is outside range of legal int values.

Question-30217236, answer-30219144
Why this should be problem in the first place is kind of nebulous to me. I suspect you've instead misunderstood something about the ways in which the type system is useful. What can we do with a <T> void x(args) ? Well, not a whole lot. Inside the body of x , T is the same as Object , so we could only do something like call toString on a and b to print them. There's really no practical reason a and b must have the same type. Just that they have some type in common, and that type is Object or a subtype of it. In fact, there's no clear reason why <T> void x(args) actually needs to be generic at all. #li The method body doesn't care what the actual types of a and b are because it couldn't use them anyway. #li The call site doesn't care what the actual types of a and b are because x is a void method so it's a black hole. It's more typical for a method to have a result, like <T> List<T> Arrays.asList(args) : // This will cause a compile error because // the type inferred must be compatible // with the return assignment. List<T> r = Arrays.asList(args); Or a bound: #pre Or a bound which asserts some kind of relation: #pre

Question-20877086, answer-20877283
The Integer class has a static cache, that stores 256 special Integer objects - one for every value between -128 and 127. With that in mind, consider the difference between these three. new Integer(args); This (obviously) makes a brand new Integer object. Integer.parseInt(args); This returns an int primitive value after parsing the String . Integer.valueOf(args); This is more complex than the others. It starts off by parsing the String . Then, if the value is between -128 and 127, it returns the corresponding object from the static cache. If the value is outside of this range, then it invokes new Integer(args) and passes in the value, so that you get a new object. Now, consider the three expressions in the question. Integer.valueOf(args)==Integer.valueOf(args); This returns true, because the Integer whose value is 127 is retrieved twice from the static cache, and compared to itself. There's only one Integer object involved, so this returns true . Integer.valueOf(args)==Integer.valueOf(args); This returns false , because 128 is not in the static cache. So a new Integer is created for each side of the equality. Since there are two different Integer objects, and == for objects only returns true if both sides are the exact same object, this is going to be false . Integer.parseInt(args)==Integer.valueOf(args); This is comparing the primitive int value 128 on the left, with a newly created Integer object on the right. But because it doesn't make sense to compare an int to an Integer , Java will auto-unbox the Integer before doing the comparison; so you end up comparing an int to an int . Since the primitive 128 is equal to itself, this returns true .

Question-8579657, answer-35264580
Main difference is that when program calls start(args) method a new Thread is created and code inside run() method is executed in new Thread while if you call run(args) method directly no new Thread is created and code inside run() will execute on current Thread . Another difference between start vs run in Java thread is that you can not call start() method twice on thread object . once started, second call of start() will throw IllegalStateException in Java while you can call run() method twice.

Question-23079003, answer-23079174
You can use the overloaded version of toArray , as the following: #pre The purpose of the IntFunction<T> generator is to convert an integer, the size of the array, to a new array. Example code: #pre Prints: #pre Another option is to use a method reference to the string array constructor, this one is a bit more tricky. Usage is easy: String[] stringArray = streamString.toArray(args); What it does, is find a method that takes in an integer (the size) as argument, and returns a String[] , which is exactly what (one of the overloads of) new String[] does.

Question-8189466
Note: I am aware of the Iterator#remove(args) method. In the following code sample, I don't understand why the List.remove in main method throws ConcurrentModificationException but not in the remove method. #pre

Question-7032070, answer-7032208
clear(args) will go through the underlying Array and set each entry to null; removeAll(args) will go through the ArrayList checking for collection and remove(args) it if it exists. I would imagine that clear(args) is way faster then removeAll because it's not comparing, etc.

Question-7032070, answer-7032137
Unless there is a specific optimization that checks if the argument passed to removeAll(args) is the collection itself (and I highly doubt that such an optimization is there) it will be significantly slower than a simple .clear(args) . Apart from that (and at least equally important): arraylist.removeAll(args) is just obtuse, confusing code. It is a very backwards way of saying "clear this collection". What advantage would it have over the very understandable arraylist.clear(args) ?

Question-32356762, answer-32370677
There is a small overhead in calling methods var an interface rather than directly on an object. This overhead is often no more than 1 or 2 processor instructions. The overhead of calling a method is even lower if the JIT knows that the method is final. This is not measurable for most code you and me right, but for the low level methods in java.utils may be used in some code where it is an issue. Also as has been pointed out in other answers, the concrete type of the object that is return (even when hidden behind an interface) effects the performance of code that uses it. This change in performance can be very great, so such an extent that the calling software fails to work. Clearly the authors of java.utils have no way to know what all the software that calls Collections.list() does with the result and no way to re-test this software if they change the implantation of Collections.list(). Therefore they are not going to change the implantation of Collections.list() to return a different type of List, even if the type system allowed it! When writing your own software, you (hopefully) have automated test that cover all your code and a good understand of how your code interrelates include know where performance is an issue. Being able to make a change to a method, without having to change the callers is of great value while the design of the software is changing. Therefore the two set of trade offs are very different.

Question-23932061, answer-23936723
There's a much better answer than using spliteratorUnknownSize directly, which is both easier and gets a better result. Iterable has a spliterator(args) method, so you should just use that to get your spliterator. In the worst case, its the same code (the default implementation uses spliteratorUnknownSize ), but in the more common case, where your Iterable is already a collection, you'll get a better spliterator, and therefore better stream performance (maybe even good parallelism.) Its also less code: StreamSupport.stream(args) .filter(args) .moreStreamOps(args); As you can see, getting a stream from an Iterable (see Why does Iterable<T> not provide stream() and parallelStream() methods? ) is not very painful.

Question-17489250, answer-17489437
Java.lang.String is not just a class. It's an integral part of the core language. The compiler has syntactic sugar for it. For example, StringLiteral is like an abbreviation for new String(args) . When written StringLiteral the compiler optimizes identical strings to the same instance to save space. StringLiteral + 5 == StringLiteral ==> true The compiler has syntactic sugar for a lot of stuff, including not having to box/unbox between object versions and their native types, no parent means Object, default constructor, ...

Question-27845223, answer-27846417
Pavel Horal's answer is nice. As he says, the word "file" has totally different (practically unrelated) meanings in URL#getFile vs java.io.File - may be that's part of the confusion. Just to add: #li A resource in Java is an abstract concept, a source of data that can be read. The location (or address) of a resource is represented in Java by a URL object. #li A resource can correspond to a regular file in the local filesystem (specifically, when its URL begins with file:// ). But a resource is more general (it can be also some file stored in a jar, or some data to be read from the network, or from memory, or...). And it's also more limited, because a File (besides being other things than a regular file: a directory, a link) can also be created and writen to. #li Remember in Java a File object does not really represents "a file" but the location (the full name, with path) of a file. So, a File object allows you to locate (and open) a file, as a URL allows you to access (and open) a resource. (There is no Resource class in Java to represent a resource, but neither there is one to represent a file! once more : File is not a file, it's the path of a file).

Question-4818699, answer-4818783
The absolute simplest example I can think of is to make incrementing an atomic operation. With standard ints: #pre With AtomicInteger: #pre The latter is a very simple way to perform simple mutations effects (especially counting, or unique-indexing), without having to resort to synchronizing all access. More complex synchronization-free logic can be employed by using compareAndSet(args) as a type of optimistic locking - get the current value, compute result based on this, set this result iff value is still the input used to do the calculation, else start again - but the counting examples are very useful, and I'll often use AtomicIntegers for counting and VM-wide unique generators if there's any hint of multiple threads being involved, because they're so easy to work with I'd almost consider it premature optimisation to use plain ints . While you can almost always achieve the same synchronization guarantees with ints and appropriate synchronized declarations, the beauty of AtomicInteger is that the thread-safety is built into the actual object itself, rather than you needing to worry about the possible interleavings, and monitors held, of every method that happens to access the int value. It's much harder to accidentally violate threadsafety when calling getAndIncrement(args) than when returning i++ and remembering (or not) to acquire the correct set of monitors beforehand.

Question-30125296, answer-30125487
I suggest 2 more options: #pre The second one uses Collectors.summingInt() collector. Besides, Java 8 introduces a very effective LongAdder accumulator designed to speed-up summarizing in parallel streams and multi-thread environments. Here, it may be used as follows: #pre

Question-22435833, answer-22497858
The answer from skiwi covered many of the major points already. I'll fill in a bit more background. The design of any API is a series of tradeoffs. In Java, one of the difficult issues is dealing with design decisions that were made long ago. Primitives have been in Java since 1.0. They make Java an "impure" object-oriented language, since the primitives are not objects. The addition of primitives was, I believe, a pragmatic decision to improve performance at the expense of object-oriented purity. This is a tradeoff we're still living with today, nearly 20 years later. The autoboxing feature added in Java 5 mostly eliminated the need to clutter source code with boxing and unboxing method calls, but the overhead is still there. In many cases it's not noticeable. However, if you were to perform boxing or unboxing within an inner loop, you'd see that it can impose significant CPU and garbage collection overhead. When designing the Streams API, it was clear that we had to support primitives. The boxing/unboxing overhead would kill any performance benefit from parallelism. We didn't want to support all of the primitives, though, since that would have added a huge amount of clutter to the API. (Can you really see a use for a ShortStream ?) "All" or "none" are comfortable places for a design to be, yet neither was acceptable. So we had to find a reasonable value of "some". We ended up with primitive specializations for int , long , and double . (Personally I would have left out int but that's just me.) For CharSequence.chars(args) we considered returning Stream<T> (an early prototype might have implemented this) but it was rejected because of boxing overhead. Considering that a String has char values as primitives, it would seem to be a mistake to impose boxing unconditionally when the caller would probably just do a bit of processing on the value and unbox it right back into a string. We also considered a CharStream primitive specialization, but its use would seem to be quite narrow compared to the amount of bulk it would add to the API. It didn't seem worthwhile to add it. The penalty this imposes on callers is that they have to know that the IntStream contains char values represented as ints and that casting must be done at the proper place. This is doubly confusing because there are overloaded API calls like PrintStream.print(args) and PrintStream.print(args) that differ markedly in their behavior. An additional point of confusion possibly arises because the codePoints(args) call also returns an IntStream but the values it contains are quite different. So, this boils down to choosing pragmatically among several alternatives: #li We could provide no primitive specializations, resulting in a simple, elegant, consistent API, but which imposes a high performance and GC overhead; #li we could provide a complete set of primitive specializations, at the cost of cluttering up the API and imposing a maintenance burden on JDK developers; or #li we could provide a subset of primitive specializations, giving a moderately sized, high performing API that imposes a relatively small burden on callers in a fairly narrow range of use cases (char processing). We chose the last one.

Question-20945049, answer-21008747
[Disclaimer this is a deliberately opinionated style of answer as I feel a more "don't do this at home kids" answer is warranted] The sin is the line field.setAccessible(args); which says to violate the public api by allowing access to a private field. Thats a giant security hole which can be locked down by configuring a security manager. The phenomenon in the question are implementation details which you would never see when not using that dangerous line of code to violate the access modifiers via reflection. Clearly two (normally) immutable strings can share the same char array. Whether a substring shares the same array depends on whether it can and whether the developer thought to share it. Normally these are invisible implementation details which you should not have to know unless you shoot the access modifier through the head with that line of code. It is simply not a good idea to rely upon such details which cannot be experienced without violating the access modifiers using reflection. The owner of that class only supports the normal public API and is free to make implementation changes in the future. Having said all that the line of code is really very useful when you have a gun held you your head forcing you to do such dangerous things. Using that back door is usually a code smell that you need to upgrade to better library code where you don't have to sin. Another common use of that dangerous line of code is to write a "voodoo framework" (orm, injection container, ...). Many folks get religious about such frameworks (both for and against them) so I will avoid inviting a flame war by saying nothing other than the vast majority of programmers don't have to go there.

Question-28840047, answer-28840048
This is of course a "feature" . The ConcurrentHashMap.computeIfAbsent() Javadoc reads: #blockquote The "must not" wording is a clear contract, which my algorithm violated, although not for the same concurrency reasons. What's still interesting is that there is no ConcurrentModificationException . Instead, the program just never halts - which still is a rather dangerous bug in my opinion (i.e. infinite loops. or: anything that can possibly go wrong, does ). The simplest use-site solution for this concrete problem would be to not use a ConcurrentHashMap , but just a HashMap instead: static Map<T> cache = new HashMap<T>(args); Now, everything works fine. Note: The HashMap.computeIfAbsent() or Map.computeIfAbsent() Javadoc don't forbid such recursive computation, which is of course ridiculous as the type of the cache is Map<T> , not ConcurrentHashMap<T> . It is very dangerous for subtypes to drastically re-define super type contracts ( Set vs. SortedSet is greeting). It should thus be forbidden also in super types, to perform such recursion.

Question-8777257, answer-8777279
array1.equals(args) is the same as array1 == array2 , i.e. is it the same array. As @alf points out it's not what most people expect. Arrays.equals(args) compares the contents of the arrays. Similarly array.toString(args) may not be very useful and you need to use Arrays.toString(args) .

Question-13195797
I want to delete all files inside ABC directory. When I tried with FileUtils.deleteDirectory(args); it also deletes folder ABC. Is there a one liner solution where I can delete files inside directory but not directory?

Question-31922866, answer-31924845
There are almost no good reasons for not using Optional as parameters. The arguments against this rely on arguments from authority (see Brian Goetz - his argument is we can't enforce non null optionals) or that the Optional arguments may be null (essentially the same argument). Of course, any reference in Java can be null, we need to encourage rules being enforced by the compiler, not programmers memory (which is problematic and does not scale). Functional programming languages encourage Optional parameters. One of the best ways of using this is to have multiple optional parameters and using liftM2 to use a function assuming the parameters are not empty and returning an optional (see #a ). Java 8 has unfortunately implemented a very limited library supporting optional. As Java programmers we should only be using null to interact with legacy libraries.

Question-30125296, answer-35035659
You can use reduce method: long creditAmountSum = result.stream(args).map(args).reduce(args);

Question-7935858
I have prepared a simple code snippet in order to separate the erroneous portion from my web application. #pre I have tested it while building a web application JSF. I just want to know why in the above code temp.split(args) does not work. The statement, System.out.println(args); displays nothing on the console means that it doesn't go through the loop. When I change the argument of the temp.split(args) method to other characters, It works just fine as usual. What might be the problem?

Question-29262002, answer-29262520
Basicly, new String(args) is an executable piece of code that actually does something (it creates a new String and then returns it). The returned value can be ignored and new String(args) can still be used in void-return lambda to create a new String. However, StringLiteral is just a constant that doesn't do anything on it's own. The only reasonable thing to do with it in lambda body is to return it. But the lambda method would have to have return type String or Object , but it returns void , hence the String cannot be casted to void error.

Question-8172420, answer-15633542
Nice question. I've got of the following five 6 methods to do it. #pre #blockquote String.valueOf(args) invokes new String(args) , which in turn sets the value char array. #pre On the other hand String.valueOf(args) invokes the following package private constructor. #pre Source code from String.java in Java 8 source code #blockquote #li Java :: How to convert primitive char to String in Java #li How to convert Char to String in Java with Example

Question-8579657, answer-8641412
Thread.start(args) code registers the Thread with scheduler and the scheduler calls the run(args) method. Also, Thread is class while Runnable is an interface.

Question-27430092, answer-27430172
A possible use case is in testing primality of a given number (at test which in itself has many uses). The isProbablePrime algorithm will run much faster than an exact algorithm, so if the number fails isProbablePrime , then one need not go to the expense of running the more expensive algorithm.

Question-30581531
What is the maximum number of parameters that a method in Java can have and why? I am using Java 1.8 on a 64-bit Windows system. All the answers on StackOverflow about this say that the technical limit is 255 parameters without specifying why. To be precise, 255 for static and 254 for non-static ( this will be the 255th in this case) methods. I thought this could be specified in some sort of specification and that this was simply a statically defined maximum number of parameters allowed. But this was only valid for int and all 4-bytes types . I did some tests with long parameters, and I was only able to declare 127 parameters in that case. With String parameters, the allowed number i deduced from testing is 255 (it may be because the reference size is 4 bytes in Java?). But since I am using a 64-bit system, references size should be 8 bytes wide and so with String parameters the maximum allowed number should be 127, similar to long types. How does this limit is exactly applied? Does the limit have anything to do with the stack size of the method? Note: I am not really going to use these many parameters in any method, but this question is only to clarify the exact behavior.

Question-4759570, answer-19459145
This works on Windows with Cygwin installed: System.getenv(args)

Question-12732422
I'm trying to add header for my request using HttpUrlConnection but the method setRequestProperty(args) doesn't seem working. The server side doesn't receive any request with my header. Can anyone help me? Thanks in advance. #pre

Question-7693324, answer-7693341
To convert a String to a Long (object), use Long.valueOf(args).longValue(args); See link

Question-6271417, answer-6271520
Try using this.getClass(args).getCanonicalName(args) or this.getClass(args).getSimpleName(args) . If it's an anonymous class, use this.getClass.getSuperclass.getName(args)

Question-7693324
I got a simple question in Java: How can I convert a String that was obtained by Long.toString(args) to long ?

Question-12576156, answer-12576394
By specifying the the my.list.of.strings=ABC,CDE,EFG in .properties file and using @Value(args) private String[] myString; You can get the arrays of strings. And using CollectionUtils.addAll(args) , you can get the list of strings.

Question-18410035
Being somewhat new to the Java language I'm trying to familiarize myself with all the ways (or at least the non-pathological ones) that one might iterate through a list (or perhaps other collections) and the advantages or disadvantages of each. Given a List<T> list object, I know of the following ways to loop through all elements: Basic for loop (of course, there're equivalent while / do while loops as well) #pre Note: As @amarseillan pointed out, this form is a poor choice for iterating over List s because the actual implementation of the get method may not be as efficient as when using an Iterator . For example, LinkedList implementations must traverse all of the elements preceding i to get the i-th element. In the above example there's no way for the List implementation to "save its place" to make future iterations more efficient. For an ArrayList it doesn't really matter because the complexity/cost of get is constant time (O(1)) whereas for a LinkedList is it proportional to the size of the list (O(n)). For more information about the computational complexity of the built-in Collections implementations, check out this question . Enhanced for loop (nicely explained in this question ) #pre Iterator #pre EDIT: Added ListIterator ListIterator #pre EDIT: Added "functional-style" solution (thanks Dave Newton) Functional Java list.stream(args).map(args); // can apply a transformation function for e EDIT: Added map method from Java 8's Stream API (see @i_am_zero's answer) Iterable.forEach , Stream.forEach , ... In Java 8 collection classes that implement Iterable (for example all List s) now have a forEach method, which can be used instead of the for loop statement demonstrated above. (Here is another question that provides a good comparison.) #pre What other ways are there, if any? I feel like this has got to be a duplicate, but I haven't been able to find what I'm looking for, so I apologize for this question potentially being redundant. (BTW, my interest does not stem at all from a desire to optimize performance ; I just want to know what forms are available to me as a developer.) EDIT: Moved ListIterationExample.java to a suggested answer

Question-5585779, answer-36394016
Whenever there is the slightest possibility that the given String does not contain an Integer, you have to handle this special case. Sadly, the standard Java methods Integer::parseInt and Integer::valueOf throw a NumberFormatException to signal this special case. Thus, you have to use exceptions for flow control, which is generally considered bad coding style. In my opinion, this special case should be handled by returning an Optional<T> . Since Java does not offer such a method, I use the following wrapper: #pre Usage: #pre While this is still using exceptions for flow control internally, the usage code becomes very clean.

Question-13659217
I declare an enum as : enum Sex {MALE,FEMALE}; And then, iterate enum as shown below : #pre I checked the Java API but can't find the values() method? I'm curious as to where this method comes from? API link : #a

Question-5868369, answer-5868454
You need to use the readLine(args) method in class BufferedReader . Create a new object from that class and operate this method on him and save it to a string. BufferReader API

Question-26375932, answer-26407637
It is an integer overflow. The int data type is 4 bytes, or 32 bits. Therefore, numbers larger than 2^(32 - 1) - 1 (2,147,483,647) cannot be stored in this data type. Your numerical values will be incorrect. For very large numbers, you will want to import and use the class java.math.BigInteger: #pre NOTE: For numerical values that are still too large for the int data type, but small enough to fit within 8 bytes (absolute value less than or equal to 2^(64 - 1) - 1), you should probably use the long primitive. HackerRank's practice problems (www.hackerrank.com), such as the Algorithms practice section, ( #a ) include some very good large-number questions that give good practice about how to think about the appropriate data type to use.

Question-31202946, answer-31203218
You can of course choose to shoot yourself in the foot, but that doesn't mean you must. #blockquote Because the recommended way to create a start a thread is not to subclass Thread. The recommended way is to define a Runnable , and pass it as argument to the Thread constructor: #pre #blockquote Yes and no. You can't replace the implementation of start() by your own implementation, but you can do additional things in start() if you want: #pre That said, if Java was redesigned from scratch today, there is a good chance the design would be different. Remember that this class dates from Java 1.0, and is still backward-compatible.

Question-19416644, answer-19416665
One simple way is to use Float.NaN : #pre #pre You can do the same with Double.NaN . From JLS §15.21.1. Numerical Equality Operators == and != : #blockquote

Question-24914525, answer-24914586
std::list in C++ is a linked list, whereas java.util.ArrayList is an array. Try replacing std::list by std::vector . Also, be sure to compile with optimization turned on.

Question-28459498, answer-28513908
I have some recollections from the early design of the Streams API that might shed some light on the design rationale. Back in 2012, we were adding lambdas to the language, and we wanted a collections-oriented or "bulk data" set of operations, programmed using lambdas, that would facilitate parallelism. The idea of lazily chaining operations together was well established by this point. We also didn't want the intermediate operations to store results. The main issues we needed to decide were what the objects in the chain looked like in the API and how they hooked up to data sources. The sources were often collections, but we also wanted to support data coming from a file or the network, or data generated on-the-fly, e.g., from a random number generator. There were many influences of existing work on the design. Among the more influential were Google's Guava library and the Scala collections library. (If anybody is surprised about the influence from Guava, note that Kevin Bourrillion , Guava lead developer, was on the JSR-335 Lambda expert group.) On Scala collections, we found this talk by Martin Odersky to be of particular interest: Future-Proofing Scala Collections: from Mutable to Persistent to Parallel . (Stanford EE380, 2011 June 1.) Our prototype design at the time was based around Iterable . The familiar operations filter , map , and so forth were extension (default) methods on Iterable . Calling one added an operation to the chain and returned another Iterable . A terminal operation like count would call iterator(args) up the chain to the source, and the operations were implemented within each stage's Iterator. Since these are Iterables, you can call the iterator(args) method more than once. What should happen then? If the source is a collection, this mostly works fine. Collections are Iterable, and each call to iterator(args) produces a distinct Iterator instance that is independent of any other active instances, and each traverses the collection independently. Great. Now what if the source is one-shot, like reading lines from a file? Maybe the first Iterator should get all the values but the second and subsequent ones should be empty. Maybe the values should be interleaved among the Iterators. Or maybe each Iterator should get all the same values. Then, what if you have two iterators and one gets farther ahead of the other? Somebody will have to buffer up the values in the second Iterator until they're read. Worse, what if you get one Iterator and read all the values, and only then get a second Iterator. Where do the values come from now? Is there a requirement for them all to be buffered up just in case somebody wants a second Iterator? Clearly, allowing multiple Iterators over a one-shot source raises a lot of questions. We didn't have good answers for them. We wanted consistent, predictable behavior for what happens if you call iterator(args) twice. This pushed us toward disallowing multiple traversals, making the pipelines one-shot. We also observed others bumping into these issues. In the JDK, most Iterables are collections or collection-like objects, which allow multiple traversal. It isn't specified anywhere, but there seemed to be an unwritten expectation that Iterables allow multiple traversal. A notable exception is the NIO DirectoryStream interface. Its specification includes this interesting warning: #blockquote [bold in original] This seemed unusual and unpleasant enough that we didn't want to create a whole bunch of new Iterables that might be once-only. This pushed us away from using Iterable. About this time, an article by Bruce Eckel appeared that described a spot of trouble he'd had with Scala. He'd written this code: #pre It's pretty straightforward. It parses lines of text into Registrant objects and prints them out twice. Except that it actually only prints them out once. It turns out that he thought that registrants was a collection, when in fact it's an iterator. The second call to foreach encounters an empty iterator, from which all values have been exhausted, so it prints nothing. This kind of experience convinced us that it was very important to have clearly predictable results if multiple traversal is attempted. It also highlighted the importance of distinguishing between lazy pipeline-like structures from actual collections that store data. This in turn drove the separation of the lazy pipeline operations into the new Stream interface and keeping only eager, mutative operations directly on Collections. Brian Goetz has explained the rationale for that. What about allowing multiple traversal for collection-based pipelines but disallowing it for non-collection-based pipelines? It's inconsistent, but it's sensible. If you're reading values from the network, of course you can't traverse them again. If you want to traverse them multiple times, you have to pull them into a collection explicitly. But let's explore allowing multiple traversal from collections-based pipelines. Let's say you did this: #pre (The into operation is now spelled collect(args) .) If source is a collection, then the first into(args) call will create a chain of Iterators back to the source, execute the pipeline operations, and send the results into the destination. The second call to into(args) will create another chain of Iterators, and execute the pipeline operations again . This isn't obviously wrong but it does have the effect of performing all the filter and map operations a second time for each element. I think many programmers would have been surprised by this behavior. As I mentioned above, we had been talking to the Guava developers. One of the cool things they have is an Idea Graveyard where they describe features that they decided not to implement along with the reasons. The idea of lazy collections sounds pretty cool, but here's what they have to say about it. Consider a List.filter(args) operation that returns a List : #blockquote To take a specific example, what's the cost of get(args) or size(args) on a List? For commonly used classes like ArrayList , they're O(1). But if you call one of these on a lazily-filtered list, it has to run the filter over the backing list, and all of a sudden these operations are O(n). Worse, it has to traverse the backing list on every operation. This seemed to us to be too much laziness. It's one thing to set up some operations and defer actual execution until you so "Go". It's another to set things up in such a way that hides a potentially large amount of recomputation. In proposing to disallow non-linear or "no-reuse" streams, Paul Sandoz described the potential consequences of allowing them as giving rise to "unexpected or confusing results." He also mentioned that parallel execution would make things even trickier. Finally, I'd add that a pipeline operation with side effects would lead to difficult and obscure bugs if the operation were unexpectedly executed multiple times, or at least a different number of times than the programmer expected. (But Java programmers don't write lambda expressions with side effects, do they? DO THEY??) So that's the basic rationale for the Java 8 Streams API design that allows one-shot traversal and that requires a strictly linear (no branching) pipeline. It provides consistent behavior across multiple different stream sources, it clearly separates lazy from eager operations, and it provides a straightforward execution model. With regard to IEnumerable , I am far from an expert on C# and .NET, so I would appreciate being corrected (gently) if I draw any incorrect conclusions. It does appear, however, that IEnumerable permits multiple traversal to behave differently with different sources; and it permits a branching structure of nested IEnumerable operations, which may result in some significant recomputation. While I appreciate that different systems make different tradeoffs, these are two characteristics that we sought to avoid in the design of the Java 8 Streams API. The quicksort example given by the OP is interesting, puzzling, and I'm sorry to say, somewhat horrifying. Calling QuickSort takes an IEnumerable and returns an IEnumerable , so no sorting is actually done until the final IEnumerable is traversed. What the call seems to do, though, is build up a tree structure of IEnumerables that reflects the partitioning that quicksort would do, without actually doing it. (This is lazy computation, after all.) If the source has N elements, the tree will be N elements wide at its widest, and it will be lg(N) levels deep. It seems to me -- and once again, I'm not a C# or .NET expert -- that this will cause certain innocuous-looking calls, such as pivot selection via ints.First(args) , to be more expensive than they look. At the first level, of course, it's O(1). But consider a partition deep in the tree, at the right-hand edge. To compute the first element of this partition, the entire source has to be traversed, an O(N) operation. But since the partitions above are lazy, they must be recomputed, requiring O(lg N) comparisons. So selecting the pivot would be an O(N lg N) operation, which is as expensive as an entire sort. But we don't actually sort until we traverse the returned IEnumerable . In the standard quicksort algorithm, each level of partitioning doubles the number of partitions. Each partition is only half the size, so each level remains at O(N) complexity. The tree of partitions is O(lg N) high, so the total work is O(N lg N). With the tree of lazy IEnumerables, at the bottom of the tree there are N partitions. Computing each partition requires a traversal of N elements, each of which requires lg(N) comparisons up the tree. To compute all the partitions at the bottom of the tree, then, requires O(N^2 lg N) comparisons. (Is this right? I can hardly believe this. Somebody please check this for me.) In any case, it is indeed cool that IEnumerable can be used this way to build up complicated structures of computation. But if it does increase the computational complexity as much as I think it does, it would seem that programming this way is something that should be avoided unless one is extremely careful.

Question-32164385, answer-32167166
#blockquote I must agree with other answers that there is no direct way to determine that method will modify your object or not and yes to make sure that method can not modify your Object you all have to do it is from your side. #blockquote Here the method name comes to the scene. Moving ahead with the naming convention of method we have to take a look at some method declarations which clearly convince you that your Object will not be changed at all. For example, You know that Arrays.copyOf will not change your actual array, System.out.println(args) will not change your boo Method names are real weapons to provide as much information as possible to the method user. (Yes! it's always not possible but quite a good practice to follow.) Let's consider it in your case that say printBoo will only print, copyBoo will only copy, clearBoo will reset all attributes, checkAndCreateNewBoo will check your boo Object and create new if required. So, ultimately if we can use them in a proper way caller can be assured with the fact that Object will remain the same after calling the method.

Question-22725537, answer-36334855
As my previous answer appeared not to be very popular, I will give this another go. A short answer: You are mostly on a right track. The shortest code to get to your desired output I could come up with is this: things.stream(args) .map(args) .filter(args) .findFirst(args) .flatMap(args); This will fit all your requirements: #li It will find first response that resolves to a nonempty Optional<T> #li It calls this::resolve lazily as needed #li this::resolve will not be called after first non-empty result #li It will return Optional<T> Longer answer The only modification compared to OP initial version was that I removed .map(args) before call to .findFirst(args) and added .flatMap(args) as the last call in the chain. This has a nice effect of getting rid of the double-Optional, whenever stream finds an actual result. You can't really go any shorter than this in Java. The alternative snippet of code using the more conventional for loop technique is going to be about same number of lines of code and have more or less same order and number of operations you need to perform: #li Calling this.resolve , #li filtering based on Optional.isPresent #li returning the result and #li some way of dealing with negative result (when nothing was found) Just to prove that my solution works as advertised, I wrote a small test program: #pre (It does have few extra lines for debugging and verifying that only as many calls to resolve as needed...) Executing this on a command line, I got the following results: #pre

Question-6094575, answer-6094600
You can use Class.forName() to get a Class object of the desired class. Then use getConstructor() to find the desired Constructor object. Finally, call newInstance() on that object to get your new instance. #pre

Question-20358883, answer-29784337
The other answers all use Arrays.asList(args) , which returns an unmodifiable list (an UnsupportedOperationException is thrown if you try to add or remove an element). To get a mutable list you can wrap the returned list in a new ArrayList as a couple of answers point out, but a cleaner solution is to use Guava's Lists.newArrayList() (available since at least Guava 10 , released in 2011). For example: Lists.newArrayList(args);

Question-31188231, answer-31188818
Ironically default methods in interfaces were introduced to allow existing libraries using those interfaces not to break, while introducing massive new functionality in the interfaces. (backward compatibility.) Conflicts like that sort method might arise. Something to pay for the extra functionality. In your case also something to investigate (should new functionality be used instead?). Java forward compatibility breaks are little, more in its typing system, which was constantly enlarged. First with generic types and now with inferred types from functional interfaces. From version to version and from compiler to compiler there were slight differences.

Question-6608795, answer-22327270
I tried reading from input1.txt which was inside one of my packages together with the class which was trying to read it. The following works: #pre The most important part was to call getPath(args) if you want the correct path name in String format. DO NOT USE toString(args) because it will add some extra formatting text which will TOTALLY MESS UP the fileName (you can try it and see the print out). Spent 2 hours debugging this... :(

Question-16635398, answer-16635489
The advantage comes into account when the operations can be executed in parallel. (See #a - the section about internal and external iteration) #li The main advantage from my point of view is that the implementation of what is to be done within the loop can be defined without having to decide if it will be executed in parallel or sequential #li If you want your loop to be executed in parallel you could simply write joins.parallelStream(args).forEach(args); You will have to write some extra code for thread handling etc. Note : for my answer I assumed joins implementing the java.util.Stream interface. If joins implements only the java.util.Iterable interface this is no longer true.

Question-7348711
Which of the following is the best and most portable way to get the hostname of the current computer in Java? Runtime.getRuntime(args).exec(args) vs InetAddress.getLocalHost(args).getHostName(args)

Question-20129762
In Java 8 we have the class Stream<T> , which curiously have a method Iterator<T> iterator(args) So you would expect it to implement interface Iterable<T> , which requires exactly this method, but that's not the case. When I want to iterate over a Stream using a foreach loop, I have to do something like #pre Am I missing something here?

Question-5439529, answer-15357940
Or simply mystring.matches(args) though it would return true for numbers larger than an int

Question-32693704, answer-32745612
For me, the reason is a likely performance inprovement, at a negligible cost in terms of code clarity. Note that the implementation of the fill method is trivial, a simple for-loop setting each array element to null. So, replacing a call to it with the actual implementation does not cause any significant degradation in the clarity/conciseness of the caller method. The potential performance benefits are not so insignificant, if you consider everything that is involved: #li There will be no need for the JVM to resolve the Arrays class, plus loading and initializing it if needed. This is a non-trivial process where the JVM performs several steps. Firstly, it checks the class loader to see if the class is already loaded, and this happens every time a method is called; there are optimizations involved here, of course, but it still takes some effort. If the class is not loaded, the JVM will need to go through the expensive process of loading it, verifying the bytecode, resolving other necessary dependencies, and finally performing static initialization of the class (which can be arbitrarily expensive). Given that HashMap is such a core class, and that Arrays is such a huge class (3600+ lines), avoiding these costs may add up to noticeable savings. #li Since there is no Arrays.fill(args) method call, the JVM won't have to decide whether/when to inline the method into the caller's body. Since HashMap#clear(args) tends to get called a lot, the JVM will eventually perform the inlining, which requires JIT recompilation of the clear method. With no method calls, clear will always run at top-speed (once initially JITed). Another benefit of no longer calling methods in Arrays is that it simplifies the dependency graph inside the java.util package, since one dependency is removed.

Question-7935858, answer-7935873
java.lang.String.split splits on regular expressions, and . in a regular expression means "any character". Try temp.split(args) .

Question-12862659, answer-12862662
use the second argument on the Mockito.verify method, as in: verify(args).someMethod(args)

Question-8189466, answer-8189786
Here's why: As it is says in the Javadoc: #blockquote This check is done in the next(args) method of the iterator (as you can see by the stacktrace). But we will reach the next(args) method only if hasNext(args) delivered true, which is what is called by the for each to check if the boundary is met. In your remove method, when hasNext(args) checks if it needs to return another element, it will see that it returned two elements, and now after one element was removed the list only contains two elements. So all is peachy and we are done with iterating. The check for concurrent modifications does not occur, as this is done in the next(args) method which is never called. Next we get to the second loop. After we remove the second number the hasNext method will check again if can return more values. It has returned two values already, but the list now only contains one. But the code here is: #pre 1 != 2, so we continue to the next(args) method, which now realizes that someone has been messing with the list and fires the exception. Hope that clears your question up.

Question-5439529, answer-5439543
You can use Integer.parseInt(args) or Integer.valueOf(args) to get the integer from the string, and catch the exception if it is not a parsable int. You want to be sure to catch the NumberFormatException it can throw. It may be helpful to note that valueOf() will return an Integer object, not the primitive int.

Question-19431234, answer-23526153
Everything is here : #a The answer with "round-tripping" is not exact : when you do LocalDateTime ldt = LocalDateTime.ofInstant(args); if your system timezone is not UTC/GMT, you change the time !

Question-19431234, answer-23885950
Short answer: #pre Explanation: (based on this question about LocalDate ) Despite its name, java.util.Date represents an instant on the time-line, not a "date". The actual data stored within the object is a long count of milliseconds since 1970-01-01T00:00Z (midnight at the start of 1970 GMT/UTC). The equivalent class to java.util.Date in JSR-310 is Instant , thus there are convenient methods to provide the conversion to and fro: #pre A java.util.Date instance has no concept of time-zone. This might seem strange if you call toString(args) on a java.util.Date , because the toString is relative to a time-zone. However that method actually uses Java's default time-zone on the fly to provide the string. The time-zone is not part of the actual state of java.util.Date . An Instant also does not contain any information about the time-zone. Thus, to convert from an Instant to a local date-time it is necessary to specify a time-zone. This might be the default zone - ZoneId.systemDefault(args) - or it might be a time-zone that your application controls, such as a time-zone from user preferences. LocalDateTime has a convenient factory method that takes both the instant and time-zone: #pre In reverse, the LocalDateTime the time-zone is specified by calling the atZone(args) method. The ZonedDateTime can then be converted directly to an Instant : #pre Note that the conversion from LocalDateTime to ZonedDateTime has the potential to introduce unexpected behaviour. This is because not every local date-time exists due to Daylight Saving Time. In autumn/fall, there is an overlap in the local time-line where the same local date-time occurs twice. In spring, there is a gap, where an hour disappears. See the Javadoc of atZone(ZoneId) for more the definition of what the conversion will do. Summary, if you round-trip a java.util.Date to a LocalDateTime and back to a java.util.Date you may end up with a different instant due to Daylight Saving Time.

Question-18448671, answer-18448699
Use an Iterator and call remove() : #pre

Question-16148575
I am trying to build a HashMap which will have integer as keys and objects as values. My syntax is: HashMap<T> myMap = new HashMap<T>(args); However, the error returned is - Syntax error on token "int", Dimensions expected after this token - I don't understand why I should add a dimension (ie: making the int into an array) since I only need to store a digit as key. What could I do? Thanks in advance! :)

Question-4812570
How can I get the e.printStackTrace(args) and store it into a String variable? I want to use the string generated by e.printStackTrace(args) later in my program. I'm still new to Java so I'm not too familiar with StringWriter that I think will be the solution. Or if you have any other ideas please let me know. Thanks

Question-12552863, answer-18496449
The first style is the one suggested by Oracle . BufferedWriter doesn't throw checked exceptions, so if any exception is thrown, the program is not expected to recover from it, making resource recover mostly moot. Mostly because it could happen in a thread, with the thread dieing but the program still continuing -- say, there was a temporary memory outage that wasn't long enough to seriously impair the rest of the program. It's a rather corner case, though, and if it happens often enough to make resource leak a problem, the try-with-resources is the least of your problems.

Question-4576352, answer-4576367
using public String replaceAll(args) will work usage would be str.replace(args); executing StringLiteral.replaceAll(args); returns: lakjsdf xx

Question-16148575, answer-16149127
You can't use a primitive because HashMap use object internally for the key. So you can only use an object that inherits from Object (that is any object). That is the function put() in HashMap and as you can see it uses Object for K: #pre The expression "k = e.key" should make it clear. I suggest to use a wrapper like Integer and autoboxing.

Question-32693704, answer-32752970
I will try to summarize three moreless reasonable versions which were proposed in comments. @Holger says : #blockquote This is the most easy thing to test. Let's compile such program: #pre Run it with java -verbose:class HashMapTest . This will print the class loading events as they occur. With JDK 1.8.0_60 I see more than 400 classes loaded: #pre As you can see, HashMap is loaded long before application code and Arrays is loaded only 14 classes after HashMap . The HashMap load is triggered by sun.reflect.Reflection initialization as it has HashMap static fields. The Arrays load is likely to be triggered by WeakHashMap load which actually has Arrays.fill in the clear(args) method. The WeakHashMap load is triggered by java.lang.ClassValue$ClassValueMap which extends WeakHashMap . The ClassValueMap is present in every java.lang.Class instance. So to me seems that without Arrays class the JDK cannot be initialized at all. Also the Arrays static initializer is very short, it only initializes the assertion mechanism. This mechanism is used in many other classes (including, for example, java.lang.Throwable which is loaded very early). No other static initialization steps are performed in java.util.Arrays . Thus @Holger version seems incorrect to me. Here we also found very interesting thing. The WeakHashMap.clear(args) still uses Arrays.fill . It's interesting when it appeared there, but unfortunately this goes to prehistoric times (it was already there in the very first public OpenJDK repository). Next, @MarcoTopolnik says : #blockquote It was actually surprising for me that Arrays.fill is not directly intrinsified (see intrinsic list generated by @apangin ). Seems that such loop can be recognized and vectorized by JVM without explicit intrinsic handling. So it's true that extra call can be not inlined in very specific cases (for example if MaxInlineLevel limit is reached). On the other hand it's very rare situation and it's only a single call, it's not a call inside loop, and it's a static, not virtual/interface call, thus the performance improvement could be only marginal and only in some specific scenarios. Not the thing the JVM developers usually care. Also it should be noted that even C1 'client' compiler (tier 1-3) is capable to inline Arrays.fill called, for example, in WeakHashMap.clear(args) , as inlining log ( -XX:+UnlockDiagnosticVMOptions -XX:+PrintCompilation -XX:+PrintInlining ) says: #pre Of course, it's also easily inlined by smart and powerful C2 'server' compiler. Thus I see no problems here. Seems that @Marco version is incorrect either. Finally we have a couple of comments from @StuartMarks (who is JDK developer, thus some official voice): #blockquote Indeed the HashMap.clear(args) contained the loop many years, was replaced with Arrays.fill on Apr 10th, 2013 and stayed less one half-a-year until Sept 4th when the discussed commit was introduced. The discussed commit was actually a major rewrite of the HashMap internals to fix JDK-8023463 issue. It was a long story about possibility to poison the HashMap with keys having duplicating hashcodes reducing HashMap search speed to linear making it vulnerable to DoS-attacks. The attempts to solve this were performed in JDK-7 including some randomization of String hashCode. So seems that the HashMap implementation was forked from the earlier commit, developed independently, then merged into the master branch overwriting several changes introduced in-between. We may support this hypothesis performing a diff. Take the version where Arrays.fill was removed (2013-09-04) and compare it with previous version (2013-07-30). The diff -U0 output has 4341 lines. Now let's diff against the version prior to one when Arrays.fill was added (2013-04-01). Now diff -U0 contains only 2680 lines. Thus the newer version actually more similar to the older than to immediate parent. Conclusion So to conclude I would agree with Stuart Marks. There were no concrete reason to remove Arrays.fill , it's just because the in-between change was overwritten by mistake. Using Arrays.fill is perfectly fine both in JDK code and in user applications and used, for example, in WeakHashMap . The Arrays class is loaded anyways pretty early during the JDK initialization, has very simple static initializer and Arrays.fill method can be easily inlined even by client compiler, so no performance drawback should be noted.

Question-5175728, answer-5175771
Have a look at the Date class. There's also the newer Calendar class which is the preferred method of doing many date / time operations (a lot of the methods on Date have been deprecated.) If you just want the current date, then either create a new Date object or call Calendar.getInstance(args); .

Question-5868369, answer-31265714
In Java 8, there is also an alternative to using Files.lines() . If your input source isn't a file but something more abstract like a Reader or an InputStream , you can stream the lines via the BufferedReader s lines(args) method. For example: #pre will call processLine(args) for each input line read by the BufferedReader .

Question-15202997, answer-36978943
I've been confused by the wide range of different naming schemes as well, and was just about to ask and answer my own question on this when I found this question here. I think my findings fit it well enough, and complement what's already here. My focus is looking for documentation on the various terms, and adding some more related terms that might crop up in other places. Consider the following example: #pre #li The simple name of D is D . That's just the part you wrote when declaring the class. Anonymous classes have no simple name. Class.getSimpleName() returns this name or the empty string. It is possible for the simple name to contain a $ if you write it like this, since $ is a valid part of an identifier. #li According to the JLS section 6.7 , both a.b.C.D and a.b.C.D.D.D would be fully qualified names , but only a.b.C.D would be the canonical name of D . So every canonical name is a fully qualified name, but the converes is not always true. Class.getCanonicalName() will return the canonical name or null . #li Class.getName() is documented to return the binary name , as specified in JLS section 13.1 . In this case it returns a.b.C$D for D and [La.b.C$D; for D[] . #li This answer demonstrates that it is possible for two classes loaded by the same class loader to have the same canonical name but distinct binary names . Neither name is sufficient to reliably deduce the other: if you have the canonical name, you don't know which parts of the name are packages and which are containing classes. If you have the binary name, you don't know which $ were introduced as separators and which were part of some simple name. #li Anonymous classes and local classes have no fully qualified names but still have a binary name . The same holds for classes nested inside such classes. Every class has a binary name. #li Running javap -v -private on a/b/C.class shows that the bytecode refers to the type of d as La/b/C$D; and that of the array ds as [La/b/C$D; . These are called descriptors , and they are specified in JVMS section 4.3 . #li The class name a/b/C$D used in both of these descriptors is what you get by replacing . by / in the binary name. The JVM spec apparently calls this the internal form of the binary name . JVMS section 4.2.1 describes it, and states that the difference from the binary name were for historical reasons. #li The file name of a class in one of the typical filename-based class loaders is what you get if you interpret the / in the internal form of the binary name as a directory separator, and append the file name extension .class to it. It's resolved relative to the class path used by the class loader in question.

Question-29140402, answer-36771568
In Eclipse, Go to your class, Right click->source->Generate toString(); It will override the toString() method and print the object of that class.

Question-17781150, answer-17781189
The only int value for which it works is Integer.MIN_VALUE . It's because integers are negated using the two's complement way . Using System.out.println(args); you see that Integer.MIN_VALUE is 10000000000000000000000000000000 Taking the negative value is done by first swapping 0 and 1 , which gives 01111111111111111111111111111111 and by adding 1 , which gives 10000000000000000000000000000000 As you can see in the link I gave, Wikipedia mentions the problem with the most negative numbers and specifies it's the sole exception : #blockquote Of course you have the same phenomenon for Long.Min_Value if you store it in a long variable. Note that this is only due to choices that were made regarding the binary storage of ints in Java . Another (bad) solution could for example have been to negate by simply changing the most significant bit and letting the other bits unchanged, this would have avoided this problem with MIN_VALUE but would have made 2 different 0 values and complicated binary arithmetic (how would you have incremented for example ?).

Question-14534767
I have a StringBuilder object, #pre Now I want to append a newline character to the StringBuilder . How can I do it? result.append(args); Does not work. So, I was thinking about writing a newline using Unicode. Will this help? If so, how can I add one?

Question-7032070, answer-7032180
The clear(args) method removes all the elements of a single ArrayList . It's a fast operation, as it just sets some array elements to null . The removeAll(args) method, which is inherited from AbstractCollection , removes all the elements that are in the argument collection from the collection you call the method on. It's a relatively slow operation, as it has to search through one of the collections involved.

Question-18636561, answer-18824858
Whenever a new keyword is used it Creates a Object at the Heap 1)StringBuilder sample = new StringBuilder(); 2) StringBuilder referToSample = sample; In 2) the Reference of referSample is created on same object sample thus referToSample = null; is Nulling Only the referSample Reference giving no effect to sample that's why you are not getting NULL Pointer Exception Thanks to Java's Garbage Collection

Question-9481865, answer-9481939
You can use java.net.InetAddress API. Try this : InetAddress.getLocalHost(args).getHostAddress(args);

Question-13195797, answer-20043507
Peter Lawrey's answer is great because it is simple and not depending on anything special, and it's the way you should do it. If you need something that removes subdirectories and their contents as well, use recursion: #pre To spare subdirectories and their contents (part of your question), modify as follows: #pre Or, since you wanted a one-line solution: for(args) if(args) file.delete(args); Using an external library for such a trivial task is not a good idea unless you need this library for something else anyway, in which case it is preferrable to use existing code. You appear to be using the Apache library anyway so use its FileUtils.cleanDirectory(args) method.

Question-5374311, answer-17909134
I can see many answers showing how to solve problem, but only Stephen's answer is trying to explain why problem occurs so I will try to add something more on this subject. It is a story about possible reasons why Object[] toArray wasn't changed to T[] toArray where generics ware introduced to Java. Why String[] stockArr = (String[]) stock_list.toArray(args); wont work? In Java, generic type exists at compile-time only . At runtime information about generic type (like in your case <String> ) is removed and replaced with Object type (take a look at type erasure ). That is why at runtime toArray(args) have no idea about what precise type to use to create new array, so it uses Object as safest type, because each class extends Object so it can safely store instance of any class. Now the problem is that you can't cast instance of Object[] to String[] . Why? Take a look at this example (lets assume that class B extends A ): #pre Although such code will compile, at runtime we will see thrown ClassCastException because instance held by reference a is not actually of type B (or its subtypes). Why is this problem (why this exception needs to be cast)? One of the reasons is that B could have new methods/fields which A doesn't, so it is possible that someone will try to use these new members via b reference even if held instance doesn't have (doesn't support) them. In other words we could end up trying to use data which doesn't exist, which could lead to many problems. So to prevent such situation JVM throws exception, and stop further potentially dangerous code. You could ask now "So why aren't we stopped even earlier? Why code involving such casting is even compilable? Shouldn't compiler stop it?". Answer is: no because compiler can't know for sure what is the actual type of instance held by a reference, and there is a chance that it will hold instance of class B which will support interface of b reference. Take a look at this example: #pre Now lets go back to your arrays. As you see in question, we can't cast instance of Object[] array to more precise type String[] like #pre Here problem is a little different. Now we are sure that String[] array will not have additional fields or methods because every array support only: #li [] operator, #li length filed, #li methods inherited from Object supertype, So it is not arrays interface which is making it impossible. Problem is that Object[] array beside Strings can store any objects (for instance Integers ) so it is possible that one beautiful day we will end up with trying to invoke method like strArray[i].substring(args) on instance of Integer which doesn't have such method. So to make sure that this situation will never happen, in Java array references can hold only #li instances of array of same type as reference (reference String[] strArr can hold String[] ) #li instances of array of subtype ( Object[] can hold String[] because String is subtype of Object ), but can't hold #li array of supertype of type of array from reference ( String[] can't hold Object[] ) #li array of type which is not related to type from reference ( Integer[] can't hold String[] ) In other words something like this is OK #pre You could say that one way to resolve this problem is to find at runtime most common type between all list elements and create array of that type, but this wont work in situations where all elements of list will be of one type derived from generic one. Take a look #pre now most common type is B , not A so toArray(args) A[] arr = elements.toArray(args); would return array of B class new B[] . Problem with this array is that while compiler would allow you to edit its content by adding new A(args) element to it, you would get ArrayStoreException because B[] array can hold only elements of class B or its subclass, to make sure that all elements will support interface of B , but instance of A may not have all methods/fields of B . So this solution is not perfect. Best solution to this problem is explicitly tell what type of array toArray(args) should be returned by passing this type as method argument like String[] arr = list.toArray(args); or String[] arr = list.toArray(args); //if size of array is smaller then list it will be automatically adjusted.

Question-18723596, answer-18723651
Println(args) uses String.valueOf(args) #pre Print(args) does null check. #pre

Question-21375659, answer-21375716
String is immutable irrespective of how it is instantiated 1) Short answer is yes , new String(args) is immutable too. Because every possible mutable operation (like replace , toLowerCase etcetra) that you perform on String does not affect the original String instance and returns you a new instance . You may check this in Javadoc for String . Each public method of String that is exposed returns a new String instance and does not alter the present instance on which you called the method. This is very helpful in Multi-threaded environment as you don't have to think about mutability ( someone will change the value ) every time you pass or share the String around. String can easily be the most used data type, so the designers have blessed us all to not think about mutability everytime and saved us a lot of pain. Immutability allowed String pool or caching It is because of immutability property that the internal pool of string was possible, as when same String value is required at some other place then that immutable reference is returned. If String would have been mutable then it would not have been possible to share String s like this to save memory. String immutablity was not because of pooling, but immutability has more benefits attached to it. String interning or pooling is an example of Flyweight Design pattern 2) Yes it will be interned like any other String as a blank String is also as much a String as other String instances. References: #li Immutability benefits of String

Question-16159203, answer-16323196
#blockquote currentPos = new Point(args); does a few things, including writing default values to x and y (0) and then writing their initial values in the constructor. Since your object is not safely published those 4 write operations can be freely reordered by the compiler / JVM. So from the perspective of the reading thread, it is a legal execution to read x with its new value but y with its default value of 0 for example. By the time you reach the println statement (which by the way is synchronized and therefore does influence the read operations), the variables have their initial values and the program prints the expected values. Marking currentPos as volatile will ensure safe publication since your object is effectively immutable - if in your real use case the object is mutated after construction, volatile guarantees won't be enough and you could see an inconsistent object again. Alternatively, you can make the Point immutable which will also ensure safe publication, even without using volatile . To achieve immutability, you simply need to mark x and y final. As a side note and as already mentioned, synchronized(args) {} can be treated as a no-op by the JVM (I understand you included it to reproduce the behaviour).

Question-7520432, answer-35399386
The String pool (aka interning ) and Integer pool blur the difference further, and may allow you to use == for objects in some cases instead of .equals This can give you greater performance (?), at the cost of greater complexity. E.g.: #pre Complexity tradeoff: the following may surprise you: #pre I advise you to stay away from such micro-optimization, and always use .equals for objects, and == for primitives: #pre

Question-25850328, answer-25853827
I would argue first-off that Serializable and Cloneable are bad examples of marker interfaces. Sure, they're interfaces with methods, but they imply methods, such as writeObject(args) . (The compiler will create a writeObject(args) method for you if you don't override it, and all objects already have clone(args) , but the compiler will again create a real clone(args) method for you but with caveats. Both of these are weird edge cases that really aren't good design examples.) Marker interfaces are generally used for one of two purposes: 1) As a shortcut to avoid an excessively long type, which can happen with lots of generics. For instance, say you have this method signature: public void doSomething(args) { ... } That's messy and annoying to type, and more importantly, difficult to understand. Consider this instead: public interface Widget extends Foobar<T> { } Then your method looks like this: public void doSomething(args) { ... } Not only is it clearer, but you can now Javadoc the Widget interface, and it's also easier to search for all occurrences in your code of Widget. 2) Marker interfaces can also be used as a way around Java's lack of intersection types. With a marker interface, you can require something to be of two different types, such as in a method signature. Say you have some interface Widget in your application, like we described above. If you have a method that requires a Widget that also happens to let you iterate over it (it's contrived, but work with me here), your only good solution is to create a marker interface that extends both interfaces: public interface IterableWidget extends Iterable<T>, Widget { } And in your code: #pre

Question-29945627, answer-29945754
The lambda: () -> { System.out.println(args); }; actually represents an implementation for an interface like: #pre which is completely different than the one you've defined. That's why you get an error. Since you can't extend your @FunctionalInterface , nor introduce a brand new one, then I think you don't have much options. You can use the Optional<T> interfaces to denote that some of the values (return type or method parameter) is missing, though. However, this won't make the lambda body simpler.

Question-19431234, answer-23884116
the following seems to work when converting from new API LocalDateTime into java.util.date: Date.from(args); the reverse conversion can be (hopefully) achieved similar way... hope it helps...

Question-20358883, answer-20358928
You can use the utility method Arrays.asList and feed that result into a new ArrayList . ArrayList<T> list = new ArrayList<T>(args); Other options: ArrayList<T> list = new ArrayList<T>(args); and ArrayList<T> list = new ArrayList<T>(args); #li ArrayList(Collection) constructor. #li Arrays.asList method. #li Collections.nCopies method. #li Collections.singletonList method.

Question-25441088, answer-25441208
I think you're just looking for the overload which takes another Collector to specify what to do with each group... and then Collectors.counting(args) to do the counting: #pre Result: {Hello=2, World=1} (There's also the possibility of using groupingByConcurrent for more efficiency. Something to bear in mind for your real code, if it would be safe in your context.)

Question-4645020
It is supposed to be generally preferable to use a StringBuilder for string concatenation in Java. Is this always the case? What I mean is this: Is the overhead of creating a StringBuilder object, calling the append(args) method and finally toString(args) already smaller then concatenating existing strings with the + operator for two strings, or is it only advisable for more (than two) strings? If there is such a threshold, what does it depend on (perhaps the string length, but in which way)? And finally, would you trade the readability and conciseness of the + concatenation for the performance of the StringBuilder in smaller cases like two, three or four strings? EDIT Explicit use of StringBuilder for regular concatenations is being mentioned as obsolete at obsolete java optimization tips as well as at java urban myths .

Question-23699371
In Java 8 how can I filter a collection using the Stream API by checking the distinctness of a property of each object? For example I have a list of Person object and I want to remove people with the same name, persons.stream(args).distinct(args); Will use the default equality check for a Person object, so I need something like, persons.stream(args).distinct(args); Unfortunately the distinct(args) method has no such overload. Without modifying the equality check inside the Person class is it possible to do this succinctly?

Question-29095967, answer-29111023
Although there are several answers already, and an accepted answer, there are still a couple points missing from this topic. First, the consensus seems to be that solving this problem using streams is merely an exercise, and that the conventional for-loop approach is preferable. Second, the answers given thus far have overlooked an approach using array or vector-style techniques that I think improves the streams solution considerably. First, here's a conventional solution, for purposes of discussion and analysis: #pre This is mostly straightforward but there's a bit of subtlety. One point is that a pending sublist from prev to cur is always open. When we encounter null we close it, add it to the result list, and advance prev . After the loop we close the sublist unconditionally. Another observation is that this is a loop over indexes, not over the values themselves, thus we use an arithmetic for-loop instead of the enhanced "for-each" loop. But it suggests that we can stream using the indexes to generate subranges instead of streaming over values and putting the logic into the collector (as was done by Joop Eggen's proposed solution ). Once we've realized that, we can see that each position of null in the input is the delimiter for a sublist: it's the right end of the sublist to the left, and it (plus one) is the left end of the sublist to the right. If we can handle the edge cases, it leads to an approach where we find the indexes at which null elements occur, map them to sublists, and collect the sublists. The resulting code is as follows: #pre Getting the indexes at which null occurs is pretty easy. The stumbling block is adding -1 at the left and size at the right end. I've opted to use Stream.of to do the appending and then flatMapToInt to flatten them out. (I tried several other approaches but this one seemed like the cleanest.) It's a bit more convenient to use arrays for the indexes here. First, the notation for accessing an array is nicer than for a List: indexes[i] vs. indexes.get(args) . Second, using an array avoids boxing. At this point, each index value in the array (except for the last) is one less than the beginning position of a sublist. The index to its immediate right is the end of the sublist. We simply stream over the array and map each pair of indexes into a sublist and collect the output. Discussion The streams approach is slightly shorter than the for-loop version, but it's denser. The for-loop version is familiar, because we do this stuff in Java all the time, but if you're not already aware of what this loop is supposed to be doing, it's not obvious. You might have to simulate a few loop executions before you figure out what prev is doing and why the open sublist has to be closed after the end of the loop. (I initially forgot to have it, but I caught this in testing.) The streams approach is, I think, easier to conceptualize what's going on: get a list (or an array) that indicates the boundaries between sublists. That's an easy streams two-liner. The difficulty, as I mentioned above, is finding a way to tack the edge values onto the ends. If there were a better syntax for doing this, e.g., // Java plus pidgin Scala int[] indexes = [-1] ++ IntStream.range(args) .filter(args) ++ [input.size(args)]; it would make things a lot less cluttered. (What we really need is array or list comprehension.) Once you have the indexes, it's a simple matter to map them into actual sublists and collect them into the result list. And of course this is safe when run in parallel. UPDATE 2016-02-06 Here's a nicer way to create the array of sublist indexes. It's based on the same principles, but it adjusts the index range and adds some conditions to the filter to avoid having to concatenate and flatmap the indexes. #pre

Question-28681737, answer-28684917
The short answer is: it's safe if you use them safely :) The snarky answer: tell me what you mean by traits, and maybe I'll give you a better answer :) In all seriousness, the term "trait" is not well-defined. Many Java developers are most familiar with traits as they are expressed in Scala, but Scala is far from the first language to have traits, either in name or in effect. For example, in Scala, traits are stateful (can have var variables); in Fortress they are pure behavior. Java's interfaces with default methods are stateless; does this mean they are not traits? (Hint: that was a trick question.) Again, in Scala, traits are composed through linearization; if class A extends traits X and Y , then the order in which X and Y are mixed in determines how conflicts between X and Y are resolved. In Java, this linearization mechanism is not present (it was rejected, in part, because it was too "un-Java-like".) The proximate reason for adding default methods to interfaces was to support interface evolution , but we were well aware that we were going beyond that. Whether you consider that to be "interface evolution++" or "traits--" is a matter of personal interpretation. So, to answer your question about safety ... so long as you stick to what the mechanism actually supports, rather than trying to wishfully stretch it to something it does not support, you should be fine. A key design goal was that, from the perspective of the client of an interface, default methods should be indistinguishable from "regular" interface methods. The default-ness of a method, therefore, is only interesting to the designer and implementor of the interface. Here are some use cases that are well within the design goals: #li Interface evolution. Here, we are adding a new method to an existing interface, which has a sensible default implementation in terms of existing methods on that interface. An example would be adding the forEach method to Collection , where the default implementation is written in terms of the iterator(args) method. #li "Optional" methods. Here, the designer of an interface is saying "Implementors need not implement this method if they are willing to live with the limitations in functionality that entails". For example, Iterator.remove was given a default which throws UnsupportedOperationException ; since the vast majority of implementations of Iterator have this behavior anyway, the default makes this method essentially optional. (If the behavior from AbstractCollection were expressed as defaults on Collection , we might do the same for the mutative methods.) #li Convenience methods. These are methods that are strictly for convenience, again generally implemented in terms of non-default methods on the class. The logger(args) method in your first example is a reasonable illustration of this. #li Combinators. These are compositional methods that instantiate new instances of the interface based on the current instance. For example, the methods Predicate.and(args) or Comparator.thenComparing(args) are examples of combinators. If you provide a default implementation, you should also provide some specification for the default (in the JDK, we use the @implSpec javadoc tag for this) to aid implementors in understanding whether they want to override the method or not. Some defaults, like convenience methods and combinators, are almost never overridden; others, like optional methods, are often overridden. You need to provide enough specification (not just documentation) about what the default promises to do, so the implementor can make a sensible decision about whether they need to override it.

Question-5694385, answer-5694473
Create a File object, passing the directory path to the constructor. Use the listFiles(args) to retrieve an array of File objects for each file in the directory, and then call the getName(args) method to get the filename. #pre

Question-5071040, answer-22547954
Always use either String.valueOf(args) or Integer.toString(args) . Using "" + number is an overhead and does the following: #pre

Question-25850328, answer-31838310
The main purpose of marker interfaces is to create special types where types themselves have no behavior of their own. #pre Here save method makes sure that only the objects of classes that implement the MarkerEntity interface are saved, for other types InvalidEntityFoundException is thrown. So here MarkerEntity marker interface is defining a type that adds special behavior to the classes implementing it. Though annotations can also used now to mark classes for some special treatments but marker annotations are replacement for naming pattern not for Marker interfaces. But marker annotations can't fully replace the marker interfaces because; marker interfaces are used to define type (as already explained above) where as marker annotations do not. Source for marker interface comment

Question-22929237, answer-28564046
You can use java.sql.Date.valueOf(args) method as: Date date = java.sql.Date.valueOf(args); No need to add time and time zone info here because they are taken implicitly. See Simpliest java8 LocalDate to java.util.Date conversion and vice versa?

Question-28584669, answer-28596792
To me, it seems that "because it should behave the same as zero" would make a good answer. Arithmetic overflow and underflow should be handlable similarly. If you underflow from the largest near-infinitesimally small value which can be stored in a float, you get zero, and zeros compare as identical. If you overflow from the largest near-infinitely large value which can be stored in a float, you get INF, and INFs compare as identical. This means that code which handles numbers which are out-of-scope in both directions will not require separate special-casing for one or the other. Instead, either both or neither will need to be treated differently. And the simplest requirement is covered by the "neither" case: you want to check if something over/underflowed, you can compare it to zero/INF using just the normal arithmetic comparison operators, without needing to know you current language's special syntax for the checking command: is it Math.isInfinite(), Float.checkForPositiveInfinity(), hasOverflowed()...?

Question-31270759
Exceptions, especially checked ones, can severely interrupt the flow of program logic when the FP idiom is used in Java 8. Here is an arbitrary example: #pre The above code breaks when there's an exception for an unparseable string. But say I just want to replace that with a default value, much like I can with Optional : Stream.of(args).forEach(args); Of course, this still fails because Optional only handles null s. I would like something as follows: Stream.of(args).forEach(args); Note: this is a self-answered question.

Question-19235606, answer-19235857
Spliterator basically means "splittable Iterator". Single thread can traverse/process the entire Spliterator itself, but the Spliterator also has a method trySplit(args) which will "split off" a section for someone else (typically, another thread) to process -- leaving the current spliterator with less work. Collector combines the specification of a reduce function (of map-reduce fame), with an initial value, and a value to combine two results (thus enabling results from Spliterated streams of work, to be combined.) For example, the most basic Collector would have an initial vaue of 0, add an integer onto an existing result, and would 'combine' two results by adding them. Thus summing a spliterated stream of integers. See: #li Spliterator.trySplit() #li Collector<T,A,R>

Question-12317668, answer-12375312
Here we are faced with a bug in the JIT-compiler. Compiler determines that the allocated array is filled after allocation in Arrays.fill(args) , but the check for uses between the allocation and the fill is faulty. So, compiler performs an illegal optimization - it skips zeroing of allocated array. This bug is placed in Oracle bug tracker ( bug id 7196857 ). Unfortunately, I did not wait for any clarifications from Oracle about the following points. As I see, this bug is OS-specific: it absolutely reproducible on 64-bit Linux and Mac, but, as I see from comments, it reproduces not regularly on Windows (for similar versions of JDK). Additionally it would be nice to know when this bug will be fixed. There is only advice at the moment: do not use JDK1.7.0_04 or later if you depend on JLS for newly declared arrays. Update at October 5: In the new Build 10 of the JDK 7u10 (early access) released at October 04, 2012, this bug was fixed at least for Linux OS (I did not test for other). Thanks to @Makoto, who found that this bug is no longer available for public access in Oracle bug database. Unfortunately, I do not know for the reasons Oracle removed it from public access, but it is available in Google cache . Also, this bug has caught the attention of Redhat: the CVE identifiers CVE-2012-4420 ( bugzilla ) and CVE-2012-4416 ( bugzilla ) were assigned to this flaw.

Question-12552863, answer-12665271
Here's my take on the alternatives: 1) #pre For me, the best thing coming to Java from traditional C++ 15 years ago was that you could trust your program. Even if things are in the muck and going wrong, which they often do, I want the rest of the code to be on best behaviour and smelling of roses. Indeed, the BufferedWriter might throw an exception here. Running out of memory wouldn't be unusual, for instance. For other decorators, do you know which of the java.io wrapper classes throw a checked exception from their constructors? I don't. Doesn't do code understandability much good if you rely upon that sort of obscure knowledge. Also there's the "destruction". If there is an error condition, then you probably don't want to be flushing rubbish to a file that needs deleting (code for that not shown). Although, of course, deleting the file is also another interesting operation to do as error handling. Generally you want finally blocks to be as short and reliable as possible. Adding flushes does not help this goal. For many releases some of the buffering classes in the JDK had a bug where an exception from flush within close caused close on the decorated object not be called. Whilst that has been fixed for some time, expect it from other implementations. 2) #pre We're still flushing in the implicit finally block (now with repeated close - this gets worse as you add more decorators), but the construction is safe and we have to implicit finally blocks so even a failed flush doesn't prevent resource release. 3) #pre There's a bug here. Should be: #pre Some poorly implemented decorators are in fact resource and will need to be closed reliably. Also some streams may need to be closed in a particular way (perhaps they are doing compression and need to write bits to finish off, and can't just flush everything. Verdict Although 3 is a technically superior solution, software development reasons make 2 the better choice. However, try-with-resource is still an inadequate fix and you should stick with the Execute Around idiom, which should have a clearer syntax with closures in Java SE 8.

Question-20331163, answer-20331243
Create a DateTimeFormatter using DateTimeFormat.forPattern(String) Using Joda time you would do it like this: #pre Also, if you wanted to use standard Java, you would do it like this: #pre

