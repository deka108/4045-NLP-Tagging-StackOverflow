Question-5192512, answer-22694891
I think many of the answers here may be missing a quality method included in StringBuilder : .delete(args) . I know this is a late reply; however, this should be made known (and explained a bit more thoroughly). Let's say you have a StringBuilder table - which you wish to modify, dynamically, throughout your program (one I am working on right now does this), e.g. StringBuilder table = new StringBuilder(args); If you are looping through the method and alter the content, use the content, then wish to discard the content to "clean up" the StringBuilder for the next iteration, you can delete it's contents, e.g. table.delete(args). start and end being the indices of the chars you wish to remove. Don't know the length in chars and want to delete the whole thing? table.delete(args); NOW, for the kicker. StringBuilders , as mentioned previously, take a lot of overhead when altered frequently (and can cause safety issues with regard to threading); therefore, use StringBuffer - same as StringBuilder (with a few exceptions) - if your StringBuilder is used for the purpose of interfacing with the user.

Question-6416706, answer-6416800
With Guava you can use Lists.newArrayList(Iterable) or Sets.newHashSet(Iterable) , among other similar methods. This will of course copy all the elements in to memory. If that isn't acceptable, I think your code that works with these ought to take Iterable rather than Collection . Guava also happens to provide convenient methods for doing things you can do on a Collection using an Iterable (such as Iterables.isEmpty(args) or Iterables.contains(args) ), but the performance implications are more obvious.
Question-7488643, answer-7488710
Arrays.asList returns a fixed-size List backed by the array. If you want a normal mutable java.util.ArrayList you need to do this: List<T> list = new ArrayList<T>(args); Or, using Guava : List<T> list = Lists.newArrayList(args); Using a Splitter gives you more flexibility in how you split the string and gives you the ability to, for example, skip empty strings in the results and trim results. It also has less weird behavior than String.split as well as not requiring you to split by regex (that's just one option).

Question-22182669, answer-22222274
StackOverflowError occurs due to an application recurses too deeply (This is not an answer you are expecting). Now other things to happen to StackOverflowError is keep calling methods from methods till you get StackOverflowError , but nobody can program to get StackOverflowError and even if those programmer are doing so then they are not following coding standards for cyclomatic complixity that every programmer has to understand while programming. Such reason for 'StackOverflowError' will require much time to rectify it. But unknowingly coding one line or two line which causes StackOverflowError is understandable and JVM throws that and we can rectify it instantly. Here is my answer with picture for some other question.

Question-15202997, answer-29527145
Adding local classes, lambdas and the toString(args) method to complete the previous two answers. Further, I add arrays of lambdas and arrays of anonymous classes (which do not make any sense in practice though): #pre This is the full output: #pre So, here are the rules. First, lets start with primitive types and void : #li If the class object represents a primitive type or void , all the four methods simply returns its name. Now the rules for the getName(args) method: #li Every non-lambda and non-array class or interface (i.e, top-level, nested, inner, local and anonymous) has a name (which is returned by getName(args) ) that is the package name followed by a dot (if there is a package), followed by the name of its class-file as generated by the compiler (whithout the suffix .class ). If there is no package, it is simply the name of the class-file. If the class is an inner, nested, local or anonymous class, the compiler should generate at least one $ in its class-file name. Note that for anonymous classes, the class name would end with a dollar-sign followed by a number. #li Lambda class names are generally unpredictable, and you shouldn't care about they anyway. Exactly, their name is the name of the enclosing class, followed by $$Lambda$ , followed by a number, followed by a slash, followed by another number. #li The class descriptor of the primitives are Z for boolean , B for byte , S for short , C for char , I for int , J for long , F for float and D for double . For non-array classes and interfaces the class descriptor is L followed by what is given by getName(args) followed by ; . For array classes, the class descriptor is [ followed by the class descriptor of the component type (which may be itself another array class). #li For array classes, the getName(args) method returns its class descriptor. This rule seems to fail only for array classes whose the component type is a lambda (which possibly is a bug), but hopefully this should not matter anyway because there is no point even on the existence of array classes whose component type is a lambda. Now, the toString(args) method: #li If the class instance represents an interface (or an annotation, which is a special type of interface), the toString(args) returns StringLiteral + getName(args) . If it is a primitive, it returns simply getName(args) . If it is something else (a class type, even if it is a pretty weird one), it returns StringLiteral + getName(args) . The getCanonicalName(args) method: #li For top-level classes and interfaces, the getCanonicalName(args) method returns just what the getName(args) method returns. #li The getCanonicalName(args) method returns null for anonymous or local classes and for array classes of those. #li For inner and nested classes and interfaces, the getCanonicalName(args) method returns what the getName(args) method would replacing the compiler-introduced dollar-signs by dots. #li For array classes, the getCanonicalName(args) method returns null if the canonical name of the component type is null . Otherwise, it returns the canonical name of the component type followed by [] . The getSimpleName(args) method: #li For top-level, nested, inner and local classes, the getSimpleName(args) returns the name of the class as written in the source file. #li For anonymous classes the getSimpleName(args) returns an empty String . #li For lambda classes the getSimpleName(args) just returns what the getName(args) would return without the package name. This do not makes much sense and looks like a bug for me, but there is no point in calling getSimpleName(args) on a lambda class to start with. #li For array classes the getSimpleName(args) method returns the simple name of the component class followed by [] . This have the funny/weird side-effect that array classes whose component type is an anonymous class have just [] as their simple names.

Question-10796160, answer-10796174
You need test.split(args); split uses regular expression and in regex | is metacharacter representing OR operator. You need to escape that character using \ (written in String as StringLiteral since \ is also metacharacter in String literals and require another \ to escape it). You can also use test.split(args); and let Pattern.quote create escaped version of regex representing | .

Question-14534767, answer-33687544
For HTML response below code can be used bufString.append(args);

Question-20001427, answer-22245383
:: is called Method Reference. It is basically a reference to a single method. i.e. it refers to an existing method by name. Short Explanation : Below is an example of a reference to a static method: #pre square can be passed around just like object reference's and trigger when at need. In fact, it can be perfectly used as a reference to a normal method of an object and not just static ones. #pre Function above is a functional interface . Well to fully explain :: , it is important to understand Functional Interface. Plainly, Function interface is an interface with just one abstract method. For example: Runnable , Callable , ActionListener and so. Function above is a functional interface with just one method apply . It takes one argument and produces a result. The reason why :: are awesome is because: #blockquote i.e. Just like writing lambda body: Function<T> square = (Double x) -> x * x; You can simply do: Function<T> square = Hey::square; At runtime they behave exactly the same. The bytecode may/not be the same (For above case, it generates the same bytecode (compile above and check javap -c )) The only major criteria to satisfy is: the method you provide should have a similar signature to method of the FunctionalInterface you use as object reference. Below is illegal Supplier<T> p = Hey::square; //illegal square expects an argument and returns a double. get method in Supplier expects an argument but doesn't return anything. So it is an error. Method Reference refers to a method of the functional interface (As mentioned, functional interface can only have one method). Some more examples: accept method in Consumer takes an input but doesnt return anything. #pre Above getRandom takes no argument and returns a double. So any functional interface that satisfies the criteria of: take no argument and return double can be used. Another example: #pre In case of Parametrized Types : #pre Method Reference can be obtained in different styles, but fundamentally they all mean the same and can simply be visualized as a lambda: #li A static method ( ClassName::methName ) #li An instance method of a particular object ( instanceRef::methName ) #li A super method of a particular object ( super::methName ) #li An instance method of an arbitrary object of a particular type ( ClassName::methName ) #li A class constructor reference ( ClassName::new ) #li An array constructor reference ( TypeName[]::new ) For further reference: #a

Question-22725537, answer-27215810
A slightly shorter version using reduce : things.stream(args) .map(args) .reduce(args); You could also move the reduce function to a static utility method and then it becomes: .reduce(args);

Question-4812570, answer-21765043
You can use the ExceptionUtils.getStackTrace(args); from Apache Commons 3 class org.apache.commons.lang3.exception.ExceptionUtils . #a

Question-7520432, answer-29226136
Also note that .equals(args) normally contains == for testing as this is the first thing you would wish to test for if you wanted to test if two objects are equal. And == actually does look at values for primitive types, for objects it checks the reference.

Question-32714194
String is a special case in Java. It's a class, which I can examine in the source code , but it also has its own infix operator + , which seems to be syntactic sugar for StringBuilder . For example, StringLiteral + yourName; could become new StringBuilder(args).append(args).append(args).toString(args); There are no user-defined operators in Java, so where is + specified for String ? Could the same mechanism be used to make additional operators, such as for vectors?

Question-13102045
I am using Scanner methods nextInt(args) and nextLine(args) for reading input. Basically, it looks like this: #pre The problem is that after entering the numerical value, the first input.nextLine(args) is skipped and the second input.nextLine(args) is executed, so that my output looks like this: #pre I tested my application and it looks like the problem lies in using input.nextInt(args) . If I delete it, then both string1 = input.nextLine(args) and string2 = input.nextLine(args) are executed as I want them to be.

Question-9481865, answer-9482369
This could be a bit tricky in the most general case. On the face of it, InetAddress.getLocalHost(args) should give you the IP address of this host. The problem is that a host could have lots of network interfaces, and an interface could be bound to more than one IP address. And to top that, not all IP addresses will be reachable outside of your machine or your LAN. For example, they could be IP addresses for virtual network devices, private network IP addresses, and so on. What this means is that the IP address returned by InetAddress.getLocalHost(args) might not be the right one to use. How can you deal with this? #li One approach is to use NetworkInterface.getNetworkInterfaces(args) to get all of the known network interfaces on the host, and then iterate over each NI's addresses. #li Another approach is to (somehow) get the externally advertized FQDN for the host, and use InetAddress.getByName(args) to look up the primary IP address. (But how do you get it, and how do you deal with a DNS-based load balancer?) #li A variation of the previous is to get the preferred FQDN from a config file or a command line parameter. #li Another variation is to get the preferred IP address from a config file or a command line parameter. In summary, InetAddress.getLocalHost(args) will typically work, but you may need to provide an alternative method for the cases where your code is run in an environment with "complicated" networking. #blockquote #li Any address in the range 127.xxx.xxx.xxx is a "loopback" address. It is only visible to "this" host. #li Any address in the range 192.168.xxx.xxx is a private (aka site local) IP address. These are reserved for use within an organization. The same applies to 10.xxx.xxx.xxx addresses, and 172.16.xxx.xxx through 172.31.xxx.xxx. #li Addresses in the range 169.254.xxx.xxx are link local IP addresses. These are reserved for use on a single network segment. #li Addresses in the range 224.xxx.xxx.xxx through 239.xxx.xxx.xxx are multicast addresses. #li The address 255.255.255.255 is the broadcast address. #li Anything else should be a valid public point-to-point IPv4 address. In fact, the InetAddress API provides methods for testing for loopback, link local, site local, multicast and broadcast addresses. You can use these to sort out which of the IP addresses you get back is most appropriate.

Question-5192512, answer-30190425
I'll vote for sb.setLength(args); not only because it's one function call but because it don't actually copy the array into another array like sb.delete(args); , It just fill the remaining characters to be 0 and set the length variable to the new length. You can take a look into their implementation to validate my point from here at setLength function and delete0 function.

Question-29262002, answer-29262511
The first case is ok because you are invoking a "special" method (a constructor) and you are no actually taking the created object. Just to make it more clear, I'll put the optional braces in your lambdas: #pre And more clear, I'll translate that to the older notation: #pre In the first case you are executing a constructor, but you are NOT returning the created object, in the second case you are attempting to return a String value, but your method in your interface BiConsumer returns void, hence the compiler error.

Question-24630963
The Java 8 Collectors.toMap throws a NullPointerException if one of the values is 'null'. I don't understand this behaviour, maps can contain null pointers as value without any problems. Is there a good reason why values cannot be null for Collectors.toMap ? Also, is there a nice Java 8 way of fixing this, or should I revert to plain old for loop? An example of my problem: #pre Stacktrace: #pre

Question-28584669, answer-28584954
Because thats the standard. Infinity represents a number greater than or less than Double.MAX_VALUE/-Double.MAX_VALUE. NaN represents the outcome of an operation that didn't make sense. That is, the operation didn't possibly come out with a number. I would guess the logic is once a number gets big enough (infinity) and because of the limitation of floating point numbers, adding numbers to it won't change the outcome, so its 'like' infinity. So if you want to compare to really big numbers, at some point you might just say those two big numbers are close enough for all intents and purposes. But if you want to compare two things that both aren't numbers, you can't compare them so its false. At least you couldn't compare them as a primitive.

Question-29095967, answer-29098447
The solution is to use Stream.collect . To create a Collector using its builder pattern is already given as solution. The alternative is the other overloaded collect being a tiny bit more primitive. #pre As one sees, I make a list of string lists, where there always is at least one last (empty) string list. #li The first function creates a starting list of string lists. It specifies the result (typed) object. #li The second function is called to process each element. It is an action on the partial result and an element. #li The third is not really used, it comes into play on parallelising the processing, when partial results must be combined. A solution with an accumulator: As @StuartMarks points out, the combiner does not fullfill the contract for parallelism. Due to the comment of @ArnaudDenoyelle a version using reduce . #pre #li The first parameter is the accumulated object. #li The second function accumulates. #li The third is the aforementioned combiner.

Question-5263187, answer-5263201
System.out.println(args);

Question-18571223, answer-18571348
The object your method decompressGZIP(args) needs is a byte[] . So the basic, technical answer to the question you have asked is: #pre However the problem you appear to be wrestling with is that this doesn't display very well. Calling toString(args) will just give you the default Object.toString(args) which is the class name + memory address. In your result [B@38ee9f13 , the [B means byte[] and 38ee9f13 is the memory address, separated by an @ . For display purposes you can use: Arrays.toString(args); But this will just display as a sequence of comma-separated integers, which may or may not be what you want. To get a readable String back from a byte[] , use: String string = new String(args); The reason the Charset version is favoured, is that all String objects in Java are stored internally as UTF-16. When converting to a byte[] you will get a different breakdown of bytes for the given glyphs of that String , depending upon the chosen charset.

Question-28584669
Why doesn't infinity comparison follow the logic applied to NaNs? This code prints out false three times: #pre However, if I change Double.NaN to Double.POSITIVE_INFINITY , I get true for equality, but false for the greater-than and less-than comparisons: #pre This seems dangerous. Assuming that infinite values result from overflows, I imagine it's more likely that two variables that ended up as infinities wouldn't actually be equal in perfect arithmetic.

Question-19431234, answer-30133063
Much more convenient way if you are sure you need a default timezone : Date d = java.sql.Timestamp.valueOf(args);

Question-23932061, answer-23932216
You can easily create a Stream out of an Iterable or Iterator : #pre

Question-14809293, answer-14821488
The Collections.unmodifiableList has already been mentioned - the Arrays.asList(args) strangely not! My solution would also be to use the list from the outside and wrap the array as follows: #pre The problem with copying the array is: if you're doing it every time you access the code and the array is big, you'll create a lot of work for the garbage collector for sure. So the copy is a simple but really bad approach - I'd say "cheap", but memory-expensive! Especially when you're having more than just 2 elements. If you look at the source code of Arrays.asList and Collections.unmodifiableList there is actually not much created. The first just wraps the array without copying it, the second just wraps the list, making changes to it unavailable.

Question-30727515, answer-30739477
Since this hasn’t addressed yet, here an explanation, why the translation of Unicode escapes happens before any other source code processing: The idea behind it was that it allows lossless translations of Java source code between different character encodings. Today, there is widespread Unicode support, and this doesn’t look like a problem, but back then it wasn’t easy for a developer from a western country to receive some source code from his Asian colleague containing Asian characters, make some changes (including compiling and testing it) and sending the result back, all without damaging something. So, Java source code can be written in any encoding and allows a wide range of characters within identifiers, character and String literals and comments. Then, in order to transfer it losslessly, all characters not supported by the target encoding are replaced by their Unicode escapes. This is a reversible process and the interesting point is that the translation can be done by a tool which doesn’t need to know anything about the Java source code syntax as the translation rule is not dependent on it. This works as the translation to their actual Unicode characters inside the compiler happens independently to the Java source code syntax as well. It implies that you can perform an arbitrary number of translation steps in both directions without ever changing the meaning of the source code. This is the reason for another weird feature which hasn’t even mentioned: the \uuuuuuxxxx syntax: When a translation tool is escaping characters and encounters a sequence that is already an escaped sequence, it should insert an additional u into the sequence, converting \ucafe to \uucafe . The meaning doesn’t change, but when converting into the other direction, the tool should just remove one u and replace only sequences containing a single u by their Unicode characters. That way, even Unicode escapes are retained in their original form when converting back and forth. I guess, no-one ever used that feature…

Question-28276423, answer-28276463
If all of the streams have been instantiated then closing only the outermost is just fine. The documentation on Closeable interface states that close method: #blockquote The releasing system resources includes closing streams. It also states that: #blockquote So if you close them explicitly afterwards, nothing wrong will happen.

Question-9510125
Swing components have multiple methods related to updates of screen layout, in particular: #li validate() #li invalidate() #li revalidate() The Java documentation defines these somewhat from a technical perspective, but it's not particularly clear how they are meant to be used. What is the difference between these, and in what circumstances should you use one rather than the others?

Question-28818506, answer-28821352
It's not pretty, but this will work: return serviceA(args) .map(args).orElseGet(args) .map(args).orElseGet(args) .map(args).orElseGet(args); .map(args).orElseGet(args) is a fairly handy pattern for use with Optional . It means "If this Optional contains value v , give me func(args) , otherwise give me sup.get(args) ". In this case, we call serviceA(args) and get an Optional<T> . If that Optional contains value v , we want to get Optional.of(args) , but if it is empty, we want to get serviceB(args) . Rinse-repeat with more alternatives. Other uses of this pattern are #li .map(args).orElseGet(args) #li .map(args).orElseGet(args)

Question-14316487, answer-14316543
A very simple implementation with String.split() : #pre

Question-19416644, answer-19775881
Create your own class System in tha same package with Condition . In this case your System class will hide java.lang.System class #pre Ideone DEMO

Question-16098046, answer-25307973
In short: If you want to get rid of trailing zeros and Locale problems, then you should use : #pre Explanation: Why other answers did not suit me : #li Double.toString(args) or System.out.println or FloatingDecimal.toJavaFormatString uses scientific notations if double is less than 10^-3 or greater than or equal to 10^7 #li by using %f , the default decimal precision is 6, otherwise you can hardcode it but it results in extra zeros added if you have less decimals. Example : #pre #li by using setMaximumFractionDigits(args); or %.0f you remove any decimal precision, which is fine for integers/longs but not for double #pre #li by using DecimalFormat, you are local dependent. In French locale, the decimal separator is a comma, not a point : #pre Using the ENGLISH locale makes sure you get a point for decimal separator, wherever your program will run Why using 340 then for setMaximumFractionDigits ? Two reasons : #li setMaximumFractionDigits accepts an integer but its implementation has a maximum digits allowed of DecimalFormat.DOUBLE_FRACTION_DIGITS which equals 340 #li Double.MIN_VALUE = 4.9E-324 so with 340 digits you are sure not to round your double and loose precision

Question-24676877, answer-24679745
The answer is, as always, "it depends". It depends on how big the returned collection will be. It depends on whether the result changes over time, and how important consistency of the returned result is. And it depends very much on how the user is likely to use the answer. First, note that you can always get a Collection from a Stream, and vice versa: // If API returns Collection, convert with stream(args) getFoo(args).stream(args)... // If API returns Stream, use collect(args) Collection<T> c = getFooStream(args).collect(args); So the question is, which is more useful to your callers. If your result might be infinite, there's only one choice: Stream. If your result might be very large, you probably prefer Stream, since there may not be any value in materializing it all at once, and doing so could create significant heap pressure. If all the caller is going to do is iterate through it (search, filter, aggregate), you should prefer Stream, since Stream has these built-in already and there's no need to materialize a collection (especially if the user might not process the whole result.) This is a very common case. Even if you know that the user will iterate it multiple times or otherwise keep it around, you still may want to return a Stream instead, for the simple fact that whatever Collection you choose to put it in (e.g., ArrayList) may not be the form they want, and then the caller has to copy it anyway. if you return a stream, they can do collect(args) and get it in exactly the form they want. The above "prefer Stream" cases mostly derive from the fact that Stream is more flexible; you can late-bind to how you use it without incurring the costs and constraints of materializing it to a Collection. The one case where you must return a Collection is when there are strong consistency requirements, and you have to produce a consistent snapshot of a moving target. Then, you will want put the elements into a collection that will not change. So I would say that most of the time, Stream is the right answer -- it is more flexible, it doesn't impose usually-unnecessary materialization costs, and can be easily turned into the Collection of your choice if needed. But sometimes, you may have to return a Collection (say, due to strong consistency requirements), or you may want to return Collection because you know how the user will be using it and know this is the most convenient thing for them.

Question-20363719, answer-34675066
I was trying to do this and found that, using the answers above, when using Functions.identity(args) for the key to the Map, then I had issues with using a local method like this::localMethodName to actually work because of typing issues. Functions.identity(args) actually does something to the typing in this case so the method would only work by returning Object and accepting a param of Object To solve this, I ended up ditching Functions.identity(args) and using s->s instead. So my code, in my case to list all directories inside a directory, and for each one use the name of the directory as the key to the map and then call a method with the directory name and return a collection of items, looks like: Map<T> items = Arrays.stream(args) .map(args) .collect(args);

Question-6416706, answer-6416788
As soon as you call contains , containsAll , equals , hashCode , remove , retainAll , size or toArray , you'd have to traverse the elements anyway. If you're occasionally only calling methods such as isEmpty or clear I suppose you'd be better of by creating the collection lazily. You could for instance have a backing ArrayList for storing previously iterated elements. I don't know of any such class in any library, but it should be a fairly simple exercise to write up.

Question-22740464, answer-22741520
Unfortunately this answer is probably of little or no help whatsoever, but I did a forensics analysis of the Java Lambda Mailing list to see if I could find the cause of this design. This is what I found out. In the beginning there was an instance method for Stream.concat(Stream) In the mailing list I can clearly see the method was originally implemented as an instance method, as you can read in this thread by Paul Sandoz, about the concat operation. In it they discuss the issues that could arise from those cases in which the stream could be infinite and what concatenation would mean in those cases, but I do not think that was the reason for the modification. You see in this other thread that some early users of the JDK 8 questioned about the behavior of the concat instance method when used with null arguments. This other thread reveals, though, that the design of the concat method was under discussion. Refactored to Streams.concat(Stream,Stream) But without any explanation, suddenly, the methods were changed to static methods, as you can see in this thread about combining streams . This is perhaps the only mail thread that sheds a bit of light about this change, but it was not clear enough for me to determine the reason for the refactoring. But we can see they did a commit in which they suggested to move the concat method out of Stream and into the helper class Streams . Refactored to Stream.concat(Stream,Stream) Later, it was moved again from Streams to Stream , but yet again, no explanation for that. So, bottom line, the reason for the design is not entirely clear for me and I could not find a good explanation. I guess you could still ask the question in the mailing list. Some Alternatives for Stream Concatenation This other thread by Michael Hixson discusses/asks about other ways to combine/concat streams #blockquote

Question-5554217, answer-17300003
Another way is to use an array as a type, e.g.: MyClass[] mcArray = gson.fromJson(args); This way you avoid all the hassle with the Type object, and if you really need a list you can always convert the array to a list by: List<T> mcList = Arrays.asList(args); IMHO this is much more readable. And to make it be an actual list (that can be modified, see limitations of Arrays.asList(args) ) then just do the following: List<T> mcList = new ArrayList<T>(args);

Question-17828584
I was wondering what happens when you try to catch an StackOverflowError and came up with the following method: #pre Now my question: Why does this method print '4'? I thought maybe it was because System.out.println(args) needs 3 segments on the call stack, but I don't know where the number 3 comes from. When you look at the source code (and bytecode) of System.out.println(args) , it normally would lead to far more method invocations than 3 (so 3 segments on the call stack would not be sufficient). If it's because of optimizations the Hotspot VM applies (method inlining), I wonder if the result would be different on another VM. Edit : As the output seems to be highly JVM specific, I get the result 4 using Java(TM) SE Runtime Environment (build 1.6.0_41-b02) Java HotSpot(TM) 64-Bit Server VM (build 20.14-b01, mixed mode) Explanation why I think this question is different from Understanding java stack : My question is not about why there is a cnt > 0 (obviously because System.out.println(args) requires stack size and throws another StackOverflowError before something gets printed), but why it has the particular value of 4, respectively 0,3,8,55 or something else on other systems.

Question-16635398, answer-20177092
The better practice is to use for-each . Besides violating the Keep It Simple, Stupid principle, the new-fangled forEach(args) has at least the following deficiencies: #li Can't use non-final variables . So, code like the following can't be turned into a forEach lambda: #blockquote #li Can't handle checked exceptions . Lambdas aren't actually forbidden from throwing checked exceptions, but common functional interfaces like Consumer don't declare any. Therefore, any code that throws checked exceptions must wrap them in try-catch or Throwables.propagate(args) . But even if you do that, it's not always clear what happens to the thrown exception. It could get swallowed somewhere in the guts of forEach(args) #li Limited flow-control . A return in a lambda equals a continue in a for-each, but there is no equivalent to a break . It's also difficult to do things like return values, short circuit, or set flags (which would have alleviated things a bit, if it wasn't a violation of the no non-final variables rule). "This is not just an optimization, but critical when you consider that some sequences (like reading the lines in a file) may have side-effects, or you may have an infinite sequence." #li Might execute in parallel , which is a horrible, horrible thing for all but the 0.1% of your code that needs to be optimized. Any parallel code has to be thought through (even if it doesn't use locks, volatiles, and other particularly nasty aspects of traditional multi-threaded execution). Any bug will be tough to find. #li Might hurt performance , because the JIT can't optimize forEach()+lambda to the same extent as plain loops, especially now that lambdas are new. By "optimization" I do not mean the overhead of calling lambdas (which is small), but to the sophisticated analysis and transformation that the modern JIT compiler performs on running code. #li If you do need parallelism, it is probably much faster and not much more difficult to use an ExecutorService . Streams are both automagical (read: don't know much about your problem) and use a specialized (read: inefficient for the general case) parallelization strategy ( fork-join recursive decomposition ). #li Makes debugging more confusing , because of the nested call hierarchy and, god forbid, parallel execution. The debugger may have issues displaying variables from the surrounding code, and things like step-through may not work as expected. #li Streams in general are more difficult to code, read, and debug . Actually, this is true of complex " fluent " APIs in general. The combination of complex single statements, heavy use of generics, and lack of intermediate variables conspire to produce confusing error messages and frustrate debugging. Instead of "this method doesn't have an overload for type X" you get an error message closer to "somewhere you messed up the types, but we don't know where or how." Similarly, you can't step through and examine things in a debugger as easily as when the code is broken into multiple statements, and intermediate values are saved to variables. Finally, reading the code and understanding the types and behavior at each stage of execution may be non-trivial. #li Sticks out like a sore thumb . The Java language already has the for-each statement. Why replace it with a function call? Why encourage hiding side-effects somewhere in expressions? Why encourage unwieldy one-liners? Mixing regular for-each and new forEach willy-nilly is bad style. Code should speak in idioms (patterns that are quick to comprehend due to their repetition), and the fewer idioms are used the clearer the code is and less time is spent deciding which idiom to use (a big time-drain for perfectionists like myself!). As you can see, I'm not a big fan of the forEach() except in cases when it makes sense. Particularly offensive to me is the fact that Stream does not implement Iterable (despite actually having method iterator ) and cannot be used in a for-each, only with a forEach(). I recommend casting Streams into Iterables with (Iterable<T>)stream::iterator . A better alternative is to use StreamEx which fixes a number of Stream API problems, including implementing Iterable . That said, forEach(args) is useful for the following: #li Atomically iterating over a synchronized list . Prior to this, a list generated with Collections.synchronizedList(args) was atomic with respect to things like get or set, but was not thread-safe when iterating. #li Parallel execution (using an appropriate parallel stream) . This saves you a few lines of code vs using an ExecutorService, if your problem matches the performance assumptions built into Streams and Spliterators. #li Specific containers which , like the synchronized list, benefit from being in control of iteration (although this is largely theoretical unless people can bring up more examples) #li Calling a single function more cleanly by using forEach(args) and a method reference argument (ie, list.forEach(args) ). However, keep in mind the points on checked exceptions, more difficult debugging, and reducing the number of idioms you use when writing code. Articles I used for reference: #li Everything about Java 8 #li Iteration Inside and Out (as pointed out by another poster) EDIT: Looks like some of the original proposals for lambdas (such as #a ) solved some of the issues I mentioned (while adding their own complications, of course).

Question-14846920, answer-14846960
From Effective Java , Item #43 - StringLiteral demonstrates returning an empty collection and perhaps even demonstrates using these emptyList(args) , emptySet(args) , and emptyMap(args) methods on the Collections class to get an empty collection that also has the additional benefit of being immutable. From Item #15 StringLiteral . From Collections-emptySet-Collections-emptyList-Collections #blockquote Note: Below code is just an example (change it according to your use case): #pre These methods offer a couple of advantages: #li They're more concise because you don't need to explicitly type out the generic type of the collection - it's generally just inferred from the context of the method call. #li They're more efficient because they don't bother creating new objects; they just re-use an existing empty and immutable object. This effect is generally very minor, but it's occasionally (well, rarely) important.

Question-5673260, answer-5673375
You should be able to write the file on the response directly. Something like #pre and then write the file as a binary stream on response.getOutputStream(args) . Remember to do response.flush(args) at the end and that should do it.

Question-29095967
I have this list ( List<T> ): [StringLiteral, StringLiteral, null, StringLiteral, null, StringLiteral, StringLiteral] And I'd like something like this: [[StringLiteral, StringLiteral], [StringLiteral], [StringLiteral, StringLiteral]] In other words I want to split my list in sublists using the null value as separator, in order to obtain a list of lists ( List<T> ). I'm looking for a Java 8 solution. I've tried with Collectors.partitioningBy but I'm not sure it is what I'm looking for. Thanks!

Question-31922866, answer-31923015
I believe the reson of being is you have to first check whether or not Optional is null itself and then try to evaluate value it wraps. Too many unnecessary validations.

Question-8894258
In Java, what would the fastest way to iterate over all the chars in a String, this: #pre Or this: #pre EDIT : What I'd like to know is if the cost of repeatedly calling the charAt method during a long iteration ends up being either less than or greater than the cost of performing a single call to toCharArray at the beginning and then directly accessing the array during the iteration. It'd be great if someone could provide a robust benchmark for different string lengths, having in mind JIT warm-up time, JVM start-up time, etc. and not just the difference between two calls to System.currentTimeMillis(args) .

Question-27888429, answer-27888452
Alternative to @sol4me's solution: Stream.of(args) Of the difference between this and Arrays.stream(args) : it does make a difference if your array is of a primitive type. For instance, if you do: Arrays.stream(args) where someArray is a long[] , it will return a LongStream . Stream.of(args) , on the other hand, will return a Stream<T> with a single element.

Question-11821801, answer-11821900
A ReentrantLock is unstructured , unlike synchronized constructs -- i.e. you don't need to use a block structure for locking and can even hold a lock across methods. An example: #pre Such flow is impossible to represent via a single monitor in a synchronized construct. Aside from that, ReentrantLock supports lock polling and interruptible lock waits that support time-out . ReentrantLock also has support for configurable fairness policy , allowing more flexible thread scheduling. #blockquote ReentrantLock may also be more scalable , performing much better under higher contention. You can read more about this here . This claim has been contested, however; see the following comment: #blockquote When should you use ReentrantLock s? According to that developerWorks article... #blockquote

Question-13744450, answer-13744816
In very simple terms (because the other answers are referring you to all the official design patterns anyway, so look at them for further details): If you want to have a class which is monitored by other classes in the ecosystem of your program you say that you want the class to be observable. I.e. there might be some changes in its state which you would want to broadcast to the rest of the program. Now, to do this we have to call some kind of method. We don't want the Observable class to be tightly coupled with the classes that are interested in observing it. It doesn't care who it is as long as it fulfils certain criteria. (Imagine it is a radio station, it doesn't care who is listening as long as they have an FM radio tuned on their frequency). To achieve that we use an interface, referred to as the Observer. Therefore, the Observable class will have a list of Observers (i.e. instances implementing the Observer interface methods you might have). Whenever it wants to broadcast something, it just calls the method on all the observers, one after the other. The last thing to close the puzzle is how will the Observable class know who is interested? So the Observable class must offer some mechanism to allow Observers to register their interest. A method such as addObserver(args) internally adds the Observer to the list of observers, so that when something important happens, it loops through the list and calls the respective notification method of the Observer interface of each instance in the list. It might be that in the interview they did not ask you explicitly about the java.util.Observer and java.util.Observable but about the generic concept. The concept is a design pattern, which Java happens to provide support for directly out of the box to help you implement it quickly when you need it. So I would suggest that you understand the concept rather than the actual methods/classes (which you can look up when you need them). UPDATE In response to your comment, the actual java.util.Observable class offers the following facilities: #li Maintaining a list of java.util.Observer instances. New instances interested in being notified can be added through addObserver(args) , and removed through deleteObserver(args) . #li Maintaining an internal state, specifying whether the object has changed since the last notification to the observers. This is useful because it separates the part where you say that the Observable has changed, from the part where you notify the changes. (E.g. Its useful if you have multiple changes happening and you only want to notify at the end of the process rather than at each small step). This is done through setChanged(args) . So you just call it when you changed something to the Observable and you want the rest of the Observers to eventually know about it. #li Notifying all observers that the specific Observable has changed state. This is done through notifyObservers(args) . This checks if the object has actually changed (i.e. a call to setChanged(args) was made) before proceeding with the notification. There are 2 versions, one with no arguments and one with an Object argument, in case you want to pass some extra information with the notification. Internally what happens is that it just iterates through the list of Observer instances and calls the update(Observable o, Object arg) method for each of them. This tells the Observer which was the Observable object that changed (you could be observing more than one), and the extra Object arg to potentially carry some extra information (passed through notifyObservers(args) .

Question-12544479
I am looking for the easiest and simplest way to bind and convert data in Spring MVC. If possible, without doing any xml configuration. So far I've been using PropertyEditors like so : #pre and #pre It is simple : both conversion are defined in the same class, and the binding is straightforward. If I wanted to do a general binding across all my controllers, I could still add 3 lines in my xml config . But Spring 3.x introduced a new way to do it, using Converters : #blockquote So let's say I want to use Converters because it is "the latest alternative". I would have to create two converters : #pre First drawback : I have to make two classes. Benefit : no need to cast thanks to genericity. Then, how do I simply data bind the converters ? Second drawback : I haven't found any simple way (annotations or other programmatic facilities) to do it in a controller : nothing like someSpringObject.registerCustomConverter(args); . The only ways I've found would be tedious, not simple, and only about general cross-controller binding : #li XML config : #pre #li Java config ( only in Spring 3.1+ ) : #pre With all these drawbacks, why using Converters ? Am I missing something ? Are there other tricks that I am not aware of ? I am tempted to go on using PropertyEditors... Binding is much easier and quicker.

Question-21242110
What is the best way to convert a java.util.Date object to the new JDK 8/JSR-310 java.time.LocalDate ? #pre

Question-13291076, answer-13291109
It really depends on what you want to do with the returned value: #li If you need to get the exact name used to declare the enum constant, you should use name(args) as toString may have been overriden #li If you want to print the enum constant in a user friendly way, you should use toString which may have been overriden (or not!). When I feel that it might be confusing, I provide a more specific getXXX method, for example: #pre

Question-31419029, answer-31419047
An empty HashMap object is much smaller than an array of 2000 Object references. Even though you pass 2000 to the initialCapacity parameter of the HashMap constructor, it's not actually creating 2000 spaces for objects yet.

Question-15655012, answer-15655071
If you make foo static, you must initialize it in the class constructor (or inline where you define it) like the following examples. Class constructor (not instance): #pre Inline: private static final List foo = new ArrayList(args); The problem here is not how the final modifier works, but rather how the static modifier works. The final modifier enforces an initialization of your reference by the time the call to your constructor completes (i.e. you must initialize it in the constructor). When you initialize an attribute in-line, it gets initialized before the code you have defined for the constructor is run, so you get the following outcomes: #li if foo is static , foo = new ArrayList(args) will be executed before the static{} constructor you have defined for your class is executed #li if foo is not static , foo = new ArrayList(args) will be executed before your constructor is run When you do not initilize an attribute in-line, the final modifier enforces that you initialize it and that you must do so in the constructor. If you also have a static modifier, the constructor you will have to initialize the attribute in is the class' initialization block : static{} . The error you get in your code is from the fact that static{} is run when the class is loaded, before the time you instantiate an object of that class. Thus, you will have not initialized foo when the class is created. Think of the static{} block as a constructor for an object of type Class . This is where you must do the initialization of your static final class attributes (if not done inline). Side note: The final modifier assures const-ness only for primitive types and references. When you declare a final object, what you get is a final reference to that object, but the object itself is not constant. What you are really achieving when declaring a final attribute is that, once you declare an object for your specific purpose (like the final List that you have declared), that and only that object will be used for that purpose: you will not be able to change List foo to another List , but you can still alter your List by adding/removing items (the List you are using will be the same, only with its contents altered).

Question-5778658, answer-10768914
You will need an intermediate class which will buffer between. Each time InputStream.read(args) is called, the buffering class will fill the passed in byte array with the next chunk passed in from OutputStream.write(args) . Since the sizes of the chunks may not be the same, the adapter class will need to store a certain amount until it has enough to fill the read buffer and/or be able to store up any buffer overflow. This article has a nice breakdown of a few different approaches to this problem: #a

Question-15655012, answer-24895623
First of all, the place in your code where you are initializing (i.e. assigning for the first time) foo is here: foo = new ArrayList(args); foo is an object (with type List) so it is a reference type, not a value type (like int). As such, it holds a reference to a memory location (e.g. 0xA7D2A834) where your List elements are stored. Lines like this foo.add(args); // Modification-1 do not change the value of foo (which, again, is just a reference to a memory location). Instead, they just add elements into that referenced memory location. To violate the final keyword, you would have to try to re-assign foo as follows again: foo = new ArrayList(args); That would give you a compilation error. Now, with that out of the way, think about what happens when you add the static keyword. When you do NOT have the static keyword, each object that instantiates the class has its own copy of foo. Therefore, the constructor assigns a value to a blank, fresh copy of the foo variable, which is perfectly fine. However, when you DO have the static keyword, only one foo exists in memory that is associated with the class. If you were to create two or more objects, the constructor would be attempting to re-assign that one foo each time, violating the final keyword.

Question-15430247, answer-25757711
ArrayList shrinks or expands dynamically. This is a effective but costly operation, if you know size of your array will be fixed then its better to mention the size of the array,If you don't, new array will be created at each insertion and reallocation will be done for each element. this will cost you. ensureCapacity(args) this method help to avoid reallocations and helps increase size of arraylist. trimToSize(args) this is reverse used to shrink size Arraylist has 3 constructors: #li ArrayList() -builds empty ArrayList #li ArrayList(Collection c) - builds a ArrayList initialized with elements of collection c. #li ArrayList(int capacity) -builds an ArrayList with specified initial capacity.

Question-30522698
The problem I would like to be able to override my apps resources such as R.colour.brand_colour or R.drawable.ic_action_start at runtime. My application connects to a CMS system that will provide branding colours and images. Once the app has downloaded the CMS data it needs to be able to re-skin itself. I know what you are about to say - overriding resources at runtime is not possible. Except that it kinda is. In particular I have found this Bachelor Thesis from 2012 which explains the basic concept - The Activity class in android extends ContextWrapper , which contains the attachBaseContext method. You can override attachBaseContext to wrap the Context with your own custom class which overrides methods such as getColor and getDrawable. Your own implementation of getColor could look the colour up however it wanted. The Calligraphy library uses a similar approach to inject a custom LayoutInflator which can deal with loading custom fonts. The code I have created a simple Activity which uses this approach to override the loading of a colour. #pre The problem is, it doesn't work! The logging shows calls to load resources such as layout/activity_main and mipmap/ic_launcher however color/theme_colour is never loaded. It seems that the context is being used to create the window and action bar, but not the activity's content view. My questions is - Where does the layout inflator load resources from, if not the activities context? I would also like to know - Is there a workable way to override the loading of colours and drawables at runtime? A word about alternative approaches I know its possible to theme an app from CMS data other ways - for example we could create a method getCMSColour(args) then inside our onCreate(args) we have a bunch of code along the lines of: myTextView.setTextColour(args) A similar approach could be taken for drawables, strings, etc. However this would result in a large amount of boilerplate code - all of which needs maintaining. When modifying the UI it would be easy to forget to set the colour on a particular view. Wrapping the Context to return our own custom values is 'cleaner' and less prone to breakage. I would like to understand why it doesn't work, before exploring alternative approaches.

Question-5071040, answer-5071064
There are multiple ways: #li String.valueOf(args) (my preference) #li StringLiteral + number (I don't know how the compiler handles it, perhaps it is as efficient as the above) #li Integer.toString(args)

Question-15202997, answer-37603567
this is best document I found describing getName(), getSimpleName(), getCanonicalName() #a #pre

Question-20746429, answer-24531394
Here is a version done on ints - as asked in the question. Usage: StreamUtil.takeWhile(args); Here's code for StreamUtil: #pre

Question-5031614
There have been some discussions here about JPA entities and which hashCode(args) / equals(args) implementation should be used for JPA entity classes. Most (if not all) of them depend on Hibernate, but I'd like to discuss them JPA-implementation-neutrally (I am using EclipseLink, by the way). All possible implementations are having their own advantages and disadvantages regarding: #li hashCode(args) / equals(args) contract conformity (immutability) for List / Set operations #li Whether identical objects (e.g. from different sessions, dynamic proxies from lazily-loaded data structures) can be detected #li Whether entities behave correctly in detached (or non-persisted) state As far I can see, there are three options : #li Do not override them; rely on Object.equals(args) and Object.hashCode(args) #li hashCode(args) / equals(args) work #li cannot identify identical objects, problems with dynamic proxies #li no problems with detached entities #li Override them, based on the primary key #li hashCode(args) / equals(args) are broken #li correct identity (for all managed entities) #li problems with detached entities #li Override them, based on the Business-Id (non-primary key fields; what about foreign keys?) #li hashCode(args) / equals(args) are broken #li correct identity (for all managed entities) #li no problems with detached entities My questions are: #li Did I miss an option and/or pro/con point? #li What option did you choose and why? UPDATE 1: By " hashCode(args) / equals(args) are broken", I mean that successive hashCode(args) invocations may return differing values, which is (when correctly implemented) not broken in the sense of the Object API documentation, but which causes problems when trying to retrieve a changed entity from a Map , Set or other hash-based Collection . Consequently, JPA implementations (at least EclipseLink) will not work correctly in some cases. UPDATE 2: Thank you for your answers -- most of them have remarkable quality. Unfortunately, I am still unsure which approach will be the best for a real-life application, or how to determine the best approach for my application. So, I'll keep the question open and hope for some more discussions and/or opinions.

Question-8894258, answer-22676782
Despite @Saint Hill's answer if you consider the time complexity of str.toCharArray() , the first one is faster even for very large strings. You can run the code below to see it for yourself. #pre output: #pre

Question-21947452, answer-29434641
I performed tests on Eclipse vs Netbeans 8.0.2, both with Java version 1.8; I used System.nanoTime(args) for measurements. Eclipse: I got the same time on both cases - around 1.564 seconds . Netbeans: #li Using "#": 1.536 seconds #li Using "B": 44.164 seconds So, it looks like Netbeans has bad performance on print to console. After more research I realized that the problem is line-wrapping of the max buffer of Netbeans (it's not restricted to System.out.println command), demonstrated by this code: #pre The time results are less then 1 millisecond every iteration except every fifth iteration , when the time result is around 225 millisecond. Something like (in nanoseconds): #pre And so on.. Summary: #li Eclipse works perfectly with "B" #li Netbeans has a line-wrapping problem that can be solved (because the problem does not occur in eclipse)(without adding space after B ("B ")).

Question-31922866
I've read on many Web sites Optional should be used as a return type only, and not used in method arguments. I'm struggling to find a logical reason why. For example I have a piece of logic which has 2 optional parameters. Therefore I think it would make sense to write my method signature like this (solution 1): #pre Many web pages specify Optional should not be used as method arguments. With this in mind I could use the following method signature and add a clear Javadoc comment specifying the arguments maybe null hoping future future maintainers will read the javadoc and therefore always carry out null checks prior to using the arguments (solution 2): #pre Alternatively I could replace my method with 4 public methods to provide a nicer interface and make it more obvious p1 and p2 are optional (solution 3): #pre Now I try writing the code of the class which invokes this piece of logic for each approach. I first retrieve the 2 input parameters from another object which returns optionals and then I invoke calculateSomething. Therefore if solution 1 is used the calling code would look like this: #pre if solution 2 is used the calling code would look like this: #pre if solution 3 is used I could use the code above or I could use the following (but its a significant amount more code): #pre So my question is why is it considered bad practice to use Optionals as method arguments as in solution 1? It looks like the most readable solution to me and makes it most obvious that the parameters could be empty/null to future maintainers. (I'm aware the designers of Optional intended it to only be used as a return type, but I can't find any logical reasons not to use it in this scenario)

Question-31922866, answer-31923105
Oh, those coding styles are to be taken with a bit of salt. #li (+) Passing an Option result to another method, without any semantic analysis; leaving that to the method, is quite alright. #li (-) Using Optional parameters causing conditional logic inside the methods is literally contra-productive. #li (-) Needing to pack an argument in an Optional, is suboptimal for the compiler, and does an unnecessary wrapping. #li (-) In comparison to nullable parameters Optional is more costly. In general: Optional unifies two states, which have to be unraveled. Hence better suited for result than input, for the complexity of the data flow.

Question-29262002, answer-29262126
The JLS specify that #blockquote Now let's see that in detail, Since your takeBiConsumer method is of void type, the lambda receiving new String(args) will interpret it as a block like #pre which is valid in a void, hence the first case compile. However, in the case where the lambda is -> StringLiteral , a block such as #pre is not valid syntax in java. Therefore the only thing to do with "hi" is to try and return it. #pre which is not valid in a void and explain the error message #pre For a better understanding, note that if you change the type of takeBiConsumer to a String, -> StringLiteral will be valid as it will simply try to directly return the string. Note that at first I tought the error was caused by the lambda being in a wrong invocation context, so I'll share this possibility with the community : JLS 15.27 #blockquote However in our case, we are in an invocation context which is correct.

Question-5673260, answer-5673356
#pre Generally speaking, when you have response.getOutputStream(args) , you can write anything there. You can pass this output stream as a place to put generated PDF to your generator. Also, if you know what file type you are sending, you can set response.setContentType(args);

Question-7707556, answer-15870428
There is a subtle issue here that is a bit of a gotcha. The toString(args) method has a base implementation in Object . CharSequence is an interface; and although the toString(args) method appears as part of that interface, there is nothing at compile-time that will force you to override it and honor the additional constraints that the CharSequence toString(args) method's javadoc puts on the toString(args) method; ie that it should return a string containing the characters in the order returned by charAt(args) . Your IDE won't even help you out by reminding that you that you probably should override toString(args) . For example, in intellij, this is what you'll see if you create a new CharSequence implementation: #a . Note the absence of toString(args) . If you rely on toString(args) on an arbitrary CharSequence , it should work provided the CharSequence implementer did their job properly. But if you want to avoid any uncertainty altogether, you should use a StringBuilder and append(args) , like so: #pre

Question-10786042, answer-16226168
I would not use URLEncoder . Besides being incorrectly named ( URLEncoder has nothing to do with URLs), inefficient (it uses a StringBuffer instead of Builder and does a couple of other things that are slow) Its also way too easy to screw it up. Instead I would use URIBuilder or Spring's URIUtils or Commons Apache HttpClient . The reason being you have to escape the query parameters name (ie BalusC's answer q ) differently than the parameter value. The only downside to the above (that I found out painfully) is that URL's are not a true subset of URI's . Since I'm just linking to other answers I marked this as a community wiki. Feel free to edit.

Question-25850328, answer-25850576
#li Is the definition of a marker interface mentioned above in 1st point wrong? - It is correct in the parts that (1) a marker interface must be empty, and (2) implementing it is meant to imply some special treatment of the implementing class. The part that is incorrect is that it implies that JVM or the compiler would treat the objects of that class differently: you are correct in observing that it is the code of Java class library that treats these objects as cloneable, serializable, etc. It has nothing to do with the compiler or the JVM. #li instead of using the instanceOf operator why can't the method be something like writeObject(args) so that there is a compile-time type checking - This lets you avoid polluting your code with the name of the marker interface when a "plain Object " is needed. For example, if you make a class that needs to be serializable, and has object members, you would be forced to either do casting or make your objects Serializable at compile time. This is inconvenient, because the interface is devoid of any functionality. #li How Annotations are better than Marker Interfaces? - They let you achieve the same purpose of conveying metadata about the class to its consumers without creating a separate type for it. Annotations are more powerful, too, letting programmers pass more sophisticated information to classes that "consume" it.

Question-13950338, answer-17066803
Grant Vibration Permission Before you start implementing any vibration code, you have to give your application the permission to vibrate: <uses-permission android:name=StringLiteral/> Make sure to include this line in your AndroidManifest.xml file. Import the Vibration Library Most IDEs will do this for you, but here is the import statement if yours doesn't: import android.os.Vibrator; Make sure this in the activity where you want the vibration to occur. How to Vibrate for a Given Time In most circumstances, you'll be wanting to vibrate the device for a short, predetermined amount of time. You can achieve this by using the vibrate(args) method. Here is a quick example: #pre That's it, simple! How to Vibrate Indefinitely It may be the case that you want the device to continue vibrating indefinitely. For this, we use the vibrate(args) method: #pre When you're ready to stop the vibration, just call the cancel(args) method: v.cancel(args); How to use Vibration Patterns If you want a more bespoke vibration, you can attempt to create your own vibration patterns: #pre More Complex Vibrations There are multiple SDKs that offer a more comprehensive range of haptic feedback. One that I use for special effects is Immersion's Haptic Development Platform for Android . Troubleshooting If your device won't vibrate, first make sure that it can vibrate: #pre Secondly, please ensure that you've given your application the permission to vibrate! Refer back to the first point.

Question-8725387
In Java there are the SortedSet and SortedMap interfaces. Both belong to Java's standard Collections framework and provide a sorted way to access the elements. However, in my understanding there is no SortedList in Java. You can use java.util.Collections.sort(args) to sort a list. Any idea why it is designed like that?

Question-27430092, answer-27449187
The standard use case for BigInteger.isProbablePrime(int) is in cryptography. Specifically, certain cryptographic algorithms, such as RSA , require randomly chosen large primes. Importantly, however, these algorithms don't really require these numbers to be guaranteed to be prime — they just need to be prime with a very high probability. How high is very high? Well, in a crypto application, one would typically call .isProbablePrime(args) with an argument somewhere between 128 and 256. Thus, the probability of a non-prime number passing such a test is less than one in 2 128 or 2 256 . Let's put that in perspective: if you had 10 billion computers, each generating 10 billion probable prime numbers per second (which would mean less than one clock cycle per number on any modern CPU), and the primality of those numbers was tested with .isProbablePrime(args) , you would, on average, expect one non-prime number to slip in once in every 100 billion years . That is, that would be the case, if those 10 billion computers could somehow all run for hundreds of billions of years without experiencing any hardware failures. In practice, though, it's a lot more likely for a random cosmic ray to strike your computer at just the right time and place to flip the return value of .isProbablePrime(args) from false to true, without causing any other detectable effects, than it is for a non-prime number to actually pass the probabilistic primality test at that certainty level. Of course, the same risk of random cosmic rays and other hardware faults also applies to deterministic primality tests like AKS . Thus, in practice, even these tests have a (very small) baseline false positive rate due to random hardware failures (not to mention all other possible sources of errors, such as implementation bugs). Since it's easy to push the intrinsic false positive rate of the Miller–Rabin primality test used by .isProbablePrime(args) far below this baseline rate, simply by repeating the test sufficiently many times, and since, even repeated so many times, the Miller–Rabin test is still much faster in practice than the best known deterministic primality tests like AKS, it remains the standard primality test for cryptographic applications. (Besides, even if you happened to accidentally select a strong pseudoprime as one of the factors of your RSA modulus, it would not generally lead to a catastrophic failure. Typically, such pseudoprimes would be products of two (or rarely more) primes of approximately half the length, which means that you'd end up with a multi-prime RSA key . As long as none of the factors were too small (and if they were, the primality test should've caught them), the RSA algorithm will still work just fine, and the key, although somewhat weaker against certain types of attacks than normal RSA keys of the same length, should still be reasonably secure if you didn't needlessly skimp on the key length.)

Question-9481865, answer-33093380
You may try isReachable(args) method of InetAddress class to figure out which IP address is your real publicly available IP address. I think other type of addresses (site local,link local) are not reachable from outside. #pre

Question-34509566, answer-34529067
Keep in mind that Java holds a pool of all string literals found in program, used for matching purposes among others, so any different string literal concatenation above will lead to the same object, to the same string literal. You can check out this useful article for more. On the other hand, the concatenation of a String object and a literal (case c + StringLiteral ) will lead to the creation of a as StringBuilder object at runtime, different to the literals found in pool.

Question-16159203, answer-18258659
You have ordinary memory, the 'currentpos' reference and the Point object and its fields behind it, shared between 2 threads, without synchronisation. Thus, there is no defined ordering between the writes that happen to this memory in the main thread and the reads in the created thread (call it T). Main thread is doing the following writes (ignoring the initial setup of point, will result in p.x and p.y having default values): #li to p.x #li to p.y #li to currentpos Because there is nothing special about these writes in terms of synchronisation/barriers, the runtime is free to allow the T thread see them occur in any order (the main thread of course always sees writes and reads ordered according to programme order), and occur at any point between the reads in T. So T is doing: #li reads currentpos to p #li read p.x and p.y (in either order) #li compare, and take the branch #li read p.x and p.y (either order) and call System.out.println Given there's no ordering relationships between the writes in main, and the reads in T, there are clearly several ways this can produce your result, as T may see main's write to currentpos before the writes to currentpos.y or currentpos.x: #li It reads currentpos.x first, before the x write has occurred - gets 0, then reads currentpos.y before the y write has occurred - gets 0. Compare evals to true. The writes become visible to T. System.out.println is called. #li It reads currentpos.x first, after the x write has occurred, then reads currentpos.y before the y write has occurred - gets 0. Compare evals to true. Writes become visible to T... etc. #li It reads currentpos.y first, before the y write has occurred (0), then reads currentpos.x after the x write, evals to true. etc. and so on... There are a number of data races here. I suspect the flawed assumption here is thinking that the writes that result from this line are made visible across all the threads in the programme order of the thread executing it: currentPos = new Point(args); Java makes no such guarantee (it'd be terrible for performance). Something more must be added if your programme needs a guaranteed ordering of the writes relative to reads in other threads. Others have suggested making the x,y fields final, or alternatively making currentpos volatile. #li If you make the x,y fields final, then Java guarantees that the writes of their values will be seen to occur before the constructor returns, in all threads. Thus, as the assignment to currentpos is after the constructor, the T thread is guaranteed to see the writes in the correct order. #li If you make currentpos volatile, then Java guarantees that that this is a synchronisation point which will be total-ordered wrt other synchronisation points. As in main the writes to x and y must happen before the write to currentpos, then any read of currentpos in another thread must see also the writes of x, y that happened before. Using final has the advantage that it makes the fields immutable, and thus allows the values to be cached. Using volatile leads to synchronisation on every write and read of currentpos, which might hurt performance. See chapter 17 of the Java Language Spec for the gory details: #a (Initial answer assumed a weaker memory model, as I was not sure the JLS guaranteed volatile was sufficient. Answer edited to reflect comment from assylias, pointing out the Java model is stronger - happens-before is transitive - and so volatile on currentpos also suffices).

Question-10631715, answer-10631738
You could do this: #pre Basically the .split() method will split the string according to (in this case) delimiter you are passing and will return an array of strings. However, you seem to be after a List of Strings rather than an array, so the array must be turned into a list by using the Arrays.asList() utility. Just as an FYI you could also do something like so: #pre But it is usually better practice to program to an interface rather than to an actual concrete implementation, so I would recommend the 1st option.

Question-22718744, answer-27477312
The behavior of String.split (which calls Pattern.split ) changes between Java 7 and Java 8. Documentation Comparing between the documentation of Pattern.split in Java 7 and Java 8 , we observe the following clause being added: #blockquote The same clause is also added to String.split in Java 8 , compared to Java 7 . Reference implementation Let us compare the code of Pattern.split of the reference implemetation in Java 7 and Java 8. The code is retrieved from grepcode, for version 7u40-b43 and 8-b132. Java 7 #pre Java 8 #pre The addition of the following code in Java 8 excludes the zero-length match at the beginning of the input string, which explains the behavior above. #pre Maintaining compatibility Following behavior in Java 8 and above To make split behaves consistently across versions and compatible with the behavior in Java 8: #li If your regex can match zero-length string, just add (?!\A) at the end of the regex and wrap the original regex in non-capturing group (?:...) (if necessary). #li If your regex can't match zero-length string, you don't need to do anything. #li If you don't know whether the regex can match zero-length string or not, do both the actions in step 1. (?!\A) checks that the string does not end at the beginning of the string, which implies that the match is an empty match at the beginning of the string. Following behavior in Java 7 and prior There is no general solution to make split backward-compatible with Java 7 and prior, short of replacing all instance of split to point to your own custom implementation.

Question-23699371, answer-23733628
The easiest way to implement this is to jump on the sort feature as it already provides an optional Comparator which can be created using an element’s property. Then you have to filter duplicates out which can be done using a statefull Predicate which uses the fact that for a sorted stream all equal elements are adjacent: #pre Of course, a statefull Predicate is not thread-safe, however if that’s your need you can move this logic into a Collector and let the stream take care of the thread-safety when using your Collector . This depends on what you want to do with the stream of distinct elements which you didn’t tell us in your question.

Question-31370403
I'm currently in the process of writing a paint program in java, designed to have flexible and comprehensive functionalities. It stemmed from my final project, that I wrote overnight the day before. Because of that, it's got tons and tons of bugs, which I've been tackling one by one (e.g. I can only save files that will be empty, my rectangles don't draw right but my circles do...). This time, I've been trying to add undo/redo functionality to my program. However, I can't "undo" something that I have done. Therefore, I got an idea to save copies of my BufferedImage each time a mouseReleased event was fired. However, with some of the images going to 1920x1080 resolution, I figured that this wouldn't be efficient: storing them would probably take gigabytes of memory. The reason for why I can't simply paint the same thing with the background colour to undo is because I have many different brushes, which paint based on Math.random(args) , and because there are many different layers (in a single layer). Then, I've considered cloning the Graphics objects that I use to paint to the BufferedImage . Like this: #pre I haven't done this before, so I have a couple questions: #li Would I still be wasting pointless memory by doing this, like cloning my BufferedImages ? #li Is there necessarily a different way I can do this?

Question-32323081
I have a question regarding Java 8 inference with respect to lambdas and their related exception signatures. If I define some method foo: #pre then I get the nice and concise semantic of being able to write foo(args); in most cases for a given T . However, in this example, if my getTheT operation declares that it throws Exception , my foo method which takes a Supplier no longer compiles: the Supplier method signature for get doesn't throw exceptions. It seems like a decent way to get around this would be to overload foo to accept either option, with the overloaded definition being: #pre where ThrowingSupplier is defined as #pre In this way, we have one Supplier type which throws exceptions and one which doesn't. The desired syntax would be something like this: #pre However, this causes issues due to the lambda type being ambiguous (presumably unable to resolve between Supplier and ThrowingSupplier). Doing an explicit cast a la foo(args); would work, but it gets rid of most of the conciseness of the desired syntax. I guess the underlying question is: if the Java compiler is able to resolve the fact that one of my lambdas is incompatible due to it throwing an exception in the Supplier-only case, why isn't it able to use that same information to derive the type of the lambda in the secondary, type-inference case? Any information or resources which anyone could point me to would likewise be much appreciated, as I'm just not too sure where to look for more information on the matter. Thanks!

Question-18571223, answer-20262456
You might wanna try return new String(args)

Question-33147339, answer-33148103
Looking at the code: int newCapacity = oldCapacity + (oldCapacity >> 1); If oldCapacity is quite large, this will overflow, and newCapacity will be a negative number. A comparison like newCapacity < oldCapacity will incorrectly evaluate true and the ArrayList will fail to grow. Instead, the code as written ( newCapacity - minCapacity < 0 returns false) will allow the negative value of newCapacity to be further evaluated in the next line, resulting in recalculating newCapacity by invoking hugeCapacity ( newCapacity = hugeCapacity(args); ) to allow for the ArrayList to grow up to MAX_ARRAY_SIZE . This is what the // overflow-conscious code comment is trying to communicate, though rather obliquely. So, bottom line, the new comparison protects against allocating an ArrayList larger than the predefined MAX_ARRAY_SIZE while allowing it to grow right up to that limit if needed.

Question-18263489, answer-29873100
It isn't pretty, but String.valueOf(args) allows you to use a null String in a switch. If it finds null , it converts it to StringLiteral , otherwise it just returns the same String you passed it. If you don't handle StringLiteral explicitly, then it will go to default . The only caveat is that there is no way of distinguishing between the String StringLiteral and an actual null String. #pre

Question-5243754
What is the difference between getAttribute(args) and getParameter(args) methods within HttpServletRequest class?

Question-5455794, answer-5455809
st.replaceAll(args) removes all whitespaces and non-visible characters (e.g., tab, \n ). st.replaceAll(args) and st.replaceAll(args) produce the same result. The second regex is 20% faster than the first one, but as the number consecutive spaces increases, the first one performs better than the second one. Assign the value to a variable, if not used directly: st = st.replaceAll(args)

Question-31993377, answer-31993478
You are consuming the value of next(args) , but asking for hasNext(args) and hasNextLine(args) . next(args) , per default, returns everything to the next whitespace(args) . So you are iterating through all whitespace seperated strings, and after each of them you are asking about the nextLine(args) . i 1 1 -> hasNextLine(args) ? True. hasNext(args) ? Also true. 1 1 -> hasNextLine(args) ? True. hasNext(args) ? Also true (still a whitespace left) 1 -> hasNextLine(args) ? True (Line Seperator, probably). haxNext? False, no whitespace anymore.

Question-31993377, answer-31993534
You have a single extra newline at the end of your file. #li hasNextLine() checks to see if there is another linePattern in the buffer. #li hasNext() checks to see if there is a parseable token in the buffer, as separated by the scanner's delimiter. Since the scanner's delimiter is whitespace, and the linePattern is also white space, it is possible for there to be a linePattern in the buffer but no parseable tokens. Typically, the most common way to deal with this issue by always calling nextLine(args) after parsing all the tokens (e.g. numbers) in each line of your text. You need to do this when using Scanner when reading a user's input too from System.in . To advance the scanner past this whitespace delimiter, you must use scanner.nextLine(args) to clear the line delimiter. See: Using scanner.nextLine() Appendix: LinePattern is defined to be a Pattern that matches this: #pre The default token delimiter is this Pattern : private static Pattern WHITESPACE_PATTERN = Pattern.compile(args);

Question-29328785
#pre Compile >javac BigDecimalTest.java Execute >java BigDecimalTest Output #pre The value of z.toString(args) in the output is correct 4.883242e+888 / 7.115109e+302 = 6.863200e+585 as is the value of y.toString(args) , but notice that the value given for x.toString(args) is completely wrong. Why is this? Strangely, if the scale (i.e. desired decimal places) of the result of the division is changed BigDecimal z = x.divide(args); then x.toString(args) will produce the correct value for x . Or, if the operands are swapped BigDecimal z = y.divide(args); then x.toString(args) will also then produce the correct value. Or, if the exponent of x is changed from e+888 to e.g. e+878 then x.toString(args) will be correct. Or, if another x.toString(args) call is added above the divide operation, then both x.toString(args) calls will produce the correct value! On the machine I'm testing this, Windows 7 64 bit, the behaviour is the same using java 7 and 8, both 32bit and 64 bit versions, but testing online at #a produces different results for java 7 and java 8. Using java 7, the value of x is given correctly: #a , but using java 8 its value is incorrect: #a . Also, this behaviour is not unique to this particular value of x , as calling toString on other BigDecimals with more than about 1500 digits after passing them as the first operand to a divide operation will also produce incorrect values. What is the explanation for this? The divide operation seems to be mutating the value produced by subsequent toString calls on its operands. Does this happen on your platform? Edit: The issue seems to be with the java 8 runtime only, as the above program compiled with java 7 produces correct output when executed with the java 7 runtime, but incorrect output when executed with the java 8 runtime. Edit: I've tested with the early access jre1.8.0_60 and the bug does not appear, and according to Marco13's answer it was fixed in build 51. The Oracle JDK 8 product binaries are only at update 40 though so it may be some time before the fixed versions are widely used.

Question-5868369, answer-20593147
In Java 8, you could do: #pre Some notes: The stream returned by Files.lines (unlike most streams) needs to be closed. For the reasons mentioned here I avoid using forEach(args) . The strange code (Iterable<T>) lines::iterator casts a Stream to an Iterable.

Question-22463062, answer-28324294
You can also use LocalDate.parse(args) or LocalDateTime.parse(args) on a String without providing it with a pattern, if the String is in ISO-8601 format . for example, #pre Output , #pre and use DateTimeFormatter only if you have to deal with other date patterns, For example, dd MMM uuuu represents the day of the month (two digits), three letters of the name of the month (Jan, Feb, Mar,...), and a four-digit year: #pre Output 04 Aug 2015 parses to 2015-08-04 also remember that the DateTimeFormatter object is bidirectional; it can both parse input and format output. #pre Output 2015-08-04 formats as 04 Aug 2015 (see complete list of Patterns for Formatting and Parsing DateFormatter ) #pre

Question-29095967, answer-29096777
The only solution I come up with for the moment is by implementing your own custom collector. Before reading the solution, I want to add a few notes about this. I took this question more as a programming exercise, I'm not sure if it can be done with a parallel stream. So you have to be aware that it'll silently break if the pipeline is run in parallel . This is not a desirable behavior and should be avoided . This is why I throw an exception in the combiner part (instead of (l1, l2) -> {l1.addAll(args); return l1;} ), as it's used in parallel when combining the two lists, so that you have an exception instead of a wrong result. Also this is not very efficient due to list copying (although it uses a native method to copy the underlying array). So here's the collector implementation: #pre and how to use it: List<T> ll = list.stream(args).collect(args); Output: [[a, b], [c], [d, e]] As the answer of Joop Eggen is out , it appears that it can be done in parallel (give him credit for that!). With that it reduces the custom collector implementation to: #pre which let the paragraph about parallelism a bit obsolete, however I let it as it can be a good reminder. Note that the Stream API is not always a substitute. There are tasks that are easier and more suitable using the streams and there are tasks that are not. In your case, you could also create a utility method for that: #pre and call it like List<T> list = splitBySeparator(args); . It can be improved for checking edge-cases.

Question-32046078
I have a server side implemented in Scala and React/Flux based front end. My services return Futures and they are handled within Scalatra's AsyncResult for JSON responses. For isomorphic/server side rendering setup I did not want to change services to be blocking so I started with Scala Future-> java.util.function.Function conversion shown here . But the dispatcher in Flux would like to have JS Promise. So far I found only rather complicated sounding way around this Slides 68-81 Is there any recommended way to deal with this Scala Future -> JS Promise conversion?

Question-12468764, answer-13368831
Actual Answer: The default deserializer for enums uses .name(args) to deserialize, so it's not using the @JsonValue . So as @OldCurmudgeon pointed out, you'd need to pass in {StringLiteral: StringLiteral} to match the .name(args) value. An other option (assuming you want the write and read json values to be the same)... More Info: There is (yet) another way to manage the serialization and deserialization process with Jackson. You can specify these annotations to use your own custom serializer and deserializer: #pre Then you have to write MySerializer and MyDeserializer which look like this: MySerializer #pre MyDeserializer #pre Last little bit, particularly for doing this to an enum JsonEnum that serializes with the method getYourValue(args) , your serializer and deserializer might look like this: #pre

Question-7569335, answer-39329245
As others have pointed out the preferred way is to use: new StringBuilder(args).reverse(args).toString(args) but if you want to implement this by youself, i'am afraid that the rest of responses have flaws. The reason is that String represent a list of Unicode points, encoded in a char[] array according to the variable-length encoding: UTF-16 . This means some code points use a single element of the array (one code unit) but others use two of them, so there might be pairs of characters that must be treated as a single unit (consecutive "high" and "low" surrogates) #pre

Question-13102045, answer-22593693
There seem to be many questions about this issue with java.util.Scanner . I think a more readable/idiomatic solution would be to call scanner.skip(args) to drop any newline characters after calling nextInt(args) .

Question-6271417, answer-6271460
The "$1" is not "useless non-sense". If your class is anonymous, a number is appended. If you don't want the class itself, but its declaring class, then you can use getEnclosingClass(args) . For example: #pre You can move that in some static utility method. But note that this is not the current class name. The anonymous class is different class than its enclosing class. The case is similar for inner classes.

Question-8579657, answer-19629304
If you do run(args) in main method, the thread of main method will invoke the run method instead of the thread you require to run. The start(args) method creates new thread and for which the run(args) method has to be done

Question-6271417, answer-29938300
Use this method,but be careful to make an object in your main. public static void setName(args){ Class setClass = obj.getClass(args); String className = setClass.getName(args); System.out.println(args); }

Question-28276423, answer-28276497
No, the topmost level Stream or reader will ensure that all underlying streams / readers are closed. Check the close(args) method implementation of your topmost level stream.

Question-27908213
Are enum names interned in Java? I.e. is it guaranteed that enum1.name(args) == enum2.name(args) in case of the same name? And is it safe to compare enum.name(args) to a String that is guaranteed to be interned.

Question-25903137, answer-25903190
#pre It's not quite as nice as the list code. You can't construct new Map.Entry s in a map(args) call so the work is mixed into the collect(args) call.

Question-8894258, answer-8894348
The first one using str.charAt should be faster. If you dig inside the source code of String class, we can see that charAt is implemented as follows: #pre Here, all it does is index an array and return the value. Now, if we see the implementation of toCharArray , we will find the below: #pre As you see, it is doing a System.arraycopy which is definitely going to be a tad slower than not doing it.

Question-16635398, answer-16637740
forEach(args) can be implemented to be faster than for-each loop, because the iterable knows the best way to iterate its elements, as opposed to the standard iterator way. So the difference is loop internally or loop externally. For example ArrayList.forEach(args) may be simply implemented as #pre as opposed to the for-each loop which requires a lot of scaffolding #pre However, we also need to account for two overhead costs by using forEach(args) , one is making the lambda object, the other is invoking the lambda method. They are probably not significant. see also #a for comparing internal/external iterations for different use cases.

Question-20129762, answer-30548433
I would like to point out that StreamEx does implement Iterable (and Stream ), as well as a host of other immensely awesome functionality missing from Stream .

Question-32859038
I have a List<T> collection. I need to convert it into Map<T> The key of the map must be the index of the item in the collection. I can not figure it out how to do this with streams. Something like: items.stream(args).collect(args); Any help? As this question is identified as possible duplicate I need to add that my concrete problem was - how to get the position of the item in the list and put it as a key value

Question-20945049
We all know that String is immutable in Java, but check the following code: #pre Why does this program operate like this? And why is the value of s1 and s2 changed, but not s3 ?

Question-10904911
I am using trying to use the toString(args) method, but I think I am doing it wrong: #a My code: #pre The output is: [I@23fc4bec Also I tried printing like this, but: #pre I took this code out of bigger and more complex code, but I can add it if needed. But this should give general information. I am looking for output, like in Oracle's documentation: #blockquote

Question-20129762, answer-20130475
To convert a Stream to an Iterable , you can do #pre To pass a Stream to a method that expects Iterable , void foo(args) simply foo(args) however it probably looks funny; it might be better to be a little bit more explicit foo(args);

Question-14833008, answer-14833048
You need to escape the dot if you want to split on a literal dot: String extensionRemoved = filename.split(args)[0]; Otherwise you are splitting on the regex . , which means "any character". Note the double backslash needed to create a single backslash in the regex. You're getting an ArrayIndexOutOfBoundsException because your input string is just a dot, ie StringLiteral , which is an edge case that produces an empty array when split on dot; split(regex) removes all trailing blanks from the result, but since splitting a dot on a dot leaves only two blanks, after trailing blanks are removed you're left with an empty array. To avoid getting an ArrayIndexOutOfBoundsException for this edge case, use the overloaded version of split(regex, limit) , which has a second parameter that is the size limit for the resulting array. When limit is negative , the behaviour of removing trailing blanks from the resulting array is disabled: StringLiteral.split(args) // returns an array of two blanks, ie [StringLiteral, StringLiteral] ie, when filename is just a dot StringLiteral , calling filename.split(args)[0] will return a blank, but calling filename.split(args)[0] will throw an ArrayIndexOutOfBoundsException .

Question-31471444, answer-31476657
From Class NumberUtils you'll see it's defined as: #pre So, you'll see that INTEGER_ONE is not the same as 1. It's an object that's already been constructed for you. So, if we're needing an instance of Integer(args) , rather than create your own, you can reuse the one from the library saving time and memory. It really depends on your application, if you indeed what the int version of 1, then, you'd probably be better of using that instead of this Integer class.

Question-27888429, answer-27888481
Stream.of(args) Or, if you are already have an array, you can also do Stream.of(args) For primitive types use IntStream.of or LongStream.of etc.

Question-29095967, answer-29099896
This is a very interesting problem. I came up with a one line solution. It might not very performant but it works. #pre It is a similar idea that @Rohit Jain came up with. I'm grouping the space between the null values. If you really want a List<T> you may append: List<T> ll = cl.stream(args).collect(args);

Question-34250207
As I recall, before Java 8, the default capacity of ArrayList was 10. Surprisingly, the comment on the default (void) constructor still says: Constructs an empty list with an initial capacity of ten. From ArrayList.java : #pre

Question-29922296, answer-29922469
My guess is that enums are limited in size (i.e the size is not limited by language but limited by usage)and thus they don't need a native stream api. Streams are very good when you have to manipulate transform and recollect the elements in a stream; these are not common uses case for Enum (usually you iterate over enum values, but rarely you need to transform, map and collect them). If you need only to do an action over each elements perhaps you should expose only a forEach method #pre

Question-16148575, answer-32866218
The main reason with HashMap not allowing primitive as keys is that HashMap is designed in such a way that for comparing the keys, it makes use of equals() method, and a method can be called only on an object not on a primitive. Thus when int is autoboxed to Integer, Hashmap can call equals() method on Integer object. That is why, you should use Integer instead of int. I mean hashmap throws an error while putting int as a key (Don't know the meaning of the error that is thrown) And if you think that, you can make Map performance faster by making a primitive as a key, there is a library called FastUtil which contains a Map implementation with int type as a key. Because of this, it is much faster than Hashmap
Question-18571223, answer-18571358
Try using String.getBytes(). It returns a byte[] representing string data. Example: #pre

Question-29229373
I have the following sample code: #pre The output is as follows: #pre From here I see that in first case stream really behaves lazily - we use findFirst(args) so once we have first element our filtering lambda is not invoked. However, in second case which uses flatMaps we see that despite first element which fulfils the filter condition is found (it's just any first element as lambda always returns true) further contents of the stream are still being fed through filtering function. I am trying to understand why it behaves like this rather than giving up after first element is calculated as in the first case. Any helpful information would be appreciated.

Question-10796160, answer-21025279
Use proper escaping: string.split(args) Or the helper Regexp.quote(args) which has been created for exactly this purpose: string.split(args) which works with arbitrary input strings. Very useful when you need to quote / escape user input.

Question-34509566, answer-34509669
The difference between d and e is that when you concatenate string literals , the concatenation is performed at compile time. Java compiler treats StringLiteral + StringLiteral expression in the same way as StringLiteral expression, producing the same literal at compile time. Since all String literals get interned, d , which is a result of StringLiteral + StringLiteral , also ends up referencing the same object as a and b 's StringLiteral . The expression for e , which is c + StringLiteral , is evaluated at runtime . Even though it produces the same string, this fact is not used by the compiler. That's why a different String object is produced, resulting in failed comparison on == .

Question-18987692, answer-18987738
You can use IsNull.nullValue() method: #pre

Question-28459498, answer-28465634
I think there are very few differences between the two when you look closely enough. At it's face, an IEnumerable does appear to be a reusable construct: #pre However, the compiler is actually doing a little bit of work to help us out; it generates the following code: #pre Each time you would actually iterate over the enumerable, the compiler creates an enumerator. The enumerator is not reusable; further calls to MoveNext will just return false, and there is no way to reset it to the beginning. If you want to iterate over the numbers again, you will need to create another enumerator instance. To better illustrate that the IEnumerable has (can have) the same 'feature' as a Java Stream, consider a enumerable whose source of the numbers is not a static collection. For example, we can create an enumerable object which generates a sequence of 5 random numbers: #pre Now we have very similar code to the previous array-based enumerable, but with a second iteration over numbers : #pre The second time we iterate over numbers we will get a different sequence of numbers, which isn't reusable in the same sense. Or, we could have written the RandomNumberStream to thrown an exception if you try to iterate over it multiple times, making the enumerable actually unusable (like a Java Stream). Also, what does your enumerable-based quick sort mean when applied to a RandomNumberStream ? Conclusion So, the biggest difference is that .NET allows you to reuse an IEnumerable by implicitly creating a new IEnumerator in the background whenever it would need to access elements in the sequence. This implicit behavior is often useful (and 'powerful' as you state), because we can repeatedly iterate over a collection. But sometimes, this implicit behavior can actually cause problems. If your data source is not static, or is costly to access (like a database or web site), then a lot of assumptions about IEnumerable have to be discarded; reuse is not that straight-forward

Question-31922866, answer-31923214
This seems a bit silly to me, but the only reason I can think of is that object arguments in method parameters already are optional in a way - they can be null. Therefore forcing someone to take an existing object and wrap it in an optional is sort of pointless. That being said, chaining methods together that take/return optionals is a reasonable thing to do, e.g. Maybe monad.

Question-4576352
I can use this: #pre Is there a way to remove all occurrences of character X from a String in Java? I tried this and is not what I want: str.replace(args); //replace with space

Question-12539365, answer-29349910
I must say, that you are absolutely right from a classical approach's point of view: #li If you first create (or change) business logic of your application and then cover it with (adopt) tests ( Test-Last approach ), then it will be very painful and dangerous to let tests know anything about how your software works, other than checking inputs and outputs. #li If you are practicing a Test-Driven approach , then your tests are the first to be written, to be changed and to reflect the use cases of your software's functionality. The implementation depends on tests. That sometimes mean, that you want your software to be implemented in some particular way, e.g. rely on some other component's method or even call it a particular amount of times. That is where Mockito.verify() comes in handy! It is important to remember, that there are no universal tools. The type of software, it's size, company goals and market situation, team skills and many other things influence the decision on which approach to use at your particular case.

Question-16252269, answer-29652714
You can use Collections.sort(args) to sort list if your list contains Comparable elements. Otherwise I would recommend you to implement that interface like here: public class Circle implements Comparable<T> {} and of course provide your own realization of compareTo method like here: #pre And then you can again use Colection.sort(args) as now list contains objects of Comparable type and can be sorted. Order depends on compareTo method. Check this #a for more detailed information.

Question-5982447, answer-5982478
Use the Set#toArray(T[]) method taking a typed array argument of the same size. String[] GPXFILES1 = myset.toArray(args); A different size can also, but that would force the toArray(args) method to create a new array to return instead of reusing the provided argument, which may end up to be less efficient. See also the source code of AbstractCollection#toArray() .

Question-29922296, answer-29926133
I'd go for EnumSet . Because forEach(args) is also defined on Iterable , you can avoid creating the stream altogether: EnumSet.allOf(args).forEach(args); Or with a method reference: EnumSet.allOf(args).forEach(args); Still, the oldschool for-loop feels a bit simpler: #pre

Question-22561614, answer-22561853
Let me explain what is happening here, because it isn't obvious! First, Stream.max() accepts an instance of Comparator so that items in the stream can be compared against each other to find the minimum or maximum, in some optimal order that you don't need to worry too much about. So the question is, of course, why is Integer::max accepted? After all it's not a comparator! The answer is in the way that the new lambda functionality works in Java 8. It relies on a concept which is informally known as "single abstract method" interfaces, or "SAM" interfaces. The idea is that any interface with one abstract method can be automatically implemented by any lambda - or method reference - whose method signature is a match for the one method on the interface. So examining the Comparator interface (simple version): #pre If a method is looking for a Comparator<T> , then it's essentially looking for this signature: int xxx(args); I use "xxx" because the method name is not used for matching purposes . Therefore, both Integer.min(args) and Integer.max(args) are close enough that autoboxing will allow this to appear as a Comparator<T> in a method context.

Question-6684665, answer-6684822
You can't just take the returned string and construct a string from it... it's not a byte[] data type anymore, it's already a string; you need to parse it. For example : #pre ** EDIT ** You get an hint of your problem in your question, where you say " Whatever I seem to try I end up getting a byte array which looks as follows... [91, 45, ... ", because 91 is the byte value for [ , so [91, 45, ... is the byte array of the string " [-45, 1, 16, ... " string. The method Arrays.toString(args) will return a String representation of the specified array; meaning that the returned value will not be a array anymore. For example : #pre As you can see, s1 holds the string representation of the array b1 , while s2 holds the string representation of the bytes contained in b1 . Now, in your problem, your server returns a string similar to s1 , therefore to get the array representation back, you need the opposite constructor method. If s2.getBytes(args) is the opposite of new String(args) , you need to find the opposite of Arrays.toString(args) , thus the code I pasted in the first snippet of this answer.

Question-17781150, answer-17781168
The value you are looking for is Integer.MIN_VALUE . #blockquote That's off-topic for Stack Exchange. But you could do it starting from the definition of Java integers ( JLS 4.2 ) #blockquote and #blockquote and the definition of the Java unary '-' operator ( JLS 15.15.4 ): #blockquote

Question-24603186
In Java 8, the Collection interface was extended with two methods that return Stream<T> : stream(args) , which returns a sequential stream, and parallelStream(args) , which returns a possibly-parallel stream. Stream itself also has a parallel(args) method that returns an equivalent parallel stream (either mutating the current stream to be parallel or creating a new stream). The duplication has obvious disadvantages: #li It's confusing. A question asks whether calling both parallelStream().parallel() is necessary to be sure the stream is parallel , given that parallelStream() may return a sequential stream. Why does parallelStream() exist if it can't make a guarantee? The other way around is also confusing -- if parallelStream() returns a sequential stream, there's probably a reason (e.g., an inherently sequential data structure for which parallel streams are a performance trap); what should Stream.parallel() do for such a stream? (UnsupportedOperationException is not allowed by parallel()'s specification.) #li Adding methods to an interface risks conflicts if an existing implementation has a similarly-named method with an incompatible return type. Adding parallelStream() in addition to stream() doubles the risk for little gain. (Note that parallelStream() was at one point just named parallel(), though I don't know if it was renamed to avoid name clashes or for another reason.) Why does Collection.parallelStream() exist when calling Collection.stream().parallel() does the same thing?

Question-22463062, answer-22463063
Parsing date and time To create a LocalDateTime object from a string you can use the static LocalDateTime.parse() method. It takes a string and a DateTimeFormatter as parameter. The DateTimeFormatter is used to specify the date/time pattern. #pre Formatting date and time To create a formatted string out a LocalDateTime object you can use the format(args) method. #pre Note that there are some commonly used date/time formats predefined as constants in DateTimeFormatter . For example: Using DateTimeFormatter.ISO_DATE_TIME to format the LocalDateTime instance from above would result in the string StringLiteral . The parse(args) and format(args) methods are available for all date/time related objects (e.g. LocalDate or ZonedDateTime )

Question-32820722, answer-32821016
If you look at IntFunction it might become clearer: IntFunction<T> is a FunctionalInterface . It represents a function that takes an int and returns a value of type R . In this case, the return type R is also a FunctionalInterface , namely an IntUnaryOperator . So the first (outer) function itself returns a function. In this case: When applied to an int , curriedAdd is supposed to return a function that again takes an int (and returns again int , because that's what IntUnaryOperator does). In functional programming it is common to write the type of a function as param -> return_value and you see exactly that here. So the type of curriedAdd is int -> int -> int (or int -> (int -> int) if you like that better). Java 8's lambda syntax goes along with this. To define such a function, you write a -> b -> a + b which is very much similar to actual lambda calculus: λa λb a + b λb a + b is a function that takes a single parameter b and returns a value (the sum). λa λb a + b is a function that accepts a single parameter a and returns another function of a single parameter. λa λb a + b returns λb a + b with a set to the parameter value.

Question-9749746
How do atomic / volatile / synchronized work internally? What is the difference between the following code blocks? Code 1 #pre Code 2 #pre Code 3 #pre Does volatile work in the following way? Is #pre equivalent to #pre I think that two threads cannot enter a synchronized block at the same time... am I right? If this is true then how does atomic.incrementAndGet(args) work without synchronized ? And is it thread-safe? And what is the difference between internal reading and writing to volatile variables / atomic variables? I read in some article that the thread has a local copy of the variables - what is that?

Question-26791441, answer-26886202
You are performing multiple search-replace operations on the input. This will produce undesired results when the replacement strings contain search strings. Consider the foo->bar, bar-foo example, here are the results for each iteration: #li Once upon a time, there was a foo and a bar. (input) #li Once upon a time, there was a bar and a bar. (foo->bar) #li Once upon a time, there was a foo and a foo. (bar->foo, output) You need to perform the replacement in one iteration without going back. A brute-force solution is as follows: #li Search the input from current position to end for multiple search strings until a match is found #li Replace the matched search string with corresponding replace string #li Set current position to the next character after the replaced string #li Repeat A function such as String.indexOfAny(args) -> int[]{index, whichString} would be useful. Here is an example (not the most efficient one): #pre Some tests: #pre Demo on IDEONE Demo on IDEONE, alternate code

Question-33358248
Currently the BlendModes (Subtract, Exclusion etc) use the LauncherImage as the mask. Can I apply these BlendModes to a ColorMatrix? I'm using the GPUImageLibrary colorMatrix[ 0.393, 0.7689999, 0.18899999, 0, 0, 0.349, 0.6859999, 0.16799999, 0, 0, 0.272, 0.5339999, 0.13099999, 0, 0, 0, 0, 0, 1, 0]; SubtractBlendFilter.java #pre GPUIMageTwoInputFilter.java #pre My guess it involves changing something with String SUBTRACT_BLEND_GRAGMENT_SHADER & String VERTEX_SHADER .

Question-27504925, answer-27505121
I'd like to point out this article . It seems as though arrays and objects follow different opcodes. I can't honestly summarize it more than that however it seems, arrays are simply not treated as Objects like we're normally used to so they don't inherit Object methods. Full credits to the author of that post as it's a very interesting read, both short & detailed. Upon further digging into the topic via multiple sources I've decided to give a more elaborate version of my previous answer. The first thing to note that instantiation of Objects and Arrays are very different within the JVM, their follow their respective bytecode. Object: Object instantiation follows a simple Opcode new which is a combination of two operands - indexbyte1 & indexbyte2 . Once instantiated the JVM pushes the reference to this object onto the stack . This occurs for all objects irrespective of their types. Arrays: Array Opcodes (regarding instantiation of an array) however are divided into three different codes. #blockquote newarray opcode is used when creating arrays that involve primitive datatypes ( byte short char int long float double boolean ) rather than object references. #blockquote anewarray opcode is used when creating arrays of object references #blockquote multianewarray instruction is used when allocating multi-dimensional arrays Object can be a class instance or an array. Take from Oracle Docs #blockquote BUT #blockquote This goes hand in hand with the information regarding the opcodes. Arrays are simply not developed to be class interfaces but are instead explicitly created by array creation expression thus naturally wouldn't implicitly be able to inherit and/or override Object . As we have seen, it has nothing to do with the fact that arrays may hold primitive datatypes. After giving it some thought though, it isn't very common to come across situations where one might want to toString(args) or equals(args) however was still a very interesting question to try and answer. Resources: Oracle-Docs chapter 4.3.1 Oracle-Docs chapter 15.10.1 Artima - UnderTheHood

Question-4576352, answer-11325546
You can use str = str.replace(args); as mentioned before and you will be fine. For your information CharLiteral is not an empty (or a valid) character but CharLiteral is. So you could use str = str.replace(args); instead.

Question-32676771, answer-32677400
Despite of the fact that there is no AtomicDouble or AtomicDoubleArray in java, you can easily create your own based on AtomicLongArray . #pre As you can see, I use Double.doubleToLongBits and Double.longBitsToDouble to store Doubles as Longs in AtomicLongArray . They both have the same size in bits, so precision is not lost (except for -NaN, but I don't think it is important). In Java 8 the implementation of add can be even easier, as you can use accumulateAndGet method of AtomicLongArray that was added in java 1.8. Upd : It appears that I virtually re-implemented guava's AtomicDoubleArray .

Question-27949213, answer-27949367
The strategy they describe is to simply reuse the internal character array of one String in possibly many equal Strings. There's no need for each String to have its own copy if they are equal. In order to more quickly determine if 2 strings are equal, the hash code is used as a first step, as it is a fast way to determine if Strings may be equal. Hence their statement: #blockquote This is to make a certain (but slower) comparison for equality once possible equality has been determined using the hash code. In the end, equal Strings will share a single underlying char array. Java has had String.intern(args) for a long time, to do more or less the same (i.e. save memory by deduplicating equal Strings). What's novel about this is that it happens during garbage collection time and can be externally controlled.

Question-18448671, answer-18448685
If you want to modify your List during traversal, then you need to use the Iterator . And then you can use iterator.remove(args) to remove the elements during traversal.

Question-4818699, answer-4818916
The primary use of AtomicInteger is when you are in a multithreaded context and you need to perform thread safe operations on an integer without using synchronized . The assignation and retrieval on the primitive type int are already atomic but AtomicInteger comes with many operations which are not atomic on int . The simplest are the getAndXXX or xXXAndGet . For instance getAndIncrement(args) is an atomic equivalent to i++ which is not atomic because it is actually a short cut for three operations: retrieval, addition and assignation. compareAndSet is very useful to implements semaphores, locks, latches, etc. Using the AtomicInteger is faster and more readable than performing the same using synchronization. A simple test: #pre On my PC with Java 1.6 the atomic test runs in 3 seconds while the synchronized one runs in about 5.5 seconds. The problem here is that the operation to synchronize ( notAtomic++ ) is really short. So the cost of the synchronization is really important compared to the operation. Beside atomicity AtomicInteger can be use as a mutable version of Integer for instance in Map s as values.

Question-22740464
I can add streams or extra elements, like this: Stream stream = Stream.concat(stream1, Stream.concat(args); And I can add new stuff as I go, like this: Stream stream = Stream.concat(args) .filter(args); But this is ugly, because concat is static. If concat were an instance method, the above examples would be much easier to read: Stream stream = stream1.concat(args).concat(args); And Stream stream = stream1 .filter(args) .concat(args) .filter(args) .concat(args) .filter(args); My question is: 1) Is there any good reason why concat is static? Or is there some equivalent instance method I'm missing? 2) In any case, is there a better way of doing this?

Question-28818506, answer-38560612
This is part of JDK 9 in the form of or , which takes a Supplier<T> . Your example would then be: return serviceA(args) .or(args) .or(args); For details see the (preliminary) Javadoc or this post I wrote.

Question-6652687, answer-6652772
Use String#trim() method or String allRemoved = myString.replaceAll(args) for trim both the end. For left trim: String leftRemoved = myString.replaceAll(args); For right trim: String rightRemoved = myString.replaceAll(args);

Question-11408427, answer-11408482
The Java language provides special support for the string concatenation operator (+) and for conversion of other objects to strings. String concatenation is implemented through the StringBuilder (or StringBuffer ) class and its append method.

Question-29095967, answer-29097694
Please do not vote. I do not have enough place to explain this in comments . This is a solution with a Stream and a foreach but this is strictly equivalent to Alexis's solution or a foreach loop (and less clear, and I could not get rid of the copy constructor) : #pre I understand that you want to find a more elegant solution with Java 8 but I truly think that it has not been designed for this case. And as said by Mr spoon, highly prefer the naive way in this case.

Question-22409102, answer-22501695
The approach used by Math.min is similar to what Jesper proposes but a little clearer: #pre

Question-30384955, answer-30385298
Replacing the definition of TbinList with class TbinList<T> extends ArrayList<T> {} and defining test2 with TbinList<T> test2 = new TbinList<T>(args); instead would solve the issue. With your definition you're ending up with an ArrayList<T> where T is any fixed class extending Base .

Question-27949213
Since String in Java (like other languages) consumes a lot of memory because each character consumes two bytes, Java 8 has introduced a new feature called String Deduplication which takes advantage of the fact that the char arrays are internal to strings and final, so the JVM can mess around with them. I have read this example so far but since I am not a pro java coder, I am having a hard time grasping the concept. Here is what it says, #blockquote My First question, There is still a lack of resources on this topic since it is recently added in Java 8 update 20, could anyone here share some practical examples on how it help in reducing the memory consumed by String in Java ? Edit: The above link says, #blockquote My 2nd question, If hash code of two String are same then the Strings are already the same, then why compare them char by char once it is found that the two String have same hash code ?

Question-4818699, answer-4818753
There are two main uses of AtomicInteger : #li As an atomic counter ( incrementAndGet(args) , etc) that can be used by many threads concurrently #li As a primitive that supports compare-and-swap instruction ( compareAndSet(args) ) to implement non-blocking algorithms. Here is an example of non-blocking random number generator from Brian Göetz's Java Concurrency In Practice : #pre As you can see, it basically works almost the same way as incrementAndGet(args) , but performs arbitrary calculation ( calculateNext(args) ) instead of increment (and processes the result before return).

Question-16635398, answer-16636899
I feel that I need to extend my comment a bit... About paradigm\style That's probably the most notable aspect. FP became popular due to what you can get avoiding side-effects. I won't delve deep into what pros\cons you can get from this, since this is not related to the question. However, I will say that the iteration using Iterable.forEach is inspired by FP and rather result of bringing more FP to Java (ironically, I'd say that there is no much use for forEach in pure FP, since it does nothing except introducing side-effects). In the end I would say that it is rather a matter of taste\style\paradigm you are currently writing in. About parallelism. From performance point of view there is no promised notable benefits from using Iterable.forEach over foreach(...). According to official docs on Iterable.forEach : #blockquote ... i.e. docs pretty much clear that there will be no implicit parallelism. Adding one would be LSP violation. Now, there are "parallell collections" that are promised in Java 8, but to work with those you need to me more explicit and put some extra care to use them (see mschenk74's answer for example). BTW: in this case Stream.forEach will be used, and it doesn't guarantee that actual work will be done in parallell (depends on underlying collection). UPDATE: might be not that obvious and a little stretched at a glance but there is another facet of style and readability perspective. First of all - plain old forloops are plain and old. Everybody already knows them. Second, and more important - you probably want to use Iterable.forEach only with one-liner lambdas. If "body" gets heavier - they tend to be not-that readable. You have 2 options from here - use inner classes (yuck) or use plain old forloop. People often gets annoyed when they see the same things (iteratins over collections) being done various vays/styles in the same codebase, and this seems to be the case. Again, this might or might not be an issue. Depends on people working on code.

Question-17828584, answer-17832168
I think the number displayed is the number of time the System.out.println call throws the Stackoverflow exception. It probably depend on the implementation of the println and the number of stacking call it is made in it. As an illustration: The main(args) call trigger the Stackoverflow exception at call i. The i-1 call of main catch the exception and call println which trigger a second Stackoverflow . cnt get increment to 1. The i-2 call of main catch now the exception and call println . In println a method is called triggering a 3rd exception. cnt get increment to 2. this continue until println can make all its needed call and finally display the value of cnt . This is then dependent of the actual implementation of println . For the JDK7 either it detect cycling call and throws the exception earlier either it keep some stack resource and throw the exception before reaching the limit to give some room for remediation logic either the println implementation doesn't make calls either the ++ operation is done after the println call thus is by pass by the exception.

Question-5243754, answer-13612866
It is crucial to know that attributes are not parameters . The return type for attributes is an Object , whereas the return type for a parameter is a String . When calling the getAttribute(args) method, bear in mind that the attributes must be cast. Additionally, there is no servlet specific attributes , and there are no session parameters . This post is written with the purpose to connect on @Bozho's response, as additional information that can be useful for other people.

Question-14491966, answer-14563808
It is very unlikely that random number generation performance would be an issue for any use-case you came up with unless accessing a single Random instance from multiple threads (because Random is synchronized ). However, if that really is the case and you need lots of random numbers fast, your solution is far too unreliable. Sometimes it gives good results, sometimes it gives horrible results (based on the initial settings). If you want the same numbers that the Random class gives you, only faster, you could get rid of the synchronization in there: #pre I simply took the java.util.Random code and removed the synchronization which results in twice the performance compared to the original on my Oracle HotSpot JVM 7u9. It is still slower than your QuickRandom , but it gives much more consistent results. To be precise, for the same seed values and single threaded applications, it gives the same pseudo-random numbers as the original Random class would. This code is based on the current java.util.Random in OpenJDK 7u which is licensed under GNU GPL v2 . EDIT 10 months later: I just discovered that you don't even have to use my code above to get an unsynchronized Random instance. There's one in the JDK, too! Look at Java 7's ThreadLocalRandom class. The code inside it is almost identical to my code above. The class is simply a local-thread-isolated Random version suitable for generating random numbers quickly. The only downside I can think of is that you can't set its seed manually. Example usage: Random random = ThreadLocalRandom.current(args);

Question-16148575, answer-18481387
If you code in Android, there is SparseArray , mapping integer to object.

Question-18666710, answer-18792306
An important feature of parametric types is the ability to write polymorphic algorithms, i.e. algorithms that operate on a data structure regardless of its parameter value, such as Arrays.sort(args) . With generics, that's done with wildcard types: <E extends Comparable<T>> void sort(args); To be truly useful, wildcard types require wildcard capture, and that requires the notion of a type parameter. None of that was available at the time arrays were added to Java, and makings arrays of reference type covariant permitted a far simpler way to permit polymorphic algorithms: void sort(args); However, that simplicity opened a loophole in the static type system: #pre requiring a runtime check of every write access to an array of reference type. In a nutshell, the newer approach embodied by generics makes the type system more complex, but also more statically type safe, while the older approach was simpler, and less statically type safe. The designers of the language opted for the simpler approach, having more important things to do than closing a small loophole in the type system that rarely causes problems. Later, when Java was established, and the pressing needs taken care of, they had the resources to do it right for generics (but changing it for arrays would have broken existing Java programs).

Question-10786042
Say I have a URL http://example.com/query?q= and I have a query entered by the user such as: #blockquote I want the result to be a properly encoded URL: http://example.com/query?q=random%20word%20%A3500%20bank%20%24 What's the best way to achieve this? I tried URLEncoder and creating URI/URL objects but none of them come out quite right.

Question-32334319, answer-39380442
As stated across many of the answers. The Quicksort is used by Arrays.sort for sorting primitive collections because stability isn't required (you won't know or care if two identical ints were swapped in the sort) MergeSort or more specifically Timsort is used by Arrays.sort for sorting collections of objects. Stability is required. Quicksort does not provide for stability, Timsort does. Collections.sort delegates to Arrays.sort which is why you see the javadoc referencing the MergeSort.

Question-6470651, answer-6548647
Static field holding object reference [esp final field] #pre Calling String.intern() on lengthy String #pre (Unclosed) open streams ( file , network etc... ) #pre Unclosed connections #pre Areas that are unreachable from JVM's garbage collector , such as memory allocated through native methods In web applications, some objects are stored in application scope until the application is explicitly stopped or removed. getServletContext(args).setAttribute(args); Incorrect or inappropriate JVM options , such as the noclassgc option on IBM JDK that prevents unused class garbage collection See IBM jdk settings .

Question-33635717
I'm reading up about Java streams and discovering new things as I go along. One of the new things I found was the peek(args) function. Almost everything I've read on peek says it should be used to debug your Streams. What if I had a Stream where each Account has a username, password field and a login() and loggedIn() method. I also have Consumer<T> login = account -> account.login(args); and Predicate<T> loggedIn = account -> account.loggedIn(args); Why would this be so bad? #pre Now as far as I can tell this does exactly what it's intended to do. It; #li Takes a list of accounts #li Tries to log in to each account #li Filters out any account which aren't logged in #li Collects the logged in accounts into a new list What is the downside of doing something like this? Any reason I shouldn't proceed? Lastly, if not this solution then what? The original version of this used the .filter() method as follows; #pre

Question-25222811, answer-26676046
To begin with ( and unrelated ), instantiating the Application class by yourself does not seem to be its intended use. From what one can read from its source , you are rather expected to use the static instance returned by getApplication(args) . Now let's get to the error Eclipse reports. I've ran into a similar issue recently: Access restriction: The method ... is not API(args) . I called the method in question as a method of an object which inherited that method from a super class. All I had to do was to add the package the super class was in to the packages imported by my plugin. However, there is a lot of different causes for errors based on "restriction on required project/library ". Similar to the problem described above, the type you are using might have dependencies to packages that are not exported by the library or might not be exported itself. In that case you can try to track down the missing packages and export them my yourself, as suggested here , or try Access Rules. Other possible scenarios include: #li Eclipse wants to keep you from using available packages that are not part of the public Java API (solution 1 , 2 ) #li Dependencies are satisfied by multiple sources, versions are conflicting etc. (solution 1 , 2 , 3 ) #li Eclipse is using a JRE where a JDK is necessary (which might be the case here, from what your errors say; solution ) or JRE/JDK version in project build path is not the right one This ended up as more like a medley of restriction-related issues than an actual answer. But since restriction on required projects is such a versatile error to be reported, the perfect recipe is probably still to be found.

Question-28319064, answer-28323553
One of the main benefits of using streams is that it gives the ability to process data in a declarative way, that is, using a functional style of programming. It also gives multi-threading capability for free meaning there is no need to write any extra multi-threaded code to make your stream concurrent. Assuming the reason you are exploring this style of programming is that you want to exploit these benefits then your first code sample is potentially not functional since the foreach method is classed as being terminal (meaning that it can produce side-effects). The second way is preferred from functional programming point of view since the map function can accept stateless lambda functions. More explicitly, the lambda passed to the map function should be #li Non-interfering, meaning that the function should not alter the source of the stream if it is non-concurrent (e.g. ArrayList ). #li Stateless to avoid unexpected results when doing parallel processing (caused by thread scheduling differences). Another benefit with the second approach is if the stream is parallel and the collector is concurrent and unordered then these characteristics can provide useful hints to the reduction operation to do the collecting concurrently.

Question-16635398
Which of the following is better practice in Java 8? Java 8: joins.forEach(args); Java 7: #pre I have lots of for loops that could be "simplified" with lambdas, but is there really any advantage of using them including performance and readability? EDIT I'll also extend this question to longer methods - I know that you cant return or break the parent function from a lambda and this should be mentioned to if they are compared, but is there anything else to be considered?

Question-24511052
I am looking for a concise way to convert an Iterator to a Stream or more specifically to "view" the iterator as a stream. For performance reason, I would like to avoid a copy of the iterator in a new list: #pre Based on the some suggestions in the comments, I have also tried to use Stream.generate : #pre However, I get a NoSuchElementException (since there is no invocation of hasNext ) #pre I have looked at StreamSupport and Collections but I didn't find anything.

Question-20375176, answer-20375622
A parallel stream has a much higher overhead compared to a sequential one. Coordinating the threads takes a significant amount of time. I would use sequential streams by default and only consider parallel ones if #li I have a massive amount of items to process (or the processing of each item takes time and is parallelizable) #li I have a performance problem in the first place #li I don't already run the process in a multi-thread environment (for example: in a web container, if I already have many requests to process in parallel, adding an additional layer of parallelism inside each request could have more negative than positive effects) In your example, the performance will anyway be driven by the synchronized access to System.out.println(args) , and making this process parallel will have no effect, or even a negative one. Moreover, remember that parallel streams don't magically solve all the synchronization problems. If a shared resource is used by the predicates and functions used in the process, you'll have to make sure that everything is thread-safe. In particular, side effects are tings you really have to worry about if you go parallel. In any case, measure, don't guess! Only a measurement will tell you if the parallelism is worth it or not.

Question-4871051, answer-27760556
System.getProperty(args)

Question-28584669, answer-28590286
Since Double.Nan.equals (Double.NaN) was mentioned: It's one thing what should happen when you perform arithmetic and compare numbers, it's a totally different thing when you consider how objects should behave. Two typical problem cases are: Sorting an array of numbers, and using hash values to implement dictionaries, sets, and so on. There are two exceptional cases where the normal ordering with <, = and > doesn't apply: One case is that +0 = -0 and the other is that NaN ≠ NaN, and x < NaN, x > NaN, x = NaN will always be false whatever x is. Sorting algorithms can get into trouble with this. A sorting algorithm may assume that x = x is always true. So if I know that x is stored in an array and look for it, I might not do any bounds check because the search for it must find something. Not if x is NaN. A sorting algorithm may assume that exactly one of a < b and a >= b must be true. Not if one is NaN. So a naive sorting algorithm may crash when NaNs are present. You'd have to decide where you want NaNs to end up when sorting the array, and then change your comparison code so that it works. Now dictionaries and sets and generally hashing: What if I use an NaN as the key? A set contains unique objects. If the set contains an NaN and I try to add another one, is it unique because it is not equal to the one that is already there? What about +0 and -0, should they be considered equal or different? There's the rule that any two items considered equal must have the same hash value. So the sensible thing is (probably) that a hash function returns one unique value for all NaNs, and one unique value for +0 and -0. And after the hash lookup when you need to find an element with the same hash value that is actually equal, two NaNs should be considered equal (but different from anything else). That's probably why Double.Nan.equal () behaves different from ==.

Question-16148575, answer-16148647
Please use HashMap<T> myMap = new HashMap<T>(args);

Question-27888429, answer-27888447
You can use Arrays.stream E.g. Arrays.stream(args); You can also use Stream.of as mentioned by @fge , which looks like #pre But note Stream.of(args) will return Stream<T> whereas Arrays.stream(args) will return IntStream providing you pass an array of type int[] . So in a nutshell for primitives type you can observe the difference between 2 methods E.g. #pre When you pass primitive array to Arrays.stream , the following code is invoked #pre and when you pass primitive array to Stream.of the following code is invoked #pre Hence you get different results. Updated : As mentioned by Stuart Marks comment The subrange overload of Arrays.stream is preferable to using Stream.of(args).skip(args).limit(args) because the former results in a SIZED stream whereas the latter does not. The reason is that limit(args) doesn't know whether the size is m or less than m, whereas Arrays.stream does range checks and knows the exact size of the stream You can read the source code for stream implementation returned by Arrays.stream(args) here , whereas for stream implementation returned by Stream.of(args).skip(args).limit(args) is within this method .

Question-21488056, answer-35074360
I have written a complete utility class (inspired by Askar's proposal) that can take Java 8 lambda expression and turn them (if applicable) into any typed standard Java 8 lambda defined in the package java.util.function . You can for example do: #li asPredicate(args).negate(args) #li asBiPredicate(args).negate(args) Because there would be numerous ambiguities if all the static methods would be named just as(args) , I opted to call the method "as" followed by the returned type. This gives us full control of the lambda interpretation. Below is the first part of the (somewhat large) utility class revealing the pattern used. Have a look at the complete class here (at gist). #pre

Question-16635398, answer-25855691
TL;DR : List.stream(args).forEach(args) was the fastest. I felt I should add my results from benchmarking iteration. I took a very simple approach (no benchmarking frameworks) and benchmarked 5 different methods: #li classic for #li classic foreach #li List.forEach(args) #li List.stream(args).forEach(args) #li List.parallelStream(args).forEach the testing procedure and parameters #pre The list in this class shall be iterated over and have some doIt(args) applied to all it's members, each time via a different method. in the Main class I run the tested method three times to warm up the JVM. I then run the test method 1000 times summing the time it takes for each iteration method (using System.nanoTime(args) ). After that's done i divide that sum by 1000 and that's the result, average time. example: #pre I ran this on a i5 4 core CPU, with java version 1.8.0_05 classic for #pre execution time: 4.21 ms classic foreach #pre execution time: 5.95 ms List.forEach(args) list.forEach(args); execution time: 3.11 ms List.stream(args).forEach(args) list.stream(args).forEach(args); execution time: 2.79 ms List.parallelStream(args).forEach list.parallelStream(args).forEach(args); execution time: 3.6 ms

Question-17489250, answer-17489376
String gets special treatment in the JLS: it's one of the two non-primitive types for which literals exist (the other is Class ) * . From the JLS : #blockquote * well, there's also the "null type" with it's "null literal" null , but most people don't think of the "null type" as a proper type.

Question-13604703, answer-13604748
Lambdas are purely a call-site construct: the recipient of the lambda does not need to know that a Lambda is involved, instead it accepts an Interface with the appropriate method. In other words, you define or use a functional interface (i.e. an interface with a single method) that accepts and returns exactly what you want. For this Java 8 comes with a set of commonly-used interface types in java.util.function (thanks to Maurice Naftalin for the hint about the JavaDoc). For this specific use case there's java.util.function.IntBinaryOperator with a single int applyAsInt(int left, int right) method , so you could write your method like this: #pre But you can just as well define your own interface and use it like this: #pre Using your own interface has the advantage that you can have names that more clearly indicate the intent.

Question-5778658, answer-5778863
An OutputStream is one where you write data to. If some module exposes an OutputStream , the expectation is that there is something at the other end that is reading. Something that exposes an InputStream on the other hand is indicating that you will need to listen to this stream, and there will be data that you can read. So it is possible to connect an InputStream to an OutputStream InputStream----read---> intermediateBytes[n] ----write----> OutputStream As someone metioned, this is what the copy(args) method from IOUtils lets you do. It does not make sense to go the other way... hopefully this makes some sense UPDATE: Of course the more I think of this, the more I can see how this actually would be a requirement. I know some of the comments mentioned Piped input/ouput streams, but there is another possibility. If the output stream that is exposed is a ByteArrayOutputStream , then you can always get the full contents by calling the toByteArray(args) method. Then you can create an input stream wrapper by using the ByteArrayInputStream sub-class. These two are pseudo-streams, they both basically just wrap an array of bytes. Using the streams this way, therefore, is technically possible, but to me it is still very strange...

Question-5585779, answer-35834484
Integer.decode You can also use public static Integer decode(args) throws NumberFormatException . It also works for base 8 and 16: #pre If you want to get int instead of Integer you can use: #li Unboxing: int val = Integer.decode(args); #li intValue(args) : Integer.decode(args).intValue(args);

Question-26549659
Google Guava has a predicate that always returns true . Does Java 8 have something similar for its Predicate ? I know I could use (foo)->{return true;} , but I want something pre-made, analogous to Collections.emptySet(args) .

Question-19235606, answer-19235863
You should almost certainly never have to deal with Spliterator as a user; it should only be necessary if you're writing Collection types yourself and also intending to optimize parallelized operations on them. For what it's worth, a Spliterator is a way of operating over the elements of a collection in a way that it's easy to split off part of the collection, e.g. because you're parallelizing and want one thread to work on one part of the collection, one thread to work on another part, etc. You should essentially never be saving values of type Stream to a variable, either. Stream is sort of like an Iterator , in that it's a one-time-use object that you'll almost always use in a fluent chain, as in the Javadoc example: int sum = widgets.stream(args) .filter(args) .mapToInt(args) .sum(args); Collector is the most generalized, abstract possible version of a "reduce" operation a la map/reduce; in particular, it needs to support parallelization and finalization steps. Examples of Collector s include: #li summing, e.g. Collectors.reducing(args) #li StringBuilder appending, e.g. Collectors.of(args)

Question-13291076, answer-13291166
name(args) is a "built-in" method of enum . It is final and you cannot change its implementation. It returns the name of enum constant as it is written, e.g. in upper case, without spaces etc. Compare MOBILE_PHONE_NUMBER and Mobile phone number . Which version is more readable? I believe the second one. This is the difference: name(args) always returns MOBILE_PHONE_NUMBER , toString(args) may be overriden to return Mobile phone number .

Question-14534767, answer-14534791
Escape should be done with \ , not / . So r.append(args); or r.append(args); will work ( StringBuilder has overloaded methods for char and String type).

Question-30217236, answer-30217518
Presumably, you are not calling your generic method in a generic fashion, so it's treated like a call to x(args) . In this example: #pre The first call to x is not made generically so it compiles. The second call equates T to String , so it fails because 1 and 2 are not Strings . The third call compiles because it properly passes in Strings .

Question-6840803, answer-6840856
SimpleDateFormat stores intermediate results in instance fields. So if one instance is used by two threads they can mess each other's results. Looking at the source code reveals that there is a Calendar instance field, which is used by operations on DateFormat / SimpleDateFormat For example parse(args) calls calendar.clear(args) initially and then calendar.add(args) . If another thread invokes parse(args) before the completion of the first invocation, it will clear the calendar, but the other invocation will expect it to be populated with intermediate results of the calculation. One way to reuse date formats without trading thread-safety is to put them in a ThreadLocal - some libraries do that. That's if you need to use the same format multiple times within one thread. But in case you are using a servlet container (that has a thread pool), remember to clean the thread-local after you finish. To be honest, I don't understand why they need the instance field, but that's the way it is. You can also use joda-time DateTimeFormat which is threadsafe.

Question-25056607, answer-25056821
Documentation: For: System.out.println(args); #blockquote It will simply return the entire string that's why it returns 1. For the second case, String.split will discard the , so the result will be empty. String.split silently discards trailing separators see guava StringsExplained too

Question-22435833
In Java 8, there is a new method String.chars() which returns a stream of int s ( IntStream ) that represent the character codes. I guess many people would expect a stream of char s here instead. What was the motivation to design the API this way?

