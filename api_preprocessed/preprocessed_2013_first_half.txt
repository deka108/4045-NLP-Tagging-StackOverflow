{
    "items": [
        {
            "cleaned": "The following print statement would print \"hello world\".\nCould anyone explain this? #pre And randomString(_exprs) looks like this: #pre",
            "question_id": 15182496
        },
        {
            "cleaned": "I am working on some Java code which needs to be highly optimized as it will run in hot functions that are invoked at many points in my main program logic. Part of this code involves multiplying double variables by 10 raised to arbitrary non-negative int exponent s. One fast way (edit: but not the fastest possible, see Update 2 below) to get the multiplied value is to switch on the exponent : #pre The commented ellipses above indicate that the case int constants continue incrementing by 1, so there are really 19 case s in the above code snippet. Since I wasn't sure whether I would actually need all the powers of 10 in case statements 10 thru 18 , I ran some microbenchmarks comparing the time to complete 10 million operations with this switch statement versus a switch with only case s 0 thru 9 (with the exponent limited to 9 or less to avoid breaking the pared-down switch ). I got the rather surprising (to me, at least!) result that the longer switch with more case statements actually ran faster. On a lark, I tried adding even more case s which just returned dummy values, and found that  I could get the switch to run even faster with around 22-27 declared case s (even though those dummy cases are never actually hit while the code is running). (Again, case s were added in a contiguous fashion by incrementing the prior case constant by 1 .) These execution time differences are not very significant: for a random exponent between 0 and 10 , the dummy padded switch statement finishes 10 million executions in 1.49 secs versus 1.54 secs for the unpadded version, for a grand total savings of 5ns per execution. So, not the kind of thing that makes obsessing over padding out a switch statement worth the effort from an optimization standpoint. But I still just find it curious and counter-intuitive that a switch doesn't become slower (or perhaps at best maintain constant time) to execute as more case s are added to it. #img These are the results I obtained from running with various limits on the randomly-generated exponent values. I didn't include the results all the way down to 1 for the exponent limit, but the general shape of the curve remains the same, with a ridge around the 12-17 case mark, and a valley between 18-28. All tests were run in JUnitBenchmarks using shared containers for the random values to ensure identical testing inputs. I also ran the tests both in order from longest switch statement to shortest, and vice-versa, to try and eliminate the possibility of ordering-related test problems.  I've put my testing code up on a github repo if anyone wants to try to reproduce these results. So, what's going on here? Some vagaries of my architecture or micro-benchmark construction? Or is the Java switch really a little faster to execute in the 18 to 28 case range than it is from 11 up to 17 ? #a I cleaned up the benchmarking library quite a bit and added a text file in /results with some output across a wider range of possible exponent values. I also added an option in the testing code not to throw an Exception from default , but this doesn't appear to affect the results. Found some pretty good discussion of this issue from back in 2009 on the xkcd forum here: #a . The OP's discussion of using Array.binarySearch(_exprs) gave me the idea for a simple array-based implementation of the exponentiation pattern above. There's no need for the binary search since I know what the entries in the array are. It appears to run about 3 times faster than using switch , obviously at the expense of some of the control flow that switch affords. That code has been added to the github repo also.",
            "question_id": 15621083
        },
        {
            "cleaned": "Which of the following is better practice in Java 8? Java 8: #pre Java 7: #pre I have lots of for loops that could be \"simplified\" with lambdas, but is there really any advantage of using them including performance and readability?  I'll also extend this question to longer methods - I know that you cant return or break the parent function from a lambda and this should be mentioned to if they are compared, but is there anything else to be considered?",
            "question_id": 16635398
        },
        {
            "cleaned": "I am trying to use the org.springframework.orm.jdo.TransactionAwarePersistenceManagerFactoryProxy in my Spring project, but I am not sure how to use it or whether it's exactly what I am looking for. I realize it can help make my DAOs work with a plain JDO PersistenceManagerFactory . Another question is: what happens if the proxy doesn't get made properly? Can I still use it to access my factory to create a transaction aware persistence manager? If the object managed by the factory is a singleton, does this change things? Why not just access the PersistenceManagerFactory directly? Perhaps PersistenceManagerFactoryUtils.getPersistenceManager would be more suited to my needs? Can getObject return null?",
            "question_id": 14636178
        },
        {
            "cleaned": "I made a class called QuickRandom , and its job is to produce random numbers quickly. It's really simple: just take the old value, multiply by a double , and take the decimal part. Here is my QuickRandom class in its entirety: #pre And here is the code I wrote to test it: #pre It is a very simple algorithm that simply multiplies the previous double by a \"magic number\" double. I threw it together pretty quickly, so I could probably make it better, but strangely, it seems to be working fine. This is sample output of the commented-out lines in the main method: #pre Hm. Pretty random. In fact, that would work for a random number generator in a game. Here is sample output of the non-commented out part: #pre Wow! It performs almost 4 times faster than Math.random . I remember reading somewhere that Math.random used System.nanoTime(_exprs) and tons of crazy modulus and division stuff. Is that really necessary? My algorithm performs a lot faster and it seems pretty random. I have two questions: #li Is my algorithm \"good enough\" (for, say, a game, where random numbers aren't too important)? #li Why does Math.random do so much when it seems just simple multiplication and cutting out the decimal will suffice?",
            "question_id": 14491966
        },
        {
            "cleaned": "I have a method with a void return type. It can also throw a number of exceptions so I'd like to test those exceptions being thrown. All attempts have failed with the same reason: #blockquote Any ideas how I can get the method to throw a specified exception? #pre",
            "question_id": 15156857
        },
        {
            "cleaned": "I'm using Spring MVC for a simple JSON API, with @ResponseBody based approach like the following. (I already have a service layer producing JSON directly.) #pre Question is, in the given scenario, ? I did come across approaches like: #pre ...but I can't use it here since my method's return type is String, not ResponseEntity.",
            "question_id": 16232833
        },
        {
            "cleaned": "The usual constructor of ArrayList is: #pre But there is also an overloaded constructor with a parameter for its initial capacity: #pre Why is it useful to create an ArrayList with an initial capacity when we can append to it as we please?",
            "question_id": 15430247
        },
        {
            "cleaned": "What are some of the situations where I can use Collections.emptyMap(_exprs) ? The Documentation says I can use this method if I want my collection to be immutable. ",
            "question_id": 14846920
        },
        {
            "cleaned": "I have a #a object, #pre Now I want to append a newline character to the StringBuilder . How can I do it? #pre Does not work. So, I was thinking about writing a newline using Unicode. Will this help? If so, how can I add one?",
            "question_id": 14534767
        },
        {
            "cleaned": "All I'm trying to do is download some JSON and deserialize it into an object. I haven't got as far as downloading the JSON yet. Almost every single HttpClient example I can find, including those on the apache site looks something like... #pre However, Netbeans tells me that DefaultHttpClient is deprecated. I've tried googling for DefaultHttpClient deprecated and as many other variations as I can think of and can't find any useful results, so I'm obviously missing something. What is the correct Java7 way to download the contents of a webpage? Is there really no decent Http Client as part of the language? I find that hard to believe. My Maven dependency for this is... #pre",
            "question_id": 15336477
        },
        {
            "cleaned": "Why do Double.parseDouble(null) and Integer.parseInt(null) throw different exceptions? Is this a historical accident or intentional? The documentation clearly states two types of exceptions for #a and one for #a , but it seems inconsistent: #pre However #pre",
            "question_id": 16324831
        },
        {
            "cleaned": "I'm relative new to the webservices world and my research seems to have confused me more than enlighten me, my problem is that I was given a library(jar) which I have to extend with some webservice functionality. This library will be shared to other developers, and among the classes in the jar will be classes that have a method which calls a webservice (that essentially sets an attribute of the class, does some business logic, like storing the object in a db, etc and sends back the object with those modifications). I want to make the call to this service as simple as possible, hopefully as simple so that the developer using the class only need to do. #pre I have been studying JAX-WS to use on the server but seems to me that I don't need to create a wsimport in the server nor the wsimport on the client, since I know that both have the classes, I just need some interaction between classes shared in both the server and the client. How do you think makes sense to do the webservice and the call in the class?",
            "question_id": 15940234
        },
        {
            "cleaned": "I am trying to build a HashMap which will have integer as keys and objects as values. My syntax is: #pre However, the error returned is - Syntax error on token \"int\", Dimensions expected after this token - I don't understand why I should add a dimension (ie: making the int into an array) since I only need to store a digit as key. What could I do? Thanks in advance! :)",
            "question_id": 16148575
        },
        {
            "answer_id": 15182578,
            "cleaned": "The other answers explain why, but here is how: #pre The first 6 numbers that the above random generates are: #pre and the first 6 numbers that new Random(_exprs).nextInt(_exprs) generates are: #pre Then just add those numbers to the integer representation of the character ` (which is 96): #pre",
            "question_id": 15182496
        },
        {
            "answer_id": 15203417,
            "cleaned": "If you're unsure about something, try writing a test first. I did this: #pre Prints: #pre There's an empty line in the last block where getSimpleName returns an empty string. The upshot looking at this is: #li the is the name that you'd use to dynamically load the class with, for example, a call to Class.forName with the default ClassLoader . #li the is the name that would be used in an import statement and uniquely identifies the class.  Might be useful during toString or logging operations. #li the loosely identifies the class, again might be useful during toString or logging operations but is not guaranteed to be unique.",
            "question_id": 15202997
        },
        {
            "answer_id": 29527145,
            "cleaned": "Adding local classes, lambdas and the toString(_exprs) method to complete the previous two answers. Further, I add arrays of lambdas and arrays of anonymous classes (which do not make any sense in practice though): #pre This is the full output: #pre So, here are the rules. First, lets start with primitive types and void : #li If the class object represents a primitive type or void , all the four methods simply returns its name. Now the rules for the getName(_exprs) method: #li Every non-lambda and non-array class or interface (i.e, top-level, nested, inner, local and anonymous) has a name (which is returned by getName(_exprs) ) that is the package name followed by a dot (if there is a package), followed by the name of its class-file as generated by the compiler (whithout the suffix .class ). If there is no package, it is simply the name of the class-file. If the class is an inner, nested, local or anonymous class, the compiler should generate at least one $ in its class-file name. Note that for anonymous classes, the class name would end with a dollar-sign followed by a number. #li Lambda class names are generally unpredictable, and you shouldn't care about they anyway. Exactly, their name is the name of the enclosing class, followed by $$Lambda$ , followed by a number, followed by a slash, followed by another number. #li The class descriptor of the primitives are Z for boolean , B for byte , S for short , C for char , I for int , J for long , F for float and D for double . For non-array classes and interfaces the class descriptor is L followed by what is given by getName(_exprs) followed by ; . For array classes, the class descriptor is [ followed by the class descriptor of the component type (which may be itself another array class). #li For array classes, the getName(_exprs) method returns its class descriptor. This rule seems to fail only for array classes whose the component type is a lambda (which possibly is a bug), but hopefully this should not matter anyway because there is no point even on the existence of array classes whose component type is a lambda. Now, the toString(_exprs) method: #li If the class instance represents an interface (or an annotation, which is a special type of interface), the toString(_exprs) returns _str + getName(_exprs) . If it is a primitive, it returns simply getName(_exprs) . If it is something else (a class type, even if it is a pretty weird one), it returns _str + getName(_exprs) . The getCanonicalName(_exprs) method: #li For top-level classes and interfaces, the getCanonicalName(_exprs) method returns just what the getName(_exprs) method returns. #li The getCanonicalName(_exprs) method returns null for anonymous or local classes and for array classes of those. #li For inner and nested classes and interfaces, the getCanonicalName(_exprs) method returns what the getName(_exprs) method would replacing the compiler-introduced dollar-signs by dots. #li For array classes, the getCanonicalName(_exprs) method returns null if the canonical name of the component type is null . Otherwise, it returns the canonical name of the component type followed by [] . The getSimpleName(_exprs) method: #li For top-level, nested, inner and local classes, the getSimpleName(_exprs) returns the name of the class as written in the source file. #li For anonymous classes the getSimpleName(_exprs) returns an empty String . #li For lambda classes the getSimpleName(_exprs) just returns what the getName(_exprs) would return without the package name. This do not makes much sense and looks like a bug for me, but there is no point in calling getSimpleName(_exprs) on a lambda class to start with. #li For array classes the getSimpleName(_exprs) method returns the simple name of the component class followed by [] . This have the funny/weird side-effect that array classes whose component type is an anonymous class have just [] as their simple names.",
            "question_id": 15202997
        },
        {
            "answer_id": 36978943,
            "cleaned": "I've been confused by the wide range of different naming schemes as well, and was just about to ask and answer my own question on this when I found this question here. I think my findings fit it well enough, and complement what's already here. My focus is looking for on the various terms, and adding some more related terms that might crop up in other places. Consider the following example: #pre #li The of D is D . That's just the part you wrote when declaring the class. #a have no simple name. #a returns this name or the empty string. It is possible for the simple name to contain a $ if you write it like this, since $ is a valid part of an identifier. #li According to #a , both a.b.C.D and a.b.C.D.D.D would be , but only a.b.C.D would be the of D . So every canonical name is a fully qualified name, but the converes is not always true. #a will return the canonical name or null . #li #a is documented to return the , as specified in #a . In this case it returns a.b.C$D for D and [La.b.C$D; for D[] . #li #a demonstrates that it is possible for two classes loaded by the same class loader to have the same but distinct . Neither name is sufficient to reliably deduce the other: if you have the canonical name, you don't know which parts of the name are packages and which are containing classes. If you have the binary name, you don't know which $ were introduced as separators and which were part of some simple name. #li #a and #a have no but still have a . The same holds for classes nested inside such classes. class has a binary name. #li Running javap -v -private on a/b/C.class shows that the bytecode refers to the type of d as La/b/C$D; and that of the array ds as [La/b/C$D; . These are called , and they are specified in #a . #li The class name a/b/C$D used in both of these descriptors is what you get by replacing . by / in the binary name. The JVM spec apparently calls this the . #a describes it, and states that the difference from the binary name were for historical reasons. #li The of a class in one of the typical filename-based class loaders is what you get if you interpret the / in the internal form of the binary name as a directory separator, and append the file name extension .class to it. It's resolved relative to the class path used by the class loader in question.",
            "question_id": 15202997
        },
        {
            "answer_id": 37603567,
            "cleaned": "this is best document I found describing getName(), getSimpleName(), getCanonicalName() #a #pre",
            "question_id": 15202997
        },
        {
            "answer_id": 16635489,
            "cleaned": "The advantage comes into account when the operations can be executed in parallel. (See #a - the section about internal and external iteration) #li The main advantage from my point of view is that the implementation of what is to be done within the loop can be defined without having to decide if it will be executed in parallel or sequential #li If you want your loop to be executed in parallel you could simply write #pre You will have to write some extra code for thread handling etc. for my answer I assumed joins implementing the java.util.Stream interface. If joins implements only the java.util.Iterable interface this is no longer true.",
            "question_id": 16635398
        },
        {
            "answer_id": 16636899,
            "cleaned": "I feel that I need to extend my comment a bit...  That's probably the most notable aspect. FP became popular due to what you can get avoiding side-effects. I won't delve deep into what pros\\cons you can get from this, since this is not related to the question. However, I will say that the iteration using Iterable.forEach is inspired by FP and rather result of bringing more FP to Java (ironically, I'd say that there is no much use for forEach in pure FP, since it does nothing except introducing side-effects). In the end I would say that it is rather a matter of taste\\style\\paradigm you are currently writing in.  From performance point of view there is no promised notable benefits from using Iterable.forEach over foreach(...). According to official #a : #blockquote ... i.e. docs pretty much clear that there will be no implicit parallelism. Adding one would be LSP violation. Now, there are \"parallell collections\" that are promised in Java 8, but to work with those you need to me more explicit and put some extra care to use them (see mschenk74's answer for example). BTW: in this case #a will be used, and it doesn't guarantee that actual work will be done in parallell (depends on underlying collection). might be not that obvious and a little stretched at a glance but there is another facet of style and readability perspective. First of all - plain old forloops are plain and old. Everybody already knows them. Second, and more important - you probably want to use Iterable.forEach only with one-liner lambdas. If \"body\" gets heavier - they tend to be not-that readable.\nYou have 2 options from here - use inner classes (yuck) or use plain old forloop.\nPeople often gets annoyed when they see the same things (iteratins over collections) being done various vays/styles in the same codebase, and this seems to be the case. Again, this might or might not be an issue. Depends on people working on code.",
            "question_id": 16635398
        },
        {
            "answer_id": 16637740,
            "cleaned": "forEach(_exprs) can be implemented to be faster than for-each loop, because the iterable knows the best way to iterate its elements, as opposed to the standard iterator way. So the difference is loop internally or loop externally. For example ArrayList.forEach(_exprs) may be simply implemented as #pre as opposed to the for-each loop which requires a lot of scaffolding #pre However, we also need to account for two overhead costs by using forEach(_exprs) , one is making the lambda object, the other is invoking the lambda method. They are probably not significant. see also #a for comparing internal/external iterations for different use cases.",
            "question_id": 16635398
        },
        {
            "answer_id": 20177092,
            "cleaned": "The better practice is to use for-each . Besides violating the principle, the new-fangled forEach(_exprs) has at least the following deficiencies: #li . So, code like the following can't be turned into a forEach lambda: #blockquote #li . Lambdas aren't actually forbidden from throwing checked exceptions, but common functional interfaces like Consumer don't declare any. Therefore, any code that throws checked exceptions must wrap them in try-catch or Throwables.propagate(_exprs) . But even if you do that, it's not always clear what happens to the thrown exception. It could get swallowed somewhere in the guts of forEach(_exprs) #li . A return in a lambda equals a continue in a for-each, but there is no equivalent to a break . It's also difficult to do things like return values,  short circuit, or (which would have alleviated things a bit, if it wasn't a violation of the rule). #a #li , which is a horrible, horrible thing for all but the 0.1% of your code that needs to be optimized. Any parallel code has to be thought through (even if it doesn't use locks, volatiles, and other particularly nasty aspects of traditional multi-threaded execution). Any bug will be tough to find. #li , because the JIT can't optimize forEach()+lambda to the same extent as plain loops, especially now that lambdas are new. By \"optimization\" I do not mean the overhead of calling lambdas (which is small), but to the sophisticated analysis and transformation that the modern JIT compiler performs on running code. #li . Streams are both automagical (read: don't know much about your problem) use a specialized (read: inefficient for the general case) parallelization strategy ( #a ). #li , because of the nested call hierarchy and, god forbid, parallel execution. The debugger may have issues displaying variables from the surrounding code, and things like step-through may not work as expected. #li . Actually, this is true of complex \" #a \" APIs in general. The combination of complex single statements, heavy use of generics, and lack of intermediate variables conspire to produce confusing error messages and frustrate debugging. Instead of \"this method doesn't have an overload for type X\" you get an error message closer to \"somewhere you messed up the types, but we don't know where or how.\" Similarly, you can't step through and examine things in a debugger as easily as when the code is broken into multiple statements, and intermediate values are saved to variables. Finally, reading the code and understanding the types and behavior at each stage of execution may be non-trivial. #li . The Java language already has the for-each statement. Why replace it with a function call? Why encourage hiding side-effects somewhere in expressions? Why encourage unwieldy one-liners? Mixing regular for-each and new forEach willy-nilly is bad style. Code should speak in idioms (patterns that are quick to comprehend due to their repetition), and the fewer idioms are used the clearer the code is and less time is spent deciding which idiom to use (a big time-drain for perfectionists like myself!). As you can see, I'm not a big fan of the forEach() except in cases when it makes sense. Particularly offensive to me is the fact that Stream does not implement Iterable (despite actually having method iterator ) and cannot be used in a for-each, only with a forEach(). I recommend casting Streams into Iterables with (_exprs)stream::iterator . A better alternative is to use #a which fixes a number of Stream API problems, including implementing Iterable . That said, forEach(_exprs) is useful for the following: #li . Prior to this, a list generated with Collections.synchronizedList(_exprs) was atomic with respect to things like get or set, but was not thread-safe when iterating. #li . This saves you a few lines of code vs using an ExecutorService, if your problem matches the performance assumptions built into Streams and Spliterators. #li , like the synchronized list, benefit from being in control of iteration (although this is largely theoretical unless people can bring up more examples) #li by using forEach(_exprs) and a method reference argument (ie, list.forEach (_exprs) ). However, keep in mind the points on checked exceptions, more difficult debugging, and reducing the number of idioms you use when writing code. Articles I used for reference: #li #a #li #a (as pointed out by another poster) Looks like some of the original proposals for lambdas (such as #a ) solved some of the issues I mentioned (while adding their own complications, of course).",
            "question_id": 16635398
        },
        {
            "answer_id": 22502206,
            "cleaned": "When reading this question one can get the impression, that Iterable#forEach in combination with lambda expressions is a shortcut/replacement for writing a traditional for-each loop. This is simply not true. This code from the OP: #pre is intended as a shortcut for writing #pre and should certainly not be used in this way. Instead it is intended as a shortcut (although it is exactly the same) for writing #pre And it is as a replacement for the following Java 7 code: #pre Replacing the body of a loop with a functional interface, as in the examples above, makes your code more explicit: You are saying that (1) the body of the loop does not affect the surrounding code and control flow, and (2) the body of the loop may be replaced with a different implementation of the function, without affecting the surrounding code. Not being able to access non final variables of the outer scope is not a deficit of functions/lambdas, it is a that distinguishes the semantics of Iterable#forEach from the semantics of a traditional for-each loop. Once one gets used to the syntax of Iterable#forEach , it makes the code more readable, because you immediately get this additional information about the code. Traditional for-each loops will certainly stay (to avoid the overused term \" #a \") in Java. But this doesn't mean, that Iterable#forEach should be considered bad practice or bad style. It is always good practice, to use the right tool for doing the job, and this includes mixing traditional for-each loops with Iterable#forEach , where it makes sense. Since the downsides of Iterable#forEach have already been discussed in this thread, here are some reasons, why you might probably want to use Iterable#forEach : #li As described above, Iterable#forEach make your code more explicit and readable in some situations. #li Using a function as the body of a loop allows you to replace this function with different implementations (see #a ). You could e.g. easily replace the lambda expression with a method call, that may be overwritten by sub-classes: #pre Then you could provide default strategies using an enum, that implements the functional interface. This not only makes your code more extensible, it also increases maintainability because it decouples the loop implementation from the loop declaration. #li Seperating the loop implementation from the declaration can also make debugging more easy, because you could have a specialized debug implementation, that prints out debug messages, without the need to clutter your main code with if(_exprs)System.out.println(_exprs) . The debug implementation could e.g. be a #a , that #a the actual function implementation. #li Contrary to some of the assertions in this thread, Iterable#forEach already provide better performance than a traditional for-each loop, at least when using ArrayList and running Hotspot in \"-client\" mode. While this performance boost is small and negligible for most use cases, there are situations, where this extra performance can make a difference. E.g. library maintainers will certainly want to evaluate, if some of their existing loop implementations should be replaced with Iterable#forEach . To back this statement up with facts, I have done some micro-benchmarks with #a . Here is the test code (latest Caliper from git is needed): #pre And here are the results: #li #a #li #a When running with \"-client\", Iterable#forEach outperforms the traditional for loop over an ArrayList, but is still slower than directly iterating over an array. When running with \"-server\", the performance of all approaches is about the same. #li It has already been said here, that the possibility to execute the functional interface of Iterable#forEach in parallel using #a , is certainly an important aspect. Since Collection#parallelStream(_exprs) does not guarantee, that the loop is actually executed in parallel, one must consider this an feature. By iterating over your list with list.parallelStream(_exprs).forEach(_exprs); , you explicitly say: This loop parallel execution, but it does not depend on it. Again, this is a feature and not a deficit! By moving the decision for parallel execution away from your actual loop implementation, you allow optional optimization of your code, without affecting the code itself, which is a good thing. Also, if the default parallel stream implementation does not fit your needs, no one is preventing you from providing your own implementation. You could e.g. provide an optimized collection depending on the underlying operating system, on the size of the collection, on the number of cores, and on some preference settings: #pre The nice thing here is, that your loop implementation doesn't need to know or care about these details.",
            "question_id": 16635398
        },
        {
            "answer_id": 25855691,
            "cleaned": ": List.stream(_exprs).forEach(_exprs) was the fastest. I felt I should add my results from benchmarking iteration.\nI took a very simple approach (no benchmarking frameworks) and benchmarked 5 different methods: #li classic for #li classic foreach #li List.forEach(_exprs) #li List.stream(_exprs).forEach(_exprs) #li List.parallelStream(_exprs).forEach  #pre The list in this class shall be iterated over and have some doIt(_exprs) applied to all it's members, each time via a different method.\nin the Main class I run the tested method three times to warm up the JVM. I then run the test method 1000 times summing the time it takes for each iteration method (using System.nanoTime(_exprs) ). After that's done i divide that sum by 1000 and that's the result, average time.\nexample: #pre I ran this on a i5 4 core CPU, with java version 1.8.0_05  #pre execution time: 4.21 ms  #pre execution time: 5.95 ms  #pre execution time: 3.11 ms  #pre execution time: 2.79 ms  #pre execution time: 3.6 ms",
            "question_id": 16635398
        },
        {
            "answer_id": 31707746,
            "cleaned": "One of most upleasing functional forEach 's limitations is lack of checked exceptions support. One #a is to replace terminal forEach with plain old foreach loop: #pre Here is list of most popular questions with other workarounds on checked exception handling within lambdas and streams: #a #a #a #a",
            "question_id": 16635398
        },
        {
            "answer_id": 15655071,
            "cleaned": "If you make foo static, you must initialize it in the class constructor (or inline where you define it) like the following examples.  #pre  #pre The problem here is not how the final modifier works, but rather how the static modifier works. The final modifier enforces an initialization of your reference by the time the call to your constructor completes (i.e. you must initialize it in the constructor). When you initialize an attribute in-line, it gets initialized before the code you have defined for the constructor is run, so you get the following outcomes: #li if foo is static , foo = new ArrayList(_exprs) will be executed before the static{} constructor you have defined for your class is executed #li if foo is not static , foo = new ArrayList(_exprs) will be executed before your constructor is run When you do not initilize an attribute in-line, the final modifier enforces that you initialize it and that you must do so in the constructor. If you also have a static modifier, the constructor you will have to initialize the attribute in is the class' initialization block : static{} . The error you get in your code is from the fact that static{} is run when the class is loaded, before the time you instantiate an object of that class. Thus, you will have not initialized foo when the class is created. Think of the static{} block as a constructor for an object of type Class . This is where you must do the initialization of your static final class attributes (if not done inline).  The final modifier assures const-ness only for primitive types and references. When you declare a final object, what you get is a final to that object, but the object itself is not constant. What you are really achieving when declaring a final attribute is that, once you declare an object for your specific purpose (like the final List that you have declared), that and only that object will be used for that purpose: you will not be able to change List foo to another List , but you can still alter your List by adding/removing items (the List you are using will be the same, only with its contents altered).",
            "question_id": 15655012
        },
        {
            "answer_id": 15656208,
            "cleaned": "This is . Interviewer tries to find out here, how much you understand about behavior of objects with respect to constructors, methods, class variables(static variables), instance variables. #pre In above case we have defined Test constructor and setFoo method.  #pre foo is an variable. When we create Test class' object then instance variable foo will be copied inside object of Test class. If we assign foo inside constructor then compiler know that Constructor will be invoked only one time. so there is no problem to assign it inside constructor.  #pre foo is now variable. When we create object of Test class then foo will not be copied to the object of Test class because foo is static. Now foo is not the property of each object. This is the property of Test class. But foo can be seen by many objects and if every object which is created by using new keyword which ultimately invoke Test constructor then value will be changed at the time of multiple object creation (Remember static foo is not copied in every object now but is shared between multiple objects.)  #pre Above Modification-2 is from your question. In above case you are not changing first referenced object but you are adding contents inside foo which is allowed. Compiler complains if you try to assign new ArrayList(_exprs) object to the foo reference variable. class cannot be subclassed",
            "question_id": 15655012
        },
        {
            "answer_id": 24895623,
            "cleaned": "First of all, the place in your code where you are initializing (i.e. assigning for the first time) foo is here: #pre foo is an object (with type List) so it is a type, not a type (like int). As such, it holds a reference to a memory location (e.g. 0xA7D2A834) where your List elements are stored. Lines like this #pre do not change the value of foo (which, again, is just a reference to a memory location). Instead, they just add elements into that referenced memory location. To violate the keyword, you would have to try to re-assign foo as follows again: #pre That give you a compilation error. ",
            "question_id": 15655012
        },
        {
            "answer_id": 16323196,
            "cleaned": "#blockquote currentPos = new Point(_exprs); does a few things, including writing default values to x and y (0) and then writing their initial values in the constructor. Since your object is not safely published those 4 write operations can be freely reordered by the compiler / JVM. So from the perspective of the reading thread, it is a legal execution to read x with its new value but y with its default value of 0 for example. By the time you reach the println statement (which by the way is synchronized and therefore does influence the read operations), the variables have their initial values and the program prints the expected values. Marking currentPos as volatile will ensure safe publication since your object is effectively immutable - if in your real use case the object is mutated after construction, volatile guarantees won't be enough and you could see an inconsistent object again. Alternatively, you can make the Point immutable which will also ensure safe publication, even without using volatile . To achieve immutability, you simply need to mark x and y final. As a side note and as already mentioned, synchronized(_exprs) {} can be treated as a no-op by the JVM (I understand you included it to reproduce the behaviour).",
            "question_id": 16159203
        },
        {
            "answer_id": 18258659,
            "cleaned": "You have ordinary memory, the 'currentpos' reference and the Point object and its fields behind it, shared between 2 threads, without synchronisation. Thus, there is no defined ordering between the writes that happen to this memory in the main thread and the reads in the created thread (call it T). Main thread is doing the following writes (ignoring the initial setup of point, will result in p.x and p.y having default values): #li to p.x #li to p.y #li to currentpos Because there is nothing special about these writes in terms of synchronisation/barriers, the runtime is free to allow the T thread see them occur in any order (the main thread of course always sees writes and reads ordered according to programme order), and occur at any point between the reads in T. So T is doing: #li reads currentpos to p #li read p.x and p.y (in either order) #li compare, and take the branch #li read p.x and p.y (either order) and call System.out.println Given there's no ordering relationships between the writes in main, and the reads in T, there are clearly several ways this can produce your result, as T may see main's write to currentpos the writes to currentpos.y or currentpos.x: #li It reads currentpos.x first, before the x write has occurred - gets 0, then reads currentpos.y before the y write has occurred - gets 0. Compare evals to true. The writes\nbecome visible to T. System.out.println is called. #li It reads currentpos.x first, after the x write has occurred, then reads currentpos.y before the y write has occurred - gets 0. Compare evals to true. Writes become visible to T... etc. #li It reads currentpos.y first, before the y write has occurred (0), then reads currentpos.x after the x write, evals to true. etc. and so on... There are a number of data races here. I suspect the flawed assumption here is thinking that the writes that result from this line are made visible across all the threads in the programme order of the thread executing it: #pre Java makes no such guarantee (it'd be terrible for performance). Something more must be added if your programme needs a guaranteed ordering of the writes relative to reads in other threads. Others have suggested making the x,y fields final, or alternatively making currentpos volatile. #li If you make the x,y fields final, then Java guarantees that the writes of their values will be seen to occur before the constructor returns, in all threads. Thus, as the assignment to currentpos is after the constructor, the T thread is guaranteed to see the writes in the correct order. #li If you make currentpos volatile, then Java guarantees that that this is a synchronisation point which will be total-ordered wrt other synchronisation points. As in main the writes to x and y must happen before the write to currentpos, then any read of currentpos in another thread must see also the writes of x, y that happened before. Using final has the advantage that it makes the fields immutable, and thus allows the values to be cached. Using volatile leads to synchronisation on every write and read of currentpos, which might hurt performance. See chapter 17 of the Java Language Spec for the gory details: #a (Initial answer assumed a weaker memory model, as I was not sure the JLS guaranteed volatile was sufficient. Answer edited to reflect comment from assylias, pointing out the Java model is stronger - happens-before is transitive - and so volatile on currentpos also suffices).",
            "question_id": 16159203
        },
        {
            "answer_id": 14492043,
            "cleaned": "'Random' is more than just about getting numbers.... what you have is #a If pseudo-random is good enough for your purposes, then sure, it's way faster (and XOR+Bitshift will be faster than what you have) Rolf Edit: OK, after being too hasty in this answer, let me answer the real reason why your code is faster: From the JavaDoc for Math.Random() #blockquote This is likely why your code is faster.",
            "question_id": 14491966
        },
        {
            "answer_id": 14492320,
            "cleaned": "Your QuickRandom implementation hasn't really an uniform distribution. The frequencies are generally higher at the lower values while Math.random(_exprs) has a more uniform distribution. Here's a #a which shows that: #pre The average result looks like this: #pre If you repeat the test, you'll see that the QR distribution varies heavily, depending on the initial seeds, while the MR distribution is stable. Sometimes it reaches the desired uniform distribution, but more than often it doesn't. Here's one of the more extreme examples, it's even beyond the borders of the graph: #pre",
            "question_id": 14491966
        },
        {
            "answer_id": 14495128,
            "cleaned": "If the Math.Random(_exprs) function calls the operating system to get the time of day, then you cannot compare it to your function. Your function is a PRNG, whereas that function is striving for real random numbers. Apples and oranges. Your PRNG may be fast, but it does not have enough state information to achieve a long period before it repeats (and its logic is not sophisticated enough to even achieve the periods that are possible with that much state information). Period is the length of the sequence before your PRNG begins to repeat itself.  This happens as soon as the PRNG machine makes a state transition to a state which is identical to some past state. From there, it will repeat the transitions which began in that state. Another problem with PRNG's can be a low number of unique sequences, as well as degenerate convergence on a particular sequence which repeats. There can also be undesirable patterns. For instance, suppose that a PRNG looks fairly random when the numbers are printed in decimal, but an inspection of the values in binary shows that bit 4 is simply toggling between 0 and 1 on each call. Oops! Take a look at the Mersenne Twister and other algorithms. There are ways to strike a balance between the period length and CPU cycles. One basic approach (used in the Mersenne Twister) is to cycle around in the state vector. That is to say, when a number is being generated, it is not based on the entire state, just on a few words from the state array subject to a few bit operations. But at each step, the algorithm also moves around in the array, scrambling the contents a little bit at a time.",
            "question_id": 14491966
        },
        {
            "answer_id": 14502259,
            "cleaned": "There are many, many pseudo random number generators out there. For example Knuth's #a , the #a , or look for LFSR generators. Knuth's monumental \"Seminumerical algorithms\" analizes the area, and proposes some linear congruential generators (simple to implement, fast). But I'd suggest you just stick to java.util.Random or Math.random , they fast and at least OK for occasional use (i.e., games and such). If you are just paranoid on the distribution (some Monte Carlo program, or a genetic algorithm), check out their implementation (source is available somewhere), and seed them with some truly random number, either from your operating system or from #a . If this is required for some application where security is critical, you'll have to dig yourself. And as in that case you shouldn't believe what some colored square with missing bits spouts here, I'll shut up now.",
            "question_id": 14491966
        },
        {
            "answer_id": 14513598,
            "cleaned": "java.util.Random is not much different, a basic LCG described by Knuth. However it has main 2 main advantages/differences: #li thread safe - each update is a CAS which is more expensive than a simple write and needs a branch (even if perfectly predicted single threaded). Depending on the CPU it could be significant difference. #li undisclosed internal state - this is very important for anything non-trivial. You wish the random numbers not to be predictable. Below it's the main routine generating 'random' integers in java.util.Random. #pre If you remove the AtomicLong and the undisclosed sate (i.e. using all bits of the long ), you'd get more performance than the double multiplication/modulo. Last note: Math.random should not be used for anything but simple tests, it's prone to contention and if you have even a couple of threads calling it concurrently the performance degrades. One little known historical feature of it is the introduction of CAS in java - to beat an infamous benchmark (first by IBM via intrinsics and then Sun made \"CAS from Java\")",
            "question_id": 14491966
        },
        {
            "answer_id": 14526729,
            "cleaned": "The real problem with this is that it's output histogram is dependent on the initial seed far to much - much of the time it will end up with a near uniform output but a lot of the time will have distinctly un-uniform output. Inspired by #a , I made some random matrix images using QuickRandom and System.Random . This run shows how sometimes the seed can have a bad effect (in this case favouring lower numbers) where as System.Random is pretty uniform.  #img  #img  If we initialise QuickRandom as new QuickRandom(_exprs) we get this image: #img  #pre",
            "question_id": 14491966
        },
        {
            "answer_id": 14563808,
            "cleaned": "It is very unlikely that random number generation performance would be an issue for any use-case you came up with unless accessing a single Random instance from multiple threads (because Random is synchronized ). However, if that is the case and you need lots of random numbers fast, your solution is far too unreliable. Sometimes it gives good results, sometimes it gives results (based on the initial settings). If you want the same numbers that the #a class gives you, only faster, you could get rid of the synchronization in there: #pre I simply took the #a code and removed the synchronization which results in the performance compared to the original on my Oracle HotSpot JVM 7u9. It is still slower than your QuickRandom , but it gives much more consistent results. To be precise, for the same seed values and single threaded applications, it gives pseudo-random numbers as the original Random class would. ",
            "question_id": 14491966
        },
        {
            "answer_id": 14821488,
            "cleaned": "The Collections.unmodifiableList has already been mentioned - the Arrays.asList(_exprs) strangely not! My solution would also be to use the list from the outside and wrap the array as follows: #pre The problem with copying the array is: if you're doing it every time you access the code and the array is big, you'll create a lot of work for the garbage collector for sure. So the copy is a simple but really bad approach - I'd say \"cheap\", but memory-expensive! Especially when you're having more than just 2 elements. If you look at the source code of Arrays.asList and Collections.unmodifiableList there is actually not much created. The first just wraps the array without copying it, the second just wraps the list, making changes to it unavailable.",
            "question_id": 14809293
        },
        {
            "answer_id": 15157021,
            "cleaned": "You must use #pre and not #pre This is explained in #a",
            "question_id": 15156857
        },
        {
            "answer_id": 16250729,
            "cleaned": "change your return type to ResponseEntity<String> , then you can use below for 400 #pre and for correct request #pre  after spring 4.1 there are helper methods in ResponseEntity could be used as #pre and #pre",
            "question_id": 16232833
        },
        {
            "answer_id": 14833048,
            "cleaned": "You need to escape the dot if you want to split on a dot: #pre Otherwise you are splitting on the regex . , which means \"any character\". ",
            "question_id": 14833008
        },
        {
            "answer_id": 14833098,
            "cleaned": "\".\" is a special character in java. You have to use \"\\.\" to escape this character : #pre I hope this helps",
            "question_id": 14833008
        },
        {
            "answer_id": 15430259,
            "cleaned": "If you know in advance what the size of the ArrayList is going to be, it is more efficient to specify the initial capacity. If you don't do this, the internal array will have to be repeatedly reallocated as the list grows. The larger the final list, the more time you save by avoiding the reallocations. That said, even without pre-allocation, inserting n elements at the back of an ArrayList is guaranteed to take total O(_exprs) time. In other words, appending an element is an amortized constant-time operation. This is achieved by having each reallocation increase the size of the array exponentially, typically by a factor of 1.5 . With this approach, the total number of operations #a .",
            "question_id": 15430247
        },
        {
            "answer_id": 15432106,
            "cleaned": "This is to avoid possible efforts for reallocation for every single object. #pre internally new Object[] is created. #pre",
            "question_id": 15430247
        },
        {
            "answer_id": 15446006,
            "cleaned": "I actually wrote a #a on the topic 2 months ago. The article is for C#'s List<T> but Java's ArrayList has a very similar implementation. Since ArrayList is implemented using a dynamic array, it increases in size on demand. So the reason for the capacity constructor is for optimisation purposes. When one of these resizings operation occurs, the ArrayList copies the contents of the array into a new array that is twice the capacity of the old one. This operation runs in time.  Here is an example of how the ArrayList would increase in size: #pre So the list starts with a capacity of 10 , when the 11th item is added it is increase by 50% + 1 to 16 . On the 17th item the ArrayList is increased again to 25 and so on. Now consider the example where we're creating a list where the desired capacity is already known as 1000000 . Creating the ArrayList without the size constructor will call ArrayList.add 1000000 times which takes normally or on resize. #blockquote Compare this using the constructor and then calling ArrayList.add which is guaranteed to run in . #blockquote  Java is as above, starting at 10 and increasing each resize at 50% + 1 . C# starts at 4 and increases much more aggressively, doubling at each resize. The 1000000 adds example from above for C# uses 3097084 operations.  #li #a #li #a",
            "question_id": 15430247
        },
        {
            "answer_id": 25757711,
            "cleaned": "ArrayList shrinks or expands dynamically. This is a effective but costly operation, if you know size of your array will be fixed then its better to mention the size of the array,If you don't, new array will be created at each insertion and reallocation will be done for each element. this will cost you. #pre this method help to avoid reallocations and helps increase size of arraylist. #pre this is reverse used to shrink size  #li ArrayList()   -builds empty ArrayList #li ArrayList(Collection c)  - builds a ArrayList initialized with elements of collection c. #li -builds an ArrayList with specified initial capacity.",
            "question_id": 15430247
        },
        {
            "answer_id": 14846943,
            "cleaned": "It is, in my personal experience admittedly, very useful in cases where an API requires a collection of parameters, but you have nothing to provide.  For example you may have an API that looks something like this, and does not allow null references: #pre If you have a query that doesn't take any parameters, it's certainly a bit wasteful to create a HashMap, which involves allocating an array, when you could just pass in the 'Empty Map' which is effectively a constant, the way it's implemented in java.util.Collections .",
            "question_id": 14846920
        },
        {
            "answer_id": 14846960,
            "cleaned": "From , - _str demonstrates returning an empty collection and perhaps even demonstrates using these emptyList(_exprs) , emptySet(_exprs) , and emptyMap(_exprs) methods on the Collections class to get an empty collection that also has the additional benefit of being immutable. From _str . From #a #blockquote Below code is just an example (change it according to your use case): #pre These methods offer a couple of advantages: #li They're more concise because you don't need to explicitly type out the generic type of the collection - it's generally just inferred from the context of the method call. #li They're more efficient because they don't bother creating new objects; they just re-use an existing empty and immutable object. This effect is generally very minor, but it's occasionally (well, rarely) important.",
            "question_id": 14846920
        },
        {
            "answer_id": 14846963,
            "cleaned": "#blockquote For the same reason you'd use #a at some point. You want to return a Map instance that throws an exception if the user attempts to modify it. It's just a special case: the empty Map.",
            "question_id": 14846920
        },
        {
            "answer_id": 14846964,
            "cleaned": "For one, you can get away with reference sharing. A new HashMap(_exprs) etc will require an allocated object, and possibly some extra elements to hold the data, but you only need one copy of an immutable empty collection (list, set, map, or any other such). This makes it an obvious choice when a method you're calling needs to accept a Map but does not need to edit it. I suggest checking out Josh Bloch's , which lists some very nice attributes of immutable objects (including thread safety).",
            "question_id": 14846920
        },
        {
            "answer_id": 14847046,
            "cleaned": "Most of the time we use a constructor to create a new empty map . But the Collections methods offer a couple of advantages to create an empty map using static method java.util.Collections.emptyMap(_exprs) #blockquote",
            "question_id": 14846920
        },
        {
            "answer_id": 16252296,
            "cleaned": "Use util method of #a class, i.e #pre In fact, if you want to sort custom object you can use #pre see collections api",
            "question_id": 16252269
        },
        {
            "answer_id": 29652714,
            "cleaned": "You can use Collections.sort(_exprs) to sort list if your list contains Comparable elements. Otherwise I would recommend you to implement that interface like here: #pre and of course provide your own realization of compareTo method like here: #pre And then you can again use Colection.sort(_exprs) as now list contains objects of Comparable type and can be sorted. Order depends on compareTo method. Check this #a for more detailed information.",
            "question_id": 16252269
        },
        {
            "answer_id": 30210459,
            "cleaned": "Collections.sort allows you to pass an instance of a Comparator which defines the sorting logic. So instead of sorting the list in natural order and then reversing it, one can simply pass Collections.reverseOrder(_exprs) to sort in order to sort the list in reverse order: #pre As mentioned by @Marco13, apart from being more idiomatic (and possibly more efficient), using the reverse order comparator makes sure that the sort is stable (meaning that the order of elements will not be changed when they are equal according to the comparator, whereas reversing will change the order)",
            "question_id": 16252269
        },
        {
            "answer_id": 14534791,
            "cleaned": "Escape should be done with \\ , not / . So r.append(_exprs); or r.append(_exprs); will work ( StringBuilder has overloaded methods for char and String type).",
            "question_id": 14534767
        },
        {
            "answer_id": 14534798,
            "cleaned": "It should be #pre But I recommend you to do as below, #pre System.getProperty(_exprs) gives you system-dependent newline in java. Also from Java 7 there's a method that returns the value directly: #a",
            "question_id": 14534767
        },
        {
            "answer_id": 33687544,
            "cleaned": "For HTML response  below code can be used #pre",
            "question_id": 14534767
        },
        {
            "answer_id": 34073047,
            "cleaned": "Another option is to use Apache Commons StrBuilder, which has the functionality that's lacking in StringBuilder. #a",
            "question_id": 14534767
        },
        {
            "answer_id": 14602092,
            "cleaned": "From #a : #blockquote Overloaded #a is more appropriate for your case.",
            "question_id": 14602062
        },
        {
            "answer_id": 14602155,
            "cleaned": "From the documentation of #a : #blockquote So you will have to use the two argument version #a with a negative value: #pre Doc: #blockquote This will not leave out any empty elements, including the trailing ones.",
            "question_id": 14602062
        },
        {
            "answer_id": 15336606,
            "cleaned": "It got deprecated in version 4.3-alpha1 which you use because of the LATEST version specification. If you take a look at the javadoc of the class, it tells you what to use instead: HttpClientBuilder . In the latest stable version ( 4.2.3 ) the DefaultHttpClient is not deprecated yet.",
            "question_id": 15336477
        },
        {
            "answer_id": 32364785,
            "cleaned": "( #a ) use this: #pre The class org.apache.http.impl.client.HttpClients is there since version 4.3. The code for HttpClients.createDefault(_exprs) is the same as the accepted answer in here.",
            "question_id": 15336477
        },
        {
            "answer_id": 16098086,
            "cleaned": "You could use printf(_exprs) with %f : #pre This will print dexp: 12345678.000000 . If you don't want the fractional part, use #pre This uses the format specifier language explained in the #a . The default toString(_exprs) format used in your original code is spelled out #a .",
            "question_id": 16098046
        },
        {
            "answer_id": 25307973,
            "cleaned": " If you want to get rid of trailing zeros and Locale problems, then you should use : #pre  Why other answers did not suit me : #li Double.toString(_exprs) or System.out.println or FloatingDecimal.toJavaFormatString uses scientific notations if double is less than 10^-3 or greater than or equal to 10^7 #li by using %f , the default decimal precision is 6, otherwise you can hardcode it but it results in extra zeros added if you have less decimals. Example : #pre #li by using setMaximumFractionDigits(_exprs); or %.0f you remove any decimal precision, which is fine for integers/longs but not for double #pre #li by using DecimalFormat, you are local dependent. In French locale, the decimal separator is a comma, not a point : #pre Using the ENGLISH locale makes sure you get a point for decimal separator, wherever your program will run Why using 340 then for setMaximumFractionDigits ? Two reasons : #li setMaximumFractionDigits accepts an integer but its implementation has a maximum digits allowed of DecimalFormat.DOUBLE_FRACTION_DIGITS which equals 340 #li Double.MIN_VALUE = 4.9E-324 so with 340 digits you are sure not to round your double and loose precision",
            "question_id": 16098046
        },
        {
            "answer_id": 14526289,
            "cleaned": "just use #pre using : #pre",
            "question_id": 14526260
        },
        {
            "answer_id": 22092971,
            "cleaned": "For those looking for a general strategy for reading and writing a string to file:  You'll need the storage path. For the internal storage, use: #pre For the external storage (SD card), use: #pre Then create your file object: #pre  #pre Or with Google Guava #pre  #pre Or if you are using Google Guava #pre For completeness I'll mention #pre which requires no libraries, but benchmarks 50% - 400% slower than the other options (in various tests on my Nexus 5).  For each of these strategies, you'll be asked to catch an IOException. The default character encoding on Android is UTF-8. If you are using external storage, you'll need to add to your manifest either: #pre or #pre Write permission implies read permission, so you don't need both.",
            "question_id": 14376807
        },
        {
            "answer_id": 16324963,
            "cleaned": " Double.parseDouble(_exprs) goes into a Sun library (in #a ) the first important thing that happens is: #pre Integer.parseInt(_exprs) is done manually in the #a class. The first important thing that happens is: #pre I would guess there are two different authors.",
            "question_id": 16324831
        },
        {
            "answer_id": 14316543,
            "cleaned": "A very simple implementation with #a : #pre",
            "question_id": 14316487
        },
        {
            "answer_id": 16148593,
            "cleaned": "Use Integer instead. #pre Java will automatically autobox your int primitive values to Integer objects. Read more about #a from Oracle Java documentations.",
            "question_id": 16148575
        },
        {
            "answer_id": 16148619,
            "cleaned": "use int as Object not as primitive type #pre",
            "question_id": 16148575
        },
        {
            "answer_id": 16148647,
            "cleaned": "Please use HashMap<Integer, myObject> myMap = new HashMap<Integer, myObject>(_exprs);",
            "question_id": 16148575
        },
        {
            "answer_id": 16149127,
            "cleaned": "You can't use a primitive because HashMap use object internally for the key. So you can only use an object that inherits from Object (that is any object). That is the function put() in HashMap and as you can see it uses Object for K: #pre The expression \"k = e.key\" should make it clear. I suggest to use a wrapper like Integer and autoboxing.",
            "question_id": 16148575
        },
        {
            "answer_id": 16149160,
            "cleaned": "HashMap does not allow primitive data types as arguments. It can only accept objects so #pre will not work. You have to change the declaration to #pre so even when you do the following #pre The primitive data type is autoboxed to an Integer object. #pre You can read more on autoboxing here #a",
            "question_id": 16148575
        },
        {
            "answer_id": 18481387,
            "cleaned": "If you code in Android, there is #a , mapping integer to object.",
            "question_id": 16148575
        },
        {
            "answer_id": 20454885,
            "cleaned": "For everybody who codes Java for Android devices and ends up here: use SparseArray for better performance #pre with this you can use int instead of Integer like #pre",
            "question_id": 16148575
        },
        {
            "answer_id": 32866218,
            "cleaned": "The main reason with not allowing primitive as keys is that HashMap is designed in such a way that for comparing the keys, it makes use of method, and a method can be called only on an object not on a primitive. Thus when int is autoboxed to Integer, Hashmap can call method on Integer object. That is why, you should use Integer instead of int. I mean hashmap throws an error while putting int as a key (Don't know the meaning of the error that is thrown) And if you think that, you can make Map performance faster by making a primitive as a key, there is a library called which contains a Map implementation with int type as a key. Because of this, it is much faster than",
            "question_id": 16148575
        }
    ]
}