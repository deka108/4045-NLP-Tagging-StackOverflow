Question-33147339
I was reading Java's ArrayList source code and noticed some comparisons in if-statements. In Java 7, the method #a uses if (_exprs)
    newCapacity = minCapacity; In Java 6, grow didn't exist. The method #a however uses if (_exprs)
    newCapacity = minCapacity; What was the reason behind the change? Was it a performance issue or just a style? I could imagine that comparing against zero is faster, but performing a complete subtraction just to check whether it's negative seems a bit overkill to me. Also in terms of bytecode, this would involve two instructions ( ISUB and IF_ICMPGE ) instead of one ( IFGE ).

Question-31646092
I have a class used for navigating back and forth through a list of ordered pages. The pages are generally but not always accessed sequentially. Sometimes one or more pages may be skipped based on certain rules. To manage this, I maintain two stacks, forward and backward, to track which pages have previously been visited in either direction. As far as the functionality of this class is concerned, there is no reason for it to expose these stacks. However, when unit testing the navigation methods, first(_exprs) , next(_exprs) , previous(_exprs) and last(_exprs) , which all reorganize the stacks and return the appropriate page, I need to check that the stacks are in the right "state" at the end of the process. For example, calling first(_exprs) should cause the forward stack to be cleared and every other page that has previously been visited to be pushed into the backward stack. Is this alone a good enough reason to provide getters for the forward and backward stacks? One reason I am hesitant to do so is that I worry that this also exposes them to (perhaps inadvertent) outside manipulation that might cause the class to malfunction. What if a client clears a stack for example?  Some people have suggested that this question is a duplicate of the one posted #a . I think the 2 questions aren't quite the same. The other question discusses the idea of . This question, on the other hand, is specifically about t. I think there is a subtle but significant difference there, and the accepted answer clearly shows how to test the very same public methods without examining internal state.

Question-31170459
I was testing boundary conditions on some code involving a BigDecimal , and I noticed that when a BigDecimal is initialized with the String _str it behaves unexpectedly. It seems to have a value between 0 and 1e-2147483647 . When I try calling intValue(_exprs) , I get a NegativeArraySizeException . I should note that 2147483647 is the max value of an integer on my system. Am I doing something wrong, or is this a problem with BigDecimal ? 

Question-32693704
I noticed something strange in the implementation of HashMap.clear(_exprs) . This is how it looked in #a :  And this is how it looks as of #a :  I understand that now the table can be null for empty an map, thus the additional check and caching in a local variable is required. But why was Arrays.fill(_exprs) replaced with a for-loop? It seems that the change was introduced in #a . Unfortunately I found no explanation for why a plain for loop might be better than Arrays.fill(_exprs) . Is it faster? Or safer?

Question-31202946
Why was the Thread class implemented as a regular class and not an class with run(_exprs) method being abstract. Will it possibly introduce any problems? Or does it have any use in being this way? Also, the Thread.start(_exprs) method is supposed to be a very specific method (If I am not wrong). And hence I guess the final keyword would be apt for this more than any other method. But I am able to override this method and use it as I like,  It obviously only printed, #blockquote Is there any use in overriding other than confusing the engineer replacing you? If not, why was the method not declared final in Thread class?

Question-31188231
It has generally been the case the Java source code has been forward compatible.  Until Java 8, as far as I know, both compiled classes source have been forward compatible with later JDK/JVM releases.  [Update: this is not correct, see comments re 'enum', etc, below.]  However, with the addition of default methods in Java 8 this appears to no longer be the case. For example, a library I have been using has an implementation of java.util.List which includes a List<V> sort(_exprs) .  This method returns a copy of the contents of the list sorted. This library, deployed as a jar file dependency, worked fine in a project being built using JDK 1.8. However, later I had occasion to recompile the library itself using JDK 1.8 and
I found the library no longer compiles: the List -implementing class with its own sort(_exprs) method now conflicts with the Java 8 java.util.List.sort(_exprs) default method.  The Java 8 sort(_exprs) default method sorts the list in place (returns void ); my library's sort(_exprs) method - since it returns a new sorted list - has an incompatible signature. So my basic question is: #li Doesn't JDK 1.8 introduce a forward incompatibility for Java source code due to default methods? Also: #li Is this the first such forward incompatible change? #li Was this considered or discussed when default methods where designed and implemented?  Is it documented anywhere? #li Was the (admittedly small) inconvenience discounted versus the benefits? The following is an example of some code that compiles and runs under 1.7 and
runs under 1.8 - but does not compile under 1.8:  The following shows this code being compiled (or failing to) and being run. 

Question-32334319
I am using JDK-8 (x64). For Arrays.sort I found the following in the Java documentation: #blockquote For Collections.sort I found this: #blockquote If Collections.sort uses an array, why doesn't it just call Arrays.sort or use dual-pivot ? Why use ?

Question-31370403
I'm currently in the process of writing a paint program in java, designed to have flexible and comprehensive functionalities. It stemmed from my final project, that I wrote overnight the day before. Because of that, it's got tons and tons of bugs, which I've been tackling one by one (e.g. I can only save files that will be empty, my rectangles don't draw right but my circles do...). This time, I've been trying to add undo/redo functionality to my program. However, I can't "undo" something that I have done. Therefore, I got an idea to save copies of my BufferedImage each time a mouseReleased event was fired. However, with some of the images going to 1920x1080 resolution, I figured that this wouldn't be efficient: storing them would probably take gigabytes of memory. The reason for why I can't simply paint the same thing with the background colour to undo is because I have many different brushes, which paint based on Math.random(_exprs) , and because there are many different layers (in a single layer). Then, I've considered cloning the Graphics objects that I use to paint to the BufferedImage . Like this:  I haven't done this before, so I have a couple questions: #li Would I still be wasting pointless memory by doing this, like cloning my BufferedImages ? #li Is there necessarily a different way I can do this?

Question-31445024
I'm trying to determine whether the following statements are guaranteed to be true:  I've always assumed that autoboxing was equivalent to calling valueOf(_exprs) on the corresponding type. Every #a that I've seen on the #a seems to #a my assumption. But all I could find in the JLS was the following ( #a ): #blockquote That describes behavior identical to that of valueOf(_exprs) . But there doesn't seem to be any guarantee that valueOf(_exprs) is actually invoked, meaning there could theoretically be an implementation that keeps a separate, dedicated cache for autoboxed values. In such a case, there might not be identity equality between cached autoboxed values and regular cached boxed values. #a states matter-of-factly that li.add(_exprs) is compiled to li.add(_exprs) , where i is an int . But I don't know whether the tutorial should be considered an authoritative source.

Question-33147339, answer-33147762
I found #a : #blockquote In Java 6, if you use the API as:  And newCount overflows (this becomes negative), if (_exprs) will return false and you may mistakenly assume that the ArrayList was increased by len .

Question-32623834, answer-32652449
Another related point: you can make use of the constant pool to improve the performance of string comparisons in some circumstances, by using the #a method. That method returns the instance of String with the same contents as the String on which it is invoked from the String constants pool, adding it it if is not yet present. In other words, after using intern(_exprs) , all Strings with the same contents are guaranteed to be the same String instance as each other and as any String constants with those contents, meaning you can then use the equals operator ( == ) on them. This is just an example which is not very useful on its own, but it illustrates the point:  This little trick isn't worth designing your code around, but it is worth keeping in mind for the day when you notice a little more speed could be eked out of some bit of performance sensitive code by using the == operator on a string with judicious use of intern(_exprs) .

Question-31170459, answer-31170506
No, you appear to have a legit bug. The bug presents in JDK7 but fixed in JDK8. Your values are correctly representable as BigDecimal s, and should behave correctly, but don't. Tracing through #a , on line 2585, this.precision(_exprs) is 1, and this.scale is -2147483647 . this.precision(_exprs) - this.scale therefore overflows, and the following overflow is not handled correctly. This bug #a in JDK8 by #a .

Question-32693704, answer-32744190
There is no actual difference in the functionality between the 2 version's loop. Arrays.fill does the exact same thing. So the choice to use it or not may not necessarily be considered a mistake. It is left up to the developer to decide when it comes to this kind of micromanagement. There are 2 separate concerns for each approach: #li using the Arrays.fill makes the code less verbose and more readable. #li looping directly in the HashMap code (like version 8) peformance wise is actually a better option. While the overhead that inserting the Arrays class is negligible it may become less so when it comes to something as widespread as HashMap where every bit of performance enhancement has a large effect(imagine the tiniest footprint reduce of a HashMap in fullblown webapp). Take into consideration the fact that the Arrays class was used only for this one loop. The change is small enough that it doesn't make the clear method less readable. The precise reason can't be found out without asking the developer who actually did this, however i suspect it's either a mistake or a small enhancement.
better option. My opinion is it can be considered an enhancement, even if only by accident.

Question-32693704, answer-32745612
For me, the reason is a likely performance inprovement, at a negligible cost in terms of code clarity. Note that the implementation of the fill method is trivial, a simple for-loop setting each array element to null. So, replacing a call to it with the actual implementation does not cause any significant degradation in the clarity/conciseness of the caller method. The potential performance benefits are not so insignificant, if you consider everything that is involved: #li There will be no need for the JVM to resolve the Arrays class, plus loading and initializing it if needed. This is a non-trivial process where the JVM performs several steps. Firstly, it checks the class loader to see if the class is already loaded, and this happens every time a method is called; there are optimizations involved here, of course, but it still takes some effort. If the class is not loaded, the JVM will need to go through the expensive process of loading it, verifying the bytecode, resolving other necessary dependencies, and finally performing static initialization of the class (which can be arbitrarily expensive). Given that HashMap is such a core class, and that Arrays is such a huge class (3600+ lines), avoiding these costs may add up to noticeable savings. #li Since there is no Arrays.fill(_exprs) method call, the JVM won't have to decide whether/when to inline the method into the caller's body. Since HashMap#clear(_exprs) tends to get called a lot, the JVM will eventually perform the inlining, which requires JIT recompilation of the clear method. With no method calls, clear will always run at top-speed (once initially JITed). Another benefit of no longer calling methods in Arrays is that it simplifies the dependency graph inside the java.util package, since one dependency is removed.

Question-32693704, answer-32749756
I'm going to shoot in the dark here... My is that it might have been changed in order to prepare the ground for #a (aka generics over primitive types). (and I insist on ), this change is meant to make transition to Java 10 easier, in the event of specialization being part of the JDK. If you look at the #a , section, it says the following: #blockquote (Emphasis is mine). And ahead in the section, it says: #blockquote Later on, near the end of the document, in the section, it says: #blockquote 

Question-32693704, answer-32752970
I will try to summarize three moreless reasonable versions which were proposed in comments. @Holger #a : #blockquote This is the most easy thing to test. Let's compile such program:  Run it with java -verbose:class HashMapTest . This will print the class loading events as they occur. With JDK 1.8.0_60 I see more than 400 classes loaded:  As you can see, HashMap is loaded long before application code and Arrays is loaded only 14 classes after HashMap . The HashMap load is triggered by sun.reflect.Reflection initialization as it has HashMap static fields. The Arrays load is likely to be triggered by WeakHashMap load which actually has Arrays.fill in the clear(_exprs) method. The WeakHashMap load is triggered by java.lang.ClassValue$ClassValueMap which extends WeakHashMap . The ClassValueMap is present in every java.lang.Class instance. So to me seems that without Arrays class the JDK cannot be initialized at all. Also the Arrays static initializer is very short, it only initializes the assertion mechanism. This mechanism is used in many other classes (including, for example, java.lang.Throwable which is loaded very early). No other static initialization steps are performed in java.util.Arrays . Thus @Holger version seems incorrect to me. Here we also found very interesting thing. The WeakHashMap.clear(_exprs) still uses Arrays.fill . It's interesting when it appeared there, but unfortunately this goes to #a (it was already there in the very first public OpenJDK repository). Next, @MarcoTopolnik #a : #blockquote It was actually surprising for me that Arrays.fill is not directly intrinsified (see #a generated by #a ). Seems that such loop can be recognized and vectorized by JVM without explicit intrinsic handling. So it's true that extra call can be not inlined in very specific cases (for example if MaxInlineLevel limit is reached). On the other hand it's very rare situation and it's only a single call, it's not a call inside loop, and it's a static, not virtual/interface call, thus the performance improvement could be only marginal and only in some specific scenarios. Not the thing the JVM developers usually care. Also it should be noted that even C1 'client' compiler (tier 1-3) is capable to inline Arrays.fill called, for example, in WeakHashMap.clear(_exprs) , as inlining log ( -XX:+UnlockDiagnosticVMOptions -XX:+PrintCompilation -XX:+PrintInlining ) says:  Of course, it's also easily inlined by smart and powerful C2 'server' compiler. Thus I see no problems here. Seems that @Marco version is incorrect either. Finally we have a couple of #a from @StuartMarks (who is JDK developer, thus some official voice): #blockquote Indeed the HashMap.clear(_exprs) contained the loop many years, was #a with Arrays.fill on Apr 10th, 2013 and stayed less one half-a-year until Sept 4th when the discussed #a was introduced. The discussed commit was actually a major rewrite of the HashMap internals to fix #a issue. It was a long story about possibility to poison the HashMap with keys having duplicating hashcodes reducing HashMap search speed to linear making it vulnerable to DoS-attacks. The attempts to solve this were performed in JDK-7 including some randomization of String hashCode. So seems that the HashMap implementation was forked from the earlier commit, developed independently, then merged into the master branch overwriting several changes introduced in-between. We may support this hypothesis performing a diff. Take the #a where Arrays.fill was removed (2013-09-04) and compare it with #a (2013-07-30). The diff -U0 output has 4341 lines. Now let's diff against the #a prior to one when Arrays.fill was added (2013-04-01). Now diff -U0 contains only 2680 lines. Thus the newer version actually more similar to the older than to immediate parent.  So to conclude I would agree with Stuart Marks. There were no concrete reason to remove Arrays.fill , it's just because the in-between change was overwritten by mistake. Using Arrays.fill is perfectly fine both in JDK code and in user applications and used, for example, in WeakHashMap . The Arrays class is loaded anyways pretty early during the JDK initialization, has very simple static initializer and Arrays.fill method can be easily inlined even by client compiler, so no performance drawback should be noted.

Question-31202946, answer-31203252
#blockquote This question actually boils down to the fact that you should always prefer composition over inheritance. If the Thread class was declared as abstract , the language would have to provide another class that extended from it which programmers could use to create a Thread . Your question would then be about why this class that extends from Thread is not abstract . If the language did not provide another class that extends from Thread , programmers would have to create their own class that extend s from Thread and override the run(_exprs) method. #blockquote The only possible explanation I can give is that the developers of the language saw some use-cases for overriding start when the class was introduced to the JDK. The first version of Java that I used was 1.5 and I personally have not come across a use-case where I found the need to override start . As JB Nizet stated in his answer #blockquote

Question-32859038, answer-32863263
Don't feel like you have to do in/with the stream. I would just do:  As long as you don't parallelise the stream this will work and it avoids potentially expensive and/or problematic (in the case of duplicates) get(_exprs) and indexOf(_exprs) operations. (You cannot use a regular int variable in place of the AtomicInteger because variables used from outside a lambda expression must be effectively final. Note that when uncontested (as in this case), AtomicInteger is very fast and won't pose a performance problem. But if it worries you you can use a non-thread-safe counter.)

Question-32859038, answer-32869478
Using a third party library ( #a for example, but there are others) you can zip the value with its index and voila: StreamUtils.zipWithIndex(_exprs)
    .collect(_exprs); although getIndex returns a long , so you may need to cast it using something similar to: i -> Integer.valueOf(_exprs)

Question-32175145, answer-32182250
 But you have to be really evil and use reflections and Multithreading: If you run this code, there is a chance that a racing condition can change the internal Value of myInt while the comparision takes place. If you want to simulate this condition, just set a breakpoint inside of Integer.intValue(_exprs) run the code in debug and hit continue. This will create a delay which creates the race condition artificially and the console will return false. 

Question-33477695, answer-33477803
The java.time API in general have nanosecond precision. For example:  Output: 2015-11-02T12:38:00,123456789+0000 However, it's the clock value returned by OffsetDateTime.now(_exprs) which is returning a value which only has milliseconds. From #a implementation in Java 8: #blockquote So there's nothing inherently imprecise here - just the default implementation of Clock using System.currentTimeMillis(_exprs) . You could potentially create your own more precise subclass. However, you should note that adding more precision without adding more probably isn't terribly useful. (There are times when it might be, admittedly...)

Question-34250207, answer-34256637
If the very first operation that is done with an ArrayList is to pass addAll a collection which has more than ten elements, then any effort put into creating an initial ten-element array to hold the ArrayList's contents would be thrown out the window.  Whenever something is added to an ArrayList it's necessary to test whether the size of the resulting list will exceed the size of the backing store; allowing the initial backing store to have size zero rather than ten will cause this test to fail one extra time in the lifetime of a list whose first operation is an "add" which would require creating the initial ten-item array, but that cost is less than the cost of creating a ten-item array that never ends up getting used. That having been said, it might have been possible to improve performance further in some contexts if there were a overload of "addAll" which specified how many items (if any) would likely be added to the list after the present one, and which could use that to influence its allocation behavior.  In some cases code which adds the last few items to a list will have a pretty good idea that the list is never going to need any space beyond that.  There are many situations where a list will get populated once and never modified after that.  If at the point code knows that the ultimate size of a list will be 170 elements, it has 150 elements and a backing store of size 160, growing the backing store to size 320 will be unhelpful and leaving it at size 320 or trimming it to 170 will be less efficient than simply having the next allocation grow it to 170.

Question-31188231, answer-31188818
Ironically default methods in interfaces were introduced to allow existing libraries using those interfaces to break, while introducing massive functionality in the interfaces. (backward compatibility.) Conflicts like that sort method might arise. Something to pay for the extra functionality. In your case also something to investigate (should new functionality be used instead?). Java forward compatibility breaks are little, more in its typing system, which was constantly enlarged. First with generic types and now with inferred types from functional interfaces. From version to version and from compiler to compiler there were slight differences.

Question-31188231, answer-31190722
We can draw a parallel with abstract class. An abstract class is intended to be subclassed so that the abstract methods can be implemented. The abstract class itself contains concrete methods that invoke the abstract methods. The abstract class is free to evolve by adding more concrete methods; and this practice may break subclasses. Therefore the exact problem you described existed even before Java8. The problem is much more manifested on Collection APIs because there are a lot of subclasses out in the wild. While the leading motivation of default method was to add some useful methods to existing Collection APIs without breaking subclasses, they had to exercise great self-control of doing it too much, for fear of breaking subclasses. A default method is added only if it's absolutely necessary. The real question here is, why List.sort is considered absolutely necessary. I think that is debatable. Regardless of why default method was introduced in the 1st place, it is now a great tool for API designers, and we ought to treat it the same as concrete methods in abstract classes - they need to be designed carefully up front; and new ones must be introduced with great caution.

Question-34509566, answer-34509655
As you said internally the last concatenation is done to something similar to String e = new StringBuilder(_exprs).append(_exprs).append(_exprs).toString(_exprs); the implementation of toString(_exprs) of StringBuilder . Here is the implementation.  Comparing strings using == instead of .equals(_exprs) . In this case object of type . The other concatenations are performed directly by the compiler so no new String is created.

Question-32334319, answer-32334651
The API guarantees a sorting which Quicksort doesn’t offer. However, when sorting by their natural order you won’t notice a difference as primitive values have no identity. Therefore, Quicksort is used for primitive arrays as it is slightly more efficient. For objects you may notice, when objects which are deemed equal according to their equals implementation or the provided Comparator change their order. Therefore, Quicksort is not an option. So a variant of MergeSort is used, the current Java versions use . This applies to both, Arrays.sort and Collections.sort , though with Java 8, the List itself may override the sort algorithms.

Question-31370403, answer-31466466
Idea #1, storing the Graphics objects simply wouldn't work. The Graphics should not be considered as "holding" some display memory, but rather as a handle to access an area of display memory. In the case of BufferedImage , each Graphics object will be always the handle to the same given image memory buffer, so they all will represent the same image. Even more importantly, As they do not store anything, there is no way whatsoever they could "re-store" anything. Idea #2, cloning the BufferedImage s is a much better idea, but you'll indeed be wasting memory, and quickly run out of it. It helps only to store those parts of the image affected by the draw, for example using rectangular areas, but it still costs a lot of memory. Buffering those undo images to disk could help, but it will make your UI slow and unresponsive, and that's ; furthermore, it makes you application more . My alternative would be to store store the image modifications in a list, rendered from first to last on top of the image. An undo operation then simply consists of removing the modification from the list. This requires you to , i.e. create a class that implements a single modification, by providing a void draw(_exprs) method which performs the actual drawing. As you said, pose an additional problem. However, the key problem is your use of Math.random(_exprs) to create random numbers. Instead, perform each random modification with a Random created from a fixed seed value, so that the (pseudo-)random number sequences are the same on each invocation of draw(_exprs) , i.e., each draw has exactly the same effects. (That's why they are called "pseudo-random" -- the generated numbers look random, but they are just as deterministic as any other function.) In contrast to the image storing technique, which has memory problems, the problem with this technique is that many modifications may make the GUI slow, especially if the modifications are computationally intensive. To prevent this, the simplest way would be to fix an appropriate . If this limit would be exceeded by adding a new modification, remove the oldest modification the list and apply it to the backing BufferedImage itself. The following shows that (and how) this all works together. It also includes a nice "redo" feature for redoing undone actions. 

Question-31445024, answer-31445150
I first tought your question was a dupe of #a However, after your comment on @ElliottFrisch I realized it was different : #blockquote For other readers, assume that "behaves that way" means using valueOf . Remember that there are multiples compilers for Java. To be "legal" they must follow the contract given in the #a . Therefore, as long as all the rules here are respected, there is no guarantee of how autoboxing is internally implemented. But I don't see any reason to not use valueOf , specially that it uses the cached values and is the recommended way as per #a by Joseph D. Darcy.

Question-31445024, answer-31760309
Until the language specification mentions it, it is not guaranteed that autoboxing is equivalent to a call to the static valueOf methods. It is an aspect, not part of the boxing conversion specification. An implementation is theoretically free to use another mechanism as long as it conforms to the rule you mentioned from the JLS. In practice, there are many Sun JDK bug reports (e.g. #a and #a ) that clearly imply that when autoboxing was introduced in Java 5, the intention was having the compiler to rely on valueOf as stated in #a : #blockquote But that's only for javac, not necessarily all compilers.

Question-31445024, answer-31871515
Autoboxing absolutely implemented using valueOf(_exprs) ...in the OpenJDK. If that's your implementation, read on... if not, skip to below.  Java documentation states that Boolean.valueOf(_exprs) always returns Boolean.TRUE or Boolean.FALSE , therefore your reference comparisons in these cases will succeed. (_exprs) == Integer.valueOf(_exprs) For this particular example, under the OpenJDK implementation with default settings, it will work by virtue of the fact that you picked a value < 128 which is cached at startup (although this can be overridden as a commandline arg). It also work for larger values if it's frequently used enough to be cached. Unless you're working under "safe" assumptions about the Integer cache, don't expect the reference comparison to be an equality. Long , Short , Character and Byte incidentally implement this caching too, but unlike Integer , it's not tunable. Byte will always work if you're comparing autobox/ valueOf(_exprs) references since obviously, you can't go out of range. Float and Double will unsurprisingly always create a new instance. 
