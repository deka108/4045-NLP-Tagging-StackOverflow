{
    "items": [
        {
            "cleaned": "I generated two matrices of 1000 x 1000 : First Matrix: O and # . Using the following code, the first matrix took 8.52 seconds to complete: #pre With this code, the second matrix took 259.152 seconds to complete: #pre What is the reason behind the dramatically different run times? ",
            "question_id": 21947452
        },
        {
            "cleaned": "One of the most useful features of Java 8 are the new default methods on interfaces. There are essentially two reasons (there may be others) why they have been introduced: #li Providing actual default implementations. Example: #a #li Allowing for JDK API evolution. Example: #a From an API designer's perspective, I would have liked to be able to use other modifiers on interface methods, e.g. final . This would be useful when adding convenience methods, preventing \"accidental\" overrides in implementing classes: #pre The above is already common practice if Sender were a class: #pre Now, default and final are obviously contradicting keywords, but the default keyword itself #a , so I'm assuming that this contradiction is deliberate, to reflect the subtle differences between (just methods) and (default methods), i.e. differences which I have not yet understood. At some point of time, support for modifiers like static and final on interface methods was not yet fully explored, #a : #blockquote Since that time in late 2011, obviously, support for static methods in interfaces was added. Clearly, this added a lot of value to the JDK libraries themselves, such as with #a .  What is the reason final (and also static final ) never made it to Java 8 interfaces?",
            "question_id": 23453287
        },
        {
            "cleaned": "What is the best way to convert a java.util.Date object to the new JDK 8/JSR-310 java.time.LocalDate ? #pre",
            "question_id": 21242110
        },
        {
            "cleaned": "Note: this question originates from a dead link which was a previous SO question, but here goes... See this code (note: I do know that this code won't \"work\" and that Integer::compare should be used -- I just extracted it from the linked question): #pre According to the javadoc of #a and #a , the argument of both should be a Comparator . Yet here the method references are to static methods of the #a class. So, why does this compile at all?",
            "question_id": 22561614
        },
        {
            "cleaned": "I am wondering why the Iterable interface does not provide the stream(_exprs) and parallelStream(_exprs) methods. Consider the following class: #pre It is an implementation of a as you can have cards in your hand while playing a Trading Card Game. Essentially it wraps a List<Card> , ensures a maximum capacity and offers some other useful features. It is better as implementing it directly as a List<Card> . Now, for convienience I thought it would be nice to implement Iterable<Card> , such that you can use enhanced for-loops if you want to loop over it. (My Hand class also provides a get(_exprs) method, hence the Iterable<Card> is justified in my opinion.) The Iterable interface provides the following (left out javadoc): #pre Now can you obtain a stream with: #pre So onto the real question: #li Why does Iterable<T> not provide a default methods that implement stream(_exprs) and parallelStream(_exprs) , I see nothing that would make this impossible or unwanted? A related question I found is the following though: #a",
            "question_id": 23114015
        },
        {
            "cleaned": "The new Java 8 stream framework and friends make for some very concise java code, but I have come across a seemingly-simple situation that is tricky to do concisely. Consider a List<Thing> things and method Optional<Other> resolve(_exprs) . I want to map the Thing s to Optional<Other> s and get the first Other . The obvious solution would be to use things.stream(_exprs).flatMap(_exprs).findFirst(_exprs) , but flatMap requires that you return a stream, and Optional doesn't have a stream(_exprs) method (or is it a Collection or provide a method to convert it to or view it as a Collection ). The best I can come up with is this: #pre But that seems awfully long-winded for what seems like a very common case. Anyone have a better idea?",
            "question_id": 22725537
        },
        {
            "cleaned": "I'm looking at the docs for the IntStream , and I see an toArray method, but no way to go directly to a List<Integer> Surely there is a way to convert a Stream to a List ?",
            "question_id": 23674624
        },
        {
            "cleaned": "In Java 8, there is a new method #a which returns a stream of int s ( IntStream ) that represent the character codes. I guess many people would expect a stream of char s here instead. What was the motivation to design the API this way?",
            "question_id": 22435833
        },
        {
            "cleaned": "While investigating for a #a w.r.t. using _str + n and #a to convert an integer primitive to a string I wrote this #a microbenchmark: #pre I ran it with the default JMH options with both Java VMs that exist on my Linux machine (up-to-date Mageia 4 64-bit, Intel i7-3770 CPU, 32GB RAM). The first JVM was the one supplied with Oracle JDK\n8u5 64-bit: #pre With this JVM I got pretty much what I expected: #pre I.e. using the StringBuilder class is slower due to the additional overhead of creating the StringBuilder object and appending an empty string. Using String.format(_exprs) is even slower, by an order of magnitude or so. The distribution-provided compiler, on the other hand, is based on OpenJDK 1.7: #pre The results here were : #pre Why does StringBuilder.append(_exprs) appear so much faster with this JVM? Looking at the StringBuilder class source code revealed nothing particularly interesting - the method in question is almost identical to Integer#toString(_exprs) . Interestingly enough, appending the result of Integer.toString(_exprs) (the stringBuilder2 microbenchmark) does not appear to be faster. Is this performance discrepancy an issue with the testing harness? Or does my OpenJDK JVM contain optimizations that would affect this particular code (anti)-pattern?  For a more straight-forward comparison, I installed Oracle JDK 1.7u55: #pre The results are similar to those of OpenJDK: #pre It seems that this is a more general Java 7 vs Java 8 issue. Perhaps Java 7 had more aggressive string optimizations? : For completeness, here are the string-related VM options for both of these JVMs: For Oracle JDK 8u5: #pre For OpenJDK 1.7: #pre The UseStringCache option was removed in Java 8 with no replacement, so I doubt that makes any difference. The rest of the options appear to have the same settings.  A side-by-side comparison of the source code of the AbstractStringBuilder , StringBuilder and Integer classes from the src.zip file of reveals nothing noteworty. Apart from a whole lot of cosmetic and documentation changes, Integer now has some support for unsigned integers and StringBuilder has been slightly refactored to share more code with StringBuffer . None of these changes seem to affect the code paths used by StringBuilder#append(_exprs) , although I may have missed something. A comparison of the assembly code generated for IntStr#integerToString(_exprs) and IntStr#stringBuilder0(_exprs) is far more interesting. The basic layout of the code generated for IntStr#integerToString(_exprs) was similar for both JVMs, although Oracle JDK 8u5 seemed to be more aggressive w.r.t. inlining some calls within the Integer#toString(_exprs) code. There was a clear correspondence with the Java source code, even for someone with minimal assembly experience. The assembly code for IntStr#stringBuilder0(_exprs) , however, was radically different. The code generated by Oracle JDK 8u5 was once again directly related to the Java source code - I could easily recognise the same layout. On the contrary, the code generated by OpenJDK 7 was almost unrecognisable to the untrained eye (like mine). The new StringBuilder(_exprs) call was seemingly removed, as was the creation of the array in the StringBuilder constructor. Additionaly, the disassembler plugin was not able to provide as many references to the source code as it did in JDK 8. I assume that this is either the result of a much more aggressive optimization pass in OpenJDK 7, or more probably the result of inserting hand-written low-level code for certain StringBuilder operations. I am unsure why this optimization does not happen in my JVM 8 implementation or why the same optimizations were not implemented for Integer#toString(_exprs) in JVM 7. I guess someone familiar with the related parts of the JRE source code would have to answer these questions...",
            "question_id": 23756966
        },
        {
            "cleaned": "is that you're using a terminal that attempts to do #a rather than character-wrapping, and treats B as a word character but # as a non-word character. So when it reaches the end of a line and searches for a place to break the line, it sees a # almost immediately and happily breaks there; whereas with the B , it has to keep searching for longer, and may have more text to wrap (which may be expensive on some terminals, e.g., outputting backspaces, then outputting spaces to overwrite the letters being wrapped). But that's pure speculation.",
            "answer_id": 21947627,
            "question_id": 21947452
        },
        {
            "cleaned": "I performed tests on Eclipse vs Netbeans 8.0.2, both with Java version 1.8;\nI used System.nanoTime(_exprs) for measurements.  I got the - around .  #li Using \"#\": #li Using \"B\": So, it looks like Netbeans has bad performance on print to console. After more research I realized that the problem is #a of the max buffer of Netbeans (it's not restricted to System.out.println command), demonstrated by this code: #pre The time results are less then 1 millisecond every iteration except , when the time result is around 225 millisecond. Something like (in nanoseconds): #pre And so on..  #li Eclipse works perfectly with \"B\" #li Netbeans has a line-wrapping problem that can be solved (because the problem does not occur in eclipse)(without adding space after B (\"B \")).",
            "answer_id": 29434641,
            "question_id": 21947452
        },
        {
            "cleaned": "You cannot do it more concise as you are already doing. You claim that you do not want .filter(_exprs) .map(_exprs) . This has been resolved by the method @StuartMarks describes, however as a result you now map it to an Optional<T> , so now you need to use .flatMap(_exprs) and a get(_exprs) in the end. So it still consists of two statements and you can now get exceptions with the new method! Because, what if every optional is empty? Then the findFirst(_exprs) will return an empty optional and your get(_exprs) will fail! So what you have: #pre actually the best way to accomplish what you want, and that is you want to save the result as a T , not as an Optional<T> . I took the liberty of creating a CustomOptional<T> class that wraps the Optional<T> and provides an extra method, flatStream(_exprs) . Note that you cannot extend Optional<T> : #pre You will see that I added flatStream(_exprs) , as here: #pre Used as: #pre You will need to return a Stream<T> here, as you cannot return T , because if !optional.isPresent(_exprs) , then T == null if you declare it such, but then your .flatMap(_exprs) would attempt to add null to a stream and that is not possible. As example: #pre Used as: #pre Will now throw a NullPointerException inside the stream operations.  The method you used, is actually the best method.",
            "answer_id": 22735184,
            "question_id": 22725537
        },
        {
            "cleaned": "String is immutable* but this only means you cannot change it using its public API. What you are doing here is circumventing the normal API, using reflection. The same way, you can change the values of enums, change the lookup table used in Integer autoboxing etc. Now, the reason s1 and s2 change value, is that they both refer to the same interned string. The compiler does this (as mentioned by other answers). The reason s3 does was actually a bit surprising to me, as I thought it would share the value array ( #a , before Java 7u6). However, looking at the source code of String , we can see that the value character array for a substring is actually copied (using Arrays.copyOfRange(_exprs) ). This is why it goes unchanged. You can install a SecurityManager , to avoid malicious code to do such things. But keep in mind that some libraries depend on using these kind of reflection tricks (typically ORM tools, AOP libraries etc). *) I initially wrote that String s aren't really immutable, just \"effective immutable\". This might be misleading in the current implementation of String , where the value array is indeed marked private final . It's still worth noting, though, that there is no way to declare an array in Java as immutable, so care must be taken not to expose it outside its class, even with the proper access modifiers. ",
            "answer_id": 20945113,
            "question_id": 20945049
        },
        {
            "cleaned": "The way I think about it is that you use flatMap when the function you wanted to put inside of map(_exprs) returns an Observable . In which case you might still try to use map(_exprs) but it would be unpractical. Let me try to explain why. If in such case you decided to stick with map , you would get an Observable<Observable<Something>> . For example in your case, if we used an imaginary RxGson library, that returned an Observable<String> from it's toJson(_exprs) method (instead of simply returning a String ) it would look like this: #pre At this point it would be pretty tricky to subscribe(_exprs) to such an observable. Inside of it you would get an Observable<String> to which you would again need to subscribe(_exprs) to get the value. Which is not practical or nice to look at. So to make it useful one idea is to \"flatten\" this observable of observables (you might start to see where the name _flat_Map comes from). RxJava provides a few ways to flatten observables and for sake of simplicity lets assume #a is what we want. Merge basically takes a bunch of observables and emits whenever any of them emits. (Lots of people would argue #a would be a better default. But if you're emitting just one value, it doesn't matter anyway.) So amending our previous snippet we would get: #pre This is a lot more useful, because subscribing to that (or mapping, or filtering, or...) you just get the String value. (Also, mind you, such variant of merge(_exprs) does not exist in RxJava, but if you understand the idea of merge then I hope you also understand how that would work.) So basically because such merge(_exprs) should probably only ever be useful when it succeeds a map(_exprs) returning an observable and so you don't have to type this over and over again, flatMap(_exprs) was created as a shorthand. It applies the mapping function just as a normal map(_exprs) would, but later instead of emitting the returned values it also \"flattens\" (or merges) them. That's the general use case. It is most useful in a codebase that uses Rx allover the place and you've got many methods returning observables, which you want to chain with other methods returning observables. In your use case it happens to be useful as well, because map(_exprs) can only transform one value emitted in onNext(_exprs) into another value emitted in onNext(_exprs) . But it cannot transform it into multiple values, no value at all or an error. And as #a wrote in his answer (and mind you he's much smarter than me, probably in general, but at least when it comes to RxJava) you shouldn't throw exceptions from your map(_exprs) . So instead you can use flatMap(_exprs) and #pre when all goes well, but #pre when something fails.",
            "answer_id": 37354549,
            "question_id": 22847105
        },
        {
            "cleaned": "This possible for forEach(_exprs) . The solution is not nice, but it possible. : You should not use it for controlling business logic, but purely for handling an exceptional situation which occurs during the execution of the forEach(_exprs) . Such as a resource suddenly stops being accessible, one of the processed objects is violating a contract (e.g. contract says that all the elements in the stream must not be null but suddenly and unexpectedly one of them is null ) etc. According to the documentation for #a : #blockquote So you throw an exception which will immediately break the internal loop. The code will be something like this - but it works. You create your own class BreakException which extends RuntimeException . #pre Notice that the try...catch is around the lambda expression, but rather around the whole forEach(_exprs) method. To make it more visible, see the following transcription of the code which shows it more clearly: #pre",
            "answer_id": 32566745,
            "question_id": 23308193
        },
        {
            "cleaned": "The Java libraries are heavily optimized around the constraint that any String object is immutable, regardless of how that object is constructed. Even if you create your b using new , other code that you pass that instance to will treat the value as immutable. This is an example of the Value Object pattern, and all of the advantages (thread-safety, no need to make private copies) apply. The empty string _str is a legitimate String object just like anything else, it just happens to have no internal contents, and since all compile-time constant strings are interned, I'll virtually guarantee that some runtime library has already caused it to be added to the pool.",
            "answer_id": 21375710,
            "question_id": 21375659
        },
        {
            "cleaned": "Better way is: #pre Advantages of this version: #li works regardless the input is an instance of java.util.Date or it's subclass java.sql.Date (unlike @JodaStephen's way). This is common with JDBC originated data. java.sql.Date.toInstant(_exprs) always throws an exception. #li it's the same for JDK8 and JDK7 with JSR-310 backport I personally use an utility class (but this is not backport-compatible): #pre The asLocalDate(_exprs) method here is null-safe, uses toLocalDate(_exprs) , if input is java.sql.Date (it may be overriden by the JDBC driver to avoid timezone problems or unnecessary calculations), otherwise uses the abovementioned method.",
            "answer_id": 27378709,
            "question_id": 21242110
        },
        {
            "cleaned": "To complement the given answers, also take note of the following: #pre This code will also print: false As user #a has claimed in a comment for the accepted answer, care must be taken when using operator == on objects, here you're checking if both references are the same, which is not, because they are different objets, although they represent the very same value. To compare objects, you should use the equals method instead: #pre This will print: true You may ask, . Checking the source code for the Integer.valueOf method, you can see the following: #pre If the param is an integer between IntegerCache.low (defaulted to -128) and IntegerCache.high (calculated at runtime with minimum value 127) then a pre-allocated (cached) object is returned. So when you use 127 as parameter, you're getting two references to same cached object and getting true in the comparison of the references.",
            "answer_id": 20889556,
            "question_id": 20877086
        },
        {
            "cleaned": "For simple cases such as the one illustrated, they are mostly the same. However, there are a number of subtle differences that might be significant. One issue is with ordering. With Stream.forEach , the order is . It's unlikely to occur with sequential streams, still, it's within the specification for Stream.forEach to execute in some arbitrary order. This does occur frequently in parallel streams. By contrast, Iterable.forEach is always executed in the iteration order of the Iterable , if one is specified. Another issue is with side effects. The action specified in Stream.forEach is required to be . (See the #a .) Iterable.forEach potentially has fewer restrictions. For the collections in java.util , Iterable.forEach will generally use that collection's Iterator , most of which are designed to be #a and which will throw ConcurrentModificationException if the collection is structurally modified during the iteration. However, modifications that aren't structural allowed during iteration. For example, the #a says \"merely setting the value of an element is not a structural modification.\" Thus, the action for ArrayList.forEach is allowed to set values in the underlying ArrayList without problems. The concurrent collections are yet again different. Instead of fail-fast, they are designed to be #a . The full definition is at that link. Briefly, though, consider ConcurrentLinkedDeque . The action passed to its forEach method allowed to modify the underlying deque, even structurally, and ConcurrentModificationException is never thrown. However, the modification that occurs might or might not be visible in this iteration. (Hence the \"weak\" consistency.) Still another difference is visible if Iterable.forEach is iterating over a synchronized collection. On such a collection, Iterable.forEach takes the collection's lock once and holds it across all the calls to the action method. The Stream.forEach call uses the collection's spliterator, which does not lock, and which relies on the prevailing rule of non-interference. The collection backing the stream could be modified during iteration, and if it is, a ConcurrentModificationException or inconsistent behavior could result.",
            "answer_id": 23232560,
            "question_id": 23218874
        },
        {
            "cleaned": "Technically there's an ugly 'workaround' that involves peek(_exprs) and an AtomicInteger , but really you shouldn't be using that. What I do in these cases is just collecting it in a list, like this: #pre I am not aware of a way to do this in the API, meanwhile I will work on another example involving a custom element. , You should create your own Collector for this: #pre What it does is: #li It mimicks the Collectors.toList(_exprs) collector. #li It applies an extra finisher at the end, that throws an exception, or if no exception, returns the first element of the list. Used as: #pre You can then customize this singletonCollector as much as you want, for example give the exception as argument in the constructor, tweak it to allow two values, and more. , I revised my old answer once more for singletonCollector(_exprs) , it can actually be obtained like this: #pre",
            "answer_id": 22695031,
            "question_id": 22694884
        },
        {
            "cleaned": "The #a covered many of the major points already. I'll fill in a bit more background. The design of any API is a series of tradeoffs. In Java, one of the difficult issues is dealing with design decisions that were made long ago. Primitives have been in Java since 1.0. They make Java an \"impure\" object-oriented language, since the primitives are not objects. The addition of primitives was, I believe, a pragmatic decision to improve performance at the expense of object-oriented purity. This is a tradeoff we're still living with today, nearly 20 years later. The autoboxing feature added in Java 5 mostly eliminated the need to clutter source code with boxing and unboxing method calls, but the overhead is still there. In many cases it's not noticeable. However, if you were to perform boxing or unboxing within an inner loop, you'd see that it can impose significant CPU and garbage collection overhead. When designing the Streams API, it was clear that we had to support primitives. The boxing/unboxing overhead would kill any performance benefit from parallelism. We didn't want to support of the primitives, though, since that would have added a huge amount of clutter to the API. (Can you really see a use for a ShortStream ?) \"All\" or \"none\" are comfortable places for a design to be, yet neither was acceptable. So we had to find a reasonable value of \"some\". We ended up with primitive specializations for int , long , and double . (Personally I would have left out int but that's just me.) For CharSequence.chars(_exprs) we considered returning Stream<Character> (an early prototype might have implemented this) but it was rejected because of boxing overhead. Considering that a String has char values as primitives, it would seem to be a mistake to impose boxing unconditionally when the caller would probably just do a bit of processing on the value and unbox it right back into a string. We also considered a CharStream primitive specialization, but its use would seem to be quite narrow compared to the amount of bulk it would add to the API. It didn't seem worthwhile to add it. The penalty this imposes on callers is that they have to know that the IntStream contains char values represented as ints and that casting must be done at the proper place. This is doubly confusing because there are overloaded API calls like PrintStream.print(_exprs) and PrintStream.print(_exprs) that differ markedly in their behavior. An additional point of confusion possibly arises because the codePoints(_exprs) call also returns an IntStream but the values it contains are quite different. So, this boils down to choosing pragmatically among several alternatives: #li We could provide no primitive specializations, resulting in a simple, elegant, consistent API, but which imposes a high performance and GC overhead; #li we could provide a complete set of primitive specializations, at the cost of cluttering up the API and imposing a maintenance burden on JDK developers; or #li we could provide a subset of primitive specializations, giving a moderately sized, high performing API that imposes a relatively small burden on callers in a fairly narrow range of use cases (char processing). We chose the last one.",
            "answer_id": 22497858,
            "question_id": 22435833
        },
        {
            "cleaned": "You can use java.sql.Date.valueOf(_exprs) method as: #pre No need to add time and time zone info here because they are taken implicitly.",
            "answer_id": 28564046,
            "question_id": 22929237
        },
        {
            "cleaned": "This works because Integer::min resolves to an implementation of the Comparable<Integer> interface. The method reference of Integer::min resolves to Integer.min(_exprs) , resolved to IntBinaryOperator , and presumably autoboxing occurs somewhere making it a BinaryOperator<Integer> . And the min(_exprs) resp max(_exprs) methods of the Stream<Integer> ask the Comparable<Integer> interface to be implemented. And thus the magic has happened as both methods are a BinaryOperator<Integer> .",
            "answer_id": 22561687,
            "question_id": 22561614
        },
        {
            "cleaned": "Let me explain what is happening here, because it isn't obvious! First, #a accepts an instance of #a so that items in the stream can be compared against each other to find the minimum or maximum, in some optimal order that you don't need to worry too much about. So the question is, of course, why is #a accepted?  After all it's not a comparator! The answer is in the way that the new lambda functionality works in Java 8.  It relies on a concept which is informally known as \"single abstract method\" interfaces, or \"SAM\" interfaces.  The idea is that any interface with one abstract method can be automatically implemented by any lambda - or method reference - whose method signature is a match for the one method on the interface.  So examining the #a interface (simple version): #pre If a method is looking for a Comparator<Integer> , then it's essentially looking for this signature: #pre I use \"xxx\" . Therefore, both Integer.min(_exprs) and Integer.max(_exprs) are close enough that autoboxing will allow this to appear as a Comparator<Integer> in a method context.",
            "answer_id": 22561853,
            "question_id": 22561614
        },
        {
            "cleaned": "#blockquote No it won't - it will \"break\" as soon as the first element satisfying the predicate is found. You can read more about laziness in the #a , in particular (emphasis mine): #blockquote",
            "answer_id": 23696598,
            "question_id": 23696317
        },
        {
            "cleaned": "Just do: #pre where identity(_exprs) is a static import of Function.identity(_exprs) . Concatenating multiple streams into one stream is the same as flattening a stream. However, unfortunately, for some reason there is no flatten(_exprs) method on Stream , so you have to use flatMap(_exprs) with the identity function.",
            "answer_id": 37436520,
            "question_id": 22740464
        },
        {
            "cleaned": " Imagine that you want to create the following sequence: 1, 2, 2, 3, 3, 3, 4, 4, 4, 4 etc. (in other words: 1x1, 2x2, 3x3 etc.) With flatMap it could look like: #pre where: #li IntStream.rangeClosed(_exprs) creates a stream of int from 1 to 4, inclusive #li IntStream.iterate(_exprs).limit(_exprs) creates a stream of length i of int i - so applied to i = 4 it creates a stream: 4, 4, 4, 4 #li flatMap \"flattens\" the stream and \"concatenates\" it to the original stream With Java < 8 you would need two nested loops: #pre  Let's say I have a List<TimeSeries> where each TimeSeries is essentially a Map<LocalDate, Double> . I want to get a list of all dates for which at least one of the time series has a value. flatMap to the rescue: #pre Not only is it readable, but if you suddenly need to process 100k elements, simply adding parallel(_exprs) will improve performance without you writing any concurrent code.",
            "answer_id": 22384113,
            "question_id": 22382453
        },
        {
            "cleaned": "A subsequent post by the same user in the same conversation: #blockquote (This was in response to a statement by another user, namely that \"it seems in some situations 'new T' would be better\", the idea being that new T(_exprs) is impossible due to type erasure. (This is debatable \u2014 even if T were available at runtime, it could be an abstract class or interface, or it could be Void , or it could lack a no-arg constructor, or its no-arg constructor could be private (e.g., because it's supposed to be a singleton class), or its no-arg constructor could specify a checked exception that the generic method does not catch or specify \u2014 but that was the premise. Regardless, it's true that without erasure you could at least write T.class.newInstance(_exprs) , which handles those issues.)) This view, that types are isomorphic to propositions, suggests that the user has a background in formal type theory. (S)he very likely does not like \"dynamic types\" or \"runtime-types\" and would prefer a Java without downcasts and instanceof and reflection and so on. (Think of a language like Standard ML, which has a very rich (static) type system and whose dynamic semantics do not depend on any type information whatsoever.) It's worth keeping in mind, by the way, that the user is trolling: while (s)he likely sincerely prefers (statically) typed languages, (s)he is sincerely trying to persuade others of that view. Rather, the main purpose of the original tweet was to mock those who disagree, and after some of those disagree-ers chimed in, the user posted follow-up tweets such as \"the reason java has type erasure is that Wadler et al know what they are doing, unlike users of java\". Unfortunately, this makes it hard to find out what (s)he's actually thinking; but fortunately, it also likely means that it's not very important to do so. People with actual depth to their views don't generally resort to trolls that are this content-free.",
            "answer_id": 20918709,
            "question_id": 20918650
        },
        {
            "cleaned": "You can use #a from #a #pre If you can't change the strings from List : #pre If you only need a negation of String.isEmpty(_exprs) you can also use StringPredicates.notEmpty(_exprs) . Note: I am a contributor to Eclipse Collections.",
            "answer_id": 36242382,
            "question_id": 21488056
        },
        {
            "cleaned": "The behavior of String.split (which calls Pattern.split ) changes between Java 7 and Java 8.  Comparing between the documentation of Pattern.split in #a and #a , we observe the following clause being added: #blockquote The same clause is also added to String.split in #a , compared to #a .  Let us compare the code of Pattern.split of the reference implemetation in Java 7 and Java 8. The code is retrieved from grepcode, for version 7u40-b43 and 8-b132.  #pre  #pre The addition of the following code in Java 8 excludes the zero-length match at the beginning of the input string, which explains the behavior above. #pre   To make split behaves consistently across versions and compatible with the behavior in Java 8: #li If your regex match zero-length string, just add (_exprs) at of the regex and wrap the original regex in non-capturing group (_exprs) (if necessary). #li If your regex match zero-length string, you don't need to do anything. #li If you don't know whether the regex can match zero-length string or not, do both the actions in step 1. (_exprs) checks that the string does not end at the beginning of the string, which implies that the match is an empty match at the beginning of the string.  There is no general solution to make split backward-compatible with Java 7 and prior, short of replacing all instance of split to point to your own custom implementation.",
            "answer_id": 27477312,
            "question_id": 22718744
        }
    ]
}