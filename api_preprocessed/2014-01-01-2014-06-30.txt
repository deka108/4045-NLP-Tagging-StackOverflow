Question-21947452
I generated two matrices of 1000 x 1000 : First Matrix: O and # . Second Matrix: O and B . Using the following code, the first matrix took 8.52 seconds to complete: #pre With this code, the second matrix took 259.152 seconds to complete: #pre What is the reason behind the dramatically different run times? As suggested in the comments, printing only System.out.print(_exprs); takes 7.8871 seconds, whereas System.out.print(_exprs); gives still printing... . As others who pointed out that it works for them normally, I tried Ideone.com for instance, and both pieces of code execute at the same speed. Test Conditions: #li I ran this test from Netbeans 7.2, with the output into its console #li I used System.nanoTime(_exprs) for measurements

Question-20945049
We all know that String is immutable in Java, but check the following code: #pre Why does this program operate like this? And why is the value of s1 and s2 changed, but not s3 ?

Question-23453287
One of the most useful features of Java 8 are the new default methods on interfaces. There are essentially two reasons (there may be others) why they have been introduced: #li Providing actual default implementations. Example: Iterator.remove() #li Allowing for JDK API evolution. Example: Iterable.forEach() From an API designer's perspective, I would have liked to be able to use other modifiers on interface methods, e.g. final . This would be useful when adding convenience methods, preventing "accidental" overrides in implementing classes: #pre The above is already common practice if Sender were a class: #pre Now, default and final are obviously contradicting keywords, but the default keyword itself would not have been strictly required , so I'm assuming that this contradiction is deliberate, to reflect the subtle differences between "class methods with body" (just methods) and "interface methods with body" (default methods), i.e. differences which I have not yet understood. At some point of time, support for modifiers like static and final on interface methods was not yet fully explored, citing Brian Goetz : #blockquote Since that time in late 2011, obviously, support for static methods in interfaces was added. Clearly, this added a lot of value to the JDK libraries themselves, such as with Comparator.comparing() . Question: What is the reason final (and also static final ) never made it to Java 8 interfaces?

Question-21242110
What is the best way to convert a java.util.Date object to the new JDK 8/JSR-310 java.time.LocalDate ? #pre

Question-22561614
Note: this question originates from a dead link which was a previous SO question, but here goes... See this code (note: I do know that this code won't "work" and that Integer::compare should be used -- I just extracted it from the linked question): #pre According to the javadoc of .min() and .max() , the argument of both should be a Comparator . Yet here the method references are to static methods of the Integer class. So, why does this compile at all?

Question-23114015
I am wondering why the Iterable interface does not provide the stream(_exprs) and parallelStream(_exprs) methods. Consider the following class: #pre It is an implementation of a Hand as you can have cards in your hand while playing a Trading Card Game. Essentially it wraps a List<Card> , ensures a maximum capacity and offers some other useful features. It is better as implementing it directly as a List<Card> . Now, for convienience I thought it would be nice to implement Iterable<Card> , such that you can use enhanced for-loops if you want to loop over it. (My Hand class also provides a get(_exprs) method, hence the Iterable<Card> is justified in my opinion.) The Iterable interface provides the following (left out javadoc): #pre Now can you obtain a stream with: Stream<Hand> stream = StreamSupport.stream(_exprs); So onto the real question: #li Why does Iterable<T> not provide a default methods that implement stream(_exprs) and parallelStream(_exprs) , I see nothing that would make this impossible or unwanted? A related question I found is the following though: Why does Stream<T> not implement Iterable<T>? Which is oddly enough suggesting it to do it somewhat the other way around.

Question-22463062
Java 8 added a new API for working with dates and times (JSR 310). I have date and time as string (e.g. _str ). How can I obtain a LocalDateTime instance from the given string? After I finished working with the LocalDateTime object: How can I then convert the LocalDateTime instance back to a string with the same format as shown above?

Question-23699371
In Java 8 how can I filter a collection using the Stream API by checking the distinctness of a property of each object? For example I have a list of Person object and I want to remove people with the same name, persons.stream(_exprs).distinct(_exprs); Will use the default equality check for a Person object, so I need something like, persons.stream(_exprs).distinct(_exprs); Unfortunately the distinct(_exprs) method has no such overload. Without modifying the equality check inside the Person class is it possible to do this succinctly?

Question-22725537
The new Java 8 stream framework and friends make for some very concise java code, but I have come across a seemingly-simple situation that is tricky to do concisely. Consider a List<Thing> things and method Optional<Other> resolve(_exprs) . I want to map the Thing s to Optional<Other> s and get the first Other . The obvious solution would be to use things.stream(_exprs).flatMap(_exprs).findFirst(_exprs) , but flatMap requires that you return a stream, and Optional doesn't have a stream(_exprs) method (or is it a Collection or provide a method to convert it to or view it as a Collection ). The best I can come up with is this: things.stream(_exprs) .map(_exprs) .filter(_exprs) .map(_exprs) .findFirst(_exprs); But that seems awfully long-winded for what seems like a very common case. Anyone have a better idea?

Question-21105403
I've written a factory to produce java.sql.Connection objects: #pre I'd like to validate the parameters passed to DriverManager.getConnection , but I don't know how to mock a static method. I'm using JUnit 4 and Mockito for my test cases. Is there a good way to mock/verify this specific use-case?

Question-23674624
I'm looking at the docs for the IntStream , and I see an toArray method, but no way to go directly to a List<Integer> Surely there is a way to convert a Stream to a List ?

Question-23218874
I understand that with .stream(_exprs) , I can use chain operations like .filter(_exprs) or use parallel stream. But what is difference between them if I need to execute small operations (for example, printing the elements of the list)? #pre

Question-22435833
In Java 8, there is a new method String.chars() which returns a stream of int s ( IntStream ) that represent the character codes. I guess many people would expect a stream of char s here instead. What was the motivation to design the API this way?

Question-22740464
I can add streams or extra elements, like this: Stream stream = Stream.concat(stream1, Stream.concat(_exprs); And I can add new stuff as I go, like this: Stream stream = Stream.concat(_exprs) .filter(_exprs); But this is ugly, because concat is static. If concat were an instance method, the above examples would be much easier to read: Stream stream = stream1.concat(_exprs).concat(_exprs); And Stream stream = stream1 .filter(_exprs) .concat(_exprs) .filter(_exprs) .concat(_exprs) .filter(_exprs); My question is: 1) Is there any good reason why concat is static? Or is there some equivalent instance method I'm missing? 2) In any case, is there a better way of doing this?

Question-23756966
While investigating for a little debate w.r.t. using _str + n and Integer.toString(int) to convert an integer primitive to a string I wrote this JMH microbenchmark: #pre I ran it with the default JMH options with both Java VMs that exist on my Linux machine (up-to-date Mageia 4 64-bit, Intel i7-3770 CPU, 32GB RAM). The first JVM was the one supplied with Oracle JDK 8u5 64-bit: #pre With this JVM I got pretty much what I expected: #pre I.e. using the StringBuilder class is slower due to the additional overhead of creating the StringBuilder object and appending an empty string. Using String.format(_exprs) is even slower, by an order of magnitude or so. The distribution-provided compiler, on the other hand, is based on OpenJDK 1.7: #pre The results here were interesting : #pre Why does StringBuilder.append(_exprs) appear so much faster with this JVM? Looking at the StringBuilder class source code revealed nothing particularly interesting - the method in question is almost identical to Integer#toString(_exprs) . Interestingly enough, appending the result of Integer.toString(_exprs) (the stringBuilder2 microbenchmark) does not appear to be faster. Is this performance discrepancy an issue with the testing harness? Or does my OpenJDK JVM contain optimizations that would affect this particular code (anti)-pattern? EDIT: For a more straight-forward comparison, I installed Oracle JDK 1.7u55: #pre The results are similar to those of OpenJDK: #pre It seems that this is a more general Java 7 vs Java 8 issue. Perhaps Java 7 had more aggressive string optimizations? EDIT 2 : For completeness, here are the string-related VM options for both of these JVMs: For Oracle JDK 8u5: #pre For OpenJDK 1.7: #pre The UseStringCache option was removed in Java 8 with no replacement, so I doubt that makes any difference. The rest of the options appear to have the same settings. EDIT 3: A side-by-side comparison of the source code of the AbstractStringBuilder , StringBuilder and Integer classes from the src.zip file of reveals nothing noteworty. Apart from a whole lot of cosmetic and documentation changes, Integer now has some support for unsigned integers and StringBuilder has been slightly refactored to share more code with StringBuffer . None of these changes seem to affect the code paths used by StringBuilder#append(_exprs) , although I may have missed something. A comparison of the assembly code generated for IntStr#integerToString(_exprs) and IntStr#stringBuilder0(_exprs) is far more interesting. The basic layout of the code generated for IntStr#integerToString(_exprs) was similar for both JVMs, although Oracle JDK 8u5 seemed to be more aggressive w.r.t. inlining some calls within the Integer#toString(_exprs) code. There was a clear correspondence with the Java source code, even for someone with minimal assembly experience. The assembly code for IntStr#stringBuilder0(_exprs) , however, was radically different. The code generated by Oracle JDK 8u5 was once again directly related to the Java source code - I could easily recognise the same layout. On the contrary, the code generated by OpenJDK 7 was almost unrecognisable to the untrained eye (like mine). The new StringBuilder(_exprs) call was seemingly removed, as was the creation of the array in the StringBuilder constructor. Additionaly, the disassembler plugin was not able to provide as many references to the source code as it did in JDK 8. I assume that this is either the result of a much more aggressive optimization pass in OpenJDK 7, or more probably the result of inserting hand-written low-level code for certain StringBuilder operations. I am unsure why this optimization does not happen in my JVM 8 implementation or why the same optimizations were not implemented for Integer#toString(_exprs) in JVM 7. I guess someone familiar with the related parts of the JRE source code would have to answer these questions...

Question-21947452, answer-29434641
I performed tests on Eclipse vs Netbeans 8.0.2, both with Java version 1.8; I used System.nanoTime(_exprs) for measurements. Eclipse: I got the same time on both cases - around 1.564 seconds . Netbeans: #li Using "#": 1.536 seconds #li Using "B": 44.164 seconds So, it looks like Netbeans has bad performance on print to console. After more research I realized that the problem is line-wrapping of the max buffer of Netbeans (it's not restricted to System.out.println command), demonstrated by this code: #pre The time results are less then 1 millisecond every iteration except every fifth iteration , when the time result is around 225 millisecond. Something like (in nanoseconds): #pre And so on.. Summary: #li Eclipse works perfectly with "B" #li Netbeans has a line-wrapping problem that can be solved (because the problem does not occur in eclipse)(without adding space after B ("B ")).

Question-20945049, answer-20945113
String is immutable* but this only means you cannot change it using its public API. What you are doing here is circumventing the normal API, using reflection. The same way, you can change the values of enums, change the lookup table used in Integer autoboxing etc. Now, the reason s1 and s2 change value, is that they both refer to the same interned string. The compiler does this (as mentioned by other answers). The reason s3 does not was actually a bit surprising to me, as I thought it would share the value array ( it did in earlier version of Java , before Java 7u6). However, looking at the source code of String , we can see that the value character array for a substring is actually copied (using Arrays.copyOfRange(_exprs) ). This is why it goes unchanged. You can install a SecurityManager , to avoid malicious code to do such things. But keep in mind that some libraries depend on using these kind of reflection tricks (typically ORM tools, AOP libraries etc). *) I initially wrote that String s aren't really immutable, just "effective immutable". This might be misleading in the current implementation of String , where the value array is indeed marked private final . It's still worth noting, though, that there is no way to declare an array in Java as immutable, so care must be taken not to expose it outside its class, even with the proper access modifiers. As this topic seems overwhelmingly popular, here's some suggested further reading: Heinz Kabutz's Reflection Madness talk from JavaZone 2009, which covers a lot of the issues in the OP, along with other reflection... well... madness. It covers why this is sometimes useful. And why, most of the time, you should avoid it. :-)

Question-20945049, answer-20945268
In Java, if two string primitive variables are initialized to the same literal, it assigns the same reference to both variables: #pre #blockquote That is the reason the comparison returns true. The third string is created using substring(_exprs) which makes a new string instead of pointing to the same. #blockquote When you access a string using reflection, you get the actual pointer: #pre So change to this will change the string holding a pointer to it, but as s3 is created with a new string due to substring(_exprs) it would not change. #blockquote

Question-20945049, answer-20959594
String is immutable, but through reflection you're allowed to change the String class. You've just redefined the String class as mutable in real-time. You could redefine methods to be public or private or static if you wanted.

Question-20945049, answer-21008747
[Disclaimer this is a deliberately opinionated style of answer as I feel a more "don't do this at home kids" answer is warranted] The sin is the line field.setAccessible(_exprs); which says to violate the public api by allowing access to a private field. Thats a giant security hole which can be locked down by configuring a security manager. The phenomenon in the question are implementation details which you would never see when not using that dangerous line of code to violate the access modifiers via reflection. Clearly two (normally) immutable strings can share the same char array. Whether a substring shares the same array depends on whether it can and whether the developer thought to share it. Normally these are invisible implementation details which you should not have to know unless you shoot the access modifier through the head with that line of code. It is simply not a good idea to rely upon such details which cannot be experienced without violating the access modifiers using reflection. The owner of that class only supports the normal public API and is free to make implementation changes in the future. Having said all that the line of code is really very useful when you have a gun held you your head forcing you to do such dangerous things. Using that back door is usually a code smell that you need to upgrade to better library code where you don't have to sin. Another common use of that dangerous line of code is to write a "voodoo framework" (orm, injection container, ...). Many folks get religious about such frameworks (both for and against them) so I will avoid inviting a flame war by saying nothing other than the vast majority of programmers don't have to go there.

Question-22409102, answer-22409270
You can use Float.floatToIntBits to convert it to an int and look at the bit pattern: #pre

Question-22409102, answer-22501695
The approach used by Math.min is similar to what Jesper proposes but a little clearer: #pre

Question-22409102, answer-33501556
Double.equals distinguishes ±0.0 in Java. (There's also Float.equals .) I'm a bit surprised no-one has mentioned these, as they seem to me clearer than any method given so far!

Question-22501230, answer-22511214
I don't like any of the solutions presented except for JAB's. None of the others make it easy to read the code and understand what is being computed . Here's how I would write this code -- I only know C#, not Java, but you get the picture: #pre Now it is much more clear what is being computed here: this emphasizes that we are computing who gets hit by what attack, and returning both results. However this could be even better; that Boolean array is somewhat opaque. I like the table lookup approach but I would be inclined to write it in such a way that made it clear what the intended game semantics were. That is, rather than "an attack of zero and a defense of one results in no hit", instead find a way to make the code more clearly imply "a low kick attack and a low block defense results in no hit". Make the code reflect the business logic of the game.

Question-22847105, answer-37354549
The way I think about it is that you use flatMap when the function you wanted to put inside of map(_exprs) returns an Observable . In which case you might still try to use map(_exprs) but it would be unpractical. Let me try to explain why. If in such case you decided to stick with map , you would get an Observable<Observable<Something>> . For example in your case, if we used an imaginary RxGson library, that returned an Observable<String> from it's toJson(_exprs) method (instead of simply returning a String ) it would look like this: #pre At this point it would be pretty tricky to subscribe(_exprs) to such an observable. Inside of it you would get an Observable<String> to which you would again need to subscribe(_exprs) to get the value. Which is not practical or nice to look at. So to make it useful one idea is to "flatten" this observable of observables (you might start to see where the name _flat_Map comes from). RxJava provides a few ways to flatten observables and for sake of simplicity lets assume merge is what we want. Merge basically takes a bunch of observables and emits whenever any of them emits. (Lots of people would argue switch would be a better default. But if you're emitting just one value, it doesn't matter anyway.) So amending our previous snippet we would get: #pre This is a lot more useful, because subscribing to that (or mapping, or filtering, or...) you just get the String value. (Also, mind you, such variant of merge(_exprs) does not exist in RxJava, but if you understand the idea of merge then I hope you also understand how that would work.) So basically because such merge(_exprs) should probably only ever be useful when it succeeds a map(_exprs) returning an observable and so you don't have to type this over and over again, flatMap(_exprs) was created as a shorthand. It applies the mapping function just as a normal map(_exprs) would, but later instead of emitting the returned values it also "flattens" (or merges) them. That's the general use case. It is most useful in a codebase that uses Rx allover the place and you've got many methods returning observables, which you want to chain with other methods returning observables. In your use case it happens to be useful as well, because map(_exprs) can only transform one value emitted in onNext(_exprs) into another value emitted in onNext(_exprs) . But it cannot transform it into multiple values, no value at all or an error. And as akarnokd wrote in his answer (and mind you he's much smarter than me, probably in general, but at least when it comes to RxJava) you shouldn't throw exceptions from your map(_exprs) . So instead you can use flatMap(_exprs) and return Observable.just(_exprs); when all goes well, but return Observable.error(_exprs); when something fails. See his answer for a complete snippet: #a

Question-22182669, answer-22222274
StackOverflowError occurs due to an application recurses too deeply (This is not an answer you are expecting). Now other things to happen to StackOverflowError is keep calling methods from methods till you get StackOverflowError , but nobody can program to get StackOverflowError and even if those programmer are doing so then they are not following coding standards for cyclomatic complixity that every programmer has to understand while programming. Such reason for 'StackOverflowError' will require much time to rectify it. But unknowingly coding one line or two line which causes StackOverflowError is understandable and JVM throws that and we can rectify it instantly. Here is my answer with picture for some other question.

Question-22182669, answer-22223113
The most common cause of StackOverFlowError is excessively deep or infinite recursion. For instance: #pre In Java: There are two areas in memory the heap and stack. The stack memory is used to store local variables and function call, while heap memory is used to store objects in Java. If there is no memory left in stack for storing function call or local variable, JVM will throw java.lang.StackOverFlowError while if there is no more heap space for creating object, JVM will throw java.lang.OutOfMemoryError

Question-23453287, answer-23456085
It will be hard to find and identify "THE" answer, for the resons mentioned in the comments from @EJP : There are roughly 2 (+/- 2) people in the world who can give the definite answer at all . And in doubt, the answer might just be something like "Supporting final default methods did not seem to be worth the effort of restructuring the internal call resolution mechanisms". This is speculation, of course, but it is at least backed by subtle evidences, like this Statement (by one of the two persons) in the OpenJDK mailing list : #blockquote and trivial facts like that a method is simply not considered to be a (really) final method when it is a default method, as currently implemented in the Method::is_final_method method in the OpenJDK. Further really "authorative" information is indeed hard to find, even with excessive websearches and by reading commit logs. I thought that it might be related to potential ambiguities during the resolution of interface method calls with the invokeinterface instruction and and class method calls, corresponding to the invokevirtual instruction: For the invokevirtual instruction, there may be a simple vtable lookup, because the method must either be inherited from a superclass, or implemented by the class directly. In contrast to that, an invokeinterface call must examine the respective call site to find out which interface this call actually refers to (this is explained in more detail in the InterfaceCalls page of the HotSpot Wiki). However, final methods do either not get inserted into the vtable at all, or replace existing entries in the vtable (see klassVtable.cpp. Line 333 ), and similarly, default methods are replacing existing entries in the vtable (see klassVtable.cpp, Line 202 ). So the actual reason (and thus, the answer) must be hidden deeper inside the (rather complex) method call resolution mechanisms, but maybe these references will nevertheless be considered as being helpful, be it only for others that manage to derive the actual answer from that.

Question-23079003, answer-23079174
You can use the overloaded version of toArray , as the following: #pre The purpose of the IntFunction<A[]> generator is to convert an integer, the size of the array, to a new array. Example code: #pre Prints: #pre Another option is to use a method reference to the string array constructor, this one is a bit more tricky. Usage is easy: String[] stringArray = streamString.toArray(_exprs); What it does, is find a method that takes in an integer (the size) as argument, and returns a String[] , which is exactly what (one of the overloads of) new String[] does.

Question-21242110, answer-27378709
Better way is: #pre Advantages of this version: #li works regardless the input is an instance of java.util.Date or it's subclass java.sql.Date (unlike @JodaStephen's way). This is common with JDBC originated data. java.sql.Date.toInstant(_exprs) always throws an exception. #li it's the same for JDK8 and JDK7 with JSR-310 backport I personally use an utility class (but this is not backport-compatible): #pre The asLocalDate(_exprs) method here is null-safe, uses toLocalDate(_exprs) , if input is java.sql.Date (it may be overriden by the JDBC driver to avoid timezone problems or unnecessary calculations), otherwise uses the abovementioned method.

Question-22036885, answer-22037068
As said in API #blockquote It's because of cannot represent double value exactly. So you have to use BigDecimal bigDecimal = BigDecimal.valueOf(_exprs); instead of BigDecimal bigDecimal = new BigDecimal(_exprs);

Question-20877086, answer-20877161
Integer objects caches between -128 and 127 of 256 Integer You should not compare object references with == or != . You should use . equals(..) instead, or better - use the primitive int rather than Integer. parseInt : Parses the string argument as a signed decimal integer. The characters in the string must all be decimal digits, except that the first character may be an ASCII minus sign '-' ('\u002D') to indicate a negative value. The resulting integer value is returned, exactly as if the argument and the radix 10 were given as arguments to the parseInt(java.lang.String, int) method. valueOf Returns an Integer object holding the value extracted from the specified String when parsed with the radix given by the second argument. The first argument is interpreted as representing a signed integer in the radix specified by the second argument, exactly as if the arguments were given to the parseInt(java.lang.String, int) method. The result is an Integer object that represents the integer value specified by the string. equivalent to new Integer(_exprs) radix - the radix to be used in interpreting s so if you equal Integer.valueOf(_exprs) for the integer inbetween -128 to 127 it returns true in your condition for lesser than -128 and greater than 127 it gives false

Question-20877086, answer-20877283
The Integer class has a static cache, that stores 256 special Integer objects - one for every value between -128 and 127. With that in mind, consider the difference between these three. new Integer(_exprs); This (obviously) makes a brand new Integer object. Integer.parseInt(_exprs); This returns an int primitive value after parsing the String . Integer.valueOf(_exprs); This is more complex than the others. It starts off by parsing the String . Then, if the value is between -128 and 127, it returns the corresponding object from the static cache. If the value is outside of this range, then it invokes new Integer(_exprs) and passes in the value, so that you get a new object. Now, consider the three expressions in the question. Integer.valueOf(_exprs)==Integer.valueOf(_exprs); This returns true, because the Integer whose value is 127 is retrieved twice from the static cache, and compared to itself. There's only one Integer object involved, so this returns true . Integer.valueOf(_exprs)==Integer.valueOf(_exprs); This returns false , because 128 is not in the static cache. So a new Integer is created for each side of the equality. Since there are two different Integer objects, and == for objects only returns true if both sides are the exact same object, this is going to be false . Integer.parseInt(_exprs)==Integer.valueOf(_exprs); This is comparing the primitive int value 128 on the left, with a newly created Integer object on the right. But because it doesn't make sense to compare an int to an Integer , Java will auto-unbox the Integer before doing the comparison; so you end up comparing an int to an int . Since the primitive 128 is equal to itself, this returns true .

Question-20877086, answer-20889556
To complement the given answers, also take note of the following: #pre This code will also print: false As user Jay has claimed in a comment for the accepted answer, care must be taken when using operator == on objects, here you're checking if both references are the same, which is not, because they are different objets, although they represent the very same value. To compare objects, you should use the equals method instead: #pre This will print: true You may ask, But then why the first line printed true ? . Checking the source code for the Integer.valueOf method, you can see the following: #pre If the param is an integer between IntegerCache.low (defaulted to -128) and IntegerCache.high (calculated at runtime with minimum value 127) then a pre-allocated (cached) object is returned. So when you use 127 as parameter, you're getting two references to same cached object and getting true in the comparison of the references.

Question-21163108, answer-21172732
The parallel streams use the default ForkJoinPool which by default has one less threads as you have processors , as returned by Runtime.getRuntime(_exprs).availableProcessors(_exprs) (so parallel streams use all your processors because they also use the main thread): #blockquote To change the way parallel streams are executed, you can either #li submit the parallel stream execution to your own ForkJoinPool: yourFJP.submit(_exprs); or #li you can change the size of the common pool using system properties: System.setProperty(_exprs) for a target parallelism of 20 threads. Example of the latter on my machine which has 8 processors. If I run the following program: #pre The output is: #blockquote So you can see that the parallel stream processes 8 items at a time, i.e. it uses 8 threads. However if I uncomment the commented line, the output is: #blockquote This time the parallel stream has used 20 threads and all 20 elements in the stream have been processed comcurrently.

Question-21163108, answer-22269778
There actually is a trick how to execute a parallel operation in a specific fork-join pool. If you execute it as a task in a fork-join pool, it stays there and does not use the common one. #pre The trick is based on ForkJoinTask.fork which specifies: "Arranges to asynchronously execute this task in the pool the current task is running in, if applicable, or using the ForkJoinPool.commonPool() if not inForkJoinPool()"

Question-21163108, answer-34930831
To measure the actual number of used threads, you can check Thread.activeCount(_exprs) : #pre This can produce on a 4-core CPU an output like: #pre Without .parallel(_exprs) it gives: #pre

Question-22382453, answer-22384113
Made up example Imagine that you want to create the following sequence: 1, 2, 2, 3, 3, 3, 4, 4, 4, 4 etc. (in other words: 1x1, 2x2, 3x3 etc.) With flatMap it could look like: #pre where: #li IntStream.rangeClosed(_exprs) creates a stream of int from 1 to 4, inclusive #li IntStream.iterate(_exprs).limit(_exprs) creates a stream of length i of int i - so applied to i = 4 it creates a stream: 4, 4, 4, 4 #li flatMap "flattens" the stream and "concatenates" it to the original stream With Java < 8 you would need two nested loops: #pre Real world example Let's say I have a List<TimeSeries> where each TimeSeries is essentially a Map<LocalDate, Double> . I want to get a list of all dates for which at least one of the time series has a value. flatMap to the rescue: list.stream(_exprs).parallel(_exprs) .flatMap(_exprs) // for each TS, stream dates and flatmap .distinct(_exprs) // remove duplicates .sorted(_exprs) // sort ascending .collect(_exprs); Not only is it readable, but if you suddenly need to process 100k elements, simply adding parallel(_exprs) will improve performance without you writing any concurrent code.

Question-22694884, answer-22695031
Technically there's an ugly 'workaround' that involves peek(_exprs) and an AtomicInteger , but really you shouldn't be using that. What I do in these cases is just collecting it in a list, like this: #pre I am not aware of a way to do this in the API, meanwhile I will work on another example involving a custom element. Update , You should create your own Collector for this: #pre What it does is: #li It mimicks the Collectors.toList(_exprs) collector. #li It applies an extra finisher at the end, that throws an exception, or if no exception, returns the first element of the list. Used as: User resultUser = users.stream(_exprs) .filter(_exprs) .collect(_exprs); You can then customize this singletonCollector as much as you want, for example give the exception as argument in the constructor, tweak it to allow two values, and more. New update , I revised my old answer once more for singletonCollector(_exprs) , it can actually be obtained like this: #pre

Question-22694884, answer-39385411
As Collectors.toMap(_exprs) uses a throwing merger to handle multiple entries with the same key it is easy: #pre You will get a IllegalStateException for duplicate keys. But at the end I am not sure if the code would not be even more readable using an if .

Question-23932061, answer-23932216
You can easily create a Stream out of an Iterable or Iterator : #pre

Question-23932061, answer-23936723
There's a much better answer than using spliteratorUnknownSize directly, which is both easier and gets a better result. Iterable has a spliterator(_exprs) method, so you should just use that to get your spliterator. In the worst case, its the same code (the default implementation uses spliteratorUnknownSize ), but in the more common case, where your Iterable is already a collection, you'll get a better spliterator, and therefore better stream performance (maybe even good parallelism.) Its also less code: StreamSupport.stream(_exprs) .filter(_exprs) .moreStreamOps(_exprs); As you can see, getting a stream from an Iterable (see Why does Iterable<T> not provide stream() and parallelStream() methods? ) is not very painful.

Question-20918650, answer-20918709
A subsequent post by the same user in the same conversation: #blockquote (This was in response to a statement by another user, namely that "it seems in some situations 'new T' would be better", the idea being that new T(_exprs) is impossible due to type erasure. (This is debatable — even if T were available at runtime, it could be an abstract class or interface, or it could be Void , or it could lack a no-arg constructor, or its no-arg constructor could be private (e.g., because it's supposed to be a singleton class), or its no-arg constructor could specify a checked exception that the generic method does not catch or specify — but that was the premise. Regardless, it's true that without erasure you could at least write T.class.newInstance(_exprs) , which handles those issues.)) This view, that types are isomorphic to propositions, suggests that the user has a background in formal type theory. (S)he very likely does not like "dynamic types" or "runtime-types" and would prefer a Java without downcasts and instanceof and reflection and so on. (Think of a language like Standard ML, which has a very rich (static) type system and whose dynamic semantics do not depend on any type information whatsoever.) It's worth keeping in mind, by the way, that the user is trolling: while (s)he likely sincerely prefers (statically) typed languages, (s)he is not sincerely trying to persuade others of that view. Rather, the main purpose of the original tweet was to mock those who disagree, and after some of those disagree-ers chimed in, the user posted follow-up tweets such as "the reason java has type erasure is that Wadler et al know what they are doing, unlike users of java". Unfortunately, this makes it hard to find out what (s)he's actually thinking; but fortunately, it also likely means that it's not very important to do so. People with actual depth to their views don't generally resort to trolls that are quite this content-free.

Question-22561614, answer-22561687
This works because Integer::min resolves to an implementation of the Comparable<Integer> interface. The method reference of Integer::min resolves to Integer.min(_exprs) , resolved to IntBinaryOperator , and presumably autoboxing occurs somewhere making it a BinaryOperator<Integer> . And the min(_exprs) resp max(_exprs) methods of the Stream<Integer> ask the Comparable<Integer> interface to be implemented. Now this resolves to the single method Integer compareTo(_exprs) . Which is of type BinaryOperator<Integer> . And thus the magic has happened as both methods are a BinaryOperator<Integer> .

Question-22561614, answer-22561690
Comparator is a functional interface , and Integer::max complies with that interface (after autoboxing/unboxing is taken into consideration). It takes two int values and returns an int - just as you'd expect a Comparator<Integer> to (again, squinting to ignore the Integer/int difference). However, I wouldn't expect it to do the right thing, given that Integer.max doesn't comply with the semantics of Comparator.compare . And indeed it doesn't really work in general. For example, make one small change: #pre ... and now the max value is -20 and the min value is -1. Instead, both calls should use Integer::compare : #pre

Question-22561614, answer-22561853
Let me explain what is happening here, because it isn't obvious! First, Stream.max() accepts an instance of Comparator so that items in the stream can be compared against each other to find the minimum or maximum, in some optimal order that you don't need to worry too much about. So the question is, of course, why is Integer::max accepted? After all it's not a comparator! The answer is in the way that the new lambda functionality works in Java 8. It relies on a concept which is informally known as "single abstract method" interfaces, or "SAM" interfaces. The idea is that any interface with one abstract method can be automatically implemented by any lambda - or method reference - whose method signature is a match for the one method on the interface. So examining the Comparator interface (simple version): #pre If a method is looking for a Comparator<Integer> , then it's essentially looking for this signature: int xxx(_exprs); I use "xxx" because the method name is not used for matching purposes . Therefore, both Integer.min(_exprs) and Integer.max(_exprs) are close enough that autoboxing will allow this to appear as a Comparator<Integer> in a method context.

Question-23114015, answer-23177907
This was not an omission; there was detailed discussion on the EG list in June of 2013. The definitive discussion of the Expert Group is rooted at this thread . While it seemed "obvious" (even to the Expert Group, initially) that stream(_exprs) seemed to make sense on Iterable , the fact that Iterable was so general became a problem, because the obvious signature: Stream<T> stream(_exprs) was not always what you were going to want. Some things that were Iterable<Integer> would rather have their stream method return an IntStream , for example. But putting the stream(_exprs) method this high up in the hierarchy would make that impossible. So instead, we made it really easy to make a Stream from an Iterable , by providing a spliterator(_exprs) method. The implementation of stream(_exprs) in Collection is just: #pre Any client can get the stream they want from an Iterable with: Stream s = StreamSupport.stream(_exprs); In the end we concluded that adding stream(_exprs) to Iterable would be a mistake.

Question-23114015, answer-32874755
If you know the size you could use java.util.Collection which provides the stream(_exprs) method: #pre And then: new Hand(_exprs).stream(_exprs).map(_exprs) I faced the same problem and was surprised that my Iterable implementation could be very easily extended to an AbstractCollection implementation by simply adding the size(_exprs) method (luckily I had the size of the collection :-) You should also consider to override Spliterator<E> spliterator(_exprs) .

Question-21524642, answer-21524694
Or.. Pattern#quote : String[] value_split = rat_values.split(_exprs); This is happening because String#split accepts a regex : | has a special meaning in regex . quote will return a String representation for the regex .

Question-22463062, answer-22463063
Parsing date and time To create a LocalDateTime object from a string you can use the static LocalDateTime.parse() method. It takes a string and a DateTimeFormatter as parameter. The DateTimeFormatter is used to specify the date/time pattern. #pre Formatting date and time To create a formatted string out a LocalDateTime object you can use the format(_exprs) method. #pre Note that there are some commonly used date/time formats predefined as constants in DateTimeFormatter . For example: Using DateTimeFormatter.ISO_DATE_TIME to format the LocalDateTime instance from above would result in the string _str . The parse(_exprs) and format(_exprs) methods are available for all date/time related objects (e.g. LocalDate or ZonedDateTime )

Question-22463062, answer-28324294
You can also use LocalDate.parse(_exprs) or LocalDateTime.parse(_exprs) on a String without providing it with a pattern, if the String is in ISO-8601 format . for example, #pre Output , #pre and use DateTimeFormatter only if you have to deal with other date patterns, For example, dd MMM uuuu represents the day of the month (two digits), three letters of the name of the month (Jan, Feb, Mar,...), and a four-digit year: #pre Output 04 Aug 2015 parses to 2015-08-04 also remember that the DateTimeFormatter object is bidirectional; it can both parse input and format output. #pre Output 2015-08-04 formats as 04 Aug 2015 (see complete list of Patterns for Formatting and Parsing DateFormatter ) #pre

Question-21488056, answer-30506585
Predicate has methods and , or and negate . However, String::isEmpty is not a Predicate . It could as well be Function<String, Boolean> or MyProprietaryClass . The type information is inferred from the variable or the call. So, you need to cast a method reference explicitly (as @axtavt mentioned): (_exprs).negate(_exprs) But it's absolutely ugly and Predicate seems to use lambdas under the hood anyway. So I think you are better off writing a lambda or even your own not(_exprs) method (e.g. in utility, static import).

Question-21488056, answer-35074360
I have written a complete utility class (inspired by Askar's proposal) that can take Java 8 lambda expression and turn them (if applicable) into any typed standard Java 8 lambda defined in the package java.util.function . You can for example do: #li asPredicate(_exprs).negate(_exprs) #li asBiPredicate(_exprs).negate(_exprs) Because there would be numerous ambiguities if all the static methods would be named just as(_exprs) , I opted to call the method "as" followed by the returned type. This gives us full control of the lambda interpretation. Below is the first part of the (somewhat large) utility class revealing the pattern used. Have a look at the complete class here (at gist). #pre

Question-21488056, answer-36242382
You can use Predicates from Eclipse Collections #pre If you can't change the strings from List : #pre If you only need a negation of String.isEmpty(_exprs) you can also use StringPredicates.notEmpty(_exprs) . Note: I am a contributor to Eclipse Collections.

Question-23699371, answer-23733628
The easiest way to implement this is to jump on the sort feature as it already provides an optional Comparator which can be created using an element’s property. Then you have to filter duplicates out which can be done using a statefull Predicate which uses the fact that for a sorted stream all equal elements are adjacent: #pre Of course, a statefull Predicate is not thread-safe, however if that’s your need you can move this logic into a Collector and let the stream take care of the thread-safety when using your Collector . This depends on what you want to do with the stream of distinct elements which you didn’t tell us in your question.

Question-23699371, answer-34731808
You can use the distinct(_exprs) method in Eclipse Collections . #pre If you can refactor persons to implement an Eclipse Collections interface, you can call the method directly on the list. #pre HashingStrategy is simply a strategy interface that allows you to define custom implementations of equals and hashcode. #pre Note: I am a committer for Eclipse Collections.

Question-22725537, answer-22735184
You cannot do it more concise as you are already doing. You claim that you do not want .filter(_exprs) and .map(_exprs) . This has been resolved by the method @StuartMarks describes, however as a result you now map it to an Optional<T> , so now you need to use .flatMap(_exprs) and a get(_exprs) in the end. So it still consists of two statements and you can now get exceptions with the new method! Because, what if every optional is empty? Then the findFirst(_exprs) will return an empty optional and your get(_exprs) will fail! So what you have: things.stream(_exprs) .map(_exprs) .filter(_exprs) .map(_exprs) .findFirst(_exprs); is actually the best way to accomplish what you want, and that is you want to save the result as a T , not as an Optional<T> . I took the liberty of creating a CustomOptional<T> class that wraps the Optional<T> and provides an extra method, flatStream(_exprs) . Note that you cannot extend Optional<T> : #pre You will see that I added flatStream(_exprs) , as here: #pre Used as: String result = Stream.of(_exprs) .map(_exprs) .flatMap(_exprs) .findFirst(_exprs) .get(_exprs); You still will need to return a Stream<T> here, as you cannot return T , because if !optional.isPresent(_exprs) , then T == null if you declare it such, but then your .flatMap(_exprs) would attempt to add null to a stream and that is not possible. As example: #pre Used as: String result = Stream.of(_exprs) .map(_exprs) .map(_exprs) .findFirst(_exprs) .get(_exprs); Will now throw a NullPointerException inside the stream operations. Conclusion The method you used, is actually the best method.

Question-22725537, answer-27215810
A slightly shorter version using reduce : things.stream(_exprs) .map(_exprs) .reduce(_exprs); You could also move the reduce function to a static utility method and then it becomes: .reduce(_exprs);

Question-22725537, answer-36334855
As my previous answer appeared not to be very popular, I will give this another go. A short answer: You are mostly on a right track. The shortest code to get to your desired output I could come up with is this: things.stream(_exprs) .map(_exprs) .filter(_exprs) .findFirst(_exprs) .flatMap(_exprs); This will fit all your requirements: #li It will find first response that resolves to a nonempty Optional<Result> #li It calls this::resolve lazily as needed #li this::resolve will not be called after first non-empty result #li It will return Optional<Result> Longer answer The only modification compared to OP initial version was that I removed .map(_exprs) before call to .findFirst(_exprs) and added .flatMap(_exprs) as the last call in the chain. This has a nice effect of getting rid of the double-Optional, whenever stream finds an actual result. You can't really go any shorter than this in Java. The alternative snippet of code using the more conventional for loop technique is going to be about same number of lines of code and have more or less same order and number of operations you need to perform: #li Calling this.resolve , #li filtering based on Optional.isPresent #li returning the result and #li some way of dealing with negative result (when nothing was found) Just to prove that my solution works as advertised, I wrote a small test program: #pre (It does have few extra lines for debugging and verifying that only as many calls to resolve as needed...) Executing this on a command line, I got the following results: #pre

Question-23674624, answer-23674719
IntStream.boxed turns an IntStream into a Stream<Integer> , which you can then collect into a list: theIntStream.boxed(_exprs).collect(_exprs)

Question-23308193, answer-32566745
This is possible for forEach(_exprs) . The solution is not nice, but it is possible. WARNING : You should not use it for controlling business logic, but purely for handling an exceptional situation which occurs during the execution of the forEach(_exprs) . Such as a resource suddenly stops being accessible, one of the processed objects is violating a contract (e.g. contract says that all the elements in the stream must not be null but suddenly and unexpectedly one of them is null ) etc. According to the documentation for Iterable.forEach() : #blockquote So you throw an exception which will immediately break the internal loop. The code will be something like this - I cannot say I like it but it works. You create your own class BreakException which extends RuntimeException . #pre Notice that the try...catch is not around the lambda expression, but rather around the whole forEach(_exprs) method. To make it more visible, see the following transcription of the code which shows it more clearly: #pre

Question-22929237, answer-28564046
You can use java.sql.Date.valueOf(_exprs) method as: Date date = java.sql.Date.valueOf(_exprs); No need to add time and time zone info here because they are taken implicitly. See Simpliest java8 LocalDate to java.util.Date conversion and vice versa?

Question-23218874, answer-23232560
For simple cases such as the one illustrated, they are mostly the same. However, there are a number of subtle differences that might be significant. One issue is with ordering. With Stream.forEach , the order is undefined . It's unlikely to occur with sequential streams, still, it's within the specification for Stream.forEach to execute in some arbitrary order. This does occur frequently in parallel streams. By contrast, Iterable.forEach is always executed in the iteration order of the Iterable , if one is specified. Another issue is with side effects. The action specified in Stream.forEach is required to be non-interfering . (See the java.util.stream package doc .) Iterable.forEach potentially has fewer restrictions. For the collections in java.util , Iterable.forEach will generally use that collection's Iterator , most of which are designed to be fail-fast and which will throw ConcurrentModificationException if the collection is structurally modified during the iteration. However, modifications that aren't structural are allowed during iteration. For example, the ArrayList class documentation says "merely setting the value of an element is not a structural modification." Thus, the action for ArrayList.forEach is allowed to set values in the underlying ArrayList without problems. The concurrent collections are yet again different. Instead of fail-fast, they are designed to be weakly consistent . The full definition is at that link. Briefly, though, consider ConcurrentLinkedDeque . The action passed to its forEach method is allowed to modify the underlying deque, even structurally, and ConcurrentModificationException is never thrown. However, the modification that occurs might or might not be visible in this iteration. (Hence the "weak" consistency.) Still another difference is visible if Iterable.forEach is iterating over a synchronized collection. On such a collection, Iterable.forEach takes the collection's lock once and holds it across all the calls to the action method. The Stream.forEach call uses the collection's spliterator, which does not lock, and which relies on the prevailing rule of non-interference. The collection backing the stream could be modified during iteration, and if it is, a ConcurrentModificationException or inconsistent behavior could result.

Question-22435833, answer-22497858
The answer from skiwi covered many of the major points already. I'll fill in a bit more background. The design of any API is a series of tradeoffs. In Java, one of the difficult issues is dealing with design decisions that were made long ago. Primitives have been in Java since 1.0. They make Java an "impure" object-oriented language, since the primitives are not objects. The addition of primitives was, I believe, a pragmatic decision to improve performance at the expense of object-oriented purity. This is a tradeoff we're still living with today, nearly 20 years later. The autoboxing feature added in Java 5 mostly eliminated the need to clutter source code with boxing and unboxing method calls, but the overhead is still there. In many cases it's not noticeable. However, if you were to perform boxing or unboxing within an inner loop, you'd see that it can impose significant CPU and garbage collection overhead. When designing the Streams API, it was clear that we had to support primitives. The boxing/unboxing overhead would kill any performance benefit from parallelism. We didn't want to support all of the primitives, though, since that would have added a huge amount of clutter to the API. (Can you really see a use for a ShortStream ?) "All" or "none" are comfortable places for a design to be, yet neither was acceptable. So we had to find a reasonable value of "some". We ended up with primitive specializations for int , long , and double . (Personally I would have left out int but that's just me.) For CharSequence.chars(_exprs) we considered returning Stream<Character> (an early prototype might have implemented this) but it was rejected because of boxing overhead. Considering that a String has char values as primitives, it would seem to be a mistake to impose boxing unconditionally when the caller would probably just do a bit of processing on the value and unbox it right back into a string. We also considered a CharStream primitive specialization, but its use would seem to be quite narrow compared to the amount of bulk it would add to the API. It didn't seem worthwhile to add it. The penalty this imposes on callers is that they have to know that the IntStream contains char values represented as ints and that casting must be done at the proper place. This is doubly confusing because there are overloaded API calls like PrintStream.print(_exprs) and PrintStream.print(_exprs) that differ markedly in their behavior. An additional point of confusion possibly arises because the codePoints(_exprs) call also returns an IntStream but the values it contains are quite different. So, this boils down to choosing pragmatically among several alternatives: #li We could provide no primitive specializations, resulting in a simple, elegant, consistent API, but which imposes a high performance and GC overhead; #li we could provide a complete set of primitive specializations, at the cost of cluttering up the API and imposing a maintenance burden on JDK developers; or #li we could provide a subset of primitive specializations, giving a moderately sized, high performing API that imposes a relatively small burden on callers in a fairly narrow range of use cases (char processing). We chose the last one.

Question-22718744, answer-22718904
This has been specified in the documentation of split(String regex, limit) . #blockquote In _str.split(_exprs) you got a zero-width match at the beginning so the leading empty substring is not included in the resulting array. However in your second snippet when you split on _str you got a positive width match (1 in this case), so the empty leading substring is included as expected. (Removed irrelevant source code)

Question-22718744, answer-27477312
The behavior of String.split (which calls Pattern.split ) changes between Java 7 and Java 8. Documentation Comparing between the documentation of Pattern.split in Java 7 and Java 8 , we observe the following clause being added: #blockquote The same clause is also added to String.split in Java 8 , compared to Java 7 . Reference implementation Let us compare the code of Pattern.split of the reference implemetation in Java 7 and Java 8. The code is retrieved from grepcode, for version 7u40-b43 and 8-b132. Java 7 #pre Java 8 #pre The addition of the following code in Java 8 excludes the zero-length match at the beginning of the input string, which explains the behavior above. #pre Maintaining compatibility Following behavior in Java 8 and above To make split behaves consistently across versions and compatible with the behavior in Java 8: #li If your regex can match zero-length string, just add (_exprs) at the end of the regex and wrap the original regex in non-capturing group (_exprs) (if necessary). #li If your regex can't match zero-length string, you don't need to do anything. #li If you don't know whether the regex can match zero-length string or not, do both the actions in step 1. (_exprs) checks that the string does not end at the beginning of the string, which implies that the match is an empty match at the beginning of the string. Following behavior in Java 7 and prior There is no general solution to make split backward-compatible with Java 7 and prior, short of replacing all instance of split to point to your own custom implementation.

Question-23653778, answer-25564062
Try OnStart(_exprs) method and just use View view = getView(_exprs).findViewById(_exprs); or Declare any View using getView(_exprs).findViewById method in onStart(_exprs) Declare click listener on view by anyView.setOnClickListener(_exprs);

Question-21375659, answer-21375716
String is immutable irrespective of how it is instantiated 1) Short answer is yes , new String(_exprs) is immutable too. Because every possible mutable operation (like replace , toLowerCase etcetra) that you perform on String does not affect the original String instance and returns you a new instance . You may check this in Javadoc for String . Each public method of String that is exposed returns a new String instance and does not alter the present instance on which you called the method. This is very helpful in Multi-threaded environment as you don't have to think about mutability ( someone will change the value ) every time you pass or share the String around. String can easily be the most used data type, so the designers have blessed us all to not think about mutability everytime and saved us a lot of pain. Immutability allowed String pool or caching It is because of immutability property that the internal pool of string was possible, as when same String value is required at some other place then that immutable reference is returned. If String would have been mutable then it would not have been possible to share String s like this to save memory. String immutablity was not because of pooling, but immutability has more benefits attached to it. String interning or pooling is an example of Flyweight Design pattern 2) Yes it will be interned like any other String as a blank String is also as much a String as other String instances. References: #li Immutability benefits of String

Question-21375659, answer-21375818
This isn't strictly an answer to your question, but if behind your question is a wish to have mutable strings that you can manipulate, you should check out the StringBuilder class, which implements many of the exact same methods that String has but also adds methods to change the current contents. Once you've built your string in such a way that you're content with it, you simply call toString(_exprs) on it in order to convert it to an ordinary String that you can pass to library routines and other functions that only take String s. Also, both StringBuilder and String implements the CharSequence interface, so if you want to write functions in your own code that can use both mutable and immutable strings, you can declare them to take any CharSequence object.

Question-22740464, answer-22741520
Unfortunately this answer is probably of little or no help whatsoever, but I did a forensics analysis of the Java Lambda Mailing list to see if I could find the cause of this design. This is what I found out. In the beginning there was an instance method for Stream.concat(Stream) In the mailing list I can clearly see the method was originally implemented as an instance method, as you can read in this thread by Paul Sandoz, about the concat operation. In it they discuss the issues that could arise from those cases in which the stream could be infinite and what concatenation would mean in those cases, but I do not think that was the reason for the modification. You see in this other thread that some early users of the JDK 8 questioned about the behavior of the concat instance method when used with null arguments. This other thread reveals, though, that the design of the concat method was under discussion. Refactored to Streams.concat(Stream,Stream) But without any explanation, suddenly, the methods were changed to static methods, as you can see in this thread about combining streams . This is perhaps the only mail thread that sheds a bit of light about this change, but it was not clear enough for me to determine the reason for the refactoring. But we can see they did a commit in which they suggested to move the concat method out of Stream and into the helper class Streams . Refactored to Stream.concat(Stream,Stream) Later, it was moved again from Streams to Stream , but yet again, no explanation for that. So, bottom line, the reason for the design is not entirely clear for me and I could not find a good explanation. I guess you could still ask the question in the mailing list. Some Alternatives for Stream Concatenation This other thread by Michael Hixson discusses/asks about other ways to combine/concat streams #blockquote

Question-22740464, answer-37436520
Just do: Stream.of(_exprs).flatMap(_exprs); where identity(_exprs) is a static import of Function.identity(_exprs) . Concatenating multiple streams into one stream is the same as flattening a stream. However, unfortunately, for some reason there is no flatten(_exprs) method on Stream , so you have to use flatMap(_exprs) with the identity function.
