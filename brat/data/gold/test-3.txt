Question-30217236, answer-30217518
Presumably, you are not calling your generic method in a generic fashion, so it's treated like a call to x(args) . In this example: #pre The first call to x is not made generically so it compiles. The second call equates T to String , so it fails because 1 and 2 are not Strings . The third call compiles because it properly passes in Strings .

Question-14602062, answer-14602155
From the documentation of String.split(String regex) : #blockquote So you will have to use the two argument version String.split(String regex, int limit) with a negative value: String[] split = data.split(args); Doc: #blockquote This will not leave out any empty elements, including the trailing ones.

Question-8777257, answer-8777292
The equals(args) of arrays is inherited from Object , so it does not look at the contents of the arrrays, it only considers each array equal to itself. The Arrays.equals(args) methods do compare the arrays' contents. There's overloads for all primitive types, and the one for objects uses the objects' own equals(args) methods.

Question-31922866
I've read on many Web sites Optional should be used as a return type only, and not used in method arguments. I'm struggling to find a logical reason why. For example I have a piece of logic which has 2 optional parameters. Therefore I think it would make sense to write my method signature like this (solution 1): #pre Many web pages specify Optional should not be used as method arguments. With this in mind I could use the following method signature and add a clear Javadoc comment specifying the arguments maybe null hoping future future maintainers will read the javadoc and therefore always carry out null checks prior to using the arguments (solution 2): #pre Alternatively I could replace my method with 4 public methods to provide a nicer interface and make it more obvious p1 and p2 are optional (solution 3): #pre Now I try writing the code of the class which invokes this piece of logic for each approach. I first retrieve the 2 input parameters from another object which returns optionals and then I invoke calculateSomething. Therefore if solution 1 is used the calling code would look like this: #pre if solution 2 is used the calling code would look like this: #pre if solution 3 is used I could use the code above or I could use the following (but its a significant amount more code): #pre So my question is why is it considered bad practice to use Optionals as method arguments as in solution 1? It looks like the most readable solution to me and makes it most obvious that the parameters could be empty/null to future maintainers. (I'm aware the designers of Optional intended it to only be used as a return type, but I can't find any logical reasons not to use it in this scenario)

Question-32693704
I noticed something strange in the implementation of HashMap.clear(args) . This is how it looked in OpenJDK 7u40 : #pre And this is how it looks as of OpenJDK 8u40 : #pre I understand that now the table can be null for empty an map, thus the additional check and caching in a local variable is required. But why was Arrays.fill(args) replaced with a for-loop? It seems that the change was introduced in this commit . Unfortunately I found no explanation for why a plain for loop might be better than Arrays.fill(args) . Is it faster? Or safer?

Question-22501230, answer-22511214
I don't like any of the solutions presented except for JAB's. None of the others make it easy to read the code and understand what is being computed . Here's how I would write this code -- I only know C#, not Java, but you get the picture: #pre Now it is much more clear what is being computed here: this emphasizes that we are computing who gets hit by what attack, and returning both results. However this could be even better; that Boolean array is somewhat opaque. I like the table lookup approach but I would be inclined to write it in such a way that made it clear what the intended game semantics were. That is, rather than "an attack of zero and a defense of one results in no hit", instead find a way to make the code more clearly imply "a low kick attack and a low block defense results in no hit". Make the code reflect the business logic of the game.

Question-28840047
Some time ago, I've blogged about a Java 8 functional way of calculating fibonacci numbers recursively , with a ConcurrentHashMap cache and the new, useful computeIfAbsent(args) method: #pre I chose ConcurrentHashMap because I was thinking of making this example even more sophisticated by introducing parallelism (which I didn't in the end). Now, let's increase the number from 8 to 25 and observe what happens: System.out.println(args); The program never halts. Inside the method, there's a loop that just runs forever: #pre I'm using: #pre Matthias, a reader of that blog post also confirmed the issue (he actually found it) . This is weird. I would have expected any of the following two: #li It works #li It throws a ConcurrentModificationException But just never halting? That seems dangerous. Is it a bug? Or did I misunderstand some contract?

Question-30125296, answer-30125487
I suggest 2 more options: #pre The second one uses Collectors.summingInt() collector. Besides, Java 8 introduces a very effective LongAdder accumulator designed to speed-up summarizing in parallel streams and multi-thread environments. Here, it may be used as follows: #pre

Question-9510125
Swing components have multiple methods related to updates of screen layout, in particular: #li validate() #li invalidate() #li revalidate() The Java documentation defines these somewhat from a technical perspective, but it's not particularly clear how they are meant to be used. What is the difference between these, and in what circumstances should you use one rather than the others?

Question-25168062
Why is i++ not atomic in Java? To get a bit deeper in Java I tried to count how often the loop in threads are executed. So I used a private static int total = 0; in the main class. I have two threads. #li Thread 1: Prints System.out.println(args); #li Thread 2: Prints System.out.println(args); And I count the lines printed by thread 1 and thread 2. But the lines of thread 1 + lines of thread 2 don't match the total number of lines printed out. Here is my code: #pre

Question-8275499, answer-17397548
As for the code example in the question, the standard solution is to reference the class explicitly by its name, and it is even possible to do without getClassLoader(args) call: #pre This approach still has a back side that it is not very safe against copy/paste errors in case you need to replicate this code to a number of similar classes. And as for the exact question in the headline, there is a trick posted in the adjacent thread : Class currentClass = new Object(args) { }.getClass(args).getEnclosingClass(args); It uses a nested anonymous Object subclass to get hold of the execution context. This trick has a benefit of being copy/paste safe... It may be also worth noting that if this snippet is shaped as a static method of some base class, then currenClass value will always be a reference to that base class rather than to any subclass that may be using that method.

Question-6667243, answer-25575077
You could override the toString(args) method for each enum value. Example: #pre Usage: #pre

Question-27747562
In the following code, a dowcast to an apparently incompatible type passes compilation: #pre Item and List<T> are disparate types so the cast can never succeed. Why did the compiler allow this?

Question-4576352, answer-11325546
You can use str = str.replace(args); as mentioned before and you will be fine. For your information CharLiteral is not an empty (or a valid) character but CharLiteral is. So you could use str = str.replace(args); instead.

Question-26791441, answer-26796725
Swapping Only One Occurrence If there is only one occurrence of each of the swapable strings in the input, you can do the following: Before proceeding to any replace, get the indices of the occurrences of the words. After that we only replace the word found at these indexes, and not all occurrences. This solution uses StringBuilder and does not produce intermediate String s like String.replace(args) . One thing to note: if the swapable words have different lengths, after the first replace the second index might change (if the 1st word occurs before the 2nd) exactly with the difference of the 2 lengths. So aligning the second index will ensure this works even if we're swapping words with different lengths. #pre Swapping Arbitrary Number of Occurrences Analogous to the previous case we will first collect the indexes (occurrences) of the words, but in this case it will a list of integers for each word, not just one int . For this we will use the following utility method: #pre And using this we will replace the words with the other one by decreasing index (which might require to alternate between the 2 swapable words) so that we won't even have to correct the indices after a replace: #pre

Question-6841333
If I run the following program, which parses two date strings referencing times one second apart and compares them: #pre The output is: 353 Why is ld4-ld3 not 1 (as I would expect from the one-second difference in the times), but 353 ? If I change the dates to times one second later: #pre Then ld4-ld3 will be 1 . Java version: #pre Timezone( TimeZone.getDefault(args) ): #pre

Question-31922866, answer-31923042
The pattern with Optional is for one to avoid returning null . It's still perfectly possible to pass in null to a method. While these aren't really official yet, you can use JSR-308 style annotations to indicate whether or not you accept null values into the function. Note that you'd have to have the right tooling to actually identify it, and it'd provide more of a static check than an enforceable runtime policy, but it would help. public int calculateSomething(args) {}

Question-12552863, answer-12665271
Here's my take on the alternatives: 1) #pre For me, the best thing coming to Java from traditional C++ 15 years ago was that you could trust your program. Even if things are in the muck and going wrong, which they often do, I want the rest of the code to be on best behaviour and smelling of roses. Indeed, the BufferedWriter might throw an exception here. Running out of memory wouldn't be unusual, for instance. For other decorators, do you know which of the java.io wrapper classes throw a checked exception from their constructors? I don't. Doesn't do code understandability much good if you rely upon that sort of obscure knowledge. Also there's the "destruction". If there is an error condition, then you probably don't want to be flushing rubbish to a file that needs deleting (code for that not shown). Although, of course, deleting the file is also another interesting operation to do as error handling. Generally you want finally blocks to be as short and reliable as possible. Adding flushes does not help this goal. For many releases some of the buffering classes in the JDK had a bug where an exception from flush within close caused close on the decorated object not be called. Whilst that has been fixed for some time, expect it from other implementations. 2) #pre We're still flushing in the implicit finally block (now with repeated close - this gets worse as you add more decorators), but the construction is safe and we have to implicit finally blocks so even a failed flush doesn't prevent resource release. 3) #pre There's a bug here. Should be: #pre Some poorly implemented decorators are in fact resource and will need to be closed reliably. Also some streams may need to be closed in a particular way (perhaps they are doing compression and need to write bits to finish off, and can't just flush everything. Verdict Although 3 is a technically superior solution, software development reasons make 2 the better choice. However, try-with-resource is still an inadequate fix and you should stick with the Execute Around idiom, which should have a clearer syntax with closures in Java SE 8.

Question-6271417, answer-6271460
The "$1" is not "useless non-sense". If your class is anonymous, a number is appended. If you don't want the class itself, but its declaring class, then you can use getEnclosingClass(args) . For example: #pre You can move that in some static utility method. But note that this is not the current class name. The anonymous class is different class than its enclosing class. The case is similar for inner classes.

Question-12552863, answer-12619799
I would say don't use ARM and go on with Closeable. Use method like, #pre Also you should consider calling close of BufferedWriter as it is not just delegating the close to FileWriter , but it does some cleanup like flushBuffer .

Question-14534767, answer-14534791
Escape should be done with \ , not / . So r.append(args); or r.append(args); will work ( StringBuilder has overloaded methods for char and String type).

Question-17489250, answer-17489376
String gets special treatment in the JLS: it's one of the two non-primitive types for which literals exist (the other is Class ) * . From the JLS : #blockquote * well, there's also the "null type" with it's "null literal" null , but most people don't think of the "null type" as a proper type.

Question-30217236, answer-30219144
Why this should be problem in the first place is kind of nebulous to me. I suspect you've instead misunderstood something about the ways in which the type system is useful. What can we do with a <T> void x(args) ? Well, not a whole lot. Inside the body of x , T is the same as Object , so we could only do something like call toString on a and b to print them. There's really no practical reason a and b must have the same type. Just that they have some type in common, and that type is Object or a subtype of it. In fact, there's no clear reason why <T> void x(args) actually needs to be generic at all. #li The method body doesn't care what the actual types of a and b are because it couldn't use them anyway. #li The call site doesn't care what the actual types of a and b are because x is a void method so it's a black hole. It's more typical for a method to have a result, like <T> List<T> Arrays.asList(args) : // This will cause a compile error because // the type inferred must be compatible // with the return assignment. List<T> r = Arrays.asList(args); Or a bound: #pre Or a bound which asserts some kind of relation: #pre

Question-5374311, answer-17909134
I can see many answers showing how to solve problem, but only Stephen's answer is trying to explain why problem occurs so I will try to add something more on this subject. It is a story about possible reasons why Object[] toArray wasn't changed to T[] toArray where generics ware introduced to Java. Why String[] stockArr = (String[]) stock_list.toArray(args); wont work? In Java, generic type exists at compile-time only . At runtime information about generic type (like in your case <String> ) is removed and replaced with Object type (take a look at type erasure ). That is why at runtime toArray(args) have no idea about what precise type to use to create new array, so it uses Object as safest type, because each class extends Object so it can safely store instance of any class. Now the problem is that you can't cast instance of Object[] to String[] . Why? Take a look at this example (lets assume that class B extends A ): #pre Although such code will compile, at runtime we will see thrown ClassCastException because instance held by reference a is not actually of type B (or its subtypes). Why is this problem (why this exception needs to be cast)? One of the reasons is that B could have new methods/fields which A doesn't, so it is possible that someone will try to use these new members via b reference even if held instance doesn't have (doesn't support) them. In other words we could end up trying to use data which doesn't exist, which could lead to many problems. So to prevent such situation JVM throws exception, and stop further potentially dangerous code. You could ask now "So why aren't we stopped even earlier? Why code involving such casting is even compilable? Shouldn't compiler stop it?". Answer is: no because compiler can't know for sure what is the actual type of instance held by a reference, and there is a chance that it will hold instance of class B which will support interface of b reference. Take a look at this example: #pre Now lets go back to your arrays. As you see in question, we can't cast instance of Object[] array to more precise type String[] like #pre Here problem is a little different. Now we are sure that String[] array will not have additional fields or methods because every array support only: #li [] operator, #li length filed, #li methods inherited from Object supertype, So it is not arrays interface which is making it impossible. Problem is that Object[] array beside Strings can store any objects (for instance Integers ) so it is possible that one beautiful day we will end up with trying to invoke method like strArray[i].substring(args) on instance of Integer which doesn't have such method. So to make sure that this situation will never happen, in Java array references can hold only #li instances of array of same type as reference (reference String[] strArr can hold String[] ) #li instances of array of subtype ( Object[] can hold String[] because String is subtype of Object ), but can't hold #li array of supertype of type of array from reference ( String[] can't hold Object[] ) #li array of type which is not related to type from reference ( Integer[] can't hold String[] ) In other words something like this is OK #pre You could say that one way to resolve this problem is to find at runtime most common type between all list elements and create array of that type, but this wont work in situations where all elements of list will be of one type derived from generic one. Take a look #pre now most common type is B , not A so toArray(args) A[] arr = elements.toArray(args); would return array of B class new B[] . Problem with this array is that while compiler would allow you to edit its content by adding new A(args) element to it, you would get ArrayStoreException because B[] array can hold only elements of class B or its subclass, to make sure that all elements will support interface of B , but instance of A may not have all methods/fields of B . So this solution is not perfect. Best solution to this problem is explicitly tell what type of array toArray(args) should be returned by passing this type as method argument like String[] arr = list.toArray(args); or String[] arr = list.toArray(args); //if size of array is smaller then list it will be automatically adjusted.

Question-26791441, answer-26877910
What I can only share is my own method. You can use a temporary String temp = StringLiteral; or String.Format(args); This is my example code created in console application via c# -"Idea Only, Not Exact Answer" . #pre Or you can also use the String.Format(args); #pre Output: time upon a Once, there was a bar and a foo.

Question-16148575, answer-16149127
You can't use a primitive because HashMap use object internally for the key. So you can only use an object that inherits from Object (that is any object). That is the function put() in HashMap and as you can see it uses Object for K: #pre The expression "k = e.key" should make it clear. I suggest to use a wrapper like Integer and autoboxing.

Question-5455794
I have a string like this: mysz = StringLiteral; I want to remove the whitespaces in the string. I tried trim(args) but this removes only whitespaces before and after the whole string. I also tried replaceAll(args) but then the = also gets removed. How can I achieve a string with: mysz2 = StringLiteral

Question-30522698
The problem I would like to be able to override my apps resources such as R.colour.brand_colour or R.drawable.ic_action_start at runtime. My application connects to a CMS system that will provide branding colours and images. Once the app has downloaded the CMS data it needs to be able to re-skin itself. I know what you are about to say - overriding resources at runtime is not possible. Except that it kinda is. In particular I have found this Bachelor Thesis from 2012 which explains the basic concept - The Activity class in android extends ContextWrapper , which contains the attachBaseContext method. You can override attachBaseContext to wrap the Context with your own custom class which overrides methods such as getColor and getDrawable. Your own implementation of getColor could look the colour up however it wanted. The Calligraphy library uses a similar approach to inject a custom LayoutInflator which can deal with loading custom fonts. The code I have created a simple Activity which uses this approach to override the loading of a colour. #pre The problem is, it doesn't work! The logging shows calls to load resources such as layout/activity_main and mipmap/ic_launcher however color/theme_colour is never loaded. It seems that the context is being used to create the window and action bar, but not the activity's content view. My questions is - Where does the layout inflator load resources from, if not the activities context? I would also like to know - Is there a workable way to override the loading of colours and drawables at runtime? A word about alternative approaches I know its possible to theme an app from CMS data other ways - for example we could create a method getCMSColour(args) then inside our onCreate(args) we have a bunch of code along the lines of: myTextView.setTextColour(args) A similar approach could be taken for drawables, strings, etc. However this would result in a large amount of boilerplate code - all of which needs maintaining. When modifying the UI it would be easy to forget to set the colour on a particular view. Wrapping the Context to return our own custom values is 'cleaner' and less prone to breakage. I would like to understand why it doesn't work, before exploring alternative approaches.

Question-29494800
I have trouble understanding the source code of Arrays.copyOf . #pre #li what is this line checking? (Object)newType == (Object)Object[].class #li What are the differences between (T[]) new Object[newLength] and (T[]) Array.newInstance(args) . why Array.newInstance not good enough for both cases? #li This following line compiles, but crashes at run time (as expected). When should I use this method? Integer[] nums = Arrays.copyOf(args)

Question-9749746
How do atomic / volatile / synchronized work internally? What is the difference between the following code blocks? Code 1 #pre Code 2 #pre Code 3 #pre Does volatile work in the following way? Is #pre equivalent to #pre I think that two threads cannot enter a synchronized block at the same time... am I right? If this is true then how does atomic.incrementAndGet(args) work without synchronized ? And is it thread-safe? And what is the difference between internal reading and writing to volatile variables / atomic variables? I read in some article that the thread has a local copy of the variables - what is that?

Question-17781150, answer-17781376
Like the others have mentioned, this is only fulfilled by Integer.MIN_VALUE . As for proof, let me offer an easier to understand explanation other than in binary (although it is still rooted in that). Note that Integer.MIN_VALUE is equal to -2^31 or -2147483648 and Integer.MAX_VALUE is equal to 2^31-1 or 2147483647 . -Integer.MIN_VALUE is 2^31 , which is now too large for an Integer (since it is past MAX_VALUE ) thus causing an Integer overflow, making it Integer.MIN_VALUE again. It's the only Integer that does this since MIN_VALUE is the only number with no negative equivalent aside from 0.

Question-27908213, answer-27908302
With strings you're going to want to use the equals method of Strings. That aside, you already have the enum that you could compare with the equality operator. Under what scenario would this arise? That being said, yes, the .equals method will return true if they are the same. I'm not sure about equality operator, and without looking it up, I can tell you that it's poor programming to use it if it is.

Question-34250207, answer-34250231
Technically, it's 10 , not zero, if you admit for a lazy initialisation of the backing array. See: #pre where /** * Default initial capacity. */ private static final int DEFAULT_CAPACITY = 10; What you're referring to is just the zero-sized initial array object that is shared among all initially empty ArrayList objects. I.e. the capacity of 10 is guaranteed lazily , an optimisation that is present also in Java 7. Admittedly, the constructor contract is not entirely accurate. Perhaps this is the source of confusion here. Background Here's an E-Mail by Mike Duigou #blockquote

Question-29494800, answer-29500496
First of all, the cast in that line ((Object)newType == (Object)Object[].class) are absobuletly needed. Removing them will result in a compilation error : #pre Now to answer your question What is this line checking ? It simply verify if the given array is of object type, which is part of the answer for your other question Why Array.newInstance not good enough for both cases? In the first case, we already know that the array is of Object type so there is no point in calling the newInstance method to retrieve the correct type, this would only result in performance loss. As for your final example, Integer[] nums = Arrays.copyOf(args) That it does compile, it is true. Because the given arguments to the method are all valids. It will certainly fail at runtime; what would be the expected output of converting "a" to Integer type ? Now, when to use copyOf ? When you already know the both types, and already know that they are valid together. It main usage is to return a copy but truncated or padded with [null/default values] to the original array.

Question-15430247, answer-25757711
ArrayList shrinks or expands dynamically. This is a effective but costly operation, if you know size of your array will be fixed then its better to mention the size of the array,If you don't, new array will be created at each insertion and reallocation will be done for each element. this will cost you. ensureCapacity(args) this method help to avoid reallocations and helps increase size of arraylist. trimToSize(args) this is reverse used to shrink size Arraylist has 3 constructors: #li ArrayList() -builds empty ArrayList #li ArrayList(Collection c) - builds a ArrayList initialized with elements of collection c. #li ArrayList(int capacity) -builds an ArrayList with specified initial capacity.

Question-7520432, answer-7521675
Just remember that .equals(args) has to be implemented by the class you are trying to compare. Otherwise, there isn't much of a point; the version of the method for the Object class does the same thing as the comparison operation: Object#equals . The only time you really want to use the comparison operator for objects is wen you are comparing Enums. This is because there is only one instance of an Enum value at a time. For instance, given the enum enum FooEnum {A, B, C} You will never have more than one instance of A at a time, and the same for B and C . This means that you can actually write a method like so: #pre And you will have no problems whatsoever.

Question-25056607, answer-25056878
We can take a look into the source code of java.util.regex.Pattern which is behind String.split . Way down the rabbit hole the method public String[] split(args) is invoked. Input StringLiteral For input StringLiteral this method is called as String[] parts = split(args); The intersting part of this method is : #pre And that is what happens: new String[] {input.toString()} is returned . Input StringLiteral For input StringLiteral the intersting part is #pre Here resultSize == 0 and limit == 0 so new String[0] is returned .

Question-10827872, answer-10827900
In java.lang.String , the replace method either takes a pair of char's or a pair of CharSequence 's (of which String is a subclass, so it'll happily take a pair of String's). The replace method will replace all occurrences of a char or CharSequence . On the other hand, both String arguments to replaceFirst and replaceAll are regular expressions (regex). Using the wrong function can lead to subtle bugs.

Question-27683759, answer-27684040
That line creates an empty list of strings by calling a static method with a generic type parameter. Inside the Collections class, there is a static method emptyList declared like: #pre This has a generic type parameter T . We call call this method by using: List<T> list = Collections.emptyList(args); and T is infered to be a String because of the type of list . We can also specify the type of T by putting it in angle brackets when calling emptyList . This may be needed if we want a more specific type than is inferred: List<T> list = Collections.<String>emptyList(args); emptyList<T>(args) is not correct because that placement is only valid when creating instances of generic classes, not calling methods. When using new there are two possible type parameters, the ones before the class name are for the constructor only, and the ones after the class name are for the whole instance, so with the class: #pre We can call its constructor where A is String and B is Integer like: MyClass<T> a = new<T>MyClass<T>(args); or by using type inference: MyClass<T> a = new MyClass<T>(args); See also: #li Generic Methods #li Type Inference

Question-28840047, answer-28840048
This is of course a "feature" . The ConcurrentHashMap.computeIfAbsent() Javadoc reads: #blockquote The "must not" wording is a clear contract, which my algorithm violated, although not for the same concurrency reasons. What's still interesting is that there is no ConcurrentModificationException . Instead, the program just never halts - which still is a rather dangerous bug in my opinion (i.e. infinite loops. or: anything that can possibly go wrong, does ). The simplest use-site solution for this concrete problem would be to not use a ConcurrentHashMap , but just a HashMap instead: static Map<T> cache = new HashMap<T>(args); Now, everything works fine. Note: The HashMap.computeIfAbsent() or Map.computeIfAbsent() Javadoc don't forbid such recursive computation, which is of course ridiculous as the type of the cache is Map<T> , not ConcurrentHashMap<T> . It is very dangerous for subtypes to drastically re-define super type contracts ( Set vs. SortedSet is greeting). It should thus be forbidden also in super types, to perform such recursion.

Question-5031614
There have been some discussions here about JPA entities and which hashCode(args) / equals(args) implementation should be used for JPA entity classes. Most (if not all) of them depend on Hibernate, but I'd like to discuss them JPA-implementation-neutrally (I am using EclipseLink, by the way). All possible implementations are having their own advantages and disadvantages regarding: #li hashCode(args) / equals(args) contract conformity (immutability) for List / Set operations #li Whether identical objects (e.g. from different sessions, dynamic proxies from lazily-loaded data structures) can be detected #li Whether entities behave correctly in detached (or non-persisted) state As far I can see, there are three options : #li Do not override them; rely on Object.equals(args) and Object.hashCode(args) #li hashCode(args) / equals(args) work #li cannot identify identical objects, problems with dynamic proxies #li no problems with detached entities #li Override them, based on the primary key #li hashCode(args) / equals(args) are broken #li correct identity (for all managed entities) #li problems with detached entities #li Override them, based on the Business-Id (non-primary key fields; what about foreign keys?) #li hashCode(args) / equals(args) are broken #li correct identity (for all managed entities) #li no problems with detached entities My questions are: #li Did I miss an option and/or pro/con point? #li What option did you choose and why? UPDATE 1: By " hashCode(args) / equals(args) are broken", I mean that successive hashCode(args) invocations may return differing values, which is (when correctly implemented) not broken in the sense of the Object API documentation, but which causes problems when trying to retrieve a changed entity from a Map , Set or other hash-based Collection . Consequently, JPA implementations (at least EclipseLink) will not work correctly in some cases. UPDATE 2: Thank you for your answers -- most of them have remarkable quality. Unfortunately, I am still unsure which approach will be the best for a real-life application, or how to determine the best approach for my application. So, I'll keep the question open and hope for some more discussions and/or opinions.

Question-32312876, answer-32313069
This is possible using the mergeFunction parameter of Collectors.toMap(keyMapper, valueMapper, mergeFunction) : #pre mergeFunction is a function that operates on two values associated with the same key. adress1 corresponds to the first address that was encountered when collecting elements and adress2 corresponds to the second address encountered: this lambda just tells to keep the first address and ignores the second.

Question-8725387
In Java there are the SortedSet and SortedMap interfaces. Both belong to Java's standard Collections framework and provide a sorted way to access the elements. However, in my understanding there is no SortedList in Java. You can use java.util.Collections.sort(args) to sort a list. Any idea why it is designed like that?

Question-21163108, answer-22269778
There actually is a trick how to execute a parallel operation in a specific fork-join pool. If you execute it as a task in a fork-join pool, it stays there and does not use the common one. #pre The trick is based on ForkJoinTask.fork which specifies: "Arranges to asynchronously execute this task in the pool the current task is running in, if applicable, or using the ForkJoinPool.commonPool() if not inForkJoinPool()"

Question-31922866, answer-31922994
I think that is because you usually write your functions to manipulate data, and then lift it to Optional using map and similar functions. This adds the default Optional behavior to it. Of course, there might be cases, when it is necessary to write your own auxilary function that works on Optional .

Question-31445024, answer-31871515
Autoboxing is absolutely implemented using valueOf(args) ...in the OpenJDK. If that's your implementation, read on... if not, skip to below. #pre Java documentation states that Boolean.valueOf(args) always returns Boolean.TRUE or Boolean.FALSE , therefore your reference comparisons in these cases will succeed. ((Integer)1) == Integer.valueOf(args) For this particular example, under the OpenJDK implementation with default settings, it will probably work by virtue of the fact that you picked a value < 128 which is cached at startup (although this can be overridden as a commandline arg). It may also work for larger values if it's frequently used enough to be cached. Unless you're working under "safe" assumptions about the Integer cache, don't expect the reference comparison to be an equality. Long , Short , Character and Byte incidentally implement this caching too, but unlike Integer , it's not tunable. Byte will always work if you're comparing autobox/ valueOf(args) references since obviously, you can't go out of range. Float and Double will unsurprisingly always create a new instance. Now, in purely generic terms? See this section of the JLS - you MUST be given equal references for boolean and any int or char within the -128 to 127 range. There are no guarantees for anything else.

Question-32859038, answer-32863263
Don't feel like you have to do everything in/with the stream. I would just do: #pre As long as you don't parallelise the stream this will work and it avoids potentially expensive and/or problematic (in the case of duplicates) get(args) and indexOf(args) operations. (You cannot use a regular int variable in place of the AtomicInteger because variables used from outside a lambda expression must be effectively final. Note that when uncontested (as in this case), AtomicInteger is very fast and won't pose a performance problem. But if it worries you you can use a non-thread-safe counter.)

Question-32323081, answer-32323305
Any lambda which could be accepted as a Supplier<T> can also be accepted as a ThrowingSupplier<T> . The following compiles: #pre Given the above, you probably don't need this, but if foo must accept a non-throwing Supplier<T> , you can always wrap the Exception-throwing method in a method which launders it into an unchecked Exception: #pre

Question-31922866, answer-31923214
This seems a bit silly to me, but the only reason I can think of is that object arguments in method parameters already are optional in a way - they can be null. Therefore forcing someone to take an existing object and wrap it in an optional is sort of pointless. That being said, chaining methods together that take/return optionals is a reasonable thing to do, e.g. Maybe monad.

Question-7655127, answer-7655177
String text = String.copyValueOf(args); or String text = String.valueOf(args); is arguably better (encapsulates the new String call).

Question-6470651, answer-6780439
Here's a simple/sinister one via #a . #pre Because the substring refers to the internal representation of the original, much longer string, the original stays in memory. Thus, as long as you have a StringLeaker in play, you have the whole original string in memory, too, even though you might think you're just holding on to a single-character string. The way to avoid storing an unwanted reference to the original string is to do something like this: #pre For added badness, you might also .intern(args) the substring: #pre Doing so will keep both the original long string and the derived substring in memory even after the StringLeaker instance has been discarded.

Question-28459498, answer-28459604
Background While the question appears simple, the actual answer requires some background to make sense. If you want to skip to the conclusion, scroll down... Pick your comparison point - Basic functionality Using basic concepts, C#'s IEnumerable concept is more closely related to Java's Iterable , which is able to create as many Iterators as you want. IEnumerables create IEnumerators . Java's Iterable create Iterators The history of each concept is similar, in that both IEnumerable and Iterable have a basic motivation to allow 'for-each' style looping over the members of data collections. That's an oversimplification as they both allow more than just that, and they also arrived at that stage via different progressions, but it is a significant common feature regardless. Let's compare that feature: in both languages, if a class implements the IEnumerable / Iterable , then that class must implement at least a single method (for C#, it's GetEnumerator and for Java it's iterator(args) ). In each case, the instance returned from that ( IEnumerator / Iterator ) allows you to access the current and subsequent members of the data. This feature is used in the for-each language syntax. Pick your comparison point - Enhanced functionality IEnumerable in C# has been extended to allow a number of other language features ( mostly related to Linq ). Features added include selections, projections, aggregations, etc. These extensions have a strong motivation from use in set-theory, similar to SQL and Relational Database concepts. Java 8 has also had functionality added to enable a degree of functional programming using Streams and Lambdas. Note that Java 8 streams are not primarily motivated by set theory, but by functional programming. Regardless, there are a lot of parallels. So, this is the second point. The enhancements made to C# were implemented as an enhancement to the IEnumerable concept. In Java, though, the enhancements made were implemented by creating new base concepts of Lambdas and Streams, and then also creating a relatively trivial way to convert from Iterators and Iterables to Streams, and visa-versa. So, comparing IEnumerable to Java's Stream concept is incomplete. You need to compare it to the combined Streams and Collections API's in Java. In Java, Streams are not the same as Iterables, or Iterators Streams are not designed to solve problems the same way that iterators are: #li Iterators are a way of describing the sequence of data. #li Streams are a way of describing a sequence of data transformations. With an Iterator , you get a data value, process it, and then get another data value. With Streams, you chain a sequence of functions together, then you feed an input value to the stream, and get the output value from the combined sequence. Note, in Java terms, each function is encapsulated in a single Stream instance. The Streams API allows you to link a sequence of Stream instances in a way that chains a sequence of transformation expressions. In order to complete the Stream concept, you need a source of data to feed the stream, and a terminal function that consumes the stream. The way you feed values in to the stream may in fact be from an Iterable , but the Stream sequence itself is not an Iterable , it is a compound function. A Stream is also intended to be lazy, in the sense that it only does work when you request a value from it. Note these significant assumptions and features of Streams: #li A Stream in Java is a transformation engine, it transforms a data item in one state, to being in another state. #li streams have no concept of the data order or position, the simply transform whatever they are asked to. #li streams can be supplied with data from many sources, including other streams, Iterators, Iterables, Collections, #li you cannot "reset" a stream, that would be like "reprogramming the transformation". Resetting the data source is probably what you want. #li there is logically only 1 data item 'in flight' in the stream at any time (unless the stream is a parallel stream, at which point, there is 1 item per thread). This is independent of the data source which may have more than the current items 'ready' to be supplied to the stream, or the stream collector which may need to aggregate and reduce multiple values. #li Streams can be unbound (infinite), limited only by the data source, or collector (which can be infinite too). #li Streams are 'chainable', the output of filtering one stream, is another stream. Values input to and transformed by a stream can in turn be supplied to another stream which does a different transformation. The data, in its transformed state flows from one stream to the next. You do not need to intervene and pull the data from one stream and plug it in to the next. C# Comparison When you consider that a Java Stream is just a part of a supply, stream, and collect system, and that Streams and Iterators are often used together with Collections, then it is no wonder that it is hard to relate to the same concepts which are almost all embedded in to a single IEnumerable concept in C#. Parts of IEnumerable (and close related concepts) are apparent in all of the Java Iterator, Iterable, Lambda, and Stream concepts. There are small things that the Java concepts can do that are harder in IEnumerable, and visa-versa. Conclusion #li There's no design problem here, just a problem in matching concepts between the languages. #li Streams solve problems in a different way #li Streams add functionality to Java (they add a different way of doing things, they do not take functionality away) Adding Streams gives you more choices when solving problems, which is fair to classify as 'enhancing power', not 'reducing', 'taking away', or 'restricting' it. Why are Java Streams once-off? This question is misguided, because streams are function sequences, not data. Depending on the data source that feeds the stream, you can reset the data source, and feed the same, or different stream. Unlike C#'s IEnumerable, where an execution pipeline can be executed as many times as we want, in Java a stream can be 'iterated' only once. Comparing an IEnumerable to a Stream is misguided. The context you are using to say IEnumerable can be executed as many times as you want, is best compared to Java Iterables , which can be iterated as many times as you want. A Java Stream represents a subset of the IEnumerable concept, and not the subset that supplies data, and thus cannot be 'rerun'. Any call to a terminal operation closes the stream, rendering it unusable. This 'feature' takes away a lot of power. The first statement is true, in a sense. The 'takes away power' statement is not. You are still comparing Streams it IEnumerables. The terminal operation in the stream is like a 'break' clause in a for loop. You are always free to have another stream, if you want, and if you can re-supply the data you need. Again, if you consider the IEnumerable to be more like an Iterable , for this statement, Java does it just fine. I imagine the reason for this is not technical. What were the design considerations behind this strange restriction? The reason is technical, and for the simple reason that a Stream a subset of what think it is. The stream subset does not control the data supply, so you should reset the supply, not the stream. In that context, it is not so strange. QuickSort example Your quicksort example has the signature: IEnumerable<T> QuickSort(args) You are treating the input IEnumerable as a data source: IEnumerable<T> lt = ints.Where(args); Additionally, return value is IEnumerable too, which is a supply of data, and since this is a Sort operation, the order of that supply is significant. If you consider the Java Iterable class to be the appropriate match for this, specifically the List specialization of Iterable , since List is a supply of data which has a guaranteed order or iteration, then the equivalent Java code to your code would be: #pre Note there is a bug (which I have reproduced), in that the sort does not handle duplicate values gracefully, it is a 'unique value' sort. Also note how the Java code uses data source ( List ), and stream concepts at different point, and that in C# those two 'personalities' can be expressed in just IEnumerable . Also, although I have use List as the base type, I could have used the more general Collection , and with a small iterator-to-Stream conversion, I could have used the even more general Iterable

Question-13659217, answer-13659231
You can't see this method in javadoc because it's added by the compiler. Documented in three places : #li Enum Types , The Java Tutorials #blockquote #li Enum.valueOf class (The special implicit values method is mentioned in description of valueOf method) #blockquote #li Enum Types, Section 8.9 , Java Language Specification The values function simply list all values of the enumeration.

Question-29922296
I'm wondering what the best way is in Java 8 to work with all the values of an enum. Specifically when you need to get all the values and add it to somewhere, for example, supposing that we have the following enum: #pre I could of course do the following: #pre But, I could also add the following method to the enum definition: #pre And then replace the for from above with: Letter.stream(args).forEach(args); Is this approach OK or does it have some fault in design or performance? Moreover, why don't enums have a stream() method?

Question-22740464, answer-22741520
Unfortunately this answer is probably of little or no help whatsoever, but I did a forensics analysis of the Java Lambda Mailing list to see if I could find the cause of this design. This is what I found out. In the beginning there was an instance method for Stream.concat(Stream) In the mailing list I can clearly see the method was originally implemented as an instance method, as you can read in this thread by Paul Sandoz, about the concat operation. In it they discuss the issues that could arise from those cases in which the stream could be infinite and what concatenation would mean in those cases, but I do not think that was the reason for the modification. You see in this other thread that some early users of the JDK 8 questioned about the behavior of the concat instance method when used with null arguments. This other thread reveals, though, that the design of the concat method was under discussion. Refactored to Streams.concat(Stream,Stream) But without any explanation, suddenly, the methods were changed to static methods, as you can see in this thread about combining streams . This is perhaps the only mail thread that sheds a bit of light about this change, but it was not clear enough for me to determine the reason for the refactoring. But we can see they did a commit in which they suggested to move the concat method out of Stream and into the helper class Streams . Refactored to Stream.concat(Stream,Stream) Later, it was moved again from Streams to Stream , but yet again, no explanation for that. So, bottom line, the reason for the design is not entirely clear for me and I could not find a good explanation. I guess you could still ask the question in the mailing list. Some Alternatives for Stream Concatenation This other thread by Michael Hixson discusses/asks about other ways to combine/concat streams #blockquote

Question-20358883, answer-29784337
The other answers all use Arrays.asList(args) , which returns an unmodifiable list (an UnsupportedOperationException is thrown if you try to add or remove an element). To get a mutable list you can wrap the returned list in a new ArrayList as a couple of answers point out, but a cleaner solution is to use Guava's Lists.newArrayList() (available since at least Guava 10 , released in 2011). For example: Lists.newArrayList(args);

Question-19235606, answer-19235857
Spliterator basically means "splittable Iterator". Single thread can traverse/process the entire Spliterator itself, but the Spliterator also has a method trySplit(args) which will "split off" a section for someone else (typically, another thread) to process -- leaving the current spliterator with less work. Collector combines the specification of a reduce function (of map-reduce fame), with an initial value, and a value to combine two results (thus enabling results from Spliterated streams of work, to be combined.) For example, the most basic Collector would have an initial vaue of 0, add an integer onto an existing result, and would 'combine' two results by adding them. Thus summing a spliterated stream of integers. See: #li Spliterator.trySplit() #li Collector<T,A,R>

Question-4812570, answer-4812585
You have to use getStackTrace(args) method instead of printStackTrace(args) . Here is a good example : #pre

Question-32859038, answer-32918035
Eran's answer is usually the best approach for random-access lists. If your List isn't random access, or if you have a Stream instead of a List , you can use forEachOrdered : #pre This is safe, if the stream is parallel, even though the destination map is thread-unsafe and is operated upon as a side effect. The forEachOrdered guarantees that items are processed one-at-a-time, in order. For this reason it's unlikely that any speedup will result from running in parallel. (There might be some speedup if there are expensive operations in the pipeline before the forEachOrdered .)

Question-31471444, answer-31471520
org.apache.commons.lang.math.NumberUtils.INTEGER_ONE it gives you a final static Integer object rather than primitive int 1, and as it is final static it acts as a constant and can be used in comparison of Integer objects because will always return same instance. So in the above scenario it might not look fit but somewhere if you are using it while comparison, it for sure has impact. Moreover, as much as we can, should prefer the use of constants over hardcoded beacuse: #li It can make your code easily maintainable. If any situation occurs in future for change, you can change only at a single place. #li The code looks cleaner & more readable.

Question-6608795, answer-22327270
I tried reading from input1.txt which was inside one of my packages together with the class which was trying to read it. The following works: #pre The most important part was to call getPath(args) if you want the correct path name in String format. DO NOT USE toString(args) because it will add some extra formatting text which will TOTALLY MESS UP the fileName (you can try it and see the print out). Spent 2 hours debugging this... :(

Question-7520432, answer-36875991
Basically, == compares if two objects have the same reference on the heap, so unless two references are linked to the same object, this comparison will be false. equals(args) is a method inherited from Object class. This method by default compares if two objects have the same referece. It means: object1.equals(args) <=> object1 == object2 However, if you want to establish equality between two objects of the same class you should override this method. It is also very important to override the method hashCode(args) if you have overriden equals(args) . Implement hashCode(args) when establishing equality is part of the Java Object Contract. If you are working with collections, and you haven't implemented hashCode(args) , Strange Bad Things could happen: #pre null will be printed after executing the previous code if you haven't implemented hashCode(args) .

Question-4772425, answer-4772461
Use LocalDateTime#parse() (or ZonedDateTime#parse() if the string happens to contain a time zone part) to parse a String in a certain pattern into a LocalDateTime . #pre Use LocalDateTime#format() (or ZonedDateTime#format() ) to format a LocalDateTime into a String in a certain pattern. #pre Or , when you're not on Java 8 yet, use SimpleDateFormat#parse() to parse a String in a certain pattern into a Date . #pre Use SimpleDateFormat#format() to format a Date into a String in a certain pattern. #pre See also: #li Java string to date conversion Update : as per your failed attempt: the patterns are case sensitive . Read the java.text.SimpleDateFormat javadoc what the individual parts stands for. So stands for example M for months and m for minutes. Also, years exist of four digits yyyy , not five yyyyy . Look closer at the code snippets I posted here above.

Question-7032070
Assuming that arraylist is defined as ArrayList<T> arraylist , is arraylist.removeAll(arraylist) equivalent to arraylist.clear() ? If so, can I assume that the clear(args) method is more efficient for emptying the array list? Are there any caveats in using arraylist.removeAll(args) instead of arraylist.clear(args) ?

Question-26684562, answer-26684710
Both map and flatMap can be applied to a Stream<T> and they both return a Stream<T> . The difference is that the map operation produces one output value for each input value, whereas the flatMap operation produces an arbitrary number (zero or more) values for each input value. This is reflected in the arguments to each operation. The map operation takes a Function , which is called for each value in the input stream and produces one result value, which is sent to the output stream. The flatMap operation takes a function that conceptually wants to consume one value and produce an arbitrary number of values. However, in Java, it's cumbersome for a method to return an arbitrary number of values, since methods can return only zero or one value. One could imagine an API where the mapper function for flatMap takes a value and returns an array or a List of values, which are then sent to the output. Given that this is the streams library, a particularly apt way to represent an arbitrary number of return values is for the mapper function itself to return a stream! The values from the stream returned by the mapper are drained from the stream and are passed to the output stream. The "clumps" of values returned by each call to the mapper function are not distinguished at all in the output stream, thus the output is said to have been "flattened." Typical use is for the mapper function of flatMap to return Stream.empty(args) if it wants to send zero values, or something like Stream.of(args) if it wants to return several values. But of course any stream can be returned.

Question-25850328, answer-25850622
a. I have always seen them as a design pattern and nothing JVM-Special I have used that pattern in several situations. c. I beleive that using Annotations to mark something is a better solution then using marker interfaces. Simply because Interfaces are in the first place aimed to define common interfaces of Types / Classes. They are part of the class-hierachy. Annotations are aimed to provide Meta-Informations to Code, and I think that marker are meta-informations. So they are exactly for that use-case.

Question-8157755, answer-8157791
If you want the value you are assigning in the constructor, you need to add a method in the enum definition to return that value. If you want a unique number that represent the enum value, you can use ordinal(args) .

Question-31445024
I'm trying to determine whether the following statements are guaranteed to be true: #pre I've always assumed that autoboxing was equivalent to calling valueOf(args) on the corresponding type. Every discussion that I've seen on the topic seems to support my assumption. But all I could find in the JLS was the following ( 5.1.7 ): #blockquote That describes behavior identical to that of valueOf(args) . But there doesn't seem to be any guarantee that valueOf(args) is actually invoked, meaning there could theoretically be an implementation that keeps a separate, dedicated cache for autoboxed values. In such a case, there might not be identity equality between cached autoboxed values and regular cached boxed values. Oracle's autoboxing tutorial states matter-of-factly that li.add(args) is compiled to li.add(args) , where i is an int . But I don't know whether the tutorial should be considered an authoritative source.

Question-32356762, answer-32357142
When returning List , you'll be promoting program to an interface , which is a very good practice. However, this approach has its limitation. For example, you cannot use some methods that are defined for ArrayList and don't exist in the List interface - See this answer for details. I'm quoting the API Design from the The Java Tutorials: #blockquote Since ArrayList is essentially an array, they are my first choice when I need to have a "collection-array". So if I want to convert enumeration to a list, my choice would be an array list. In any other cases, it's still valid to write: List<T> list = Collections.list(args);

Question-19757300, answer-19759653
You can also propagate your static pain with lambdas, so the whole thing looks readable: s.filter(args) propagate here receives java.util.concurrent.Callable as a parameter and converts any exception caught during the call into RuntimeException . There is a similar conversion method Throwables#propagate(Throwable) in Guava. This method seems being essential for lambda method chaining, so I hope one day it will be added to one of the popular libs or this propagating behavior would be by default. #pre

Question-27888429, answer-27888481
Stream.of(args) Or, if you are already have an array, you can also do Stream.of(args) For primitive types use IntStream.of or LongStream.of etc.

Question-23079003, answer-23079174
You can use the overloaded version of toArray , as the following: #pre The purpose of the IntFunction<T> generator is to convert an integer, the size of the array, to a new array. Example code: #pre Prints: #pre Another option is to use a method reference to the string array constructor, this one is a bit more tricky. Usage is easy: String[] stringArray = streamString.toArray(args); What it does, is find a method that takes in an integer (the size) as argument, and returns a String[] , which is exactly what (one of the overloads of) new String[] does.

Question-29280857, answer-29282558
As you have mentioned there will be 1000-10000 concurrent transaction you expecting at a time than you can store accounts on which some transaction is going on and handle concurrency One Solution is to allow system to create only one object of particulate account id, means that if you want to make a transaction between account "123" and "456" than your thread will create account object and in that constructor of account class we will check if any other object of account is there with particulate account id, if other object of account is there with same account id means that some transaction is going on with particulate account id so you have to wait to get the account object. So we can do transaction between "123" and "456" and at same time we can do transaction between "abc" and "xyz" but if at same time some other thread will try to create object of account "123" than system will say please wait for reference you can see below code Please note : #li dont forgote to remove your account id from locks map by call to freeAccount(BigDecimal accId) from LockHolder class #li I have used HasMap instand of list because list will not be a good choice when you are randomly removing element from it(or when frequently you are updating it) #pre

Question-15336477
All I'm trying to do is download some JSON and deserialize it into an object. I haven't got as far as downloading the JSON yet. Almost every single HttpClient example I can find, including those on the apache site looks something like... #pre However, Netbeans tells me that DefaultHttpClient is deprecated. I've tried googling for DefaultHttpClient deprecated and as many other variations as I can think of and can't find any useful results, so I'm obviously missing something. What is the correct Java7 way to download the contents of a webpage? Is there really no decent Http Client as part of the language? I find that hard to believe. My Maven dependency for this is... #pre

Question-29229373
I have the following sample code: #pre The output is as follows: #pre From here I see that in first case stream really behaves lazily - we use findFirst(args) so once we have first element our filtering lambda is not invoked. However, in second case which uses flatMaps we see that despite first element which fulfils the filter condition is found (it's just any first element as lambda always returns true) further contents of the stream are still being fed through filtering function. I am trying to understand why it behaves like this rather than giving up after first element is calculated as in the first case. Any helpful information would be appreciated.

Question-32676771, answer-32677400
Despite of the fact that there is no AtomicDouble or AtomicDoubleArray in java, you can easily create your own based on AtomicLongArray . #pre As you can see, I use Double.doubleToLongBits and Double.longBitsToDouble to store Doubles as Longs in AtomicLongArray . They both have the same size in bits, so precision is not lost (except for -NaN, but I don't think it is important). In Java 8 the implementation of add can be even easier, as you can use accumulateAndGet method of AtomicLongArray that was added in java 1.8. Upd : It appears that I virtually re-implemented guava's AtomicDoubleArray .

Question-11821801, answer-11821900
A ReentrantLock is unstructured , unlike synchronized constructs -- i.e. you don't need to use a block structure for locking and can even hold a lock across methods. An example: #pre Such flow is impossible to represent via a single monitor in a synchronized construct. Aside from that, ReentrantLock supports lock polling and interruptible lock waits that support time-out . ReentrantLock also has support for configurable fairness policy , allowing more flexible thread scheduling. #blockquote ReentrantLock may also be more scalable , performing much better under higher contention. You can read more about this here . This claim has been contested, however; see the following comment: #blockquote When should you use ReentrantLock s? According to that developerWorks article... #blockquote

Question-32164385, answer-32164423
#blockquote The only way is to read the code unfortunately. #blockquote The common convention is to pass an object which cannot be modified, using a wrapper if needed. This ensure the class cannot modify the object. List<T> readOnly = Collections.unmodifiableList(args); If the object is Cloneable, you can also use clone(args) but another common approach is to use a copy. List<T> readOnly = new ArrayList<T>(args); If you care about such behaviour, unit tests can show whether a method modifies an object or not. If you have unit tests already, it is usually one or two lines extra to check for this.

Question-15940234
I'm relative new to the webservices world and my research seems to have confused me more than enlighten me, my problem is that I was given a library(jar) which I have to extend with some webservice functionality. This library will be shared to other developers, and among the classes in the jar will be classes that have a method which calls a webservice (that essentially sets an attribute of the class, does some business logic, like storing the object in a db, etc and sends back the object with those modifications). I want to make the call to this service as simple as possible, hopefully as simple so that the developer using the class only need to do. #pre I have been studying JAX-WS to use on the server but seems to me that I don't need to create a wsimport in the server nor the wsimport on the client, since I know that both have the classes, I just need some interaction between classes shared in both the server and the client. How do you think makes sense to do the webservice and the call in the class?

Question-7707556, answer-15870428
There is a subtle issue here that is a bit of a gotcha. The toString(args) method has a base implementation in Object . CharSequence is an interface; and although the toString(args) method appears as part of that interface, there is nothing at compile-time that will force you to override it and honor the additional constraints that the CharSequence toString(args) method's javadoc puts on the toString(args) method; ie that it should return a string containing the characters in the order returned by charAt(args) . Your IDE won't even help you out by reminding that you that you probably should override toString(args) . For example, in intellij, this is what you'll see if you create a new CharSequence implementation: #a . Note the absence of toString(args) . If you rely on toString(args) on an arbitrary CharSequence , it should work provided the CharSequence implementer did their job properly. But if you want to avoid any uncertainty altogether, you should use a StringBuilder and append(args) , like so: #pre

Question-23674624, answer-23674719
IntStream.boxed turns an IntStream into a Stream<T> , which you can then collect into a list: theIntStream.boxed(args).collect(args)

Question-18987692, answer-18987738
You can use IsNull.nullValue() method: #pre

Question-24914525, answer-24914586
std::list in C++ is a linked list, whereas java.util.ArrayList is an array. Try replacing std::list by std::vector . Also, be sure to compile with optimization turned on.

Question-13291076
If you look in the enum api at the method name(args) it says that: #blockquote Why is better to use toString(args) ? I mean toString may be overridden when name() is already final. So if you use toString and someone overrides it to return a hard-coded value your whole application is down... Also if you look in the sources the toString() method returns exactly and just the name. It's the same thing.

Question-16098046, answer-16098086
You could use printf(args) with %f : #pre This will print dexp: 12345678.000000 . If you don't want the fractional part, use System.out.printf(args); This uses the format specifier language explained in the documentation . The default toString(args) format used in your original code is spelled out here .

Question-27949213, answer-27950675
Since your first question has already been answered, I'll answer your second question. The String objects must be compared character by character, because though equal Object s implies equal hashes, the inverse is not necessarily true. As Holger said in his comment , this represents a hash collision. The applicable specifications for the hashcode(args) method are as follows: #blockquote This means that in order for them to guarantee equality, the comparison of each character is necessary in order for them to confirm the equality of the two objects. They start by comparing hashCode s rather than using equals since they are using a hash table for the references, and this improves performance.

Question-12544479
I am looking for the easiest and simplest way to bind and convert data in Spring MVC. If possible, without doing any xml configuration. So far I've been using PropertyEditors like so : #pre and #pre It is simple : both conversion are defined in the same class, and the binding is straightforward. If I wanted to do a general binding across all my controllers, I could still add 3 lines in my xml config . But Spring 3.x introduced a new way to do it, using Converters : #blockquote So let's say I want to use Converters because it is "the latest alternative". I would have to create two converters : #pre First drawback : I have to make two classes. Benefit : no need to cast thanks to genericity. Then, how do I simply data bind the converters ? Second drawback : I haven't found any simple way (annotations or other programmatic facilities) to do it in a controller : nothing like someSpringObject.registerCustomConverter(args); . The only ways I've found would be tedious, not simple, and only about general cross-controller binding : #li XML config : #pre #li Java config ( only in Spring 3.1+ ) : #pre With all these drawbacks, why using Converters ? Am I missing something ? Are there other tricks that I am not aware of ? I am tempted to go on using PropertyEditors... Binding is much easier and quicker.

Question-5071040, answer-5071064
There are multiple ways: #li String.valueOf(args) (my preference) #li StringLiteral + number (I don't know how the compiler handles it, perhaps it is as efficient as the above) #li Integer.toString(args)

Question-15202997, answer-15203417
If you're unsure about something, try writing a test first. I did this: #pre Prints: #pre There's an empty line in the last block where getSimpleName returns an empty string. The upshot looking at this is: #li the name is the name that you'd use to dynamically load the class with, for example, a call to Class.forName with the default ClassLoader . #li the canonical name is the name that would be used in an import statement and uniquely identifies the class. Might be useful during toString or logging operations. #li the simple name loosely identifies the class, again might be useful during toString or logging operations but is not guaranteed to be unique.

Question-21947452
I generated two matrices of 1000 x 1000 : First Matrix: O and # . Second Matrix: O and B . Using the following code, the first matrix took 8.52 seconds to complete: #pre With this code, the second matrix took 259.152 seconds to complete: #pre What is the reason behind the dramatically different run times? As suggested in the comments, printing only System.out.print(args); takes 7.8871 seconds, whereas System.out.print(args); gives still printing... . As others who pointed out that it works for them normally, I tried Ideone.com for instance, and both pieces of code execute at the same speed. Test Conditions: #li I ran this test from Netbeans 7.2, with the output into its console #li I used System.nanoTime(args) for measurements

Question-16098046, answer-25307973
In short: If you want to get rid of trailing zeros and Locale problems, then you should use : #pre Explanation: Why other answers did not suit me : #li Double.toString(args) or System.out.println or FloatingDecimal.toJavaFormatString uses scientific notations if double is less than 10^-3 or greater than or equal to 10^7 #li by using %f , the default decimal precision is 6, otherwise you can hardcode it but it results in extra zeros added if you have less decimals. Example : #pre #li by using setMaximumFractionDigits(args); or %.0f you remove any decimal precision, which is fine for integers/longs but not for double #pre #li by using DecimalFormat, you are local dependent. In French locale, the decimal separator is a comma, not a point : #pre Using the ENGLISH locale makes sure you get a point for decimal separator, wherever your program will run Why using 340 then for setMaximumFractionDigits ? Two reasons : #li setMaximumFractionDigits accepts an integer but its implementation has a maximum digits allowed of DecimalFormat.DOUBLE_FRACTION_DIGITS which equals 340 #li Double.MIN_VALUE = 4.9E-324 so with 340 digits you are sure not to round your double and loose precision

Question-32334319, answer-39380442
As stated across many of the answers. The Quicksort is used by Arrays.sort for sorting primitive collections because stability isn't required (you won't know or care if two identical ints were swapped in the sort) MergeSort or more specifically Timsort is used by Arrays.sort for sorting collections of objects. Stability is required. Quicksort does not provide for stability, Timsort does. Collections.sort delegates to Arrays.sort which is why you see the javadoc referencing the MergeSort.

Question-12576156, answer-12576308
Have you considered @Autowired ing the constructor or a setter and String.split(args) ing in the body? #pre I tend to prefer doing my autowiring in one of these ways to enhance the testability of my code.

Question-4818699, answer-4819109
If you look at the methods AtomicInteger has, you'll notice that they tend to correspond to common operations on ints. For instance: #pre is the thread-safe version of this: #pre The methods map like this: ++i is i.incrementAndGet(args) i++ is i.getAndIncrement(args) --i is i.decrementAndGet(args) i-- is i.getAndDecrement(args) i = x is i.set(args) x = i is x = i.get(args) There are other convenience methods as well, like compareAndSet or addAndGet

Question-16148575, answer-16149160
HashMap does not allow primitive data types as arguments. It can only accept objects so HashMap<T> myMap = new HashMap<T>(args); will not work. You have to change the declaration to HashMap<T> myMap = new HashMap<T>(args); so even when you do the following myMap.put(args); The primitive data type is autoboxed to an Integer object. 8(args) === boxing ===> 8(args) You can read more on autoboxing here #a

Question-13604703, answer-13604748
Lambdas are purely a call-site construct: the recipient of the lambda does not need to know that a Lambda is involved, instead it accepts an Interface with the appropriate method. In other words, you define or use a functional interface (i.e. an interface with a single method) that accepts and returns exactly what you want. For this Java 8 comes with a set of commonly-used interface types in java.util.function (thanks to Maurice Naftalin for the hint about the JavaDoc). For this specific use case there's java.util.function.IntBinaryOperator with a single int applyAsInt(int left, int right) method , so you could write your method like this: #pre But you can just as well define your own interface and use it like this: #pre Using your own interface has the advantage that you can have names that more clearly indicate the intent.

Question-29229373, answer-29230939
When looking into the implementation ( ReferencePipeline.java ) we see the method [ link ] #pre which will be invoke for findFirst operation. The special thing to take care about is the sink.cancellationRequested(args) which allows to end the loop on the first match. Compare to [ link ] #pre The method for advancing one item ends up calling forEach on the sub-stream without any possibility for earlier termination and the comment at the beginning of the flatMap method even tells about this absent feature. Since this is more than just an optimization thing as it implies that the code simply breaks when the sub-stream is infinite, I hope that the developers soon prove that they can do better than this To illustrate the implications, while Stream.iterate(args).findFirst(args) works as expected, Stream.of(args).flatMap(args).findFirst(args) will end up in an infinite loop. Regarding the specification, most of it can be found in the chapter Stream operations and pipelines of the package specification : #blockquote Its clear that a short-circuiting operation doesnt guaranty a finite time termination, e.g. when a filter doesnt match any item the processing cant complete, but an implementation which doesnt support any termination in finite time by simply ignoring the short-circuiting nature of an operation is far off the specification.

Question-15202997, answer-36978943
I've been confused by the wide range of different naming schemes as well, and was just about to ask and answer my own question on this when I found this question here. I think my findings fit it well enough, and complement what's already here. My focus is looking for documentation on the various terms, and adding some more related terms that might crop up in other places. Consider the following example: #pre #li The simple name of D is D . That's just the part you wrote when declaring the class. Anonymous classes have no simple name. Class.getSimpleName() returns this name or the empty string. It is possible for the simple name to contain a $ if you write it like this, since $ is a valid part of an identifier. #li According to the JLS section 6.7 , both a.b.C.D and a.b.C.D.D.D would be fully qualified names , but only a.b.C.D would be the canonical name of D . So every canonical name is a fully qualified name, but the converes is not always true. Class.getCanonicalName() will return the canonical name or null . #li Class.getName() is documented to return the binary name , as specified in JLS section 13.1 . In this case it returns a.b.C$D for D and [La.b.C$D; for D[] . #li This answer demonstrates that it is possible for two classes loaded by the same class loader to have the same canonical name but distinct binary names . Neither name is sufficient to reliably deduce the other: if you have the canonical name, you don't know which parts of the name are packages and which are containing classes. If you have the binary name, you don't know which $ were introduced as separators and which were part of some simple name. #li Anonymous classes and local classes have no fully qualified names but still have a binary name . The same holds for classes nested inside such classes. Every class has a binary name. #li Running javap -v -private on a/b/C.class shows that the bytecode refers to the type of d as La/b/C$D; and that of the array ds as [La/b/C$D; . These are called descriptors , and they are specified in JVMS section 4.3 . #li The class name a/b/C$D used in both of these descriptors is what you get by replacing . by / in the binary name. The JVM spec apparently calls this the internal form of the binary name . JVMS section 4.2.1 describes it, and states that the difference from the binary name were for historical reasons. #li The file name of a class in one of the typical filename-based class loaders is what you get if you interpret the / in the internal form of the binary name as a directory separator, and append the file name extension .class to it. It's resolved relative to the class path used by the class loader in question.

Question-20358883, answer-20358920
Fixed size List The easiest way, that I know of, is to create a fixed-size single element List with Arrays.asList(T...) like // Returns a List backed by a varargs T. return Arrays.asList(args); Variable size List If it needs vary in size you can construct an ArrayList and the fixed-size List like return new ArrayList<T>(args); and (in Java 7+) you can use the diamond operator <> to make it return new ArrayList<T>(args);

Question-22435833, answer-22497858
The answer from skiwi covered many of the major points already. I'll fill in a bit more background. The design of any API is a series of tradeoffs. In Java, one of the difficult issues is dealing with design decisions that were made long ago. Primitives have been in Java since 1.0. They make Java an "impure" object-oriented language, since the primitives are not objects. The addition of primitives was, I believe, a pragmatic decision to improve performance at the expense of object-oriented purity. This is a tradeoff we're still living with today, nearly 20 years later. The autoboxing feature added in Java 5 mostly eliminated the need to clutter source code with boxing and unboxing method calls, but the overhead is still there. In many cases it's not noticeable. However, if you were to perform boxing or unboxing within an inner loop, you'd see that it can impose significant CPU and garbage collection overhead. When designing the Streams API, it was clear that we had to support primitives. The boxing/unboxing overhead would kill any performance benefit from parallelism. We didn't want to support all of the primitives, though, since that would have added a huge amount of clutter to the API. (Can you really see a use for a ShortStream ?) "All" or "none" are comfortable places for a design to be, yet neither was acceptable. So we had to find a reasonable value of "some". We ended up with primitive specializations for int , long , and double . (Personally I would have left out int but that's just me.) For CharSequence.chars(args) we considered returning Stream<T> (an early prototype might have implemented this) but it was rejected because of boxing overhead. Considering that a String has char values as primitives, it would seem to be a mistake to impose boxing unconditionally when the caller would probably just do a bit of processing on the value and unbox it right back into a string. We also considered a CharStream primitive specialization, but its use would seem to be quite narrow compared to the amount of bulk it would add to the API. It didn't seem worthwhile to add it. The penalty this imposes on callers is that they have to know that the IntStream contains char values represented as ints and that casting must be done at the proper place. This is doubly confusing because there are overloaded API calls like PrintStream.print(args) and PrintStream.print(args) that differ markedly in their behavior. An additional point of confusion possibly arises because the codePoints(args) call also returns an IntStream but the values it contains are quite different. So, this boils down to choosing pragmatically among several alternatives: #li We could provide no primitive specializations, resulting in a simple, elegant, consistent API, but which imposes a high performance and GC overhead; #li we could provide a complete set of primitive specializations, at the cost of cluttering up the API and imposing a maintenance burden on JDK developers; or #li we could provide a subset of primitive specializations, giving a moderately sized, high performing API that imposes a relatively small burden on callers in a fairly narrow range of use cases (char processing). We chose the last one.

Question-8894258
In Java, what would the fastest way to iterate over all the chars in a String, this: #pre Or this: #pre EDIT : What I'd like to know is if the cost of repeatedly calling the charAt method during a long iteration ends up being either less than or greater than the cost of performing a single call to toCharArray at the beginning and then directly accessing the array during the iteration. It'd be great if someone could provide a robust benchmark for different string lengths, having in mind JIT warm-up time, JVM start-up time, etc. and not just the difference between two calls to System.currentTimeMillis(args) .

Question-31370403, answer-31466466
Idea #1, storing the Graphics objects simply wouldn't work. The Graphics should not be considered as "holding" some display memory, but rather as a handle to access an area of display memory. In the case of BufferedImage , each Graphics object will be always the handle to the same given image memory buffer, so they all will represent the same image. Even more importantly, you can't actually do anything with the stored Graphics : As they do not store anything, there is no way whatsoever they could "re-store" anything. Idea #2, cloning the BufferedImage s is a much better idea, but you'll indeed be wasting memory, and quickly run out of it. It helps only to store those parts of the image affected by the draw, for example using rectangular areas, but it still costs a lot of memory. Buffering those undo images to disk could help, but it will make your UI slow and unresponsive, and that's bad ; furthermore, it makes you application more complex and error-prone . My alternative would be to store store the image modifications in a list, rendered from first to last on top of the image. An undo operation then simply consists of removing the modification from the list. This requires you to "reify" the image modifications , i.e. create a class that implements a single modification, by providing a void draw(args) method which performs the actual drawing. As you said, random modifications pose an additional problem. However, the key problem is your use of Math.random(args) to create random numbers. Instead, perform each random modification with a Random created from a fixed seed value, so that the (pseudo-)random number sequences are the same on each invocation of draw(args) , i.e., each draw has exactly the same effects. (That's why they are called "pseudo-random" -- the generated numbers look random, but they are just as deterministic as any other function.) In contrast to the image storing technique, which has memory problems, the problem with this technique is that many modifications may make the GUI slow, especially if the modifications are computationally intensive. To prevent this, the simplest way would be to fix an appropriate maximum size of the list of undoable modifications . If this limit would be exceeded by adding a new modification, remove the oldest modification the list and apply it to the backing BufferedImage itself. The following simple demo application shows that (and how) this all works together. It also includes a nice "redo" feature for redoing undone actions. #pre

Question-28770822
I understand the use of the @Native annotation. #blockquote However, while reading the java source code I noticed that in the class Integer and Long the SIZE constant is @Native while it is not for the Float, Byte, Double, Short and Character. Note that the SIZE constant represents the number of bits used to represent the actual value. #pre Edit : I just noticed that this also applies for MAX_VALUE and MIN_VALUE of the same classes. Edit 2 : I had spare time to do some research on this, and looking at the header files of the Long, Float etc. classes I had hope to figure out that the constants were not present in the other headers, but unfortunately they are. #pre Why is the SIZE constant only @Native for Integer and Long ?

Question-10786042, answer-10786112
URLEncoder should be the way to go. You only need to keep in mind to encode only the individual query string parameter name and/or value, not the entire URL, for sure not the query string parameter separator character & nor the parameter name-value separator character = . #pre Note that spaces in query parameters are represented by + , not %20 , which is legitimately valid. The %20 is usually to be used to represent spaces in URI itself (the part before the URI-query string separator character ? ), not in query string (the part after ? ). Also note that there are two encode(args) methods. One without charset argument and another with. The one without charset argument is deprecated. Never use it and always specify the charset argument. The javadoc even explicitly recommends to use the UTF-8 encoding, as mandated by RFC3986 and W3C . #blockquote See also: #li What every web developer must know about URL encoding

Question-31993377, answer-31993534
You have a single extra newline at the end of your file. #li hasNextLine() checks to see if there is another linePattern in the buffer. #li hasNext() checks to see if there is a parseable token in the buffer, as separated by the scanner's delimiter. Since the scanner's delimiter is whitespace, and the linePattern is also white space, it is possible for there to be a linePattern in the buffer but no parseable tokens. Typically, the most common way to deal with this issue by always calling nextLine(args) after parsing all the tokens (e.g. numbers) in each line of your text. You need to do this when using Scanner when reading a user's input too from System.in . To advance the scanner past this whitespace delimiter, you must use scanner.nextLine(args) to clear the line delimiter. See: Using scanner.nextLine() Appendix: LinePattern is defined to be a Pattern that matches this: #pre The default token delimiter is this Pattern : private static Pattern WHITESPACE_PATTERN = Pattern.compile(args);

Question-30384955, answer-30385298
Replacing the definition of TbinList with class TbinList<T> extends ArrayList<T> {} and defining test2 with TbinList<T> test2 = new TbinList<T>(args); instead would solve the issue. With your definition you're ending up with an ArrayList<T> where T is any fixed class extending Base .

Question-5031614, answer-26826084
#li If you have a business key , then you should use that for equals / hashCode . #li If you don't have a business key, you should not leave it with the default Object equals and hashCode implementations because that does not work after you merge and entity. #li You can use the entity identifier as suggested in this post . The only catch is that you need to use a hashCode implementation that always return the same value, like this: #pre

Question-15182496, answer-15182578
The other answers explain why, but here is how: new Random(args).nextInt(args) The first 6 numbers that the above random generates are: #pre and the first 6 numbers that new Random(args).nextInt(args) generates are: #pre Then just add those numbers to the integer representation of the character ` (which is 96): #pre

Question-12552863
The Java 7 try-with-resources syntax (also known as ARM block ( Automatic Resource Management )) is nice, short and straightforward when using only one AutoCloseable resource. However, I am not sure what is the correct idiom when I need to declare multiple resources that are dependent on each other, for example a FileWriter and a BufferedWriter that wraps it. Of course, this question concerns any case when some AutoCloseable resources are wrapped, not only these two specific classes. I came up with the three following alternatives: 1) The naive idiom I have seen is to declare only the top-level wrapper in the ARM-managed variable: #pre This is nice and short, but it is broken. Because the underlying FileWriter is not declared in a variable, it will never be closed directly in the generated finally block. It will be closed only through the close method of the wrapping BufferedWriter . The problem is, that if an exception is thrown from the bw 's constructor, it's close will not be called and therefore the underlying FileWriter will not be closed . 2) #pre Here, both the underlying and the wrapping resource are declared in the ARM-managed variables, so both of them will be certainly closed, so certainly that the underlying fw.close(args) will be called twice , first directly and for the second time through the wrapping bw.close(args) . This should not be a problem for these two specific classes that both implement Closeable (which is a subtype of AutoCloseable ), whose contract states that multiple calls to close are permitted: #blockquote However, in a general case, I can have resources that do implement only AutoCloseable (and not Closeable ), which doesn't guarantee that the close can be called multiple times: #blockquote 3) #pre This version should be theoretically correct, because only the fw represents a real resource that needs to be cleaned up. The bw does't itself hold any resource, it only delegates to the fw , so it should be sufficient to only close the underlying fw . On the other hand, the syntax is a bit irregular and also, Eclipse issues a warning, which I believe is a false alarm, but it is still a warning that one has to deal with: #blockquote So, which approach to go for? Or have I missed some other idiom that is the correct one?

Question-19431234, answer-30133063
Much more convenient way if you are sure you need a default timezone : Date d = java.sql.Timestamp.valueOf(args);

Question-20375176, answer-20375622
A parallel stream has a much higher overhead compared to a sequential one. Coordinating the threads takes a significant amount of time. I would use sequential streams by default and only consider parallel ones if #li I have a massive amount of items to process (or the processing of each item takes time and is parallelizable) #li I have a performance problem in the first place #li I don't already run the process in a multi-thread environment (for example: in a web container, if I already have many requests to process in parallel, adding an additional layer of parallelism inside each request could have more negative than positive effects) In your example, the performance will anyway be driven by the synchronized access to System.out.println(args) , and making this process parallel will have no effect, or even a negative one. Moreover, remember that parallel streams don't magically solve all the synchronization problems. If a shared resource is used by the predicates and functions used in the process, you'll have to make sure that everything is thread-safe. In particular, side effects are tings you really have to worry about if you go parallel. In any case, measure, don't guess! Only a measurement will tell you if the parallelism is worth it or not.

Question-10066590
With Mockito, I want to verify(args) a method call with byte[] in its argument list, but I didn't find how to write this. myMethod(args) I just want something like anyByteArray(args) , how to do that with Mockito ?

Question-17489250, answer-17489410
Java String is Special #blockquote For example #pre #img Note : String literals are stored in a common pool. This facilitates sharing of storage for strings with the same contents to conserve storage. String objects allocated via new operator are stored in the heap , and there is no sharing of storage for the same contents.

Question-32323081
I have a question regarding Java 8 inference with respect to lambdas and their related exception signatures. If I define some method foo: #pre then I get the nice and concise semantic of being able to write foo(args); in most cases for a given T . However, in this example, if my getTheT operation declares that it throws Exception , my foo method which takes a Supplier no longer compiles: the Supplier method signature for get doesn't throw exceptions. It seems like a decent way to get around this would be to overload foo to accept either option, with the overloaded definition being: #pre where ThrowingSupplier is defined as #pre In this way, we have one Supplier type which throws exceptions and one which doesn't. The desired syntax would be something like this: #pre However, this causes issues due to the lambda type being ambiguous (presumably unable to resolve between Supplier and ThrowingSupplier). Doing an explicit cast a la foo(args); would work, but it gets rid of most of the conciseness of the desired syntax. I guess the underlying question is: if the Java compiler is able to resolve the fact that one of my lambdas is incompatible due to it throwing an exception in the Supplier-only case, why isn't it able to use that same information to derive the type of the lambda in the secondary, type-inference case? Any information or resources which anyone could point me to would likewise be much appreciated, as I'm just not too sure where to look for more information on the matter. Thanks!

Question-23699371, answer-23733628
The easiest way to implement this is to jump on the sort feature as it already provides an optional Comparator which can be created using an elements property. Then you have to filter duplicates out which can be done using a statefull Predicate which uses the fact that for a sorted stream all equal elements are adjacent: #pre Of course, a statefull Predicate is not thread-safe, however if thats your need you can move this logic into a Collector and let the stream take care of the thread-safety when using your Collector . This depends on what you want to do with the stream of distinct elements which you didnt tell us in your question.

Question-32859038, answer-32859065
You can create a Stream of the indices using an IntStream and then convert them to a Map : Map<T> map = IntStream.range(args) .boxed(args) .collect(args);

Question-32693704, answer-32852619
Because it's much faster! I ran some thorough benchmarking tests on cut down versions of the two methods: #pre operating on arrays of various sizes containing random values. Here are the (typical) results: #pre And here are the results when operating over an array filled with nulls (so garbage collection issues are eradicated): #pre The numbers are in nanoseconds, (sd) is 1 standard deviation expressed as a percentage of the result (fyi, a "normally distributed" population has an SD of 68), vs is the JDK 8 timing relative to JDK 7. It is interesting that not only is it significantly faster, but the deviation is also slightly narrower, which means that the JDK 8 implementation gives slightly more consistent performance. The tests were run on jdk 1.8.0_45 over a large (millions) number of times on arrays populated with random Integer objects. To remove out-lying numbers, on each set of results the fastest and slowest 3% of timings were discarded. Garbage collection was requested and the thread yielded and slept just prior to running each invocation of the method. JVM warm up was done on the first 20% of work and those results were discarded.

Question-7488643, answer-7488669
Two steps: #li String [] items = commaSeparated.split(args); #li List<T> container = Arrays.asList(args);

Question-34509566, answer-34509659
Four things are going on: #li (You clearly know this, but for lurkers) == tests to see if the variables point to the same String object , not equivalent strings. So even if x is StringLiteral and y is also StringLiteral , x == y may be true or false, depending on whether x and y refer to the same String object or different ones. That's why we use equals , not == , to compare strings for equivalence. All of the following is just meant to explain why == is sometimes true, it's not a suggestion to use == to compare strings. :-) #li Equivalent string constants (strings the compiler knows are constants according to various rules in the JLS) within the same class are made to refer to the same string by the compiler (which also lists them in the class's "constant pool" ). That's why a == b is true. #li When the class is loaded, each of its string constants is automatically interned  the JVM's string pool is checked for an equivalent string and if one is found, that String object is used (if not, the new String object for the new constant is added to the pool). So even if x is a string constant initialized in class Foo and y is a string constant initialized in class Bar , they'll be == each other. Points 2 and 3 above are covered in part by JLS3.10.5 . (The bit about the class constant pool is a bit of an implementation detail, hence the link to the JVM spec earlier; the JLS just speaks of interning.) #li The compiler does string concatenation if it's dealing with constant values, so String d = StringLiteral + StringLiteral; is compiled to String d = StringLiteral; and StringLiteral is a string constant the compiler and JVM apply points 2 and 3 above to. E.g., no StringBuilder is used, the concatenation happens at compile-time , not runtime. This is covered in JLS15.28 - Constant Expressions . So a == d is true for the same reason a == b is true: They refer to the same constant string, so the compiler ensured they were referring to the same string in the class's constant pool. The compiler can't do that when any of the operands is not a constant, so it can't do that with: String e = c + StringLiteral; ...even though code analysis could easily show that the value of c will definitely be StringLiteral and thus e will definitely be StringLiteral . The specification only has the compiler do the concatenation with constant values, specifically. So since the compiler can't do it, it outputs the StringBuilder code you referred to and that work is done at runtime, creating a new String object. That string isn't automatically interned, so e ends up referring to a different String object than a does, and so a == e is false. Note that as Vinod said , if you declared c as final : final String c = StringLiteral; Then it would be a constant variable (yes, they're really called that) and so 15.28 would apply and the compiler would turn String e = c + StringLiteral; into String e = StringLiteral; and a == e would also be true. Just to reiterate: None of which means we should use == to compare strings for equivalence. :-) That's what equals is for.

Question-5439529, answer-5439543
You can use Integer.parseInt(args) or Integer.valueOf(args) to get the integer from the string, and catch the exception if it is not a parsable int. You want to be sure to catch the NumberFormatException it can throw. It may be helpful to note that valueOf() will return an Integer object, not the primitive int.

Question-14491966, answer-14563808
It is very unlikely that random number generation performance would be an issue for any use-case you came up with unless accessing a single Random instance from multiple threads (because Random is synchronized ). However, if that really is the case and you need lots of random numbers fast, your solution is far too unreliable. Sometimes it gives good results, sometimes it gives horrible results (based on the initial settings). If you want the same numbers that the Random class gives you, only faster, you could get rid of the synchronization in there: #pre I simply took the java.util.Random code and removed the synchronization which results in twice the performance compared to the original on my Oracle HotSpot JVM 7u9. It is still slower than your QuickRandom , but it gives much more consistent results. To be precise, for the same seed values and single threaded applications, it gives the same pseudo-random numbers as the original Random class would. This code is based on the current java.util.Random in OpenJDK 7u which is licensed under GNU GPL v2 . EDIT 10 months later: I just discovered that you don't even have to use my code above to get an unsynchronized Random instance. There's one in the JDK, too! Look at Java 7's ThreadLocalRandom class. The code inside it is almost identical to my code above. The class is simply a local-thread-isolated Random version suitable for generating random numbers quickly. The only downside I can think of is that you can't set its seed manually. Example usage: Random random = ThreadLocalRandom.current(args);

Question-13291076, answer-31886637
name() is literally the textual name in the java code of the enum. That means it is limited to strings that can actually appear in your java code, but not all desirable strings are expressible in code. For example, you may need a string that begins with a number. name() will never be able to obtain that string for you.

Question-5175728, answer-5175771
Have a look at the Date class. There's also the newer Calendar class which is the preferred method of doing many date / time operations (a lot of the methods on Date have been deprecated.) If you just want the current date, then either create a new Date object or call Calendar.getInstance(args); .

Question-5031614, answer-5032837
If you want to use equals(args)/hashCode(args) for your Sets, in the sense that the same entity can only be in there once, then there is only one option: Option 2. That's because a primary key for an entity by definition never changes (if somebody indeed updates it, it's not the same entity anymore) You should take that literally: Since your equals(args)/hashCode(args) are based on the primary key, you must not use these methods, until the primary key is set. So you shouldn't put entities in the set, until they're assigned a primary key. (Yes, UUIDs and similar concepts may help to assign primary keys early.) Now, it's theoretically also possible to achieve that with Option 3, even though so-called "business-keys" have the nasty drawback that they can change: "All you'll have to do is delete the already inserted entities from the set(s), and re-insert them." That is true - but it also means, that in a distributed system, you'll have to make sure, that this is done absolutely everywhere the data has been inserted to (and you'll have to make sure, that the update is performed, before other things occur). You'll need a sophisticated update mechanism, especially if some remote systems aren't currently reachable... Option 1 can only be used, if all the objects in your sets are from the same Hibernate session. The Hibernate documentation makes this very clear in chapter 13.1.3. Considering object identity : #blockquote It continues to argue in favor of Option 3: #blockquote This is true, if you #li cannot assign the id early (e.g. by using UUIDs) #li and yet you absolutely want to put your objects in sets while they're in transient state. Otherwise, you're free to choose Option 2. Then it mentions the need for a relative stability: #blockquote This is correct. The practical problem I see with this is: If you can't guarantee absolute stability, how will you be able to guarantee stability "as long as the objects are in the same Set". I can imagine some special cases (like using sets only for a conversation and then throwing it away), but I would question the general practicability of this. Short version: #li Option 1 can only be used with objects within a single session. #li If you can, use Option 2. (Assign PK as early as possible, because you can't use the objects in sets until the PK is assigned.) #li If you can guarantee relative stability, you can use Option 3. But be careful with this.

Question-10977992, answer-17939167
There are two differences: #li We can use Iterator to traverse Set and List and also Map type of Objects. While a ListIterator can be used to traverse for List-type Objects, but not for Set-type of Objects. That is, we can get a Iterator object by using Set and List, see here: By using Iterator we can retrieve the elements from Collection Object in forward direction only. Methods in Iterator: #li hasNext(args) #li next(args) #li remove(args) #pre #li But we get ListIterator object only from the List interface, see here: where as a ListIterator allows you to traverse in either directions (Both forward and backward). So it has two more methods like hasPrevious(args) and previous(args) other than those of Iterator. Also, we can get indexes of the next or previous elements (using nextIndex(args) and previousIndex(args) respectively ) Methods in ListIterator: #li hasNext() #li next() #li previous() #li hasPrevious() #li remove() #li nextIndex() #li previousIndex() ListIterator listiterator = List.listIterator(args); i.e., we can't get ListIterator object from Set interface.

Question-29262002, answer-29262126
The JLS specify that #blockquote Now let's see that in detail, Since your takeBiConsumer method is of void type, the lambda receiving new String(args) will interpret it as a block like #pre which is valid in a void, hence the first case compile. However, in the case where the lambda is -> StringLiteral , a block such as #pre is not valid syntax in java. Therefore the only thing to do with "hi" is to try and return it. #pre which is not valid in a void and explain the error message #pre For a better understanding, note that if you change the type of takeBiConsumer to a String, -> StringLiteral will be valid as it will simply try to directly return the string. Note that at first I tought the error was caused by the lambda being in a wrong invocation context, so I'll share this possibility with the community : JLS 15.27 #blockquote However in our case, we are in an invocation context which is correct.

Question-17489250, answer-17489334
Text inside double quotes creates a literal String object. String myString = StringLiteral; The code above creates a String object, using double quotes.

Question-29333689, answer-29341981
The best answer is already given (XOR-ing the elements), this is to provide an alternative, more general way. If the input array would be sorted (we can make it sorted), we could simply iterate over the elements in pairs (stepping by 2) and if the elements of the "pair" are different, we're done: #pre Note: This solution sorts the input array; if this is unwanted or not allowed, it can be cloned first: arr = arr.clone(args); If input array is sorted, the Arrays.sort(args) call can be left out of course. Generalization The advantage of this solution is that it can be applied to all types which are comparable and therefore can be sorted (types which implement Comparable ), for example String or Date . The XOR solution is limited to numbers only. Here is a slightly modified version which takes an input array of any element type which is comparable: #pre Note: In most cases you could also use arr[i].equals(args) to compare elements instead of using Comparable.compareTo() . For details read the linked javadoc. Quoting the relevant part: #blockquote Now you can call this with a String[] for example: System.out.println(args); Output: 2 Final notes: Starting from the problem statement it is not checked whether there are more than 2 occurrences of the elements, and neither is whether the array length is odd. Also the second example doesn't check for null values, these are to be added if necessary.
Question-32334319
I am using JDK-8 (x64). For Arrays.sort I found the following in the Java documentation: #blockquote For Collections.sort I found this: #blockquote If Collections.sort uses an array, why doesn't it just call Arrays.sort or use dual-pivot QuickSort ? Why use Mergesort ?

Question-14833008, answer-14833048
You need to escape the dot if you want to split on a literal dot: String extensionRemoved = filename.split(args)[0]; Otherwise you are splitting on the regex . , which means "any character". Note the double backslash needed to create a single backslash in the regex. You're getting an ArrayIndexOutOfBoundsException because your input string is just a dot, ie StringLiteral , which is an edge case that produces an empty array when split on dot; split(regex) removes all trailing blanks from the result, but since splitting a dot on a dot leaves only two blanks, after trailing blanks are removed you're left with an empty array. To avoid getting an ArrayIndexOutOfBoundsException for this edge case, use the overloaded version of split(regex, limit) , which has a second parameter that is the size limit for the resulting array. When limit is negative , the behaviour of removing trailing blanks from the resulting array is disabled: StringLiteral.split(args) // returns an array of two blanks, ie [StringLiteral, StringLiteral] ie, when filename is just a dot StringLiteral , calling filename.split(args)[0] will return a blank, but calling filename.split(args)[0] will throw an ArrayIndexOutOfBoundsException .

Question-28770822, answer-28853754
TLDR : Jump to the conclusion #blockquote A brief history of @Native I made some search on the mailing lists. I found some interesting things. At first an annotation ( 1 2 ) javax.tools.annotation.ForceNativeHeader was introduced to #blockquote It is used by com.sun.tools.javac.processing.NativeapiVisitor . By looking at the code we can see that the native header is generated if the class declare some native methods or if the class is annotated @ForceNativeHeader . Later this annotation was renamed to GenerateNativeHeader ( 1 2 ). Then this annotation was added to several types (especially Integer and Long ) with an interresting comment: #pre But by adding this annotation it add a problematic dependency from base module to the module containing javax.tools. So the annotation were removed from Integer and Long and these files were explicitly added to the build process since the header were no more automatically generated... a "(hopefully temporary) hack" . So a new annotation java.lang.annotation.Native was created and used in Integer and Long . The annotation was set a TargetType FIELD . #blockquote All the purpose of this stuff is: #blockquote It is the case of Integer and Long this was a part of the JEP 139: Enhance javac to Improve Build Speed : #blockquote A basic experimentation I made a basic experimentation on the JDK. I clone the open-jdk forest and i successfully build it. As expected the header files where generated for Integer and Long (thanks to @Native ) and for Float and Double (thanks to their native methods) but not for Byte , Short ... #pre Then i tried to remove the @Native from the Integer fields and i tried to build again the jdk but i get an error: #pre logically since the header have not been generated. I have also confirmed that java_lang_Integer.h is included in several c and cpp files : #pre like Long #pre like Float #pre and like Double #pre but neither Short find . \( -name StringLiteral -o -name StringLiteral \) -exec grep StringLiteral {} \; -print nor Byte , nor Character . Conclusion Among all these types, only Integer , Long , Float , Double are used in the native source code of the jdk . And only the Integer and Long fields are annotated with @Native because they have no native methods (as opposed to Float and Double )

Question-5694385, answer-5694473
Create a File object, passing the directory path to the constructor. Use the listFiles(args) to retrieve an array of File objects for each file in the directory, and then call the getName(args) method to get the filename. #pre

Question-20358883, answer-20358917
Very simply: Arrays.asList(args)

Question-6667243, answer-6667354
Enum is just a little bit special class. Enums can store additional fields, implement methods etc. For example #pre Now you can say: System.out.println(args) and see output: a

Question-29328785
#pre Compile >javac BigDecimalTest.java Execute >java BigDecimalTest Output #pre The value of z.toString(args) in the output is correct 4.883242e+888 / 7.115109e+302 = 6.863200e+585 as is the value of y.toString(args) , but notice that the value given for x.toString(args) is completely wrong. Why is this? Strangely, if the scale (i.e. desired decimal places) of the result of the division is changed BigDecimal z = x.divide(args); then x.toString(args) will produce the correct value for x . Or, if the operands are swapped BigDecimal z = y.divide(args); then x.toString(args) will also then produce the correct value. Or, if the exponent of x is changed from e+888 to e.g. e+878 then x.toString(args) will be correct. Or, if another x.toString(args) call is added above the divide operation, then both x.toString(args) calls will produce the correct value! On the machine I'm testing this, Windows 7 64 bit, the behaviour is the same using java 7 and 8, both 32bit and 64 bit versions, but testing online at #a produces different results for java 7 and java 8. Using java 7, the value of x is given correctly: #a , but using java 8 its value is incorrect: #a . Also, this behaviour is not unique to this particular value of x , as calling toString on other BigDecimals with more than about 1500 digits after passing them as the first operand to a divide operation will also produce incorrect values. What is the explanation for this? The divide operation seems to be mutating the value produced by subsequent toString calls on its operands. Does this happen on your platform? Edit: The issue seems to be with the java 8 runtime only, as the above program compiled with java 7 produces correct output when executed with the java 7 runtime, but incorrect output when executed with the java 8 runtime. Edit: I've tested with the early access jre1.8.0_60 and the bug does not appear, and according to Marco13's answer it was fixed in build 51. The Oracle JDK 8 product binaries are only at update 40 though so it may be some time before the fixed versions are widely used.

Question-23308193, answer-32566745
This is possible for forEach(args) . The solution is not nice, but it is possible. WARNING : You should not use it for controlling business logic, but purely for handling an exceptional situation which occurs during the execution of the forEach(args) . Such as a resource suddenly stops being accessible, one of the processed objects is violating a contract (e.g. contract says that all the elements in the stream must not be null but suddenly and unexpectedly one of them is null ) etc. According to the documentation for Iterable.forEach() : #blockquote So you throw an exception which will immediately break the internal loop. The code will be something like this - I cannot say I like it but it works. You create your own class BreakException which extends RuntimeException . #pre Notice that the try...catch is not around the lambda expression, but rather around the whole forEach(args) method. To make it more visible, see the following transcription of the code which shows it more clearly: #pre

Question-6094575, answer-6094602
Yes, something like: #pre That will only work for a single string parameter of course, but you can modify it pretty easily. Note that the class name has to be a fully-qualified one, i.e. including the namespace. For nested classes, you need to use a dollar (as that's what the compiler uses). For example: #pre To obtain the Class object for that, you'd need Class.forName(args) .

Question-16324831
Why do Double.parseDouble(null) and Integer.parseInt(null) throw different exceptions? Is this a historical accident or intentional? The documentation clearly states two types of exceptions for Double.parseDouble(...) and one for Integer.parseInt() , but it seems inconsistent: Integer.parseInt(args); // throws java.lang.NumberFormatException: null However Double.parseDouble(args); // throws java.lang.NullPointerException

Question-28584669, answer-28588854
The correct answer is a simple "because the standard (and the docs ) say so". But I'm not gonna be cynical because it's obvious that's not what you are after. In addition to the other answers here, I'll try to relate the infinities to saturating arithmetic. Other answers have already stated that the reason the comparisons on NaNs result in true , so I'm not gonna beat a dead horse. Let's say I have a saturating integer that represents grayscale colors. Why am I using saturating arithmetic? Because anything brighter than white is still white, and anything darker than black is still black (except orange ). That means BLACK - x == BLACK and WHITE + x == WHITE . Makes sense? Now, let's say we want to represent those grayscale colors with a (signed) 1s complement 8-bit integer where BLACK == -127 and WHITE == 127 . Why 1s complement? Because it gives us a signed zero like IEEE 754 floating point . And, because we are using saturating arithmetic, -127 - x == -127 and 127 + x == 127 . How does this relate to floating point infinities? Replace the integer with floating point, BLACK with NEGATIVE_INFINITY , and WHITE with POSITIVE_INFINITY and what do you get? NEGATIVE_INFINITY - x == NEGATIVE_INFINITY and POSITIVE_INFINITY + x == POSITIVE_INFINITY . Since you used POSITIVE_INFINITY , I'll use it also. First we need a class to represent our saturating integer-based color; let's call it SaturatedColor and assume it works like any other integer in Java. Now, let's take your code and replace double with our own SaturatedColor and Double.POSITIVE_INFINITY with SaturatedColor.WHITE : #pre As we established above, SaturatedColor.WHITE (just WHITE above) is 127 , so let's do that here: #pre Now we take the System.out.println statements you used and replace a and b with their value (values?): #pre It should be obvious what this will print.

Question-18571223, answer-18571358
Try using String.getBytes(). It returns a byte[] representing string data. Example: #pre

Question-18448671, answer-18448685
If you want to modify your List during traversal, then you need to use the Iterator . And then you can use iterator.remove(args) to remove the elements during traversal.

Question-8172420, answer-8172444
Try this: Character.toString(args) or just this: aChar + StringLiteral

Question-20358883, answer-20358928
You can use the utility method Arrays.asList and feed that result into a new ArrayList . ArrayList<T> list = new ArrayList<T>(args); Other options: ArrayList<T> list = new ArrayList<T>(args); and ArrayList<T> list = new ArrayList<T>(args); #li ArrayList(Collection) constructor. #li Arrays.asList method. #li Collections.nCopies method. #li Collections.singletonList method.

Question-6652687
#blockquote Is there a convenience method to strip any leading or trailing spaces from a Java String? Something like: #pre Result: no spaces:keep this myString.replace(args) would replace the space between keep and this. Thanks

Question-32294367, answer-32378895
#blockquote Yes and No. I explain: #li Referring to shared memory: Different threads in a Java process share the whole heap, therefore threads can interact in a huge number of planned and unplanned ways. However objects in the stack (e.g. a context you pass down to called method) or a ThreadLocal are their own thread's (unless they start sharing references). #li Crashing: If a thread crashes in Java (a Throwable is propagated into Thread.run(args) , or something gets looped or blocked), that mishap might not affect other threads (e.g. a pool of connections in a server will continue to operate). However as different threads interact. Other threads will easily get stranded if one of them ends abnormally (e.g. one thread trying to read from an empty pipe from another thread which did not close its end). So unless the developers are highly paranoid careful, it is very likely that side effects will occur. I doubt that any other paradigm intends threads to operate as totally independent islands. They must share information and coordinate somehow. And then there will be the chance to mess things up. It is just they will take a more defensive approach that "gives you less rope to hang yourself" (same idiom as with pointers).

Question-20331163
I have a string " 11/15/2013 08:00:00 ", I want to format it to " 11/15/2013 ", what is the correct DateTimeFormatter pattern? I've tried many and googled and still unable to find the correct pattern. edit: I am looking for Joda-Time DateTimeFormatter , not Java's SimpleDateFormat..

Question-11821801
I'm trying to understand what makes the lock in concurrency so important if one can use synchronized(args) . In the dummy code below, I can do either: #li synchronized the entire method or synchronize the vulnerable area (synchronized(this){...}) #li OR lock the vulnerable code area with a ReentrantLock . Code: #pre

Question-8881291
In Swing, the password field has a getPassword(args) (returns char[] ) method instead of the usual getText(args) (returns String ) method. Similarly, I have come across a suggestion not to use String to handle passwords. Why does String pose a threat to security when it comes to passwords? It feels inconvenient to use char[] .

Question-31471444, answer-31476657
From Class NumberUtils you'll see it's defined as: #pre So, you'll see that INTEGER_ONE is not the same as 1. It's an object that's already been constructed for you. So, if we're needing an instance of Integer(args) , rather than create your own, you can reuse the one from the library saving time and memory. It really depends on your application, if you indeed what the int version of 1, then, you'd probably be better of using that instead of this Integer class.

Question-20363719, answer-25453317
If your key is NOT guaranteed to be unique for all elements in the list, you should convert it to a Map<String, List<T> instead of a Map<T> Map<T> result = choices.stream(args).collect(args);

Question-31270759, answer-31270760
Presented below is the full code of the Exceptional class. It has a quite large API which is a pure extension of the Optional API so it can be a drop-in replacement for it in any existing codeexcept that it isn't a subtype of the final Optional class. The class can be seen as being in the same relationship with the Try monad as Optional is with the Maybe monad: it draws inspiration from it, but is adapted to the Java idiom (such as actually throwing exceptions, even from non-terminal operations). These are some key guidelines followed by the class: #li as opposed to the monadic approach, doesn't ignore Java's exception mechanism; #li instead it relieves the impedance mismatch between exceptions and higher-order functions; #li exception handling not statically typesafe (due to sneaky throwing), but always safe at runtime (never swallows an exception except on explicit request). The class tries to cover all the typical ways to handle an exception: #li recover with some handling code which provides a substitute value; #li flatRecover which, analogous to flatMap , allows to return a new Exceptional instance which will be unwrapped and the state of the current instance suitably updated; #li propagate an exception, throwing it from the Exceptional expression and making the propagate call declare this exception type; #li propagate it after wrapping into another exception ( translate it); #li handle it, resulting in an empty Exceptional ; #li as a special case of handling, swallow it with an empty handler block. The propagate approach allows one to selectively pick which checked exceptions he wants to expose from his code. Exceptions which remain unhandled at the time a terminal operation is called (like get ) will be sneakily thrown without declaration. This is often considered as an advanced and dangerous approach, but is nevertheless often employed as a way to somewhat alleviate the nuisance of checked exceptions in combination with lambda shapes which do not declare them. The Exceptional class hopes to offer a cleaner and more selective alternative to sneaky throw. #pre #pre #pre

Question-9324933
I looked at the default Zip library that comes with the JDK and the Apache compression libs and I am unhappy with them for 3 reasons: #li They are bloated and have bad API design. I have to write 50 lines of boiler plate byte array output, zip input, file out streams and close relevant streams and catch exceptions and move byte buffers on my own ? Why can't I have a simple API that looks like this Zipper.unzip(args) and Zipper.zip(args) that just works? #li It seems zipping unzipping destroys file meta-data and password handling is broken. #li Also, all the libraries I tried were 2-3x slow compared to the command line zip tools I get with UNIX? For me (2) and (3) are minor points but I really want a good tested library with a one-line interface.

Question-5243754
What is the difference between getAttribute(args) and getParameter(args) methods within HttpServletRequest class?

Question-16635398, answer-31707746
One of most upleasing functional forEach 's limitations is lack of checked exceptions support. One possible workaround is to replace terminal forEach with plain old foreach loop: #pre Here is list of most popular questions with other workarounds on checked exception handling within lambdas and streams: Java 8 Lambda function that throws exception? Java 8: Lambda-Streams, Filter by Method with Exception How can I throw CHECKED exceptions from inside Java 8 streams? Java 8: Mandatory checked exceptions handling in lambda expressions. Why mandatory, not optional?

Question-29095967, answer-29099896
This is a very interesting problem. I came up with a one line solution. It might not very performant but it works. #pre It is a similar idea that @Rohit Jain came up with. I'm grouping the space between the null values. If you really want a List<T> you may append: List<T> ll = cl.stream(args).collect(args);

Question-22463062, answer-22463063
Parsing date and time To create a LocalDateTime object from a string you can use the static LocalDateTime.parse() method. It takes a string and a DateTimeFormatter as parameter. The DateTimeFormatter is used to specify the date/time pattern. #pre Formatting date and time To create a formatted string out a LocalDateTime object you can use the format(args) method. #pre Note that there are some commonly used date/time formats predefined as constants in DateTimeFormatter . For example: Using DateTimeFormatter.ISO_DATE_TIME to format the LocalDateTime instance from above would result in the string StringLiteral . The parse(args) and format(args) methods are available for all date/time related objects (e.g. LocalDate or ZonedDateTime )

Question-13744450, answer-13744816
In very simple terms (because the other answers are referring you to all the official design patterns anyway, so look at them for further details): If you want to have a class which is monitored by other classes in the ecosystem of your program you say that you want the class to be observable. I.e. there might be some changes in its state which you would want to broadcast to the rest of the program. Now, to do this we have to call some kind of method. We don't want the Observable class to be tightly coupled with the classes that are interested in observing it. It doesn't care who it is as long as it fulfils certain criteria. (Imagine it is a radio station, it doesn't care who is listening as long as they have an FM radio tuned on their frequency). To achieve that we use an interface, referred to as the Observer. Therefore, the Observable class will have a list of Observers (i.e. instances implementing the Observer interface methods you might have). Whenever it wants to broadcast something, it just calls the method on all the observers, one after the other. The last thing to close the puzzle is how will the Observable class know who is interested? So the Observable class must offer some mechanism to allow Observers to register their interest. A method such as addObserver(args) internally adds the Observer to the list of observers, so that when something important happens, it loops through the list and calls the respective notification method of the Observer interface of each instance in the list. It might be that in the interview they did not ask you explicitly about the java.util.Observer and java.util.Observable but about the generic concept. The concept is a design pattern, which Java happens to provide support for directly out of the box to help you implement it quickly when you need it. So I would suggest that you understand the concept rather than the actual methods/classes (which you can look up when you need them). UPDATE In response to your comment, the actual java.util.Observable class offers the following facilities: #li Maintaining a list of java.util.Observer instances. New instances interested in being notified can be added through addObserver(args) , and removed through deleteObserver(args) . #li Maintaining an internal state, specifying whether the object has changed since the last notification to the observers. This is useful because it separates the part where you say that the Observable has changed, from the part where you notify the changes. (E.g. Its useful if you have multiple changes happening and you only want to notify at the end of the process rather than at each small step). This is done through setChanged(args) . So you just call it when you changed something to the Observable and you want the rest of the Observers to eventually know about it. #li Notifying all observers that the specific Observable has changed state. This is done through notifyObservers(args) . This checks if the object has actually changed (i.e. a call to setChanged(args) was made) before proceeding with the notification. There are 2 versions, one with no arguments and one with an Object argument, in case you want to pass some extra information with the notification. Internally what happens is that it just iterates through the list of Observer instances and calls the update(Observable o, Object arg) method for each of them. This tells the Observer which was the Observable object that changed (you could be observing more than one), and the extra Object arg to potentially carry some extra information (passed through notifyObservers(args) .

Question-20945049, answer-21008747
[Disclaimer this is a deliberately opinionated style of answer as I feel a more "don't do this at home kids" answer is warranted] The sin is the line field.setAccessible(args); which says to violate the public api by allowing access to a private field. Thats a giant security hole which can be locked down by configuring a security manager. The phenomenon in the question are implementation details which you would never see when not using that dangerous line of code to violate the access modifiers via reflection. Clearly two (normally) immutable strings can share the same char array. Whether a substring shares the same array depends on whether it can and whether the developer thought to share it. Normally these are invisible implementation details which you should not have to know unless you shoot the access modifier through the head with that line of code. It is simply not a good idea to rely upon such details which cannot be experienced without violating the access modifiers using reflection. The owner of that class only supports the normal public API and is free to make implementation changes in the future. Having said all that the line of code is really very useful when you have a gun held you your head forcing you to do such dangerous things. Using that back door is usually a code smell that you need to upgrade to better library code where you don't have to sin. Another common use of that dangerous line of code is to write a "voodoo framework" (orm, injection container, ...). Many folks get religious about such frameworks (both for and against them) so I will avoid inviting a flame war by saying nothing other than the vast majority of programmers don't have to go there.

Question-31419029, answer-31419077
If you look at the implementation of HashMap , the constructor looks like: #pre And init(args) looks like: #pre So initialCapacity doesn't actually get used to create an array. Where does it get used? Look at the put(args) method. #pre When doing a put, the array is actually created. I didn't show inflateTable(args) but it does some math and initializes the array.

Question-32820722, answer-32821016
If you look at IntFunction it might become clearer: IntFunction<T> is a FunctionalInterface . It represents a function that takes an int and returns a value of type R . In this case, the return type R is also a FunctionalInterface , namely an IntUnaryOperator . So the first (outer) function itself returns a function. In this case: When applied to an int , curriedAdd is supposed to return a function that again takes an int (and returns again int , because that's what IntUnaryOperator does). In functional programming it is common to write the type of a function as param -> return_value and you see exactly that here. So the type of curriedAdd is int -> int -> int (or int -> (int -> int) if you like that better). Java 8's lambda syntax goes along with this. To define such a function, you write a -> b -> a + b which is very much similar to actual lambda calculus: a b a + b b a + b is a function that takes a single parameter b and returns a value (the sum). a b a + b is a function that accepts a single parameter a and returns another function of a single parameter. a b a + b returns b a + b with a set to the parameter value.

Question-8777257, answer-8777266
It's a famous problem: .equals(args) for arrays is badly broken, just don't use it, ever. That said, it's not "broken" as in "someone has done it in a really wrong way"  it's just doing what's defined and not what's usually expected. So for purists: it's perfectly fine, and that also means, don't use it, ever. Now the expected behaviour for equals is to compare data. The default behaviour is to compare the identity, as Object does not have any data (for purists: yes it has, but it's not the point); assumption is, if you need equals in subclasses, you'll implement it. In arrays, there's no implementation for you, so you're not supposed to use it. So the difference is, Arrays.equals(args) works as you would expect (i.e. compares content), array1.equals(args) falls back to Object.equals implementation, which in turn compares identity, and thus better replaced by == (for purists: yes I know about null ). Problem is, even Arrays.equals(args) will bite you hard if elements of array do not implement equals properly. It's a very naive statement, I know, but there's a very important less-than-obvious case: consider a 2D array. 2D array in Java is an array of arrays, and arrays' equals is broken (or useless if you prefer), so Arrays.equals(args) will not work as you expect on 2D arrays. Hope that helps.

Question-29140402, answer-36771568
In Eclipse, Go to your class, Right click->source->Generate toString(); It will override the toString() method and print the object of that class.

Question-4871051, answer-4871135
Current working directory is defined differently in different Java implementations For certain prior to Java 7 there was no consistent way to get the working directory. You could work around this by launching Java with -D and defining a variable to hold the info Something like java -Dcom.mycompany.workingDir=StringLiteral That's not quite right, but you get the idea. Then System.getProperty(args) ...

Question-28584669, answer-28584932
Your reasoning is that Double.POSITIVE_INFINITY should not be equal to itself because it is likely to have been obtained as the result of a loss of accuracy. This line of reasoning applies to all of floating-point. Any finite value can be obtained as the result of an inaccurate operation. That did not push the IEEE 754 standardization committee to define == as always evaluating to false for finite values, so why should infinities be different? As defined, == is useful for people who understand what it does (that is, test the floating-point values that have been obtained , and certainly not the values that should have been obtained with real computations). For anyone who understands that, and you need to understand it to use floating-point even for computations that do not involve infinity, having Double.POSITIVE_INFINITY == Double.POSITIVE_INFINITY evaluate to true is convenient, if only to test if the floating-point result of a floating-point computation is Double.POSITIVE_INFINITY . That leaves the question of why NaN can afford to have special behavior, and infinities should follow the same general principles as finite values. NaN is different from infinities: the underlying principle of the IEEE 754 standard is that values are exactly what they are, but the result of an operation can be approximated with respect to the real result, and in this case, the resulting floating-point value is obtained according to the rounding mode. Forget for an instant that 1.0 / 0.0 is defined as +inf, which is an annoyance in this discussion. Think for the moment of Double.POSITIVE_INFINITY only as the result of operations such as 1.0e100 / 1.0e-300 or Double.MAX_VALUE + Double.MAX_VALUE . For these operations, +inf is the closest approximation of the real result, just like for operations that produce a finite result. By contrast, NaN is the result you obtain when the operation doesn't make sense. It is defensible to have NaN behave specially, but inf is just an approximation of all the values too large to represent. In reality, 1.0 / 0.0 also produces +inf, but that should be considered an exception. It would have been just as coherent to define the result of that operation as NaN, but defining it as +inf was more convenient in the implementation of some algorithms. An example is provided page 10 in Kahan's notes . More details than most will wish for are in the article Branch Cuts for Complex Elementary Functions, or Much Ado About Nothing's Sign Bit . I would also interpret the existence in IEEE 754 of a division by zero flag separate from the NaN flag as recognition that the user may want to treat division by zero specially although it is not defined as producing NaN.

Question-25903137, answer-25905196
Here are some variations on Sotirios Delimanolis' answer , which was pretty good to begin with (+1). Consider the following: #pre A couple points here. First is the use of wildcards in the generics; this makes the function somewhat more flexible. A wildcard would be necessary if, for example, you wanted the output map to have a key that's a superclass of the input map's key: #pre (There is also an example for the map's values, but it's really contrived, and I admit that having the bounded wildcard for Y only helps in edge cases.) A second point is that instead of running the stream over the input map's entrySet , I ran it over the keySet . This makes the code a little cleaner, I think, at the cost of having to fetch values out of the map instead of from the map entry. Incidentally, I initially had key -> key as the first argument to toMap(args) and this failed with a type inference error for some reason. Changing it to (X key) -> key worked, as did Function.identity(args) . Still another variation is as follows: #pre This uses Map.forEach(args) instead of streams. This is even simpler, I think, because it dispenses with the collectors, which are somewhat clumsy to use with maps. The reason is that Map.forEach(args) gives the key and value as separate parameters, whereas the stream has only one value -- and you have to choose whether to use the key or the map entry as that value. On the minus side, this lacks the rich, streamy goodness of the other approaches. :-)

Question-12862659, answer-12862662
use the second argument on the Mockito.verify method, as in: verify(args).someMethod(args)

Question-12317668, answer-12375312
Here we are faced with a bug in the JIT-compiler. Compiler determines that the allocated array is filled after allocation in Arrays.fill(args) , but the check for uses between the allocation and the fill is faulty. So, compiler performs an illegal optimization - it skips zeroing of allocated array. This bug is placed in Oracle bug tracker ( bug id 7196857 ). Unfortunately, I did not wait for any clarifications from Oracle about the following points. As I see, this bug is OS-specific: it absolutely reproducible on 64-bit Linux and Mac, but, as I see from comments, it reproduces not regularly on Windows (for similar versions of JDK). Additionally it would be nice to know when this bug will be fixed. There is only advice at the moment: do not use JDK1.7.0_04 or later if you depend on JLS for newly declared arrays. Update at October 5: In the new Build 10 of the JDK 7u10 (early access) released at October 04, 2012, this bug was fixed at least for Linux OS (I did not test for other). Thanks to @Makoto, who found that this bug is no longer available for public access in Oracle bug database. Unfortunately, I do not know for the reasons Oracle removed it from public access, but it is available in Google cache . Also, this bug has caught the attention of Redhat: the CVE identifiers CVE-2012-4420 ( bugzilla ) and CVE-2012-4416 ( bugzilla ) were assigned to this flaw.

Question-6608795
I wonder what the difference is between Class.getResource(args) and ClassLoader.getResource(args) ? edit: I especially want to know if any caching is involved on file/directory level. As in "are directory listings cached in the Class version?" AFAIK the following should essentially do the same, but they are not: #pre I discovered this when fiddling with some report generation code that creates a new file in WEB-INF/classes/ from an existing file in that directory. When using the method from Class, I could find files that were there at deployment using getClass(args).getResource(args) , but when trying to fetch the newly created file, I recieved a null object. Browsing the directory clearly shows that the new file is there. The filenames were prepended with a forward slash as in "/myFile.txt". The ClassLoader version of getResource(args) on the other hand did find the generated file. From this experience it seems that there is some kind of caching of the directory listing going on. Am I right, and if so, where is this documented? From the API docs on Class.getResource(args) #blockquote To me, this reads "Class.getResource is really calling its own classloader's getResource()". Which would be the same as doing getClass(args).getClassLoader(args).getResource(args) . But it is obviously not. Could someone please provide me with some illumination into this matter?

Question-4871051, answer-27760556
System.getProperty(args)

Question-5868369, answer-20593147
In Java 8, you could do: #pre Some notes: The stream returned by Files.lines (unlike most streams) needs to be closed. For the reasons mentioned here I avoid using forEach(args) . The strange code (Iterable<T>) lines::iterator casts a Stream to an Iterable.

Question-22409102, answer-33501556
Double.equals distinguishes 0.0 in Java. (There's also Float.equals .) I'm a bit surprised no-one has mentioned these, as they seem to me clearer than any method given so far!

Question-29095967, answer-29111023
Although there are several answers already, and an accepted answer, there are still a couple points missing from this topic. First, the consensus seems to be that solving this problem using streams is merely an exercise, and that the conventional for-loop approach is preferable. Second, the answers given thus far have overlooked an approach using array or vector-style techniques that I think improves the streams solution considerably. First, here's a conventional solution, for purposes of discussion and analysis: #pre This is mostly straightforward but there's a bit of subtlety. One point is that a pending sublist from prev to cur is always open. When we encounter null we close it, add it to the result list, and advance prev . After the loop we close the sublist unconditionally. Another observation is that this is a loop over indexes, not over the values themselves, thus we use an arithmetic for-loop instead of the enhanced "for-each" loop. But it suggests that we can stream using the indexes to generate subranges instead of streaming over values and putting the logic into the collector (as was done by Joop Eggen's proposed solution ). Once we've realized that, we can see that each position of null in the input is the delimiter for a sublist: it's the right end of the sublist to the left, and it (plus one) is the left end of the sublist to the right. If we can handle the edge cases, it leads to an approach where we find the indexes at which null elements occur, map them to sublists, and collect the sublists. The resulting code is as follows: #pre Getting the indexes at which null occurs is pretty easy. The stumbling block is adding -1 at the left and size at the right end. I've opted to use Stream.of to do the appending and then flatMapToInt to flatten them out. (I tried several other approaches but this one seemed like the cleanest.) It's a bit more convenient to use arrays for the indexes here. First, the notation for accessing an array is nicer than for a List: indexes[i] vs. indexes.get(args) . Second, using an array avoids boxing. At this point, each index value in the array (except for the last) is one less than the beginning position of a sublist. The index to its immediate right is the end of the sublist. We simply stream over the array and map each pair of indexes into a sublist and collect the output. Discussion The streams approach is slightly shorter than the for-loop version, but it's denser. The for-loop version is familiar, because we do this stuff in Java all the time, but if you're not already aware of what this loop is supposed to be doing, it's not obvious. You might have to simulate a few loop executions before you figure out what prev is doing and why the open sublist has to be closed after the end of the loop. (I initially forgot to have it, but I caught this in testing.) The streams approach is, I think, easier to conceptualize what's going on: get a list (or an array) that indicates the boundaries between sublists. That's an easy streams two-liner. The difficulty, as I mentioned above, is finding a way to tack the edge values onto the ends. If there were a better syntax for doing this, e.g., // Java plus pidgin Scala int[] indexes = [-1] ++ IntStream.range(args) .filter(args) ++ [input.size(args)]; it would make things a lot less cluttered. (What we really need is array or list comprehension.) Once you have the indexes, it's a simple matter to map them into actual sublists and collect them into the result list. And of course this is safe when run in parallel. UPDATE 2016-02-06 Here's a nicer way to create the array of sublist indexes. It's based on the same principles, but it adjusts the index range and adds some conditions to the filter to avoid having to concatenate and flatmap the indexes. #pre

Question-7520432
I wanted to clarify if I understand this correctly: #li == -> is a reference comparison, i.e. both objects point to the same memory location #li .equals(args) -> evaluates to the comparison of values in the objects Am I correct in my understanding ?

Question-28818506, answer-28818627
Perhaps this is what you're after: Get value from one Optional or another Otherwise, you may want to have a look at Optional.orElseGet . Here's an example of what I think that you're after: result = Optional.ofNullable(args);

Question-32693704, answer-32749756
I'm going to shoot in the dark here... My guess is that it might have been changed in order to prepare the ground for Specialization (aka generics over primitive types). Maybe (and I insist on maybe ), this change is meant to make transition to Java 10 easier, in the event of specialization being part of the JDK. If you look at the State of the Specialization document , Language restrictions section, it says the following: #blockquote (Emphasis is mine). And ahead in the Specializer transformations section, it says: #blockquote Later on, near the end of the document, in the Further investigation section, it says: #blockquote Now, regarding the change... If the Arrays.fill(args) method is going to be specialized, then its signature should change to Arrays.fill(args) . However this case is specifically listed in the (already mentioned) Language restrictions section (it would violate the emphasized items). So maybe someone decided that it would be better to not use it from the HashMap.clear(args) method, especially if value is null .

Question-7488643, answer-7488683
You can first split them using String.split(args) , and then convert the returned String array to an ArrayList using Arrays.asList(args)

Question-6684665, answer-6684822
You can't just take the returned string and construct a string from it... it's not a byte[] data type anymore, it's already a string; you need to parse it. For example : #pre ** EDIT ** You get an hint of your problem in your question, where you say " Whatever I seem to try I end up getting a byte array which looks as follows... [91, 45, ... ", because 91 is the byte value for [ , so [91, 45, ... is the byte array of the string " [-45, 1, 16, ... " string. The method Arrays.toString(args) will return a String representation of the specified array; meaning that the returned value will not be a array anymore. For example : #pre As you can see, s1 holds the string representation of the array b1 , while s2 holds the string representation of the bytes contained in b1 . Now, in your problem, your server returns a string similar to s1 , therefore to get the array representation back, you need the opposite constructor method. If s2.getBytes(args) is the opposite of new String(args) , you need to find the opposite of Arrays.toString(args) , thus the code I pasted in the first snippet of this answer.

Question-11408427, answer-11408526
Let's look at the following simple expressions in Java #pre The compiler converts StringLiteral+x; into a StringBuilder internally and uses .append(args) to "add" the integer to the string. 5.1.11. String Conversion #blockquote 15.18.1. #blockquote The optimized version will not actually do a full wrapped String conversion first. This is a good illustration of an optimized version used by the compiler, albeit without the conversion of a primitive, where you can see the compiler changing things into a StringBuilder in the background: #a This java code: #pre Generates this - see how the two concatenation styles lead to the very same bytecode: #pre Looking at the example above and how the byte code based on the source code in the given example is generated, you will be able to notice that the compiler has internally transformed the following statement cip+ciop; into new StringBuilder(args).append(args).toString(args); In other words, the operator + in string concatenation is effectively a shorthand for the more verbose StringBuilder idiom.

Question-13195797, answer-13195890
FileUtils.cleanDirectory(args); There is this method available in the same file. This will also recursively deletes all sub-folders and files under them. Docs: org.apache.commons.io.FileUtils.cleanDirectory

Question-16635398, answer-20177092
The better practice is to use for-each . Besides violating the Keep It Simple, Stupid principle, the new-fangled forEach(args) has at least the following deficiencies: #li Can't use non-final variables . So, code like the following can't be turned into a forEach lambda: #blockquote #li Can't handle checked exceptions . Lambdas aren't actually forbidden from throwing checked exceptions, but common functional interfaces like Consumer don't declare any. Therefore, any code that throws checked exceptions must wrap them in try-catch or Throwables.propagate(args) . But even if you do that, it's not always clear what happens to the thrown exception. It could get swallowed somewhere in the guts of forEach(args) #li Limited flow-control . A return in a lambda equals a continue in a for-each, but there is no equivalent to a break . It's also difficult to do things like return values, short circuit, or set flags (which would have alleviated things a bit, if it wasn't a violation of the no non-final variables rule). "This is not just an optimization, but critical when you consider that some sequences (like reading the lines in a file) may have side-effects, or you may have an infinite sequence." #li Might execute in parallel , which is a horrible, horrible thing for all but the 0.1% of your code that needs to be optimized. Any parallel code has to be thought through (even if it doesn't use locks, volatiles, and other particularly nasty aspects of traditional multi-threaded execution). Any bug will be tough to find. #li Might hurt performance , because the JIT can't optimize forEach()+lambda to the same extent as plain loops, especially now that lambdas are new. By "optimization" I do not mean the overhead of calling lambdas (which is small), but to the sophisticated analysis and transformation that the modern JIT compiler performs on running code. #li If you do need parallelism, it is probably much faster and not much more difficult to use an ExecutorService . Streams are both automagical (read: don't know much about your problem) and use a specialized (read: inefficient for the general case) parallelization strategy ( fork-join recursive decomposition ). #li Makes debugging more confusing , because of the nested call hierarchy and, god forbid, parallel execution. The debugger may have issues displaying variables from the surrounding code, and things like step-through may not work as expected. #li Streams in general are more difficult to code, read, and debug . Actually, this is true of complex " fluent " APIs in general. The combination of complex single statements, heavy use of generics, and lack of intermediate variables conspire to produce confusing error messages and frustrate debugging. Instead of "this method doesn't have an overload for type X" you get an error message closer to "somewhere you messed up the types, but we don't know where or how." Similarly, you can't step through and examine things in a debugger as easily as when the code is broken into multiple statements, and intermediate values are saved to variables. Finally, reading the code and understanding the types and behavior at each stage of execution may be non-trivial. #li Sticks out like a sore thumb . The Java language already has the for-each statement. Why replace it with a function call? Why encourage hiding side-effects somewhere in expressions? Why encourage unwieldy one-liners? Mixing regular for-each and new forEach willy-nilly is bad style. Code should speak in idioms (patterns that are quick to comprehend due to their repetition), and the fewer idioms are used the clearer the code is and less time is spent deciding which idiom to use (a big time-drain for perfectionists like myself!). As you can see, I'm not a big fan of the forEach() except in cases when it makes sense. Particularly offensive to me is the fact that Stream does not implement Iterable (despite actually having method iterator ) and cannot be used in a for-each, only with a forEach(). I recommend casting Streams into Iterables with (Iterable<T>)stream::iterator . A better alternative is to use StreamEx which fixes a number of Stream API problems, including implementing Iterable . That said, forEach(args) is useful for the following: #li Atomically iterating over a synchronized list . Prior to this, a list generated with Collections.synchronizedList(args) was atomic with respect to things like get or set, but was not thread-safe when iterating. #li Parallel execution (using an appropriate parallel stream) . This saves you a few lines of code vs using an ExecutorService, if your problem matches the performance assumptions built into Streams and Spliterators. #li Specific containers which , like the synchronized list, benefit from being in control of iteration (although this is largely theoretical unless people can bring up more examples) #li Calling a single function more cleanly by using forEach(args) and a method reference argument (ie, list.forEach(args) ). However, keep in mind the points on checked exceptions, more difficult debugging, and reducing the number of idioms you use when writing code. Articles I used for reference: #li Everything about Java 8 #li Iteration Inside and Out (as pointed out by another poster) EDIT: Looks like some of the original proposals for lambdas (such as #a ) solved some of the issues I mentioned (while adding their own complications, of course).

Question-5243754, answer-25074487
- getParameter() : #pre request.getParameter(args) will get the value from the posted form of the input box named "testParam" which is "Client param". It will then print it out, so you should see "Client Param" on the screen. So request.getParameter() will retrieve a value that the client has submitted. You will get the value on the server side. - getAttribute() : request.getAttribute(args) , this is all done server side. YOU add the attribute to the request and YOU submit the request to another resource, the client does not know about this. So all the code handling this would typically be in servlets.getAttribute always return object.

Question-6992608, answer-26764904
As pointed by this the best way to obtain a concurrency-able HashSet is by means of Collections.synchronizedSet(args) Set s = Collections.synchronizedSet(args); This worked for me and I haven't seen anybody really pointing to it. EDIT This is less efficient than the currently aproved solution, as Eugene points out, since it just wraps your set into a synchronized decorator, while a ConcurrentHashMap actually implements low-level concurrency and it can back your Set just as fine. So thanks to Mr. Stepanenkov for making that clear. #a

Question-32859038
I have a List<T> collection. I need to convert it into Map<T> The key of the map must be the index of the item in the collection. I can not figure it out how to do this with streams. Something like: items.stream(args).collect(args); Any help? As this question is identified as possible duplicate I need to add that my concrete problem was - how to get the position of the item in the list and put it as a key value

