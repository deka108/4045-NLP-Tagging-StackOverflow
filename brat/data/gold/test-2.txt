Question-23114015, answer-32874755
If you know the size you could use java.util.Collection which provides the stream(args) method: #pre And then: new Hand(args).stream(args).map(args) I faced the same problem and was surprised that my Iterable implementation could be very easily extended to an AbstractCollection implementation by simply adding the size(args) method (luckily I had the size of the collection :-) You should also consider to override Spliterator<T> spliterator(args) .

Question-29229373, answer-29230939
When looking into the implementation ( ReferencePipeline.java ) we see the method [ link ] #pre which will be invoke for findFirst operation. The special thing to take care about is the sink.cancellationRequested(args) which allows to end the loop on the first match. Compare to [ link ] #pre The method for advancing one item ends up calling forEach on the sub-stream without any possibility for earlier termination and the comment at the beginning of the flatMap method even tells about this absent feature. Since this is more than just an optimization thing as it implies that the code simply breaks when the sub-stream is infinite, I hope that the developers soon prove that they “can do better than this”… To illustrate the implications, while Stream.iterate(args).findFirst(args) works as expected, Stream.of(args).flatMap(args).findFirst(args) will end up in an infinite loop. Regarding the specification, most of it can be found in the chapter “Stream operations and pipelines” of the package specification : #blockquote It’s clear that a short-circuiting operation doesn’t guaranty a finite time termination, e.g. when a filter doesn’t match any item the processing can’t complete, but an implementation which doesn’t support any termination in finite time by simply ignoring the short-circuiting nature of an operation is far off the specification.

Question-11821801, answer-36827191
From oracle documentation page about ReentrantLock : #blockquote #li A ReentrantLock is owned by the thread last successfully locking, but not yet unlocking it. A thread invoking lock will return, successfully acquiring the lock, when the lock is not owned by another thread. The method will return immediately if the current thread already owns the lock. #li The constructor for this class accepts an optional fairness parameter. When set true, under contention, locks favor granting access to the longest-waiting thread . Otherwise this lock does not guarantee any particular access order. ReentrantLock key features as per this article #li Ability to lock interruptibly. #li Ability to timeout while waiting for lock. #li Power to create fair lock. #li API to get list of waiting thread for lock. #li Flexibility to try for lock without blocking. You can use ReentrantReadWriteLock.ReadLock, ReentrantReadWriteLock.WriteLock to further acquire control on granular locking on read and write operations. Have a look at this article by Benjamen on usage of different type of ReentrantLocks

Question-16232833, answer-16250729
change your return type to ResponseEntity<T> , then you can use below for 400 return new ResponseEntity<T>(args); and for correct request return new ResponseEntity<T>(args); UPDATE 1 after spring 4.1 there are helper methods in ResponseEntity could be used as return ResponseEntity.status(args).body(args); and return ResponseEntity.ok(args);

Question-21524642, answer-21524694
Or.. Pattern#quote : String[] value_split = rat_values.split(args); This is happening because String#split accepts a regex : | has a special meaning in regex . quote will return a String representation for the regex .

Question-7348711, answer-7800008
Strictly speaking - you have no choice but calling either hostname(args) or - on Unix gethostname(args) . This is the name of your computer. Any attempt to determine the hostname by an IP address like this InetAddress.getLocalHost(args).getHostName(args) is bound to fail in some circumstances: #li The IP address might not resolve into any name. Bad DNS setup, bad system setup or bad provider setup may be the reason for this. #li A name in DNS can have many aliases called CNAMEs. These can only be resolved in one direction properly: name to address. The reverse direction is ambiguous. Which one is the "official" name? #li A host can have many different IP addresses - and each address can have many different names. Two common cases are: One ethernet port has several "logical" IP addresses or the computer has several ethernet ports. It is configurable whether they share an IP or have different IPs. This is called "multihomed". #li One Name in DNS can resolve to several IP Addresses. And not all of those addresses must be located on the same computer! (Usecase: A simple form of load-balancing) #li Let's not even start talking about dynamic IP addresses. Also don't confuse the name of an IP-address with the name of the host (hostname). A metaphor might make it clearer: #blockquote This illustrates it pretty much I think. The good news is: The real hostname is usually not necessary. In most cases any name which resolves into an IP address on this host will do. (The stranger might enter the city by Northgate, but helpful locals translate the "2nd left" part.) If the remaining corner cases you must use the definitive source of this configuration setting - which is the C function gethostname(args) . That function is also called by the program hostname .

Question-15336477, answer-32364785
Examples from Apache ( link ) use this: HttpClient httpclient = HttpClients.createDefault(args); The class org.apache.http.impl.client.HttpClients is there since version 4.3. The code for HttpClients.createDefault(args) is the same as the accepted answer in here.

Question-7520432, answer-7520464
In general, the answer to your question is "yes", but... #li equals will only compare what it is written to compare, no more, no less. #li if a class does not override the equals method, then it defaults to the equals(args) method of the closest parent class that has overridden this method. #li If no parent classes have provided an override, then it defaults to the method from the ultimate parent class, Object, and so you're left with the Object#equals(args) method. Per the Object API this is the same as == ; that is, it returns true if and only if both variables refer to the same object, if their references are one and the same. Thus you will be testing for object equality and not functional equality . #li Always remember to override hashCode if you override equals so as not to "break the contract". As per the API, the result returned from the hashCode(args) method for two objects must be the same if their equals methods shows that they are equivalent. The converse is not necessarily true.

Question-32859038, answer-32863263
Don't feel like you have to do everything in/with the stream. I would just do: #pre As long as you don't parallelise the stream this will work and it avoids potentially expensive and/or problematic (in the case of duplicates) get(args) and indexOf(args) operations. (You cannot use a regular int variable in place of the AtomicInteger because variables used from outside a lambda expression must be effectively final. Note that when uncontested (as in this case), AtomicInteger is very fast and won't pose a performance problem. But if it worries you you can use a non-thread-safe counter.)

Question-34250207, answer-34250231
Technically, it's 10 , not zero, if you admit for a lazy initialisation of the backing array. See: #pre where /** * Default initial capacity. */ private static final int DEFAULT_CAPACITY = 10; What you're referring to is just the zero-sized initial array object that is shared among all initially empty ArrayList objects. I.e. the capacity of 10 is guaranteed lazily , an optimisation that is present also in Java 7. Admittedly, the constructor contract is not entirely accurate. Perhaps this is the source of confusion here. Background Here's an E-Mail by Mike Duigou #blockquote

Question-20129762, answer-20130131
There are already people asked the same on the mailing list ☺. The main reason is Iterable also has a re-iterable semantic, while Stream is not. #blockquote

Question-32334319, answer-32334651
The API guarantees a stable sorting which Quicksort doesn’t offer. However, when sorting primitive values by their natural order you won’t notice a difference as primitive values have no identity. Therefore, Quicksort is used for primitive arrays as it is slightly more efficient. For objects you may notice, when objects which are deemed equal according to their equals implementation or the provided Comparator change their order. Therefore, Quicksort is not an option. So a variant of MergeSort is used, the current Java versions use TimSort . This applies to both, Arrays.sort and Collections.sort , though with Java 8, the List itself may override the sort algorithms.

Question-31993377, answer-31993533
The reason is that hasNext(args) checks if there are any more non-whitespace characters available. hasNextLine(args) checks to see if there is another line of text available. Your text file probably has a newline at the end of it so it has another line but no more characters that are not whitespace. Many text editors automatically add a newline to the end of a file if there isn't one already. In other words, your input file is not this (the numbers are line numbers): #pre It is actually this: #pre

Question-31922866, answer-31923211
This advice is a variant of the "be as unspecific as possible regarding inputs and as specific as possible regarding outputs" rule of thumb. Usually if you have a method that takes a plain non-null value, you can map it over the Optional , so the plain version is strictly more unspecific regarding inputs. However there are a bunch of possible reasons why you would want to require an Optional argument nonetheless: #li you want your function to be used in conjunction with another API that returns an Optional #li Your function should return something other than an empty Optional if the given value is empty #li You think Optional is so awesome that whoever uses your API should be required to learn about it ;-)

Question-34172978, answer-34173658
If you want to stop either if number 5 is reached or 10 elements are collected, there's Stream.takeWhile(args) method added in Java-9: #pre

Question-12552863, answer-32302353
To concur with earlier comments: simplest is (2) to use Closeable resources and declare them in order in the try-with-resources clause. If you only have AutoCloseable, you can wrap them in another (nested) class that just checks that close is only called once (Facade Pattern), e.g. by having private bool isClosed; . In practice even Oracle just (1) chains the constructors and doesn't correctly handle exceptions partway through the chain. Alternatively, you can manually create a chained resource, using a static factory method; this encapsulates the chain, and handle cleanup if it fails part-way: #pre The complexity comes from handling multiple exceptions; otherwise it's just "close resources that you've acquired so far". A common practice seems to be to first initialize the variable that holds the object that holds the resource to null (here fileWriter ), and then include a null check in the cleanup, but that seems unnecessary: if the constructor fails, there's nothing to clean up, so we can just let that exception propagate, which simplifies the code a little. You could probably do this generically: #pre

Question-28840047
Some time ago, I've blogged about a Java 8 functional way of calculating fibonacci numbers recursively , with a ConcurrentHashMap cache and the new, useful computeIfAbsent(args) method: #pre I chose ConcurrentHashMap because I was thinking of making this example even more sophisticated by introducing parallelism (which I didn't in the end). Now, let's increase the number from 8 to 25 and observe what happens: System.out.println(args); The program never halts. Inside the method, there's a loop that just runs forever: #pre I'm using: #pre Matthias, a reader of that blog post also confirmed the issue (he actually found it) . This is weird. I would have expected any of the following two: #li It works #li It throws a ConcurrentModificationException But just never halting? That seems dangerous. Is it a bug? Or did I misunderstand some contract?

Question-20945049, answer-20945113
String is immutable* but this only means you cannot change it using its public API. What you are doing here is circumventing the normal API, using reflection. The same way, you can change the values of enums, change the lookup table used in Integer autoboxing etc. Now, the reason s1 and s2 change value, is that they both refer to the same interned string. The compiler does this (as mentioned by other answers). The reason s3 does not was actually a bit surprising to me, as I thought it would share the value array ( it did in earlier version of Java , before Java 7u6). However, looking at the source code of String , we can see that the value character array for a substring is actually copied (using Arrays.copyOfRange(args) ). This is why it goes unchanged. You can install a SecurityManager , to avoid malicious code to do such things. But keep in mind that some libraries depend on using these kind of reflection tricks (typically ORM tools, AOP libraries etc). *) I initially wrote that String s aren't really immutable, just "effective immutable". This might be misleading in the current implementation of String , where the value array is indeed marked private final . It's still worth noting, though, that there is no way to declare an array in Java as immutable, so care must be taken not to expose it outside its class, even with the proper access modifiers. As this topic seems overwhelmingly popular, here's some suggested further reading: Heinz Kabutz's Reflection Madness talk from JavaZone 2009, which covers a lot of the issues in the OP, along with other reflection... well... madness. It covers why this is sometimes useful. And why, most of the time, you should avoid it. :-)

Question-5455794
I have a string like this: mysz = StringLiteral; I want to remove the whitespaces in the string. I tried trim(args) but this removes only whitespaces before and after the whole string. I also tried replaceAll(args) but then the = also gets removed. How can I achieve a string with: mysz2 = StringLiteral

Question-12576156, answer-12576308
Have you considered @Autowired ing the constructor or a setter and String.split(args) ing in the body? #pre I tend to prefer doing my autowiring in one of these ways to enhance the testability of my code.

Question-22501230, answer-22511214
I don't like any of the solutions presented except for JAB's. None of the others make it easy to read the code and understand what is being computed . Here's how I would write this code -- I only know C#, not Java, but you get the picture: #pre Now it is much more clear what is being computed here: this emphasizes that we are computing who gets hit by what attack, and returning both results. However this could be even better; that Boolean array is somewhat opaque. I like the table lookup approach but I would be inclined to write it in such a way that made it clear what the intended game semantics were. That is, rather than "an attack of zero and a defense of one results in no hit", instead find a way to make the code more clearly imply "a low kick attack and a low block defense results in no hit". Make the code reflect the business logic of the game.

Question-5694385, answer-5694464
Rather than spoon-feed you code, here's how to look in the documentation . First, you're dealing with IO, so look in the java.io package . There are two classes that look interesting: FileFilter and FileNameFilter . When I clicked on the first, it showed me that there was a a listFiles(args) method in the File class. And the documentation for that method says: #blockquote Scrolling up in the File JavaDoc, I see the constructors. And that's really all I need to be able to create a File instance and call listFiles(args) on it. Scrolling still further, I can see some information about how files are named in different operating systems.

Question-14526260, answer-14526289
just use File.getName() #pre using String methods : #pre

Question-23218874
I understand that with .stream(args) , I can use chain operations like .filter(args) or use parallel stream. But what is difference between them if I need to execute small operations (for example, printing the elements of the list)? #pre

Question-8894258, answer-8894356
Looks like niether is faster or slower #pre For long strings I'll chose the first one. Why copy around long strings? Documentations says: #blockquote //Edit 1 I've changed the test to trick JIT optimisation. //Edit 2 Repeat test 10 times to let JVM warm up. //Edit 3 Conclusions: First of all str.toCharArray(args); copies entire string in memory. It can be memory consuming for long strings. Method String.charAt(args) looks up char in char array inside String class checking index before. It looks like for short enough Strings first method (i.e. chatAt method) is a bit slower due to this index check. But if the String is long enough, copying whole char array gets slower, and the first method is faster. The longer the string is, the slower toCharArray performs. Try to change limit in for(args) loop to see it. If we let JVM warm up code runs faster, but proportions are the same. After all it's just micro-optimisation.

Question-16098046, answer-16098086
You could use printf(args) with %f : #pre This will print dexp: 12345678.000000 . If you don't want the fractional part, use System.out.printf(args); This uses the format specifier language explained in the documentation . The default toString(args) format used in your original code is spelled out here .

Question-31471444, answer-31471520
org.apache.commons.lang.math.NumberUtils.INTEGER_ONE it gives you a final static Integer object rather than primitive int 1, and as it is final static it acts as a constant and can be used in comparison of Integer objects because will always return same instance. So in the above scenario it might not look fit but somewhere if you are using it while comparison, it for sure has impact. Moreover, as much as we can, should prefer the use of constants over hardcoded beacuse: #li It can make your code easily maintainable. If any situation occurs in future for change, you can change only at a single place. #li The code looks cleaner & more readable.

Question-5585779, answer-5585800
int foo = Integer.parseInt(args); See the Java Documentation for more information. (If you have it in a StringBuilder (or the ancient StringBuffer ), you'll need to do Integer.parseInt(args); instead).

Question-6841333
If I run the following program, which parses two date strings referencing times one second apart and compares them: #pre The output is: 353 Why is ld4-ld3 not 1 (as I would expect from the one-second difference in the times), but 353 ? If I change the dates to times one second later: #pre Then ld4-ld3 will be 1 . Java version: #pre Timezone( TimeZone.getDefault(args) ): #pre

Question-31696485
When using the Java 8 Optional class, there are two ways in which a value can be wrapped in an optional. #pre I understand Optional.ofNullable is the only safe way of using Optional , but why does Optional.of exist at all? Why not just use Optional.ofNullable and be on the safe side at all times?

Question-6992608, answer-26764904
As pointed by this the best way to obtain a concurrency-able HashSet is by means of Collections.synchronizedSet(args) Set s = Collections.synchronizedSet(args); This worked for me and I haven't seen anybody really pointing to it. EDIT This is less efficient than the currently aproved solution, as Eugene points out, since it just wraps your set into a synchronized decorator, while a ConcurrentHashMap actually implements low-level concurrency and it can back your Set just as fine. So thanks to Mr. Stepanenkov for making that clear. #a

Question-15202997, answer-15203417
If you're unsure about something, try writing a test first. I did this: #pre Prints: #pre There's an empty line in the last block where getSimpleName returns an empty string. The upshot looking at this is: #li the name is the name that you'd use to dynamically load the class with, for example, a call to Class.forName with the default ClassLoader . #li the canonical name is the name that would be used in an import statement and uniquely identifies the class. Might be useful during toString or logging operations. #li the simple name loosely identifies the class, again might be useful during toString or logging operations but is not guaranteed to be unique.

Question-31922866, answer-31923227
Optionals aren't designed for this purpose, as explained nicely by Brian Goetz . You can always use @Nullable to denote that a method argument can be null. Using an optional does not really enable you to write your method logic more neatly.

Question-21488056, answer-36242382
You can use Predicates from Eclipse Collections #pre If you can't change the strings from List : #pre If you only need a negation of String.isEmpty(args) you can also use StringPredicates.notEmpty(args) . Note: I am a contributor to Eclipse Collections.

Question-5585779, answer-33233407
We can use the parseInt(args) method of the Integer wrapper class for converting a String value to an integer value. For example: #pre The Integer class also provides the valueOf(args) method: #pre We can also use toInt(args) of NumberUtils Utility Class for the conversion: #pre

Question-11408427, answer-11408526
Let's look at the following simple expressions in Java #pre The compiler converts StringLiteral+x; into a StringBuilder internally and uses .append(args) to "add" the integer to the string. 5.1.11. String Conversion #blockquote 15.18.1. #blockquote The optimized version will not actually do a full wrapped String conversion first. This is a good illustration of an optimized version used by the compiler, albeit without the conversion of a primitive, where you can see the compiler changing things into a StringBuilder in the background: #a This java code: #pre Generates this - see how the two concatenation styles lead to the very same bytecode: #pre Looking at the example above and how the byte code based on the source code in the given example is generated, you will be able to notice that the compiler has internally transformed the following statement cip+ciop; into new StringBuilder(args).append(args).toString(args); In other words, the operator + in string concatenation is effectively a shorthand for the more verbose StringBuilder idiom.

Question-7520432, answer-36875991
Basically, == compares if two objects have the same reference on the heap, so unless two references are linked to the same object, this comparison will be false. equals(args) is a method inherited from Object class. This method by default compares if two objects have the same referece. It means: object1.equals(args) <=> object1 == object2 However, if you want to establish equality between two objects of the same class you should override this method. It is also very important to override the method hashCode(args) if you have overriden equals(args) . Implement hashCode(args) when establishing equality is part of the Java Object Contract. If you are working with collections, and you haven't implemented hashCode(args) , Strange Bad Things could happen: #pre null will be printed after executing the previous code if you haven't implemented hashCode(args) .

Question-11821801
I'm trying to understand what makes the lock in concurrency so important if one can use synchronized(args) . In the dummy code below, I can do either: #li synchronized the entire method or synchronize the vulnerable area (synchronized(this){...}) #li OR lock the vulnerable code area with a ReentrantLock . Code: #pre

Question-33804394, answer-33814549
In this sort of situation I would write #pre Interestingly you say that the "try statement will never fail", but you still took the trouble to write a statement e.printStackTrace(args); that you claim will never be executed. Why? Perhaps your belief is not that firmly held. That is good (in my opinion), since your belief is not based on the code you wrote, but rather on the expectation that your client will not violate the precondition. Better to program public methods defensively. By the way, your code won't compile for me. You can't call a.clone(args) even if the type of a is Cloneable . At least Eclipse's compiler says so. Expression a.clone(args) gives error #blockquote What I would do for your specific case is #pre Where PubliclyCloneable is defined by #pre Or, if you absolutely need the parameter type to be Cloneable , the following at least compiles. #pre

Question-6608795
I wonder what the difference is between Class.getResource(args) and ClassLoader.getResource(args) ? edit: I especially want to know if any caching is involved on file/directory level. As in "are directory listings cached in the Class version?" AFAIK the following should essentially do the same, but they are not: #pre I discovered this when fiddling with some report generation code that creates a new file in WEB-INF/classes/ from an existing file in that directory. When using the method from Class, I could find files that were there at deployment using getClass(args).getResource(args) , but when trying to fetch the newly created file, I recieved a null object. Browsing the directory clearly shows that the new file is there. The filenames were prepended with a forward slash as in "/myFile.txt". The ClassLoader version of getResource(args) on the other hand did find the generated file. From this experience it seems that there is some kind of caching of the directory listing going on. Am I right, and if so, where is this documented? From the API docs on Class.getResource(args) #blockquote To me, this reads "Class.getResource is really calling its own classloader's getResource()". Which would be the same as doing getClass(args).getClassLoader(args).getResource(args) . But it is obviously not. Could someone please provide me with some illumination into this matter?

Question-17489250, answer-17489453
Java treats String as a special class, you can initialize in both ways #li Directly assigning literal String a = StringLiteral; #li As other Objects using new keyword String a = new String(args); You need to take special care when you wants to compare with == sign: #pre That is because in first case the objects a and b are kept in something called literal pool and they both are referencing same object so they are equal in both ways. But in second case a and b references different objects like when we initialize any other objects. so they are unequal when compared with == operator whereas they are equal in values.

Question-24885223, answer-29841832
Thanks to @marmor, I updated my answer. I think it's a good solution to handle the onClick() in the ViewHolder class constructor and pass it to the parent class via OnItemClickListener interface. MyAdapter.java #pre Usage of adapter in other classes: MyFragment.java #pre

Question-4871051, answer-21274808
Use CodeSource#getLocation() . This works fine in JAR files as well. You can obtain CodeSource by ProtectionDomain#getCodeSource() and the ProtectionDomain in turn can be obtained by Class#getProtectionDomain() . #pre

Question-23453287
One of the most useful features of Java 8 are the new default methods on interfaces. There are essentially two reasons (there may be others) why they have been introduced: #li Providing actual default implementations. Example: Iterator.remove() #li Allowing for JDK API evolution. Example: Iterable.forEach() From an API designer's perspective, I would have liked to be able to use other modifiers on interface methods, e.g. final . This would be useful when adding convenience methods, preventing "accidental" overrides in implementing classes: #pre The above is already common practice if Sender were a class: #pre Now, default and final are obviously contradicting keywords, but the default keyword itself would not have been strictly required , so I'm assuming that this contradiction is deliberate, to reflect the subtle differences between "class methods with body" (just methods) and "interface methods with body" (default methods), i.e. differences which I have not yet understood. At some point of time, support for modifiers like static and final on interface methods was not yet fully explored, citing Brian Goetz : #blockquote Since that time in late 2011, obviously, support for static methods in interfaces was added. Clearly, this added a lot of value to the JDK libraries themselves, such as with Comparator.comparing() . Question: What is the reason final (and also static final ) never made it to Java 8 interfaces?

Question-33147339, answer-33147762
I found this explanation : #blockquote In Java 6, if you use the API as: #pre And newCount overflows (this becomes negative), if(args) will return false and you may mistakenly assume that the ArrayList was increased by len .

Question-31370403, answer-31466466
Idea #1, storing the Graphics objects simply wouldn't work. The Graphics should not be considered as "holding" some display memory, but rather as a handle to access an area of display memory. In the case of BufferedImage , each Graphics object will be always the handle to the same given image memory buffer, so they all will represent the same image. Even more importantly, you can't actually do anything with the stored Graphics : As they do not store anything, there is no way whatsoever they could "re-store" anything. Idea #2, cloning the BufferedImage s is a much better idea, but you'll indeed be wasting memory, and quickly run out of it. It helps only to store those parts of the image affected by the draw, for example using rectangular areas, but it still costs a lot of memory. Buffering those undo images to disk could help, but it will make your UI slow and unresponsive, and that's bad ; furthermore, it makes you application more complex and error-prone . My alternative would be to store store the image modifications in a list, rendered from first to last on top of the image. An undo operation then simply consists of removing the modification from the list. This requires you to "reify" the image modifications , i.e. create a class that implements a single modification, by providing a void draw(args) method which performs the actual drawing. As you said, random modifications pose an additional problem. However, the key problem is your use of Math.random(args) to create random numbers. Instead, perform each random modification with a Random created from a fixed seed value, so that the (pseudo-)random number sequences are the same on each invocation of draw(args) , i.e., each draw has exactly the same effects. (That's why they are called "pseudo-random" -- the generated numbers look random, but they are just as deterministic as any other function.) In contrast to the image storing technique, which has memory problems, the problem with this technique is that many modifications may make the GUI slow, especially if the modifications are computationally intensive. To prevent this, the simplest way would be to fix an appropriate maximum size of the list of undoable modifications . If this limit would be exceeded by adding a new modification, remove the oldest modification the list and apply it to the backing BufferedImage itself. The following simple demo application shows that (and how) this all works together. It also includes a nice "redo" feature for redoing undone actions. #pre

Question-9324933
I looked at the default Zip library that comes with the JDK and the Apache compression libs and I am unhappy with them for 3 reasons: #li They are bloated and have bad API design. I have to write 50 lines of boiler plate byte array output, zip input, file out streams and close relevant streams and catch exceptions and move byte buffers on my own ? Why can't I have a simple API that looks like this Zipper.unzip(args) and Zipper.zip(args) that just works? #li It seems zipping unzipping destroys file meta-data and password handling is broken. #li Also, all the libraries I tried were 2-3x slow compared to the command line zip tools I get with UNIX? For me (2) and (3) are minor points but I really want a good tested library with a one-line interface.

Question-25903137, answer-25905196
Here are some variations on Sotirios Delimanolis' answer , which was pretty good to begin with (+1). Consider the following: #pre A couple points here. First is the use of wildcards in the generics; this makes the function somewhat more flexible. A wildcard would be necessary if, for example, you wanted the output map to have a key that's a superclass of the input map's key: #pre (There is also an example for the map's values, but it's really contrived, and I admit that having the bounded wildcard for Y only helps in edge cases.) A second point is that instead of running the stream over the input map's entrySet , I ran it over the keySet . This makes the code a little cleaner, I think, at the cost of having to fetch values out of the map instead of from the map entry. Incidentally, I initially had key -> key as the first argument to toMap(args) and this failed with a type inference error for some reason. Changing it to (X key) -> key worked, as did Function.identity(args) . Still another variation is as follows: #pre This uses Map.forEach(args) instead of streams. This is even simpler, I think, because it dispenses with the collectors, which are somewhat clumsy to use with maps. The reason is that Map.forEach(args) gives the key and value as separate parameters, whereas the stream has only one value -- and you have to choose whether to use the key or the map entry as that value. On the minus side, this lacks the rich, streamy goodness of the other approaches. :-)

Question-7655127, answer-7655177
String text = String.copyValueOf(args); or String text = String.valueOf(args); is arguably better (encapsulates the new String call).

Question-8579657, answer-33375616
Most of these answers miss the big picture, which is that, as far as the Java language is concerned, there is no more difference between t.start(args) and r.run(args) than there is between any other two methods. They're both just methods. They both run in the thread that called them . They both do whatever they were coded to do, and then they both return, still in the same thread, to their callers. The biggest difference is that most of the code for t.start(args) is native code while, in most cases, the code for r.run(args) is going to be pure Java. But that's not much of a difference. Code is code. Native code is harder to find, and harder to understand when you find it, but it's still just code that tells the computer what to do. So, what does t.start(args) do? It creates a new native thread, it arranges for that thread to call t.run(args) , and then it tells the OS to let the new thread run. Then it returns. And what does r.run(args) do? The funny thing is, the person asking this question is the person who wrote it . r.run(args) does whatever you (i.e., the developer who wrote it) designed it to do. t.start(args) is the method that the library provides for your code to call when you want a new thread. r.run(args) is the method that you provide for the library to call in the new thread.

Question-20358883, answer-31965160
With Java 8 Streams: Stream.of(args).collect(args) or if you need a set: Stream.of(args).collect(args)

Question-6252678, answer-6252802
You need a DateTimeFormatter appropriate to the format you're using. Take a look at the docs for instructions on how to build one. Off the cuff, I think you need format = DateTimeFormat.forPattern(args)

Question-20746429, answer-20765715
Such an operation ought to be possible with a Java 8 Stream , but it can't necessarily be done efficiently -- for example, you can't necessarily parallelize such an operation, as you have to look at elements in order. The API doesn't provide an easy way to do it, but what's probably the simplest way is to take Stream.iterator(args) , wrap the Iterator to have a "take-while" implementation, and then go back to a Spliterator and then a Stream . Or -- maybe -- wrap the Spliterator , though it can't really be split anymore in this implementation. Here's an untested implementation of takeWhile on a Spliterator : #pre

Question-5868369, answer-32542424
What you can do is scan the entire text using Scanner and go through the text line by line. Of course you should import the following: #pre Scanner basically scans all the text. The while loop is used to traverse through the entire text. The .hasNextLine(args) function is a boolean that returns true if there are still more lines in the text. The .nextLine(args) function gives you an entire line as a String which you can then use the way you want. Try System.out.println(args) to print the text. Side Note: .txt is the file type text.

Question-14602062, answer-14602092
From String.split() API Doc : #blockquote Overloaded String.split(regex, int) is more appropriate for your case.

Question-15182496, answer-15182578
The other answers explain why, but here is how: new Random(args).nextInt(args) The first 6 numbers that the above random generates are: #pre and the first 6 numbers that new Random(args).nextInt(args) generates are: #pre Then just add those numbers to the integer representation of the character ` (which is 96): #pre

Question-4818699, answer-4819109
If you look at the methods AtomicInteger has, you'll notice that they tend to correspond to common operations on ints. For instance: #pre is the thread-safe version of this: #pre The methods map like this: ++i is i.incrementAndGet(args) i++ is i.getAndIncrement(args) --i is i.decrementAndGet(args) i-- is i.getAndDecrement(args) i = x is i.set(args) x = i is x = i.get(args) There are other convenience methods as well, like compareAndSet or addAndGet

Question-29333689, answer-29341981
The best answer is already given (XOR-ing the elements), this is to provide an alternative, more general way. If the input array would be sorted (we can make it sorted), we could simply iterate over the elements in pairs (stepping by 2) and if the elements of the "pair" are different, we're done: #pre Note: This solution sorts the input array; if this is unwanted or not allowed, it can be cloned first: arr = arr.clone(args); If input array is sorted, the Arrays.sort(args) call can be left out of course. Generalization The advantage of this solution is that it can be applied to all types which are comparable and therefore can be sorted (types which implement Comparable ), for example String or Date . The XOR solution is limited to numbers only. Here is a slightly modified version which takes an input array of any element type which is comparable: #pre Note: In most cases you could also use arr[i].equals(args) to compare elements instead of using Comparable.compareTo() . For details read the linked javadoc. Quoting the relevant part: #blockquote Now you can call this with a String[] for example: System.out.println(args); Output: 2 Final notes: Starting from the problem statement it is not checked whether there are more than 2 occurrences of the elements, and neither is whether the array length is odd. Also the second example doesn't check for null values, these are to be added if necessary.
Question-16635398, answer-22502206
When reading this question one can get the impression, that Iterable#forEach in combination with lambda expressions is a shortcut/replacement for writing a traditional for-each loop. This is simply not true. This code from the OP: joins.forEach(args); is not intended as a shortcut for writing #pre and should certainly not be used in this way. Instead it is intended as a shortcut (although it is not exactly the same) for writing #pre And it is as a replacement for the following Java 7 code: #pre Replacing the body of a loop with a functional interface, as in the examples above, makes your code more explicit: You are saying that (1) the body of the loop does not affect the surrounding code and control flow, and (2) the body of the loop may be replaced with a different implementation of the function, without affecting the surrounding code. Not being able to access non final variables of the outer scope is not a deficit of functions/lambdas, it is a feature that distinguishes the semantics of Iterable#forEach from the semantics of a traditional for-each loop. Once one gets used to the syntax of Iterable#forEach , it makes the code more readable, because you immediately get this additional information about the code. Traditional for-each loops will certainly stay good practice (to avoid the overused term " best practice ") in Java. But this doesn't mean, that Iterable#forEach should be considered bad practice or bad style. It is always good practice, to use the right tool for doing the job, and this includes mixing traditional for-each loops with Iterable#forEach , where it makes sense. Since the downsides of Iterable#forEach have already been discussed in this thread, here are some reasons, why you might probably want to use Iterable#forEach : #li To make your code more explicit: As described above, Iterable#forEach can make your code more explicit and readable in some situations. #li To make your code more extensible and maintainable: Using a function as the body of a loop allows you to replace this function with different implementations (see Strategy Pattern ). You could e.g. easily replace the lambda expression with a method call, that may be overwritten by sub-classes: joins.forEach(args); Then you could provide default strategies using an enum, that implements the functional interface. This not only makes your code more extensible, it also increases maintainability because it decouples the loop implementation from the loop declaration. #li To make your code more debuggable: Seperating the loop implementation from the declaration can also make debugging more easy, because you could have a specialized debug implementation, that prints out debug messages, without the need to clutter your main code with if(args)System.out.println(args) . The debug implementation could e.g. be a delegate , that decorates the actual function implementation. #li To optimize performance-critical code: Contrary to some of the assertions in this thread, Iterable#forEach does already provide better performance than a traditional for-each loop, at least when using ArrayList and running Hotspot in "-client" mode. While this performance boost is small and negligible for most use cases, there are situations, where this extra performance can make a difference. E.g. library maintainers will certainly want to evaluate, if some of their existing loop implementations should be replaced with Iterable#forEach . To back this statement up with facts, I have done some micro-benchmarks with Caliper . Here is the test code (latest Caliper from git is needed): #pre And here are the results: #li Results for -client #li Results for -server When running with "-client", Iterable#forEach outperforms the traditional for loop over an ArrayList, but is still slower than directly iterating over an array. When running with "-server", the performance of all approaches is about the same. #li To provide optional support for parallel execution: It has already been said here, that the possibility to execute the functional interface of Iterable#forEach in parallel using streams , is certainly an important aspect. Since Collection#parallelStream(args) does not guarantee, that the loop is actually executed in parallel, one must consider this an optional feature. By iterating over your list with list.parallelStream(args).forEach(args); , you explicitly say: This loop supports parallel execution, but it does not depend on it. Again, this is a feature and not a deficit! By moving the decision for parallel execution away from your actual loop implementation, you allow optional optimization of your code, without affecting the code itself, which is a good thing. Also, if the default parallel stream implementation does not fit your needs, no one is preventing you from providing your own implementation. You could e.g. provide an optimized collection depending on the underlying operating system, on the size of the collection, on the number of cores, and on some preference settings: #pre The nice thing here is, that your loop implementation doesn't need to know or care about these details.

Question-14491966, answer-14526729
The real problem with this is that it's output histogram is dependent on the initial seed far to much - much of the time it will end up with a near uniform output but a lot of the time will have distinctly un-uniform output. Inspired by this article about how bad php's rand() function is , I made some random matrix images using QuickRandom and System.Random . This run shows how sometimes the seed can have a bad effect (in this case favouring lower numbers) where as System.Random is pretty uniform. QuickRandom #img System.Random #img Even Worse If we initialise QuickRandom as new QuickRandom(args) we get this image: #img The Code #pre

Question-32356762, answer-32357142
When returning List , you'll be promoting program to an interface , which is a very good practice. However, this approach has its limitation. For example, you cannot use some methods that are defined for ArrayList and don't exist in the List interface - See this answer for details. I'm quoting the API Design from the The Java™ Tutorials: #blockquote Since ArrayList is essentially an array, they are my first choice when I need to have a "collection-array". So if I want to convert enumeration to a list, my choice would be an array list. In any other cases, it's still valid to write: List<T> list = Collections.list(args);

Question-19418427, answer-19418548
As per my research, all the final String are interned in Java. From one of the blog post: #blockquote So it means if you call String.intern(args) you can compare two strings using == operator. But here String.intern(args) is not necessary because in Java final String are internally interned. You can find more information String comparision using == operator and Javadoc for String.intern() method. Also refer this Stackoverflow post for more information.

Question-14602062, answer-14602155
From the documentation of String.split(String regex) : #blockquote So you will have to use the two argument version String.split(String regex, int limit) with a negative value: String[] split = data.split(args); Doc: #blockquote This will not leave out any empty elements, including the trailing ones.

Question-7348711, answer-28043703
As others have noted, getting the hostname based on DNS resolution is unreliable. Since this question is unfortunately still relevant in 2016 , I'd like to share with you my network-independent solution, with some test runs on different systems. The following code tries to do the following: #li On Windows #li Read the COMPUTERNAME environment variable through System.getenv(args) . #li Execute hostname.exe and read the response #li On Linux #li Read the HOSTNAME environment variable through System.getenv(args) #li Execute hostname and read the response #li Read /etc/hostname (to do this I'm executing cat since the snippet already contains code to execute and read. Simply reading the file would be better, though). The code: #pre Results for different operating systems: OpenSuse 13.1 #pre Ubuntu 14.04 LTS This one is kinda strange since echo $HOSTNAME returns the correct hostname, but System.getenv(args) does not: #pre EDIT: According to legolas108 , System.getenv(args) works on Ubuntu 14.04 if you run export HOSTNAME before executing the Java code. Windows 7 #pre The machine names have been replaced but I kept the capitalization and structure. Note the extra newline when executing hostname , you might have to take it into account in some cases.

Question-7032070
Assuming that arraylist is defined as ArrayList<T> arraylist , is arraylist.removeAll(arraylist) equivalent to arraylist.clear() ? If so, can I assume that the clear(args) method is more efficient for emptying the array list? Are there any caveats in using arraylist.removeAll(args) instead of arraylist.clear(args) ?

Question-5585779, answer-5585876
For example, here are two ways: #pre There is a slight difference between these methods: #li valueOf returns a new or cached instance of java.lang.Integer #li parseInt returns primitive int . The same is for all cases: Short.valueOf / parseShort , Long.valueOf / parseLong , etc.

Question-6470651, answer-18544736
Threads are not collected until they terminate. They serve as roots of garbage collection. They are one of the few objects that won't be reclaimed simply by forgetting about them or clearing references to them. Consider: the basic pattern to terminate a worker thread is to set some condition variable seen by the thread. The thread can check the variable periodically and use that as a signal to terminate. If the variable is not declared volatile , then the change to the variable might not be seen by the thread, so it won't know to terminate. Or imagine if some threads want to update a shared object, but deadlock while trying to lock on it. If you only have a handful of threads these bugs will probably be obvious because your program will stop working properly. If you have a thread pool that creates more threads as needed, then the obsolete/stuck threads might not be noticed, and will accumulate indefinitely, causing a memory leak. Threads are likely to use other data in your application, so will also prevent anything they directly reference from ever being collected. As a toy example: #pre Call System.gc(args) all you like, but the object passed to leakMe will never die. (*edited*)

Question-20877086, answer-20889556
To complement the given answers, also take note of the following: #pre This code will also print: false As user Jay has claimed in a comment for the accepted answer, care must be taken when using operator == on objects, here you're checking if both references are the same, which is not, because they are different objets, although they represent the very same value. To compare objects, you should use the equals method instead: #pre This will print: true You may ask, But then why the first line printed true ? . Checking the source code for the Integer.valueOf method, you can see the following: #pre If the param is an integer between IntegerCache.low (defaulted to -128) and IntegerCache.high (calculated at runtime with minimum value 127) then a pre-allocated (cached) object is returned. So when you use 127 as parameter, you're getting two references to same cached object and getting true in the comparison of the references.

Question-16252269, answer-16252296
Use util method of java.util.Collections class, i.e Collections.sort(args) In fact, if you want to sort custom object you can use Collections.sort(args) see collections api

Question-6667243, answer-6667310
You can use Mode.mode1.name(args) however you often don't need to do this. Mode mode = System.out.println(args);

Question-5785745, answer-15962949
If you want to make a copy of: int[] a = {1,2,3,4,5}; This is the way to go: int[] b = Arrays.copyOf(args); Arrays.copyOf may be faster than a.clone(args) on small arrays. Both copy elements equally fast but clone() returns Object so the compiler has to insert an implicit cast to int[] . You can see it in the bytecode, something like this: #pre

Question-6094575, answer-26159586
when using (i.e.) getConstructor(args) the constructor has to be declared public. Otherwise a NoSuchMethodException is thrown. if you want to access a non-public constructor you have to use instead (i.e.) getDeclaredConstructor(args) .

Question-32175145, answer-32182250
Integer a.equals( a ) can return false But you have to be really evil and use reflections and Multithreading: If you run this code, there is a chance that a racing condition can change the internal Value of myInt while the comparision takes place. If you want to simulate this condition, just set a breakpoint inside of Integer.intValue(args) run the code in debug and hit continue. This will create a delay which creates the race condition artificially and the console will return false. #pre

Question-31922866, answer-39005452
The best post I've seen on the topic was written by Daniel Olszewski and can be found at #a . While others mention when you should or should not use Optional, this post actually explains why . Cross-posting here in case the link goes down: #blockquote

Question-22036885, answer-22037068
As said in API #blockquote It's because of cannot represent double value exactly. So you have to use BigDecimal bigDecimal = BigDecimal.valueOf(args); instead of BigDecimal bigDecimal = new BigDecimal(args);

Question-8172420, answer-8172439
You can use Character.toString(char) . Note that this method simply returns a call to String.valueOf(char) , which also works. As others have noted, string concatenation works as a shortcut as well: String s = StringLiteral + CharLiteral; But this compiles down to: String s = new StringBuilder(args).append(args).append(args).toString(args); which is less efficient because the StringBuilder is backed by a char[] (over-allocated by StringBuilder() to 16 ), only for that array to be defensively copied by the resulting String . String.valueOf(args) "gets in the back door" by wrapping the char in a single-element array and passing it to the package private constructor String(char[], boolean) , which avoids the array copy.

Question-6271417, answer-6271668
I'm assuming this is happening for an anonymous class. When you create an anonymous class you actually create a class that extends the class whose name you got. The "cleaner" way to get the name you want is: If your class is an anonymous inner class, getSuperClass(args) should give you the class that it was created from. If you created it from an interface than you're sort of SOL because the best you can do is getInterfaces(args) which might give you more than one interface. The "hacky" way is to just get the name with getClassName(args) and use a regex to drop the $1 .

Question-5243754, answer-25074487
- getParameter() : #pre request.getParameter(args) will get the value from the posted form of the input box named "testParam" which is "Client param". It will then print it out, so you should see "Client Param" on the screen. So request.getParameter() will retrieve a value that the client has submitted. You will get the value on the server side. - getAttribute() : request.getAttribute(args) , this is all done server side. YOU add the attribute to the request and YOU submit the request to another resource, the client does not know about this. So all the code handling this would typically be in servlets.getAttribute always return object.

Question-5192512, answer-5193094
There are basically two alternatives, using setLength(args) to reset the StringBuilder or creating a new one in each iteration. Both can have pros and cons depending on the usage. If you know the expected capacity of the StringBuilder beforehand, creating a new one each time should be just as fast as setting a new length. It will also help the garbage collector, since each StringBuilder will be relatively short-lived and the gc is optimized for that. When you don't know the capacity, reusing the same StringBuilder might be faster. Each time you exceed the capacity when appending, a new backing array has to be allocated and the previous content has to be copied. By reusing the same StringBuilder, it will reach the needed capacity after some iterations and there won't be any copying thereafter.

Question-29494800, answer-29495065
#li It is checking if newType is array of Objects or not: #pre Why to do that? Because new Object[n] is faster than Array.newInstance #li Array.newInstance(args) creates an array of types defined by the first argument, eg String.class -> String[] . Note that String[].class.getComponentType(args) returns String.class #li You cannot use it like that, but it can be like this Integer[] nums = Arrays.copyOf(args); in this case it depends only on actual type of elements, eg Arrays.copyOf(args); will fail, you cannot write in Integer[] anything but Integer

Question-24603186, answer-24603187
The Javadocs for Collection.(parallelS|s)tream(args) and Stream itself don't answer the question, so it's off to the mailing lists for the rationale. I went through the lambda-libs-spec-observers archives and found one thread specifically about Collection.parallelStream() and another thread that touched on whether java.util.Arrays should provide parallelStream() to match (or actually, whether it should be removed). There was no once-and-for-all conclusion, so perhaps I've missed something from another list or the matter was settled in private discussion. (Perhaps Brian Goetz , one of the principals of this discussion, can fill in anything missing.) The participants made their points well, so this answer is mostly just an organization of the relevant quotes, with a few clarifications in [brackets] , presented in order of importance (as I interpret it). parallelStream() covers a very common case Brian Goetz in the first thread, explaining why Collections.parallelStream(args) is valuable enough to keep even after other parallel stream factory methods have been removed: #blockquote Brian Goetz stands by this position in the later discussion about Arrays.parallelStream(args) : #blockquote parallelStream() is more performant Brian Goetz : #blockquote In response to Kevin Bourrillion's skepticism about whether the effect is significant, Brian again : #blockquote Doug Lea follows up , but hedges his position: #blockquote Indeed, the later discussion about Arrays.parallelStream(args) takes notice of lower Stream.parallel() cost . stream().parallel() statefulness complicates the future At the time of the discussion, switching a stream from sequential to parallel and back could be interleaved with other stream operations. Brian Goetz, on behalf of Doug Lea , explains why sequential/parallel mode switching may complicate future development of the Java platform: #blockquote This mode switching was removed after further discussion . In the current version of the library, a stream pipeline is either sequential or parallel; last call to sequential(args) / parallel(args) wins. Besides side-stepping the statefulness problem, this change also improved the performance of using parallel(args) to set up a parallel pipeline from a sequential stream factory. exposing parallelStream() as a first-class citizen improves programmer perception of the library, leading them to write better code Brian Goetz again , in response to Tim Peierls's argument that Stream.parallel(args) allows programmers to understand streams sequentially before going parallel: #blockquote

Question-9510125, answer-9511578
Just IMHO. Not sure it's 100% correct. invalidate(args) marks the container as invalid. Means the content is somehow wrong and must be relayed out. But it's just a kind of mark/flag. It's possible that multiple invalid containers must be refreshed later. validate(args) performs relayout. It means invalid content is asked for all the sizes and all the subcomponents' sizes are set to proper values by LayoutManager . revalidate(args) is just sum of both. It marks the container as invalid and performs layout of the container.

Question-21242110, answer-27378709
Better way is: #pre Advantages of this version: #li works regardless the input is an instance of java.util.Date or it's subclass java.sql.Date (unlike @JodaStephen's way). This is common with JDBC originated data. java.sql.Date.toInstant(args) always throws an exception. #li it's the same for JDK8 and JDK7 with JSR-310 backport I personally use an utility class (but this is not backport-compatible): #pre The asLocalDate(args) method here is null-safe, uses toLocalDate(args) , if input is java.sql.Date (it may be overriden by the JDBC driver to avoid timezone problems or unnecessary calculations), otherwise uses the abovementioned method.

Question-27683759
I just studied about generic programming, the List<T> interface, and ArrayList , so I can understand the statement below. ArrayList<T> list = new ArrayList<T>(args); But I don't understand the next statement which I saw while surfing the web. List<T> list2 = Collections.<String>emptyList(args); #li What is Collections ? Why isn't it Collections<T> or Collections<T> ? #li Why is <String> placed before the method name emptyList ? (Isn't emptyList<T>(args) correct for Generic?) #li What does the statement mean?

Question-22561614, answer-22561687
This works because Integer::min resolves to an implementation of the Comparable<T> interface. The method reference of Integer::min resolves to Integer.min(args) , resolved to IntBinaryOperator , and presumably autoboxing occurs somewhere making it a BinaryOperator<T> . And the min(args) resp max(args) methods of the Stream<T> ask the Comparable<T> interface to be implemented. Now this resolves to the single method Integer compareTo(args) . Which is of type BinaryOperator<T> . And thus the magic has happened as both methods are a BinaryOperator<T> .

Question-28319064, answer-28319221
Don't worry about any performance differences, they're going to be minimal in this case normally. Method 2 is preferable because #li it doesn't require mutating a collection that exists outside the lambda expression, #li it's more readable because the different steps that are performed in the collection pipeline are written sequentially (first a filter operation, then a map operation, then collecting the result), (for more info on the benefits of collection pipelines, see Martin Fowler's excellent article ) #li you can easily change the way values are collected by replacing the Collector that is used. In some cases you may need to write your own Collector , but then the benefit is that you can easily reuse that.

Question-12552863
The Java 7 try-with-resources syntax (also known as ARM block ( Automatic Resource Management )) is nice, short and straightforward when using only one AutoCloseable resource. However, I am not sure what is the correct idiom when I need to declare multiple resources that are dependent on each other, for example a FileWriter and a BufferedWriter that wraps it. Of course, this question concerns any case when some AutoCloseable resources are wrapped, not only these two specific classes. I came up with the three following alternatives: 1) The naive idiom I have seen is to declare only the top-level wrapper in the ARM-managed variable: #pre This is nice and short, but it is broken. Because the underlying FileWriter is not declared in a variable, it will never be closed directly in the generated finally block. It will be closed only through the close method of the wrapping BufferedWriter . The problem is, that if an exception is thrown from the bw 's constructor, it's close will not be called and therefore the underlying FileWriter will not be closed . 2) #pre Here, both the underlying and the wrapping resource are declared in the ARM-managed variables, so both of them will be certainly closed, so certainly that the underlying fw.close(args) will be called twice , first directly and for the second time through the wrapping bw.close(args) . This should not be a problem for these two specific classes that both implement Closeable (which is a subtype of AutoCloseable ), whose contract states that multiple calls to close are permitted: #blockquote However, in a general case, I can have resources that do implement only AutoCloseable (and not Closeable ), which doesn't guarantee that the close can be called multiple times: #blockquote 3) #pre This version should be theoretically correct, because only the fw represents a real resource that needs to be cleaned up. The bw does't itself hold any resource, it only delegates to the fw , so it should be sufficient to only close the underlying fw . On the other hand, the syntax is a bit irregular and also, Eclipse issues a warning, which I believe is a false alarm, but it is still a warning that one has to deal with: #blockquote So, which approach to go for? Or have I missed some other idiom that is the correct one?

Question-27625611, answer-27625722
Because nextDouble works like this: ( source ) #pre next(args) makes x random bits. Now why does this matter? Because about half the numbers generated by the first part (before the division) are less than 1L << 52 , and therefore their significand doesn't entirely fill the 53 bits that it could fill, meaning the least significant bit of the significand is always zero for those. Because of the amount of attention this is receiving, here's some extra explanation of what a double in Java (and many other languages) really looks like and why it mattered in this question. Basically, a double looks like this: ( source ) #img A very important detail not visible in this picture is that numbers are "normalized" 1 such that the 53 bit fraction starts with a 1 (by choosing the exponent such that it is so), that 1 is then omitted. That is why the picture shows 52 bits for the fraction (significand) but there are effectively 53 bits in it. The normalization means that if in the code for nextDouble the 53rd bit is set, that bit is the implicit leading 1 and it goes away, and the other 52 bits are copied literally to the significand of the resulting double . If that bit is not set however, the remaining bits must be shifted left until it becomes set. On average, half the generated numbers fall into the case where the significand was not shifted left at all (and about half those have a 0 as their least significant bit), and the other half is shifted by at least 1 (or is just completely zero) so their least significant bit is always 0. 1: not always, clearly it cannot be done for zero, which has no highest 1. These numbers are called denormal or subnormal numbers, see wikipedia:denormal number .

Question-4772425, answer-18953213
remove one y form SimpleDateFormat dt1 = new SimpleDateFormat(args); should be SimpleDateFormat dt1 = new SimpleDateFormat(args);

Question-20358883, answer-20358920
Fixed size List The easiest way, that I know of, is to create a fixed-size single element List with Arrays.asList(T...) like // Returns a List backed by a varargs T. return Arrays.asList(args); Variable size List If it needs vary in size you can construct an ArrayList and the fixed-size List like return new ArrayList<T>(args); and (in Java 7+) you can use the diamond operator <> to make it return new ArrayList<T>(args);

Question-8275499, answer-17397548
As for the code example in the question, the standard solution is to reference the class explicitly by its name, and it is even possible to do without getClassLoader(args) call: #pre This approach still has a back side that it is not very safe against copy/paste errors in case you need to replicate this code to a number of similar classes. And as for the exact question in the headline, there is a trick posted in the adjacent thread : Class currentClass = new Object(args) { }.getClass(args).getEnclosingClass(args); It uses a nested anonymous Object subclass to get hold of the execution context. This trick has a benefit of being copy/paste safe... It may be also worth noting that if this snippet is shaped as a static method of some base class, then currenClass value will always be a reference to that base class rather than to any subclass that may be using that method.

Question-29922296
I'm wondering what the best way is in Java 8 to work with all the values of an enum. Specifically when you need to get all the values and add it to somewhere, for example, supposing that we have the following enum: #pre I could of course do the following: #pre But, I could also add the following method to the enum definition: #pre And then replace the for from above with: Letter.stream(args).forEach(args); Is this approach OK or does it have some fault in design or performance? Moreover, why don't enums have a stream() method?

Question-31445024
I'm trying to determine whether the following statements are guaranteed to be true: #pre I've always assumed that autoboxing was equivalent to calling valueOf(args) on the corresponding type. Every discussion that I've seen on the topic seems to support my assumption. But all I could find in the JLS was the following ( §5.1.7 ): #blockquote That describes behavior identical to that of valueOf(args) . But there doesn't seem to be any guarantee that valueOf(args) is actually invoked, meaning there could theoretically be an implementation that keeps a separate, dedicated cache for autoboxed values. In such a case, there might not be identity equality between cached autoboxed values and regular cached boxed values. Oracle's autoboxing tutorial states matter-of-factly that li.add(args) is compiled to li.add(args) , where i is an int . But I don't know whether the tutorial should be considered an authoritative source.

Question-32475166, answer-32475290
The chief difference is that an if else block is a statement whereas the ternary (more often known as the conditional operator in Java) is an expression . A statement can do things like return to the caller on some of the control paths. An expression can be used in an assignment: int n = condition ? 3 : 2; So the two expressions in the ternary after the condition need to be coercable to the same type. This can cause some odd effects in Java particularly with auto-boxing and automatic reference casting - this is what the comment in your posted code is referring to. The coercion of the expressions in your case would be to a java.lang.reflect.Executable type (as that's the most specialised type ) and that does not exist in older versions of Java. Stylistically you should use an if else block if the code is statement-like, and a ternary if it's expression-like. Of course, you can make an if else block behave like an expression if you use a lambda function.

Question-31696485, answer-31696584
Your question is based on assumption that the code which may throw NullPointerException is worse than the code which may not. This assumption is wrong. If you expect that your foobar is never null due to the program logic, it's much better to use Optional.of(args) as you will see a NullPointerException which will indicate that your program has a bug. If you use Optional.ofNullable(args) and the foobar happens to be null due to the bug, then your program will silently continue working incorrectly, which may be a bigger disaster. This way an error may occur much later and it would be much harder to understand at which point it went wrong.
Question-24631909, answer-24635657
Common features a) Both libraries use immutable types. Joda-Time also offers additional mutable types like MutableDateTime . b) Furthermore: Both libraries are inspired by the design study "TimeAndMoney" from Eric Evans or ideas from Martin Fowler about domain driven style so they strive more or less for a fluent programming style (although not always perfect ;-)). c) With both libraries we get a real calendar date type (called LocalDate ), a real wall time type (called LocalTime ) and the composition (called LocalDateTime ). That is a very big win compared with old java.util.Calendar and java.util.Date . d) Both libraries use a method-centric approach meaning they encourage the user to use getDayOfYear(args) instead of get(args) . This causes a lot of extra methods compared with java.util.Calendar (although latter is not type-safe at all due to excessive use of ints). Performance See the other answer by @OO7 pointing to the analysis of Mikhail Vorontsov although point 3 (exception catching) is probably obsolete - see this JDK-bug . The different performance (which is in general favour of JSR-310 ) is mainly due to the fact that the internal implementation of Joda-Time always use a machine-time-like long-primitive (in milliseconds). Null Joda-Time often use NULL as default for system timezone, default locale, current timestamp etc. while JSR-310 almost always rejects NULL values. Precision JSR-310 handles nanosecond precision while Joda-Time is limited to millisecond precision. Supported fields: An overview about supported fields in Java-8 (JSR-310) is given by some classes in the temporal-package (for example ChronoField and WeekFields ) while Joda-Time is rather weak on this area - see DateTimeFieldType . The biggest lack of Joda-Time is here the absence of localized week-related fields. A common feature of both field implementation design is that both are based on values of type long (no other types, not even enums). Enum JSR-310 offers enums like DayOfWeek or Month while Joda-Time does not offer this because it was mainly developed in years 2002-2004 before Java 5 . Zone API a) JSR-310 offers more timezone features than Joda-Time. Latter is not able to yield a programmatical access to the history of timezone offset transitions while JSR-310 is capable to do this. b) For your information: JSR-310 has moved its internal timezone repository to a new location and a different format. The old library folder lib/zi does not exist any more. Adjuster vs. Property JSR-310 has introduced the TemporalAdjuster -interface as a formalized way to externalize temporal calculations and manipulations, especially for library or framework-writers this is a nice and relative easy way to embed new extensions of JSR-310 (a kind of equivalent to static helper classes for former java.util.Date ). For most users however, this feature has very limited value because the burden to write code is still with the user. Built-in solutions based on the new TemporalAdjuster -concept are not so many, there is currently only the helper class TemporalAdjusters with a limited set of manipulations (and the enums Month or other temporal types). Joda-Time offers a field-package but practice has shown evidence that new field implementations are very hard to code. On the other side Joda-Time offers so-called properties which make some manipulations much easier and more elegant than in JSR-310, for example property.withMaximumValue() . Calendar systems JSR-310 offers 4 extra calendar systems. The most interesting one is Umalqura (used in Saudi Arabia). The other 3 are: Minguo (Taiwan), Japanese (only the modern calendar since 1871!) and ThaiBuddhist (only correct after 1940). Joda-Time offers an Islamic calendar based on calculatory base - not a sighting-based calendar like Umalqura. Thai-Buddhist is also offered by Joda-Time in a similar form, Minguo and the japanese one not. Otherwise Joda-Time offers coptic and ethiopic calendar, too (but without any support for internationalization). More interesting for Europeans: Joda-Time also offers a Gregorian , Julian and mixed-gregorian-julian calendar. However, the practical value for real historical calculations is limited because important features like different year starts in date history are not supported at all (the same criticism is valid for old java.util.GregorianCalendar ). Other calendars like Hebrew or Persian or Hindu are completely missing in both libraries. Epoch days JSR-310 has the class JulianFields while Joda-Time (version 2.0) offers some helper methods in the class DateTimeUtils . Clocks JSR-310 has no interface (a design mistake) but an abstract class java.time.Clock which can be used for any clock dependency injection. Joda-Time offers the interface MillisProvider and some helper methods in DateTimeUtils instead. So this way Joda-Time is also capable of supporting test-driven models with different clocks (mocking etc.). Duration arithmetic Both libraries support the calculation of time distances in one or more temporal units. However, when handling single-unit-durations the JSR-310-style is obviously nicer (and long-based instead of using int): JSR-310 => long days = ChronoUnit.DAYS.between(args); Joda-Time => int days = DAYS.daysBetween(args).getDays(args); Handling of multiple-unit-durations are also different. Even the calculation results can differ - see this closed Joda-Time issue . While JSR-310 use a very simple and limited approach to use just the classes Period (duration based on years, months and days) and Duration (based on seconds and nanoseconds), Joda-Time uses a more sophisticated way using the class PeriodType in order to control in which units a duration (Joda-Time call it "Period") shall be expressed. While the PeriodType -API is somehow awkward to use a similar way is not offered by JSR-310 at all. Especially it is not yet possible in JSR-310 to define mixed date and time durations (based on days and hours for example). So be warned if it comes to migration from one library to another. The libraries in discussion are incompatible - despite of partially same class names. Intervals JSR-310 does not support this feature while Joda-Time has limited support. See also this SO-answer . Formatting and Parsing Best way to compare both libraries is to view the equal-named classes DateTimeFormatterBuilder (JSR-310) and DateTimeFormatterBuilder (Joda-Time). The JSR-310-variant is a little bit more powerful (can also handle any kind of TemporalField provided the field implementor has managed to code some extension points like resolve() ). Most important difference is however - in my opinion: JSR-310 can much better parse timezone names (format pattern symbol z) while Joda-Time could not do this at all in its earlier versions and now only in a very limited way. Another advantage of JSR-310 is support for standalone month names which is important in languages like Russian or Polish etc. Joda-Time has no access to such resources - not even on Java-8 platforms. The pattern syntax in JSR-310 is also more flexible than in Joda-Time, allows for optional sections (using square brackets), is more orientated towards CLDR-standard and offers padding (letter symbol p) and more fields. Otherwise it should be noted that Joda-Time can format durations using PeriodFormatter . JSR-310 cannot do this. Hope this overview helps. All the gathered information is mainly there due to my efforts and investigations how to design and implement a better date-and-time library (nothing is perfect). Update from 2015-06-24: Meanwhile I have found the time to write and publish a tabular overview for different time libraries in Java. The tables also contain a comparison between Joda-Time v2.8.1 and Java-8 (JSR-310). It is more detailed than this post.

Question-23699371, answer-34731808
You can use the distinct(args) method in Eclipse Collections . #pre If you can refactor persons to implement an Eclipse Collections interface, you can call the method directly on the list. #pre HashingStrategy is simply a strategy interface that allows you to define custom implementations of equals and hashcode. #pre Note: I am a committer for Eclipse Collections.

Question-15156857
I have a method with a void return type. It can also throw a number of exceptions so I'd like to test those exceptions being thrown. All attempts have failed with the same reason: #blockquote Any ideas how I can get the method to throw a specified exception? doThrow(args).when(args);

Question-8777257, answer-8777266
It's a famous problem: .equals(args) for arrays is badly broken, just don't use it, ever. That said, it's not "broken" as in "someone has done it in a really wrong way" — it's just doing what's defined and not what's usually expected. So for purists: it's perfectly fine, and that also means, don't use it, ever. Now the expected behaviour for equals is to compare data. The default behaviour is to compare the identity, as Object does not have any data (for purists: yes it has, but it's not the point); assumption is, if you need equals in subclasses, you'll implement it. In arrays, there's no implementation for you, so you're not supposed to use it. So the difference is, Arrays.equals(args) works as you would expect (i.e. compares content), array1.equals(args) falls back to Object.equals implementation, which in turn compares identity, and thus better replaced by == (for purists: yes I know about null ). Problem is, even Arrays.equals(args) will bite you hard if elements of array do not implement equals properly. It's a very naive statement, I know, but there's a very important less-than-obvious case: consider a 2D array. 2D array in Java is an array of arrays, and arrays' equals is broken (or useless if you prefer), so Arrays.equals(args) will not work as you expect on 2D arrays. Hope that helps.

Question-4812570, answer-4812585
You have to use getStackTrace(args) method instead of printStackTrace(args) . Here is a good example : #pre

Question-6608795, answer-20069798
All these answers around here, as well as the answers in this question , suggest that loading absolute URLs, like "/foo/bar.properties" treated the same by class.getResourceAsStream(args) and class.getClassLoader(args).getResourceAsStream(args) . This is NOT the case, at least not in my Tomcat configuration/version (currently 7.0.40). #pre Sorry, I have absolutely no satisfying explanation, but I guess that tomcat does dirty tricks and his black magic with the classloaders and cause the difference. I always used class.getResourceAsStream(args) in the past and haven't had any problems. PS: I also posted this over here

Question-17828584, answer-17836189
I think the others have done a good job at explaining why cnt > 0, but there's not enough details regarding why cnt = 4, and why cnt varies so widely among different settings. I will attempt to fill that void here. Let #li X be the total stack size #li M be the stack space used when we enter main the first time #li R be the stack space increase each time we enter into main #li P be the stack space necessary to run System.out.println When we first get into main, the space left over is X-M. Each recursive call takes up R more memory. So for 1 recursive call (1 more than original), the memory use is M + R. Suppose that StackOverflowError is thrown after C successful recursive calls, that is, M + C * R <= X and M + C * (R + 1) > X. At the time of the first StackOverflowError, there's X - M - C * R memory left. To be able to run System.out.prinln , we need P amount of space left on the stack. If it so happens that X - M - C * R >= P, then 0 will be printed. If P requires more space, then we remove frames from the stack, gaining R memory at the cost of cnt++. When println is finally able to run, X - M - (C - cnt) * R >= P. So if P is large for a particular system, then cnt will be large. Let's look at this with some examples. Example 1: Suppose #li X = 100 #li M = 1 #li R = 2 #li P = 1 Then C = floor((X-M)/R) = 49, and cnt = ceiling((P - (X - M - C*R))/R) = 0. Example 2: Suppose that #li X = 100 #li M = 1 #li R = 5 #li P = 12 Then C = 19, and cnt = 2. Example 3: Suppose that #li X = 101 #li M = 1 #li R = 5 #li P = 12 Then C = 20, and cnt = 3. Example 4: Suppose that #li X = 101 #li M = 2 #li R = 5 #li P = 12 Then C = 19, and cnt = 2. Thus, we see that both the system (M, R, and P) and the stack size (X) affects cnt. As a side note, it does not matter how much space catch requires to start. As long as there is not enough space for catch , then cnt will not increase, so there are no external effects. EDIT I take back what I said about catch . It does play a role. Suppose it requires T amount of space to start. cnt starts to increment when the leftover space is greater than T, and println runs when the leftover space is greater than T + P. This adds an extra step to the calculations and further muddies up the already muddy analysis. EDIT I finally found time to run some experiments to back up my theory. Unfortunately, the theory doesn't seem to match up with the experiments. What actually happens is very different. Experiment setup: Ubuntu 12.04 server with default java and default-jdk. Xss starting at 70,000 at 1 byte increments to 460,000. The results are available at: #a I've created another version where every repeated data point is removed. In other words, only points that are different from the previous are shown. This makes it easier to see anomalies. #a

Question-6684665, answer-6684935
If you want to convert the string back into a byte array you will need to use String.getBytes(args) (or equivalent Python function) and this will allow you print out the original byte array.

Question-34509566, answer-34509659
Four things are going on: #li (You clearly know this, but for lurkers) == tests to see if the variables point to the same String object , not equivalent strings. So even if x is StringLiteral and y is also StringLiteral , x == y may be true or false, depending on whether x and y refer to the same String object or different ones. That's why we use equals , not == , to compare strings for equivalence. All of the following is just meant to explain why == is sometimes true, it's not a suggestion to use == to compare strings. :-) #li Equivalent string constants (strings the compiler knows are constants according to various rules in the JLS) within the same class are made to refer to the same string by the compiler (which also lists them in the class's "constant pool" ). That's why a == b is true. #li When the class is loaded, each of its string constants is automatically interned — the JVM's string pool is checked for an equivalent string and if one is found, that String object is used (if not, the new String object for the new constant is added to the pool). So even if x is a string constant initialized in class Foo and y is a string constant initialized in class Bar , they'll be == each other. Points 2 and 3 above are covered in part by JLS§3.10.5 . (The bit about the class constant pool is a bit of an implementation detail, hence the link to the JVM spec earlier; the JLS just speaks of interning.) #li The compiler does string concatenation if it's dealing with constant values, so String d = StringLiteral + StringLiteral; is compiled to String d = StringLiteral; and StringLiteral is a string constant the compiler and JVM apply points 2 and 3 above to. E.g., no StringBuilder is used, the concatenation happens at compile-time , not runtime. This is covered in JLS§15.28 - Constant Expressions . So a == d is true for the same reason a == b is true: They refer to the same constant string, so the compiler ensured they were referring to the same string in the class's constant pool. The compiler can't do that when any of the operands is not a constant, so it can't do that with: String e = c + StringLiteral; ...even though code analysis could easily show that the value of c will definitely be StringLiteral and thus e will definitely be StringLiteral . The specification only has the compiler do the concatenation with constant values, specifically. So since the compiler can't do it, it outputs the StringBuilder code you referred to and that work is done at runtime, creating a new String object. That string isn't automatically interned, so e ends up referring to a different String object than a does, and so a == e is false. Note that as Vinod said , if you declared c as final : final String c = StringLiteral; Then it would be a constant variable (yes, they're really called that) and so §15.28 would apply and the compiler would turn String e = c + StringLiteral; into String e = StringLiteral; and a == e would also be true. Just to reiterate: None of which means we should use == to compare strings for equivalence. :-) That's what equals is for.

Question-16148575, answer-16149160
HashMap does not allow primitive data types as arguments. It can only accept objects so HashMap<T> myMap = new HashMap<T>(args); will not work. You have to change the declaration to HashMap<T> myMap = new HashMap<T>(args); so even when you do the following myMap.put(args); The primitive data type is autoboxed to an Integer object. 8(args) === boxing ===> 8(args) You can read more on autoboxing here #a

Question-13291076
If you look in the enum api at the method name(args) it says that: #blockquote Why is better to use toString(args) ? I mean toString may be overridden when name() is already final. So if you use toString and someone overrides it to return a hard-coded value your whole application is down... Also if you look in the sources the toString() method returns exactly and just the name. It's the same thing.

Question-32294367, answer-32294898
#blockquote Let me ask a counterquestion: why do you think Thread.stop(args) has been deprecated for more than a decade? The reason why is precisely the negation of your statement above. To give two specific examples: you stop(args) a thread while it's executing something as innocuous-sounding as System.out.println(args) or Math.random(args) . Result: those two features are now broken for the entire JVM. The same pertains to any other synchronized code your application may execute. #blockquote The application may theoretically be coded such that absolutely no shared resource protected by locks is ever used; however that will only help to point out the exact extent to which Java threads are codependent. And the "independence" achieved will only pertain to the request-processing threads, not to all threads in such an application.

Question-23674624, answer-23674719
IntStream.boxed turns an IntStream into a Stream<T> , which you can then collect into a list: theIntStream.boxed(args).collect(args)

Question-20001427, answer-20001866
Usually, one would call the reduce method using Math.max(args) as follows: #pre That requires a lot of syntax for just calling Math.max . That's where lambda expressions come into play. Since Java 8 it is allowed to do the same thing in a much shorter way: reduce(args); How does this work? The java compiler "detects", that you want to implement a method that accepts two int s and returns one int . This is equivalent to the formal parameters of the one and only method of interface IntBinaryOperator (the parameter of method reduce you want to call). So the compiler does the rest for you - it just assumes you want to implement IntBinaryOperator . But as Math.max(args) itself fulfills the formal requirements of IntBinaryOperator , it can be used directly. Because Java 7 does not have any syntax that allows a method itself to be passed as an argument (you can only pass method results, but never method references), the :: syntax was introduced in Java 8 to reference methods: reduce(args); Note that this will be interpreted by the compiler, not by the JVM at runtime! Although it produces different bytecodes for all three code snippets, they are semantically equal, so the last two can be considered to be short (and probably more efficient) versions of the IntBinaryOperator implementation above! (See also Translation of Lambda Expressions )

Question-11359187
For the first time in my life I find myself in a position where I'm writing a Java API that will be open sourced. Hopefully to be included in many other projects. For logging I (and indeed the people I work with) have always used JUL (java.util.logging) and never had any issues with it. However now I need to understand in more detail what I should do for my API development. I've done some research on this and with the information I've got I just get more confused. Hence this post. Since I come from JUL I'm biased on that. My knowledge of the rest is not that big. From the research I've done I've come up with these reasons why people do not like JUL: #li "I started developing in Java long before Sun released JUL and it was just easier for me to continue with logging-framework-X rather than to learn something new" . Hmm. I'm not kidding, this is actually what people say. With this argument we could all be doing COBOL. (however I can certainly relate to this being a lazy dude myself) #li "I don't like the names of the logging levels in JUL" . Ok, seriously, this is just not enough of a reason to introduce a new dependency. #li "I don't like the standard format of the output from JUL" . Hmm. This is just configuration. You do not even have to do anything code-wise. (true, back in old days you may have had to create your own Formatter class to get it right). #li "I use other libraries that also use logging-framework-X so I thought it easier just to use that one" . This is a cyclic argument, isn't ? Why does 'everybody' use logging-framework-X and not JUL? #li "Everybody else is using logging-framework-X" . This to me is just a special case of the above. Majority is not always right. So the real big question is why not JUL? . What is it I have missed ? The raison d'être for logging facades (SLF4J, JCL) is that multiple logging implementations have existed historically and the reason for that really goes back to the era before JUL as I see it. If JUL was perfect then logging facades wouldn't exist, or what? Rather than embracing them shouldn't we question why they were necessary in the first place? (and see if those reasons still exist) Ok, my research so far has led to a couple of things that I can see may be real issues with JUL: #li Performance . Some say that performance in SLF4J is superior to the rest. This seems to me to be a case of premature optimization. If you need to log hundreds of megabytes per second then I'm not sure you are on the right path anyway. JUL has also evolved and the tests you did on Java 1.4 may no longer be true. You can read about it here and this fix has made it into Java 7. Many also talk about the overhead of string concatenation in logging methods. However template based logging avoids this cost and it exist also in JUL. Personally I never really write template based logging. Too lazy for that. For example if I do this with JUL: log.finest(args)); my IDE will warn me and ask permission that it should change it to: log.log(args); .. which I will of course accept. Permission granted ! Thank you for your help. So I don't actually write such statements myself, that is done by the IDE. In conclusion on the issue of performance I haven't found anything that would suggest that JUL's performance is not ok compared to the competition. #li Configuration from classpath . Out-of-the-box JUL cannot load a configuration file from the classpath. It is a few lines of code to make it do so. I can see why this may be annoying but the solution is short and simple. #li Availability of output handlers . JUL comes with 5 output handlers out-of-the-box: console, file stream, socket and memory. These can be extended or new ones can be written. This may for example be writing to UNIX/Linux Syslog and Windows Event Log. I have personally never had this requirement nor have I seen it used but I can certainly relate to why it may be a useful feature. Logback comes with an appender for Syslog for example. Still I would argue that #li 99.5% of the needs for output destinations are covered by what is in JUL out-of-the-box. #li Special needs could be catered for by custom handlers on top of JUL rather than on top of something else. There's nothing to me that suggests that it takes more time to write a Syslog output handler for JUL than it does for another logging framework. I'm really concerned that there's something I've overlooked. The use of logging facades and logging implementations other than JUL is so widespread that I have to come to the conclusion that it's me who just doesn't understand. That wouldn't be the first time, I'm afraid. :-) So what should I do with my API? I want it to become successful. I can of course just "go with the flow" and implement SLF4J (which seems the most popular these days) but for my own sake I still need to understand exactly what is wrong with the JUL of today that warrants all the fuzz? Will I sabotage myself by choosing JUL for my library ? Testing performance (section added by nolan600 on 07-JUL-2012) There's a reference below from Ceki about SLF4J's parametrization being 10 times or more faster than JUL's. So I've started doing some simple tests. At first glance the claim is certainly correct. Here are the preliminary results (but read on!): #li Execution time SLF4J, backend Logback: 1515 #li Execution time SLF4J, backend JUL: 12938 #li Execution time JUL: 16911 The numbers above are msecs so less is better. So 10 times performance difference is by first actually pretty close. My initial reaction: That is a lot ! Here is the core of the test. As can be seen an integer and a string is construted in a loop which is then used in the log statement: #pre (I wanted the log statement to have both a primitive data type (in this case an int) and a more complex data type (in this case a String). Not sure it matters but there you have it.) The log statement for SLF4J: logger.info(args); The log statement for JUL: logger.log(args); The JVM was 'warmed up' with the same test executed once before the actual measurement was done. Java 1.7.03 was used on Windows 7. Latest versions of SLF4J (v1.6.6) and Logback (v1.0.6) was used. Stdout and stderr was redirected to null device. However, careful now, it turns out JUL is spending most of its time in getSourceClassName(args) because JUL by default prints the source class name in the output, while Logback doesn't. So we are comparing apples and oranges. I have to do the test again and configure the logging implementations in a similar manner so that they actually output the same stuff. I do however suspect that SLF4J+Logback will still come out on top but far from the initial numbers as given above. Stay tuned. Btw: The test was first time I've actually worked with SLF4J or Logback. A pleasant experience. JUL is certainly a lot less welcoming when you are starting out. Testing performance (part 2) (section added by nolan600 on 08-JUL-2012) As it turns out it doesn't really matter for performance how you configure your pattern in JUL, i.e. whether or not it includes the source name or not. I tried with a very simple pattern: java.util.logging.SimpleFormatter.format=StringLiteral and that did not change the above timings at all. My profiler revealed that the logger still spent a lot of time in calls to getSourceClassName(args) even if this was not part of my pattern. The pattern doesn't matter. I'm therefore concluding on the issue of performance that at least for the tested template based log statement there seems to be roughly a factor of 10 in real performance difference between JUL (slow) and SLF4J+Logback (quick). Just like Ceki said. I can also see another thing namely that SLF4J's getLogger(args) call is a lot more expensive than JUL's ditto. (95 ms vs 0.3 ms if my profiler is accurate). This makes sense. SLF4J has to do some time on the binding of the underlying logging implementation. This doesn't scare me. These calls should be somewhat rare in the lifetime of an application. The fastness should be in the actual log calls. Final conclusion (section added by nolan600 on 08-JUL-2012) Thank you for all your answers. Contrary to what I initially thought I've ended up deciding to use SLF4J for my API. This is based on a number of things and your input: #li It gives flexibility to choose log implementation at deployment time. #li Issues with lack of flexibility of JUL's configuration when run inside an application server. #li SLF4J is certainly a lot faster as detailed above in particular if you couple it with Logback. Even if this was just a rough test I have reason to believe that a lot more effort has gone into optimization on SLF4J+Logback than on JUL. #li Documentation. The documentation for SLF4J is simply a lot more comprehensive and precise. #li Pattern flexibility. As I did the tests I set out to have JUL mimic the default pattern from Logback. This pattern includes the name of the thread. It turns out JUL cannot do this out of the box. Ok, I haven't missed it until now, but I don't think it is a thing that should be missing from a log framework. Period! #li Most (or many) Java projects today use Maven so adding a dependency is not that big a thing especially if that dependency is rather stable, i.e. doesn't constantly change its API. This seems to be true for SLF4J. Also the SLF4J jar and friends are small in size. So the strange thing that happened was that I actually got quite upset with JUL after having worked a bit with SLF4J. I still regret that it has to be this way with JUL. JUL is far from perfect but kind of does the job. Just not quite well enough. The same can be said about Properties as an example but we do not think about abstracting that so people can plug in their own configuration library and what have you. I think the reason is that Properties comes in just above the bar while the opposite is true for JUL of today ... and in the past it came in at zero because it didn't exist.

Question-5374311, answer-17909839
The correct way to do this is: String[] stockArr = stock_list.toArray(args); I'd like to add to the other great answers here and explain how you could have used the Javadocs to answer your question. The Javadoc for toArray(args) (no arguments) is here . As you can see, this method returns an Object[] and not String[] which is an array of the runtime type of your list: #blockquote Right below that method, though, is the Javadoc for toArray(args) . As you can see, this method returns a T[] where T is the type of the array you pass in. At first this seems like what you're looking for, but it's unclear exactly why you're passing in an array (are you adding to it, using it for just the type, etc). The documentation makes it clear that the purpose of the passed array is essentially to define the type of array to return (which is exactly your use case): #blockquote Of course, an understanding of generics (as described in the other answers) is required to really understand the difference between these two methods. Nevertheless, if you first go to the Javadocs, you will usually find your answer and then see for yourself what else you need to learn (if you really do). Also note that reading the Javadocs here helps you to understand what the structure of the array you pass in should be. Though it may not really practically matter, you should not pass in an empty array like this: String [] stockArr = stockList.toArray(args); Because, from the doc, this implementation checks if the array is large enough to contain the collection; if not, it allocates a new array of the correct size and type (using reflection). There's no need for the extra overhead in creating a new array when you could easily pass in the size. As is usually the case, the Javadocs provide you with a wealth of information and direction. Hey wait a minute, what's reflection?

Question-30888581, answer-30897102
Once given more thought In hindsight it sounds like they were looking for the execute around pattern . They're usually used to do things like enforce closing of streams. This is also more relevant due to this line: #blockquote The idea is you give the thing that does the "executing around" some class to do somethings with. You'll probably use Runnable but it's not necessary. ( Runnable makes the most sense and you'll see why soon.) In your StopWatch class add some method like this #pre You would then call it like this #pre This makes it fool proof. You don't have to worry about handling stop before start or people forgetting to call one and not the other, etc. The reason Runnable is nice is because #li Standard java class, not your own or third party #li End users can put whatever they need in the Runnable to be done. (If you were using it to enforce stream closing then you could put the actions that need to be done with a database connection inside so the end user doesn't need to worry about how to open and close it and you simultaneously force them to close it properly.) If you wanted, you could make some StopWatchWrapper instead leave StopWatch unmodified. You could also make measureAction(args) not return a time and make getTime(args) public instead. The Java 8 way to calling it is even simpler #pre #blockquote Original answer #blockquote To me something like this seems to be good. #pre The reason I believe this to be good is the recording is during object creation so it can't be forgotten or done out of order (can't call stop(args) method if it doesn't exist). One flaw is probably the naming of stop(args) . At first I thought maybe lap(args) but that usually implies a restarting or some sort (or at least recording since last lap/start). Perhaps read(args) would be better? This mimics the action of looking at the time on a stop watch. I chose stop(args) to keep it similar to the original class. The only thing I'm not 100% sure about is how to get the time. To be honest that seems to be a more minor detail. As long as both ... in the above code obtain current time the same way it should be fine.

Question-5243754, answer-34295445
request.getParameter() We use request.getParameter(args) to extract request parameters (i.e. data sent by posting a html form ). The request.getParameter(args) always returns String value and the data come from client. request.getAttribute() We use request.getAttribute(args) to get an object added to the request scope on the server side i.e. using request.setAttribute(args) . You can add any type of object you like here, Strings , Custom objects, in fact any object. You add the attribute to the request and forward the request to another resource, the client does not know about this. So all the code handling this would typically be in JSP/servlets. You can use request.setAttribute(args) to add extra-information and forward/redirect the current request to another resource. For example,consider about first.jsp, #pre and second.jsp: #pre From your browser, run first.jsp?CLIENT=you and the output on your browser is #pre The basic difference between getAttribute(args) and getParameter(args) is that the first method extracts a (serialized) Java object and the other provides a String value. For both cases a name is given so that its value (be it string or a java bean) can be looked up and extracted.

Question-26684562
In Java 8, what's the difference between Stream.map and Stream.flatMap methods?

Question-28770822
I understand the use of the @Native annotation. #blockquote However, while reading the java source code I noticed that in the class Integer and Long the SIZE constant is @Native while it is not for the Float, Byte, Double, Short and Character. Note that the SIZE constant represents the number of bits used to represent the actual value. #pre Edit : I just noticed that this also applies for MAX_VALUE and MIN_VALUE of the same classes. Edit 2 : I had spare time to do some research on this, and looking at the header files of the Long, Float etc. classes I had hope to figure out that the constants were not present in the other headers, but unfortunately they are. #pre Why is the SIZE constant only @Native for Integer and Long ?

Question-22382453, answer-22384113
Made up example Imagine that you want to create the following sequence: 1, 2, 2, 3, 3, 3, 4, 4, 4, 4 etc. (in other words: 1x1, 2x2, 3x3 etc.) With flatMap it could look like: #pre where: #li IntStream.rangeClosed(args) creates a stream of int from 1 to 4, inclusive #li IntStream.iterate(args).limit(args) creates a stream of length i of int i - so applied to i = 4 it creates a stream: 4, 4, 4, 4 #li flatMap "flattens" the stream and "concatenates" it to the original stream With Java < 8 you would need two nested loops: #pre Real world example Let's say I have a List<T> where each TimeSeries is essentially a Map<T> . I want to get a list of all dates for which at least one of the time series has a value. flatMap to the rescue: list.stream(args).parallel(args) .flatMap(args) // for each TS, stream dates and flatmap .distinct(args) // remove duplicates .sorted(args) // sort ascending .collect(args); Not only is it readable, but if you suddenly need to process 100k elements, simply adding parallel(args) will improve performance without you writing any concurrent code.

Question-31993377
Question How is it that for a scanner object the hasNextLine(args) method returns true while the hasNext(args) method returns false? Note: Based on the input file, the hasNext(args) method is returning the result as expected; the hasNextLine(args) does not seem to be returning the correct result. Code Here's the code I'm running that's creating the results below: #pre Input File The following is the actual content of the file that I'm passing to this scanner: #pre Result The following is the end of what's printed in the console when I run my code, and includes the portion I can't make sense of: #pre

Question-20945049, answer-20959594
String is immutable, but through reflection you're allowed to change the String class. You've just redefined the String class as mutable in real-time. You could redefine methods to be public or private or static if you wanted.

Question-6470651, answer-6780439
Here's a simple/sinister one via #a . #pre Because the substring refers to the internal representation of the original, much longer string, the original stays in memory. Thus, as long as you have a StringLeaker in play, you have the whole original string in memory, too, even though you might think you're just holding on to a single-character string. The way to avoid storing an unwanted reference to the original string is to do something like this: #pre For added badness, you might also .intern(args) the substring: #pre Doing so will keep both the original long string and the derived substring in memory even after the StringLeaker instance has been discarded.

Question-5038204, answer-5039178
The commons/lang builders are great and I have been using them for years without noticeable performance overhead (with and without hibernate). But as Alain writes, the Guava way is even nicer: Here's a sample Bean: #pre Here's equals() and hashCode() implemented with Commons/Lang: #pre and here with Guava: #pre As you can see the Guava version is shorter and avoids superfluous helper objects. In case of equals, it even allows for short-circuiting the evaluation if an earlier Object.equal(args) call returns false (to be fair: commons / lang has an ObjectUtils.equals(args) method with identical semantics which could be used instead of EqualsBuilder to allow short-circuiting as above). So: yes, the commons lang builders are very preferable over manually constructed equals(args) and hashCode(args) methods (or those awful monsters Eclipse will generate for you), but the Guava versions are even better. And a note about Hibernate: be careful about using lazy collections in your equals(), hashCode() and toString() implementations. That will fail miserably if you don't have an open Session. Note (about equals()): a) in both versions of equals() above, you might want to use one or both of these shortcuts also: #pre b) depending on your interpretation of the equals() contract, you might also change the line(s) if(args){ to #pre If you use the second version, you probably also want to call super(args) inside your equals(args) method. Opinions differ here, the topic is discussed in this question: #blockquote (although it's about hashCode(args) , the same applies to equals(args) ) Note (inspired by Comment from kayahr ) Objects.hashCode(args) (just as the underlying Arrays.hashCode(args) ) might perform badly if you have many primitive fields. In such cases, EqualsBuilder may actually be the better solution.

Question-16148575, answer-16148619
use int as Object not as primitive type HashMap<T> myMap = new HashMap<T>(args);

Question-29494800, answer-29495113
#blockquote (Object)newType == (Object)Object[].class It is checking whether variable newType holds a reference to an instance of java.lang.Class representing type Object[] . The casts are unneeded. #blockquote As far as I can tell, Array.newInstance(args) could be used in both cases, but non-reflective ordinary array construction is likely a bit faster. Thus, I suppose that Object[] is called out as a special case for performance reasons, but I have no idea whether that case is exercised frequently enough for the optimization to be important. #blockquote Integer[] nums = Arrays.copyOf(args) You should use it when you need to copy an array to an array with a possibly different (but compatible) element type, especially when the element types are not statically known. If you know you want the copy to have the same element type as the original, then it's easier to use the original array's clone(args) method.

Question-12575990, answer-12576219
A Java Date is a container for the number of milliseconds since January 1, 1970, 00:00:00 GMT. When you use something like System.out.println(args) , Java uses Date.toString(args) to print the contents. The only way to change it is to override Date and provide your own implementation of Date.toString(args) . Now before you fire up your IDE and try this, I wouldn't; it will only complicate matters. You are better off formatting the date to the format you want to use (or display). What you can do, is format the date. #pre These are actually the same date, represented differently.
Question-8725387, answer-8727998
Another point is the time complexity of insert operations. For a list insert, one expects a complexity of O(1). But this could not be guaranteed with a sorted list. And the most important point is that lists assume nothing about their elements. For example, you can make lists of things that do not implement equals or compare .

Question-21163108, answer-21172732
The parallel streams use the default ForkJoinPool which by default has one less threads as you have processors , as returned by Runtime.getRuntime(args).availableProcessors(args) (so parallel streams use all your processors because they also use the main thread): #blockquote To change the way parallel streams are executed, you can either #li submit the parallel stream execution to your own ForkJoinPool: yourFJP.submit(args); or #li you can change the size of the common pool using system properties: System.setProperty(args) for a target parallelism of 20 threads. Example of the latter on my machine which has 8 processors. If I run the following program: #pre The output is: #blockquote So you can see that the parallel stream processes 8 items at a time, i.e. it uses 8 threads. However if I uncomment the commented line, the output is: #blockquote This time the parallel stream has used 20 threads and all 20 elements in the stream have been processed comcurrently.

Question-19757300, answer-19759653
You can also propagate your static pain with lambdas, so the whole thing looks readable: s.filter(args) propagate here receives java.util.concurrent.Callable as a parameter and converts any exception caught during the call into RuntimeException . There is a similar conversion method Throwables#propagate(Throwable) in Guava. This method seems being essential for lambda method chaining, so I hope one day it will be added to one of the popular libs or this propagating behavior would be by default. #pre

Question-31202946
Why was the Thread class implemented as a regular class and not an abstract class with run(args) method being abstract. Will it possibly introduce any problems? Or does it have any use in being this way? Also, the Thread.start(args) method is supposed to be a very specific method whose functionality cannot be implemented by any other class (If I am not wrong). And hence I guess the final keyword would be apt for this more than any other method. But I am able to override this method and use it as I like, #pre It obviously only printed, #blockquote Is there any use in overriding other than confusing the engineer replacing you? If not, why was the method not declared final in Thread class?

Question-23308193, answer-32566745
This is possible for forEach(args) . The solution is not nice, but it is possible. WARNING : You should not use it for controlling business logic, but purely for handling an exceptional situation which occurs during the execution of the forEach(args) . Such as a resource suddenly stops being accessible, one of the processed objects is violating a contract (e.g. contract says that all the elements in the stream must not be null but suddenly and unexpectedly one of them is null ) etc. According to the documentation for Iterable.forEach() : #blockquote So you throw an exception which will immediately break the internal loop. The code will be something like this - I cannot say I like it but it works. You create your own class BreakException which extends RuntimeException . #pre Notice that the try...catch is not around the lambda expression, but rather around the whole forEach(args) method. To make it more visible, see the following transcription of the code which shows it more clearly: #pre

Question-8894258, answer-8894384
This is just micro-optimisation that you shouldn't worry about. char[] chars = str.toCharArray(args); returns you a copy of str character arrays (in JDK, it returns a copy of characters by calling System.arrayCopy ). Other than that, str.charAt(args) only checks if the index is indeed in bounds and returns a character within the array index. The first one doesn't create additional memory in JVM.

Question-15182496
The following print statement would print "hello world". Could anyone explain this? System.out.println(args); And randomString(args) looks like this: #pre

Question-8579657, answer-35931153
If you directly call run(args) method, you are not using multi-threading feature since run(args) method is executed as part of caller thread. If you call start(args) method on Thread, the Java Virtual Machine will call run() method and two threads will run concurrently - Current Thread ( main(args) in your example) and Other Thread (Runnable r1 in your example). Have a look at source code of start(args) method in Thread class #pre In above code, you can't see invocation to run(args) method. private native void start0(args) is responsible for calling run(args) method. JVM executes this native method.

Question-23218874, answer-23232560
For simple cases such as the one illustrated, they are mostly the same. However, there are a number of subtle differences that might be significant. One issue is with ordering. With Stream.forEach , the order is undefined . It's unlikely to occur with sequential streams, still, it's within the specification for Stream.forEach to execute in some arbitrary order. This does occur frequently in parallel streams. By contrast, Iterable.forEach is always executed in the iteration order of the Iterable , if one is specified. Another issue is with side effects. The action specified in Stream.forEach is required to be non-interfering . (See the java.util.stream package doc .) Iterable.forEach potentially has fewer restrictions. For the collections in java.util , Iterable.forEach will generally use that collection's Iterator , most of which are designed to be fail-fast and which will throw ConcurrentModificationException if the collection is structurally modified during the iteration. However, modifications that aren't structural are allowed during iteration. For example, the ArrayList class documentation says "merely setting the value of an element is not a structural modification." Thus, the action for ArrayList.forEach is allowed to set values in the underlying ArrayList without problems. The concurrent collections are yet again different. Instead of fail-fast, they are designed to be weakly consistent . The full definition is at that link. Briefly, though, consider ConcurrentLinkedDeque . The action passed to its forEach method is allowed to modify the underlying deque, even structurally, and ConcurrentModificationException is never thrown. However, the modification that occurs might or might not be visible in this iteration. (Hence the "weak" consistency.) Still another difference is visible if Iterable.forEach is iterating over a synchronized collection. On such a collection, Iterable.forEach takes the collection's lock once and holds it across all the calls to the action method. The Stream.forEach call uses the collection's spliterator, which does not lock, and which relies on the prevailing rule of non-interference. The collection backing the stream could be modified during iteration, and if it is, a ConcurrentModificationException or inconsistent behavior could result.

Question-29945627, answer-29946155
The syntax you're after is possible with a little helper function that converts a Runnable into Action<T> (you can place it in Action for example): #pre

Question-20918650, answer-20918709
A subsequent post by the same user in the same conversation: #blockquote (This was in response to a statement by another user, namely that "it seems in some situations 'new T' would be better", the idea being that new T(args) is impossible due to type erasure. (This is debatable — even if T were available at runtime, it could be an abstract class or interface, or it could be Void , or it could lack a no-arg constructor, or its no-arg constructor could be private (e.g., because it's supposed to be a singleton class), or its no-arg constructor could specify a checked exception that the generic method does not catch or specify — but that was the premise. Regardless, it's true that without erasure you could at least write T.class.newInstance(args) , which handles those issues.)) This view, that types are isomorphic to propositions, suggests that the user has a background in formal type theory. (S)he very likely does not like "dynamic types" or "runtime-types" and would prefer a Java without downcasts and instanceof and reflection and so on. (Think of a language like Standard ML, which has a very rich (static) type system and whose dynamic semantics do not depend on any type information whatsoever.) It's worth keeping in mind, by the way, that the user is trolling: while (s)he likely sincerely prefers (statically) typed languages, (s)he is not sincerely trying to persuade others of that view. Rather, the main purpose of the original tweet was to mock those who disagree, and after some of those disagree-ers chimed in, the user posted follow-up tweets such as "the reason java has type erasure is that Wadler et al know what they are doing, unlike users of java". Unfortunately, this makes it hard to find out what (s)he's actually thinking; but fortunately, it also likely means that it's not very important to do so. People with actual depth to their views don't generally resort to trolls that are quite this content-free.

Question-25850328
I was being taught that Marker interface in Java is an empty interface and is used to signal to compiler or JVM that the objects of the class implementing this interface must be treated in a special way, like serializing, cloning, etc. But lately I have learned that it actually has nothing to do with the compiler or the JVM. For example, in case of Serializable interface the method writeObject(args) of ObjectOutputStream does something like instanceOf Serializable to detect whether the class implements Serializable & throws NotSerializableException accordingly. Everything is handled in the code and this seems to be a design-pattern so I think we can define our own marker interfaces. Now my doubts: #li Is the definition of a marker interface mentioned above in 1st point wrong? How can we define a Marker interface then? #li And instead of using the instanceOf operator why can't the method be something like writeObject(args) so that there is a compile-time type checking rather than runtime? #li How are Annotations better than Marker Interfaces?

Question-8172420, answer-32174377
We have various ways to convert a char to String . One way is to make use of static method toString(args) in Character class: #pre Actually this toString method internally makes use of valueOf method from String class which makes use of char array: #pre So second way is to use this directly: String str2 = String.valueOf(args); This valueOf method in String class makes use of char array: #pre So the third way is to make use of an anonymous array to wrap a single character and then passing it to String constructor: String str4 = new String(args); The fourth way is to make use of concatenation: String str3 = StringLiteral + ch; This will actually make use of append method from StringBuilder class which is actually preferred when we are doing concatenation in a loop.

Question-15940234
I'm relative new to the webservices world and my research seems to have confused me more than enlighten me, my problem is that I was given a library(jar) which I have to extend with some webservice functionality. This library will be shared to other developers, and among the classes in the jar will be classes that have a method which calls a webservice (that essentially sets an attribute of the class, does some business logic, like storing the object in a db, etc and sends back the object with those modifications). I want to make the call to this service as simple as possible, hopefully as simple so that the developer using the class only need to do. #pre I have been studying JAX-WS to use on the server but seems to me that I don't need to create a wsimport in the server nor the wsimport on the client, since I know that both have the classes, I just need some interaction between classes shared in both the server and the client. How do you think makes sense to do the webservice and the call in the class?

Question-24649842
What's the main difference between scheduleAtFixedRate and scheduleWithFixedDelay methods of ScheduledExecutorService ? #pre they print exact the same time, seems they are executed at exact the same interval.

Question-14491966, answer-14502259
There are many, many pseudo random number generators out there. For example Knuth's ranarray , the Mersenne twister , or look for LFSR generators. Knuth's monumental "Seminumerical algorithms" analizes the area, and proposes some linear congruential generators (simple to implement, fast). But I'd suggest you just stick to java.util.Random or Math.random , they fast and at least OK for occasional use (i.e., games and such). If you are just paranoid on the distribution (some Monte Carlo program, or a genetic algorithm), check out their implementation (source is available somewhere), and seed them with some truly random number, either from your operating system or from random.org . If this is required for some application where security is critical, you'll have to dig yourself. And as in that case you shouldn't believe what some colored square with missing bits spouts here, I'll shut up now.

Question-19418427, answer-19418553
If you take a look at this methods #pre and its decompiled with javap -c ClassWithTheseMethods versions you will see #pre and #pre So if Strings are not final compiler will have to use StringBuilder to concatenate str1 and str2 so String concat=str1+str2; will be compiled to String concat = new StringBuilder(args).append(args).toString(args); which means that concat will be created at runtime so will not come from String pool. Also if Strings are final then compiler can assume that they will never change so instead of using StringBuilder it can safely concatenate its values so String concat = str1 + str2; can be changed to String concat = StringLiteral + StringLiteral; and concatenated into String concat = StringLiteral; which means that concate will become sting literal which will be interned in string pool and then compared with same string literal from that pool in if statement.

Question-18647214, answer-18647232
I would just do this. It basically takes the minimum between 100 (the max health) and what the health would be with 15 extra points. It ensures that the user's health does not exceed 100. #pre To ensure that hitpoints do not drop below zero, you can use a similar function: Math.max . #pre

Question-21105403
I've written a factory to produce java.sql.Connection objects: #pre I'd like to validate the parameters passed to DriverManager.getConnection , but I don't know how to mock a static method. I'm using JUnit 4 and Mockito for my test cases. Is there a good way to mock/verify this specific use-case?

Question-29922296, answer-29923793
I think the shortest code to get a Stream of enum constants is Stream.of(args) . It's not as nice as Letter.values(args).stream(args) but that's an issue with arrays, not specifically enums. #blockquote You are right that the nicest possible call would be Letter.stream(args) . Unfortunately a class cannot have two methods with the same signature, so it would not be possible to implicitly add a static method stream(args) to every enum (in the same way that every enum has an implicitly added static method values(args) ) as this would break every existing enum that already has a static or instance method without parameters called stream(args) . #blockquote I think so. The drawback is that stream is a static method, so there is no way to avoid code duplication; it would have to be added to every enum separately.

Question-18777989, answer-37905386
Many junior developers make the mistake of thinking of interfaces, abstract and concrete classes as slight variations of the same thing, and choose one of them purely on technical grounds: Do I need multiple inheritance? Do I need some place to put common methods? Do I need to bother with something other than just a concrete class? This is wrong, and hidden in these questions is the main problem: "I" . When you write code for yourself, by yourself, you rarely think of other present or future developers working on or with your code. Interfaces and abstract classes, although apparently similar from a technical point of view, have completely different meanings and purposes. Summary #li An interface defines a contract that some implementation will fulfill for you . #li An abstract class provides a default behavior that your implementation can reuse. These two points above is what I'm looking for when interviewing, and is a compact enough summary. Read on for more details. Alternative summary #li An interface is for defining public APIs #li An abstract class is for internal use, and for defining SPIs By example To put it differently: A concrete class does the actual work, in a very specific way. For example, an ArrayList uses a contiguous area of memory to store a list of objects in a compact manner which offers fast random access, iteration, and in-place changes, but is terrible at insertions, deletions, and occasionally even additions; meanwhile, a LinkedList uses double-linked nodes to store a list of objects, which instead offers fast iteration, in-place changes, and insertion/deletion/addition, but is terrible at random access. These two types of lists are optimized for different use cases, and it matters a lot how you're going to use them. When you're trying to squeeze performance out of a list that you're heavily interacting with, and when picking the type of list is up to you, you should carefully pick which one you're instantiating. On the other hand, high level users of a list don't really care how it is actually implemented, and they should be insulated from these details. Let's imagine that Java didn't expose the List interface, but only had a concrete List class that's actually what LinkedList is right now. All Java developers would have tailored their code to fit the implementation details: avoid random access, add a cache to speed up access, or just reimplement ArrayList on their own, although it would be incompatible with all the other code that actually works with List only. That would be terrible... But now imagine that the Java masters actually realize that a linked list is terrible for most actual use cases, and decided to switch over to an array list for their only List class available. This would affect the performance of every Java program in the world, and people wouldn't be happy about it. And the main culprit is that implementation details were available, and the developers assumed that those details are a permanent contract that they can rely on. This is why it's important to hide implementation details, and only define an abstract contract. This is the purpose of an interface: define what kind of input a method accepts, and what kind of output is expected, without exposing all the guts that would tempt programmers to tweak their code to fit the internal details that might change with any future update. An abstract class is in the middle between interfaces and concrete classes. It is supposed to help implementations share common or boring code. For example, AbstractCollection provides basic implementations for isEmpty based on size is 0, contains as iterate and compare, addAll as repeated add , and so on. This lets implementations focus on the crucial parts that differentiate between them: how to actually store and retrieve data. Another perspective: APIs versus SPIs Interfaces are low-cohesion gateways between different parts of code. They allow libraries to exist and evolve without breaking every library user when something changes internally. It's called Application Programming Interface Abstract classes are high-cohesion helpers to be used when implementing an interface, assuming some level of implementation details. Alternatively, abstract classes are used for defining SPIs, Service Provider Interfaces. The difference between an API and an SPI is subtle, but important: for an API, the focus is on who uses it, and for an SPI the focus is on who implements it. Adding methods to an API is easy, all existing users of the API will still compile. Adding methods to an SPI is hard, since every service provider (concrete implementation) will have to implement the new methods. If interfaces are used to define an SPI, a provider will have to release a new version whenever the SPI contract changes. If abstract classes are used instead, new methods could either be defined in terms of existing abstract methods, or as empty throw not implemented exception stubs, which will at least allow an older version of a service implementation to still compile and run. A note on Java 8 and default methods Although Java 8 introduced default methods for interfaces, which makes the line between interfaces and abstract classes even blurrier, this wasn't so that implementations can reuse code, but to make it easier to change interfaces that serve both as an API and as an SPI (or are wrongly used for defining SPIs instead of abstract classes). "Book knowledge" The technical details provided in the OP's answer are considered "book knowledge" because this is usually the approach used in school and in most technology books about a language: what a thing is, not how to use it in practice, especially in large scale applications. Here's an analogy: supposed the question was: #blockquote The technical answer sounds like: #blockquote That is all true, but completely misses the points that they are two completely different things, and both can be used at the same time for different purposes, and the "doing it" aspect is not the most important thing about either of the two options. The answer lacks perspective, it shows an immature way of thinking, while correctly presenting true "facts".

Question-27482579
How is the compiler not complaining when I write the following code? #pre Even though it is an instance of the same class in which testPrivate is written, shouldn't it give a compilation error at System.out.println(args) ? After all, I am trying to access a private variable directly. The code even runs fine.

Question-32859038, answer-32918035
Eran's answer is usually the best approach for random-access lists. If your List isn't random access, or if you have a Stream instead of a List , you can use forEachOrdered : #pre This is safe, if the stream is parallel, even though the destination map is thread-unsafe and is operated upon as a side effect. The forEachOrdered guarantees that items are processed one-at-a-time, in order. For this reason it's unlikely that any speedup will result from running in parallel. (There might be some speedup if there are expensive operations in the pipeline before the forEachOrdered .)

Question-24547673, answer-24547831
It's a curious omission. You would have to mark the field as transient and provide your own custom writeObject(args) method that wrote the get(args) result itself, and a readObject(args) method that restored the Optional by reading that result from the stream. Not forgetting to call defaultWriteObject(args) and defaultReadObject(args) respectively.

Question-5439529, answer-9991624
You can use Integer.parseInt(args) and catch the NumberFormatException if the string is not a valid integer, in the following fashion (as pointed out by all answers): #pre However, note here that if the evaluated integer overflows, the same exception will be thrown. Your purpose was to find out whether or not, it was a valid integer. So its safer to make your own method to check for validity: #pre

Question-18092160
Why were 181783497276652981 and 8682522807148012 chosen in Random.java ? Here's the relevant source code from Java SE JDK 1.7: #pre So, invoking new Random(args) without any seed parameter takes the current "seed uniquifier" and XORs it with System.nanoTime(args) . Then it uses 181783497276652981 to create another seed uniquifier to be stored for the next time new Random(args) is called. The literals 181783497276652981L and 8682522807148012L are not placed in constants, but they don't appear anywhere else. At first the comment gives me an easy lead. Searching online for that article yields the actual article . 8682522807148012 doesn't appear in the paper, but 181783497276652981 does appear -- as a substring of another number, 1181783497276652981 , which is 181783497276652981 with a 1 prepended. The paper claims that 1181783497276652981 is a number that yields good "merit" for a linear congruential generator. Was this number simply mis-copied into Java? Does 181783497276652981 have an acceptable merit? And why was 8682522807148012 chosen? Searching online for either number yields no explanation, only this page that also notices the dropped 1 in front of 181783497276652981 . Could other numbers have been chosen that would have worked as well as these two numbers? Why or why not?

Question-26791441, answer-26826286
It's easy to write a method to do this using String.regionMatches : #pre Testing: #pre Output: #blockquote It is not immediately obvious, but a function like this can still be dependent on the order in which the replacements are specified. Consider: #pre Output: #blockquote But reverse the replacements: truth += StringLiteral + simultaneousReplace(args); Output: #blockquote Oops! :) Therefore it is sometimes useful to make sure to look for the longest match (as PHP's strtr function does, for example). This version of the method will do that: #pre Note that the above methods are case-sensitive. If you need a case-insensitive version it is easy to modify the above because String.regionMatches can take an ignoreCase parameter.

Question-14636178
I am trying to use the org.springframework.orm.jdo.TransactionAwarePersistenceManagerFactoryProxy in my Spring project, but I am not sure how to use it or whether it's exactly what I am looking for. I realize it can help make my DAOs work with a plain JDO PersistenceManagerFactory . Another question is: what happens if the proxy doesn't get made properly? Can I still use it to access my factory to create a transaction aware persistence manager? If the object managed by the factory is a singleton, does this change things? Why not just access the PersistenceManagerFactory directly? Perhaps PersistenceManagerFactoryUtils.getPersistenceManager would be more suited to my needs? Can getObject return null?

Question-27683759, answer-27684042
In a nutshell, this creates an empty, immutable list of strings. Let's look at the expression bit by bit. Collections is the name of a class. From the Javadoc : #blockquote emptyList() is the name of a static method defined in the Collections class ( Javadoc ). It is a generic method, and the <String> in Collections.<String>emptyList(args) specifies the generic type argument. The method returns a List<T> , which in this case is List<T> : a list of strings. More specifically, it returns an empty , immutable list of strings.

Question-4709175, answer-4709892
Something none of the other answers have covered that make enums particularly powerful are the ability to have template methods . Methods can be part of the base enum and overridden by each type. And, with the behavior attached to the enum, it often eliminates the need for if-else constructs or switch statements as this blog post demonstrates - where enum.method(args) does what originally would be executed inside the conditional. The same example also shows the use of static imports with enums as well producing much cleaner DSL like code. Some other interesting qualities include the fact that enums provide implementation for equals(args) , toString(args) and hashCode(args) and implement Serializable and Comparable . For a complete rundown of all that enums have to offer I highly recommend Bruce Eckel's Thinking in Java 4th edition which devotes an entire chapter to the topic. Particularly illuminating are the examples involving a Rock, Paper, Scissors (i.e. RoShamBo) game as enums.

Question-20358883, answer-20358917
Very simply: Arrays.asList(args)

Question-5175728, answer-5175900
It depends on what form of date / time you want: #li If you want the date / time as a single numeric value, then System.currentTimeMillis(args) gives you that, expressed as the number of milliseconds after the UNIX epoch (as a Java long ). This value is a delta from a UTC time-point, and is independent of the local time-zone ... assuming that the system clock has been set correctly. #li If you want the date / time in a form that allows you to access the components (year, month, etc) numerically, you could use one of the following: #li new Date(args) gives you a Date object initialized with the current date / time. The problem is that the Date API methods are mostly flawed ... and deprecated. #li Calendar.getInstance(args) gives you a Calendar object initialized with the current date / time, using the default Locale and TimeZone . Other overloads allow you to use a specific Locale and/or TimeZone . Calendar works ... but the APIs are still cumbersome. #li new org.joda.time.DateTime(args) gives you a Joda-time object initialized with the current date / time, using the default time zone and chronology. There are lots of other Joda alternatives ... too many to describe here. #li in Java 8, calling LocalDateTime.now(args) and ZonedDateTime.now(args) will give you representations for the current date / time. Prior to Java 8, most people who know about these things recommended Joda-time as having (by far) the best Java APIs for doing things involving time point and duration calculations. With Java 8, this is no longer true. However, if you are already using Joda time in your codebase, there is no strong reason to migrate.

Question-24630963, answer-32648397
I wrote a Collector which, unlike the default java one, does not crash when you have null values: #pre Just replace your Collectors.toMap(args) call to a call to this function and it'll fix the problem.

Question-22561614
Note: this question originates from a dead link which was a previous SO question, but here goes... See this code (note: I do know that this code won't "work" and that Integer::compare should be used -- I just extracted it from the linked question): #pre According to the javadoc of .min() and .max() , the argument of both should be a Comparator . Yet here the method references are to static methods of the Integer class. So, why does this compile at all?

Question-29140402, answer-29141638
Every class in java has toString(args) method in it by default, which is called by System.out.println(args) if you pass some object of a class to it. When you try to print object of a class, the System.out.println(args) method will call toString(args) of the class which returns the className@hashcode of that object. #pre You can override the toString method of a class to get different output. See this example #pre

Question-7438612, answer-7438613
Replace will replace all instances of a letter. All you need to do is use substring() : #pre

Question-27949213, answer-27950675
Since your first question has already been answered, I'll answer your second question. The String objects must be compared character by character, because though equal Object s implies equal hashes, the inverse is not necessarily true. As Holger said in his comment , this represents a hash collision. The applicable specifications for the hashcode(args) method are as follows: #blockquote This means that in order for them to guarantee equality, the comparison of each character is necessary in order for them to confirm the equality of the two objects. They start by comparing hashCode s rather than using equals since they are using a hash table for the references, and this improves performance.

Question-13744450
The interviewer asked me: #blockquote I wasn't aware of these terms. So, when I came back to home, then I started looking into Google about Observer and Observable and found some point from different resources : #blockquote I found this example: #pre But I'm still unable to figure out why do we need Observer and Observable ? What are the setChanged(args) and notifyObservers(args) methods for?

Question-5374311, answer-5374346
What is happening is that stock_list.toArray(args) is creating an Object[] rather than a String[] and hence the typecast is failing. The correct code would be: String [] stockArr = stockList.toArray(args); or even String [] stockArr = stockList.toArray(args); For more details, refer to the javadocs for the two overloads of List.toArray . (From a technical perspective, the reason for this API behaviour / design is that an implementation of the List<T>.toArray(args) method has no information of what the <T> is at runtime. All it knows is that the raw element type is Object . By contrast, in the other case, the array parameter gives the base type of the array. (If the supplied array is big enough, it is used. Otherwise a new array of the same type and a larger size will be allocated and returned as the result.)

Question-22725537, answer-22735184
You cannot do it more concise as you are already doing. You claim that you do not want .filter(args) and .map(args) . This has been resolved by the method @StuartMarks describes, however as a result you now map it to an Optional<T> , so now you need to use .flatMap(args) and a get(args) in the end. So it still consists of two statements and you can now get exceptions with the new method! Because, what if every optional is empty? Then the findFirst(args) will return an empty optional and your get(args) will fail! So what you have: things.stream(args) .map(args) .filter(args) .map(args) .findFirst(args); is actually the best way to accomplish what you want, and that is you want to save the result as a T , not as an Optional<T> . I took the liberty of creating a CustomOptional<T> class that wraps the Optional<T> and provides an extra method, flatStream(args) . Note that you cannot extend Optional<T> : #pre You will see that I added flatStream(args) , as here: #pre Used as: String result = Stream.of(args) .map(args) .flatMap(args) .findFirst(args) .get(args); You still will need to return a Stream<T> here, as you cannot return T , because if !optional.isPresent(args) , then T == null if you declare it such, but then your .flatMap(args) would attempt to add null to a stream and that is not possible. As example: #pre Used as: String result = Stream.of(args) .map(args) .map(args) .findFirst(args) .get(args); Will now throw a NullPointerException inside the stream operations. Conclusion The method you used, is actually the best method.

Question-13291076, answer-31886637
name() is literally the textual name in the java code of the enum. That means it is limited to strings that can actually appear in your java code, but not all desirable strings are expressible in code. For example, you may need a string that begins with a number. name() will never be able to obtain that string for you.

Question-7032070, answer-7032144
The source code for clear(args) : #pre The source code for removeAll(args) (As defined in AbstractCollection ): #pre clear(args) is much faster since it doesn't have to deal with all those extra method calls. And as Atrey points out, c.contains(args) increases the time complexity of removeAll to O(n^2) as opposed to clear 's O(n).

Question-33147339, answer-33147610
a < b and a - b < 0 can mean two different things. Consider the following code: #pre When run, this will only print a - b < 0 . What happens is that a < b is clearly false, but a - b overflows and becomes -1 , which is negative. Now, having said that, consider that the array has a length that is really close to Integer.MAX_VALUE . The code in ArrayList goes like this: #pre oldCapacity is really close to Integer.MAX_VALUE so newCapacity (which is oldCapacity + 0.5 * oldCapacity ) might overflow and become Integer.MIN_VALUE (i.e. negative). Then, subtracting minCapacity underflows back into a positive number. This check ensures that the if is not executed. If the code were written as if(args) , it would be true in this case (since newCapacity is negative) so the newCapacity would be forced to minCapacity regardless of the oldCapacity . This overflow case is handled by the next if. When newCapacity has overflowed, this will be true : MAX_ARRAY_SIZE is defined as Integer.MAX_VALUE - 8 and Integer.MIN_VALUE - (Integer.MAX_VALUE - 8) > 0 is true . The newCapacity is therefore rightly handled: hugeCapacity method returns MAX_ARRAY_SIZE or Integer.MAX_VALUE . NB: this is what the // overflow-conscious code comment in this method is saying.

Question-26318569, answer-26319364
You're nesting mocking inside of mocking. You're calling getSomeList(args) , which does some mocking, before you've finished the mocking for MyMainModel . Mockito doesn't like it when you do this. Replace #pre with #pre To understand why this causes a problem, you need to know a little about how Mockito works, and also be aware in what order expressions and statements are evaluated in Java. Mockito can't read your source code, so in order to figure out what you are asking it to do, it relies a lot on static state. When you call a method on a mock object, Mockito records the details of the call in an internal list of invocations. The when method reads the last of these invocations off the list and records this invocation in the OngoingStubbing object it returns. The line Mockito.when(args).thenReturn(args); causes the following interactions with Mockito: #li Mock method mainModel.getList(args) is called, #li Static method when is called, #li Method thenReturn is called on the OngoingStubbing object returned by the when method. The thenReturn method can then instruct the mock it received via the OngoingStubbing method to handle any suitable call to the getList method to return someModelList . In fact, as Mockito can't see your code, you can also write your mocking as follows: #pre This style is somewhat less clear to read, especially since in this case the null has to be casted, but it generates the same sequence of interactions with Mockito and will achieve the same result as the line above. However, the line Mockito.when(args).thenReturn(args); causes the following interactions with Mockito: #li Mock method mainModel.getList(args) is called, #li Static method when is called, #li A new mock of SomeModel is created (inside getSomeList(args) ), #li Mock method model.getName(args) is called, At this point Mockito gets confused. It thought you were mocking mainModel.getList(args) , but now you're telling it you want to mock the model.getName(args) method. To Mockito, it looks like you're doing the following: #pre This looks silly to Mockito as it can't be sure what you're doing with mainModel.getList(args) . Note that we did not get to the thenReturn method call, as the JVM needs to evaluate the parameters to this method before it can call the method. In this case, this means calling the getSomeList(args) method. Generally it is a bad design decision to rely on static state, as Mockito does, because it can lead to cases where the Principle of Least Astonishment is violated. However, Mockito's design does make for clear and expressive mocking, even if it leads to astonishment sometimes. Finally, recent versions of Mockito add an extra line to the error message above. This extra line indicates you may be in the same situation as this question: #blockquote

Question-14846920, answer-14846963
#blockquote For the same reason you'd use Collections.unmodifiableMap() at some point. You want to return a Map instance that throws an exception if the user attempts to modify it. It's just a special case: the empty Map.

Question-31170459, answer-31170506
No, you appear to have a legit bug. The bug presents in JDK7 but fixed in JDK8. Your values are correctly representable as BigDecimal s, and should behave correctly, but don't. Tracing through the source code of BigDecimal , on line 2585, this.precision(args) is 1, and this.scale is -2147483647 . this.precision(args) - this.scale therefore overflows, and the following overflow is not handled correctly. This bug has been fixed in JDK8 by doing the subtraction in long arithmetic .

Question-8579657, answer-26159918
invoke run(args) is executing on the calling thread, like any other method call. whereas Thread.start(args) creates a new thread. invoking run(args) is a programmatic bug.

Question-7488643, answer-7488669
Two steps: #li String [] items = commaSeparated.split(args); #li List<T> container = Arrays.asList(args);

Question-28319064, answer-28319148
I prefer the second way. When you use the first way, if you decide to use a parallel stream to improve performance, you'll have no control over the order in which the elements will be added to the output list by forEach . When you use toList , the Streams API will preserve the order even if you use a parallel stream.

Question-21488056, answer-30506585
Predicate has methods and , or and negate . However, String::isEmpty is not a Predicate . It could as well be Function<T> or MyProprietaryClass . The type information is inferred from the variable or the call. So, you need to cast a method reference explicitly (as @axtavt mentioned): ((Predicate<T>) String::isEmpty).negate(args) But it's absolutely ugly and Predicate seems to use lambdas under the hood anyway. So I think you are better off writing a lambda or even your own not(args) method (e.g. in utility, static import).

Question-19431234
Java 8 has a completely new API for date and time. One of the most useful classes in this API is LocalDateTime , for holding a timezone-independent date-with-time value. There are probably millions of lines of code using the legacy class java.util.Date for this purpose. As such, when interfacing old and new code there will be a need for converting between the two. As there seems to be no direct methods for accomplishing this, how can it be done?

Question-11408427, answer-11408477
The + operator is usually replaced by a StringBuilder at compile time. Check this answer for more details on that matter.

Question-22409102, answer-33501556
Double.equals distinguishes ±0.0 in Java. (There's also Float.equals .) I'm a bit surprised no-one has mentioned these, as they seem to me clearer than any method given so far!

Question-7520432, answer-27478241
== can be used in many object types but you can use Object.equals for any type , especially Strings and Google Map Markers.

Question-5439529
I'm trying to determine if a particular item in an Array of strings is an integer or not. I am .split(args)'ing an infix expression in String form, and then trying to split the resultant array into two arrays; one for integers, one for operators, whilst discarding parentheses, and other miscellaneous items. What would be the best way to accomplish this? I thought I might be able to find a Integer.isInteger(args) method or something, but no such luck.

Question-6992608, answer-6992643
There's no built in type for ConcurrentHashSet because you can always derive a set from a map. Since there are many types of maps, you use a method to produce a set from a given map (or map class). Prior to Java 8, you produce a concurrent hash set backed by a concurrent hash map, by using Collections.newSetFromMap(map) In Java 8 (pointed out by @Matt), you can get a concurrent hash set view via ConcurrentHashMap.newKeySet() . This is a bit simpler than the old newSetFromMap which required you to pass in an empty map object. But it is specific to ConcurrentHashMap . Anyway, the Java designers could have created a new set interface every time a new map interface was created, but that pattern would be impossible to enforce when third parties create their own maps. It is better to have the static methods that derive new sets; that approach always works, even when you create your own map implementations.

Question-32859038, answer-32859065
You can create a Stream of the indices using an IntStream and then convert them to a Map : Map<T> map = IntStream.range(args) .boxed(args) .collect(args);

Question-31202946, answer-31203252
#blockquote This question actually boils down to the fact that you should always prefer composition over inheritance. If the Thread class was declared as abstract , the language would have to provide another class that extended from it which programmers could use to create a Thread . Your question would then be about why this class that extends from Thread is not abstract . If the language did not provide another class that extends from Thread , programmers would have to create their own class that extend s from Thread and override the run(args) method. #blockquote The only possible explanation I can give is that the developers of the language saw some use-cases for overriding start when the class was introduced to the JDK. The first version of Java that I used was 1.5 and I personally have not come across a use-case where I found the need to override start . As JB Nizet stated in his answer #blockquote

Question-31270759, answer-31273726
What if every functional interface provided by java.util.function was allowed to throw an exception? #pre We could use some default methods to provide the behavior you want. #li You could fallback to some default value or action #li Or you could try to perform another action which may throw an exception I've written a library which redefines most of the interfaces in java.util.function this way. I even provide a ThrowingStream which let's you use these new interfaces with the same API as a regular Stream . #pre ( Nothing is a RuntimeException that can never be thrown.) Your original example would become #pre

Question-16148575, answer-20454885
For everybody who codes Java for Android devices and ends up here: use SparseArray for better performance private final SparseArray<T> myMap = new SparseArray<T>(args); with this you can use int instead of Integer like #pre

Question-31270759, answer-31270760
Presented below is the full code of the Exceptional class. It has a quite large API which is a pure extension of the Optional API so it can be a drop-in replacement for it in any existing code—except that it isn't a subtype of the final Optional class. The class can be seen as being in the same relationship with the Try monad as Optional is with the Maybe monad: it draws inspiration from it, but is adapted to the Java idiom (such as actually throwing exceptions, even from non-terminal operations). These are some key guidelines followed by the class: #li as opposed to the monadic approach, doesn't ignore Java's exception mechanism; #li instead it relieves the impedance mismatch between exceptions and higher-order functions; #li exception handling not statically typesafe (due to sneaky throwing), but always safe at runtime (never swallows an exception except on explicit request). The class tries to cover all the typical ways to handle an exception: #li recover with some handling code which provides a substitute value; #li flatRecover which, analogous to flatMap , allows to return a new Exceptional instance which will be unwrapped and the state of the current instance suitably updated; #li propagate an exception, throwing it from the Exceptional expression and making the propagate call declare this exception type; #li propagate it after wrapping into another exception ( translate it); #li handle it, resulting in an empty Exceptional ; #li as a special case of handling, swallow it with an empty handler block. The propagate approach allows one to selectively pick which checked exceptions he wants to expose from his code. Exceptions which remain unhandled at the time a terminal operation is called (like get ) will be sneakily thrown without declaration. This is often considered as an advanced and dangerous approach, but is nevertheless often employed as a way to somewhat alleviate the nuisance of checked exceptions in combination with lambda shapes which do not declare them. The Exceptional class hopes to offer a cleaner and more selective alternative to sneaky throw. #pre #pre #pre

