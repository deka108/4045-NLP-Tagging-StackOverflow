Question-16148575, answer-20454885
For everybody who codes Java for Android devices and ends up here: use SparseArray for better performance private final SparseArray<T> myMap = new SparseArray<T>(args); with this you can use int instead of Integer like #pre

Question-16252269, answer-30210459
Collections.sort allows you to pass an instance of a Comparator which defines the sorting logic. So instead of sorting the list in natural order and then reversing it, one can simply pass Collections.reverseOrder(args) to sort in order to sort the list in reverse order: #pre As mentioned by @Marco13, apart from being more idiomatic (and possibly more efficient), using the reverse order comparator makes sure that the sort is stable (meaning that the order of elements will not be changed when they are equal according to the comparator, whereas reversing will change the order)

Question-8579657, answer-35931153
If you directly call run(args) method, you are not using multi-threading feature since run(args) method is executed as part of caller thread. If you call start(args) method on Thread, the Java Virtual Machine will call run() method and two threads will run concurrently - Current Thread ( main(args) in your example) and Other Thread (Runnable r1 in your example). Have a look at source code of start(args) method in Thread class #pre In above code, you can't see invocation to run(args) method. private native void start0(args) is responsible for calling run(args) method. JVM executes this native method.

Question-19431234, answer-23526153
Everything is here : #a The answer with "round-tripping" is not exact : when you do LocalDateTime ldt = LocalDateTime.ofInstant(args); if your system timezone is not UTC/GMT, you change the time !

Question-16635398, answer-16635489
The advantage comes into account when the operations can be executed in parallel. (See #a - the section about internal and external iteration) #li The main advantage from my point of view is that the implementation of what is to be done within the loop can be defined without having to decide if it will be executed in parallel or sequential #li If you want your loop to be executed in parallel you could simply write joins.parallelStream(args).forEach(args); You will have to write some extra code for thread handling etc. Note : for my answer I assumed joins implementing the java.util.Stream interface. If joins implements only the java.util.Iterable interface this is no longer true.

Question-28584669, answer-28590286
Since Double.Nan.equals (Double.NaN) was mentioned: It's one thing what should happen when you perform arithmetic and compare numbers, it's a totally different thing when you consider how objects should behave. Two typical problem cases are: Sorting an array of numbers, and using hash values to implement dictionaries, sets, and so on. There are two exceptional cases where the normal ordering with <, = and > doesn't apply: One case is that +0 = -0 and the other is that NaN â‰  NaN, and x < NaN, x > NaN, x = NaN will always be false whatever x is. Sorting algorithms can get into trouble with this. A sorting algorithm may assume that x = x is always true. So if I know that x is stored in an array and look for it, I might not do any bounds check because the search for it must find something. Not if x is NaN. A sorting algorithm may assume that exactly one of a < b and a >= b must be true. Not if one is NaN. So a naive sorting algorithm may crash when NaNs are present. You'd have to decide where you want NaNs to end up when sorting the array, and then change your comparison code so that it works. Now dictionaries and sets and generally hashing: What if I use an NaN as the key? A set contains unique objects. If the set contains an NaN and I try to add another one, is it unique because it is not equal to the one that is already there? What about +0 and -0, should they be considered equal or different? There's the rule that any two items considered equal must have the same hash value. So the sensible thing is (probably) that a hash function returns one unique value for all NaNs, and one unique value for +0 and -0. And after the hash lookup when you need to find an element with the same hash value that is actually equal, two NaNs should be considered equal (but different from anything else). That's probably why Double.Nan.equal () behaves different from ==.

Question-22409102, answer-22501695
The approach used by Math.min is similar to what Jesper proposes but a little clearer: #pre

Question-6684665, answer-12685471
The kind of output you are seeing from your byte array ( [B@405217f8 ) is also an output for a zero length byte array (ie new byte[0] ). It looks like this string is a reference to the array rather than a description of the contents of the array like we might expect from a regular collection's toString(args) method. As with other respondents, I would point you to the String constructors that accept a byte[] parameter to construct a string from the contents of a byte array. You should be able to read raw bytes from a socket's InputStream if you want to obtain bytes from a TCP connection. If you have already read those bytes as a String (using an InputStreamReader ), then, the string can be converted to bytes using the getBytes(args) function. Be sure to pass in your desired character set to both the String constructor and getBytes(args) functions, and this will only work if the byte data can be converted to characters by the InputStreamReader . If you want to deal with raw bytes you should really avoid using this stream reader layer.

Question-8725387, answer-8725550
Think of it like this: the List interface has methods like add(args) , set(args) . The contract is that once you added an element at position X you will find it there unless you add or remove elements before it. If any list implementation would store elements in some order other than based on the index, the above list methods would make no sense.

Question-6667243, answer-6667307
mode1.name(args) or String.valueOf(args) . It doesn't get better than that, I'm afraid

Question-20945049, answer-20945113
String is immutable* but this only means you cannot change it using its public API. What you are doing here is circumventing the normal API, using reflection. The same way, you can change the values of enums, change the lookup table used in Integer autoboxing etc. Now, the reason s1 and s2 change value, is that they both refer to the same interned string. The compiler does this (as mentioned by other answers). The reason s3 does not was actually a bit surprising to me, as I thought it would share the value array ( it did in earlier version of Java , before Java 7u6). However, looking at the source code of String , we can see that the value character array for a substring is actually copied (using Arrays.copyOfRange(args) ). This is why it goes unchanged. You can install a SecurityManager , to avoid malicious code to do such things. But keep in mind that some libraries depend on using these kind of reflection tricks (typically ORM tools, AOP libraries etc). *) I initially wrote that String s aren't really immutable, just "effective immutable". This might be misleading in the current implementation of String , where the value array is indeed marked private final . It's still worth noting, though, that there is no way to declare an array in Java as immutable, so care must be taken not to expose it outside its class, even with the proper access modifiers. As this topic seems overwhelmingly popular, here's some suggested further reading: Heinz Kabutz's Reflection Madness talk from JavaZone 2009, which covers a lot of the issues in the OP, along with other reflection... well... madness. It covers why this is sometimes useful. And why, most of the time, you should avoid it. :-)

Question-8894258, answer-8894348
The first one using str.charAt should be faster. If you dig inside the source code of String class, we can see that charAt is implemented as follows: #pre Here, all it does is index an array and return the value. Now, if we see the implementation of toCharArray , we will find the below: #pre As you see, it is doing a System.arraycopy which is definitely going to be a tad slower than not doing it.

Question-18723596, answer-18723666
You can cast null to any reference type without getting any exception. println method does not throw null pointer because it first checks whether the object is null or not. If null then it simply prints the string StringLiteral . Otherwise it will call the toString method of that object. Adding more details: Internally print methods call String.valueOf(args) method on the input object. And in valueOf method, this check helps to avoid null pointer excpeiton: return(args) ? StringLiteral : obj.toString(args); For rest of your confusion, calling any method on a null object should throw a null pointer exception, if not a special case.

Question-20331163, answer-20331241
I have a very dumb but working option. if you have the String fullDate = "11/15/2013 08:00:00"; String finalDate = fullDate.split(args)[0]; That should work easy and fast. :)

Question-15182496
The following print statement would print "hello world". Could anyone explain this? System.out.println(args); And randomString(args) looks like this: #pre

Question-31922866, answer-31923227
Optionals aren't designed for this purpose, as explained nicely by Brian Goetz . You can always use @Nullable to denote that a method argument can be null. Using an optional does not really enable you to write your method logic more neatly.

Question-15202997, answer-29527145
Adding local classes, lambdas and the toString(args) method to complete the previous two answers. Further, I add arrays of lambdas and arrays of anonymous classes (which do not make any sense in practice though): #pre This is the full output: #pre So, here are the rules. First, lets start with primitive types and void : #li If the class object represents a primitive type or void , all the four methods simply returns its name. Now the rules for the getName(args) method: #li Every non-lambda and non-array class or interface (i.e, top-level, nested, inner, local and anonymous) has a name (which is returned by getName(args) ) that is the package name followed by a dot (if there is a package), followed by the name of its class-file as generated by the compiler (whithout the suffix .class ). If there is no package, it is simply the name of the class-file. If the class is an inner, nested, local or anonymous class, the compiler should generate at least one $ in its class-file name. Note that for anonymous classes, the class name would end with a dollar-sign followed by a number. #li Lambda class names are generally unpredictable, and you shouldn't care about they anyway. Exactly, their name is the name of the enclosing class, followed by $$Lambda$ , followed by a number, followed by a slash, followed by another number. #li The class descriptor of the primitives are Z for boolean , B for byte , S for short , C for char , I for int , J for long , F for float and D for double . For non-array classes and interfaces the class descriptor is L followed by what is given by getName(args) followed by ; . For array classes, the class descriptor is [ followed by the class descriptor of the component type (which may be itself another array class). #li For array classes, the getName(args) method returns its class descriptor. This rule seems to fail only for array classes whose the component type is a lambda (which possibly is a bug), but hopefully this should not matter anyway because there is no point even on the existence of array classes whose component type is a lambda. Now, the toString(args) method: #li If the class instance represents an interface (or an annotation, which is a special type of interface), the toString(args) returns StringLiteral + getName(args) . If it is a primitive, it returns simply getName(args) . If it is something else (a class type, even if it is a pretty weird one), it returns StringLiteral + getName(args) . The getCanonicalName(args) method: #li For top-level classes and interfaces, the getCanonicalName(args) method returns just what the getName(args) method returns. #li The getCanonicalName(args) method returns null for anonymous or local classes and for array classes of those. #li For inner and nested classes and interfaces, the getCanonicalName(args) method returns what the getName(args) method would replacing the compiler-introduced dollar-signs by dots. #li For array classes, the getCanonicalName(args) method returns null if the canonical name of the component type is null . Otherwise, it returns the canonical name of the component type followed by [] . The getSimpleName(args) method: #li For top-level, nested, inner and local classes, the getSimpleName(args) returns the name of the class as written in the source file. #li For anonymous classes the getSimpleName(args) returns an empty String . #li For lambda classes the getSimpleName(args) just returns what the getName(args) would return without the package name. This do not makes much sense and looks like a bug for me, but there is no point in calling getSimpleName(args) on a lambda class to start with. #li For array classes the getSimpleName(args) method returns the simple name of the component class followed by [] . This have the funny/weird side-effect that array classes whose component type is an anonymous class have just [] as their simple names.

Question-20358883, answer-31931870
Collections.singletonList(args)

Question-6252678, answer-6252802
You need a DateTimeFormatter appropriate to the format you're using. Take a look at the docs for instructions on how to build one. Off the cuff, I think you need format = DateTimeFormat.forPattern(args)

Question-16159203, answer-16323196
#blockquote currentPos = new Point(args); does a few things, including writing default values to x and y (0) and then writing their initial values in the constructor. Since your object is not safely published those 4 write operations can be freely reordered by the compiler / JVM. So from the perspective of the reading thread, it is a legal execution to read x with its new value but y with its default value of 0 for example. By the time you reach the println statement (which by the way is synchronized and therefore does influence the read operations), the variables have their initial values and the program prints the expected values. Marking currentPos as volatile will ensure safe publication since your object is effectively immutable - if in your real use case the object is mutated after construction, volatile guarantees won't be enough and you could see an inconsistent object again. Alternatively, you can make the Point immutable which will also ensure safe publication, even without using volatile . To achieve immutability, you simply need to mark x and y final. As a side note and as already mentioned, synchronized(args) {} can be treated as a no-op by the JVM (I understand you included it to reproduce the behaviour).

Question-14602062, answer-14602092
From String.split() API Doc : #blockquote Overloaded String.split(regex, int) is more appropriate for your case.

Question-28319064, answer-28323553
One of the main benefits of using streams is that it gives the ability to process data in a declarative way, that is, using a functional style of programming. It also gives multi-threading capability for free meaning there is no need to write any extra multi-threaded code to make your stream concurrent. Assuming the reason you are exploring this style of programming is that you want to exploit these benefits then your first code sample is potentially not functional since the foreach method is classed as being terminal (meaning that it can produce side-effects). The second way is preferred from functional programming point of view since the map function can accept stateless lambda functions. More explicitly, the lambda passed to the map function should be #li Non-interfering, meaning that the function should not alter the source of the stream if it is non-concurrent (e.g. ArrayList ). #li Stateless to avoid unexpected results when doing parallel processing (caused by thread scheduling differences). Another benefit with the second approach is if the stream is parallel and the collector is concurrent and unordered then these characteristics can provide useful hints to the reduction operation to do the collecting concurrently.

Question-5011932
I am storing a SQL query in my strings.xml file and I want to use String.Format to build the final string in code. The SELECT statement uses a like, something like this: SELECT Field1, Field2 FROM mytable WHERE Field1 LIKE '%something%' In order to format that I replace 'something' with %1$s so it becomes: SELECT Field1, Field2 FROM mytable WHERE Field1 LIKE \'%%1$s%\' I escape the single quotes with the backslash. However I am not able to escape the % sign. How can I include a like statement in my strings.xml file?

Question-5455794, answer-5455820
How about replaceAll(args) . Refer here .

Question-20746429, answer-24531394
Here is a version done on ints - as asked in the question. Usage: StreamUtil.takeWhile(args); Here's code for StreamUtil: #pre

Question-18532488, answer-33142346
Once a repeat function is somewhere defined as #pre You can use it now and then this way, e.g.: repeat.accept(args); To get and equivalent to Haskell's take 8(args) You could write #pre

Question-28671903
I have a set â€“ a HashSet I want to remove some items from itâ€¦ none of the items in the "removals" collection will be in the original set. I specify the size of the "source" set and the size of the "removals" collection on the command line, and build both of them. The source set contains only non-negative integers; the removals set contains only negative integers. I measure how long it takes to remove all the elements using System.currentTimeMillis(), which isnâ€™t the world most accurate stopwatch but is more than adequate in this case, as youâ€™ll see. Hereâ€™s the code: #pre Letâ€™s start off by giving it an easy job: a source set of 100 items, and 100 to remove: #pre Okay, That's fast as I expected. Next i tried source of one million items and 300,000 items to remove? #pre That still seems pretty speedy. Now make it a bit easier â€“ 300,000 source items and 300,000 removals: #pre Nearly three minutes? Really confused !! can some one explain why this is happening.

Question-8579657, answer-35264580
Main difference is that when program calls start(args) method a new Thread is created and code inside run() method is executed in new Thread while if you call run(args) method directly no new Thread is created and code inside run() will execute on current Thread . Another difference between start vs run in Java thread is that you can not call start() method twice on thread object . once started, second call of start() will throw IllegalStateException in Java while you can call run() method twice.

Question-16148575, answer-16148647
Please use HashMap<T> myMap = new HashMap<T>(args);

Question-18723596
String x = (String) null; Why there is no exception in this statement? #pre It prints null . But .toString(args) method should throw a null pointer exception.

Question-31202946
Why was the Thread class implemented as a regular class and not an abstract class with run(args) method being abstract. Will it possibly introduce any problems? Or does it have any use in being this way? Also, the Thread.start(args) method is supposed to be a very specific method whose functionality cannot be implemented by any other class (If I am not wrong). And hence I guess the final keyword would be apt for this more than any other method. But I am able to override this method and use it as I like, #pre It obviously only printed, #blockquote Is there any use in overriding other than confusing the engineer replacing you? If not, why was the method not declared final in Thread class?

Question-9481865, answer-33093380
You may try isReachable(args) method of InetAddress class to figure out which IP address is your real publicly available IP address. I think other type of addresses (site local,link local) are not reachable from outside. #pre

Question-21488056, answer-30506585
Predicate has methods and , or and negate . However, String::isEmpty is not a Predicate . It could as well be Function<T> or MyProprietaryClass . The type information is inferred from the variable or the call. So, you need to cast a method reference explicitly (as @axtavt mentioned): ((Predicate<T>) String::isEmpty).negate(args) But it's absolutely ugly and Predicate seems to use lambdas under the hood anyway. So I think you are better off writing a lambda or even your own not(args) method (e.g. in utility, static import).

Question-7348711, answer-28043703
As others have noted, getting the hostname based on DNS resolution is unreliable. Since this question is unfortunately still relevant in 2016 , I'd like to share with you my network-independent solution, with some test runs on different systems. The following code tries to do the following: #li On Windows #li Read the COMPUTERNAME environment variable through System.getenv(args) . #li Execute hostname.exe and read the response #li On Linux #li Read the HOSTNAME environment variable through System.getenv(args) #li Execute hostname and read the response #li Read /etc/hostname (to do this I'm executing cat since the snippet already contains code to execute and read. Simply reading the file would be better, though). The code: #pre Results for different operating systems: OpenSuse 13.1 #pre Ubuntu 14.04 LTS This one is kinda strange since echo $HOSTNAME returns the correct hostname, but System.getenv(args) does not: #pre EDIT: According to legolas108 , System.getenv(args) works on Ubuntu 14.04 if you run export HOSTNAME before executing the Java code. Windows 7 #pre The machine names have been replaced but I kept the capitalization and structure. Note the extra newline when executing hostname , you might have to take it into account in some cases.

Question-25850328
I was being taught that Marker interface in Java is an empty interface and is used to signal to compiler or JVM that the objects of the class implementing this interface must be treated in a special way, like serializing, cloning, etc. But lately I have learned that it actually has nothing to do with the compiler or the JVM. For example, in case of Serializable interface the method writeObject(args) of ObjectOutputStream does something like instanceOf Serializable to detect whether the class implements Serializable & throws NotSerializableException accordingly. Everything is handled in the code and this seems to be a design-pattern so I think we can define our own marker interfaces. Now my doubts: #li Is the definition of a marker interface mentioned above in 1st point wrong? How can we define a Marker interface then? #li And instead of using the instanceOf operator why can't the method be something like writeObject(args) so that there is a compile-time type checking rather than runtime? #li How are Annotations better than Marker Interfaces?

Question-20129762, answer-30548433
I would like to point out that StreamEx does implement Iterable (and Stream ), as well as a host of other immensely awesome functionality missing from Stream .

Question-19235606
I am having trouble understanding the Stream interface in Java 8, especially where it has to do with the Spliterator and Collector interfaces. My problem is that I simply can't understand yet the Spliterator and the Collector interfaces, and as a result the Stream interface is still somewhat obscure to me. What exactly is a Spliterator and a Collector , and how can I use them? If I am willing to write my own Spliterator or Collector (and probably my own Stream in that process), what should I do and not do? I read some examples scattered around the web, but since everything here is stil new and subject to changes, examples and tutorials are still very sparse.

Question-31202946, answer-31203252
#blockquote This question actually boils down to the fact that you should always prefer composition over inheritance. If the Thread class was declared as abstract , the language would have to provide another class that extended from it which programmers could use to create a Thread . Your question would then be about why this class that extends from Thread is not abstract . If the language did not provide another class that extends from Thread , programmers would have to create their own class that extend s from Thread and override the run(args) method. #blockquote The only possible explanation I can give is that the developers of the language saw some use-cases for overriding start when the class was introduced to the JDK. The first version of Java that I used was 1.5 and I personally have not come across a use-case where I found the need to override start . As JB Nizet stated in his answer #blockquote

Question-8189466, answer-23592535
I had that same problem but in case that I was adding en element into iterated list. I made it this way #pre Now everything goes fine because you don't create any iterator over your list, you iterate over it "manually". And condition i < integerList.size(args) will never fool you because when you remove/add something into List size of the List decrement/increment.. Hope it helps, for me that was solution.

Question-28681737, answer-28684917
The short answer is: it's safe if you use them safely :) The snarky answer: tell me what you mean by traits, and maybe I'll give you a better answer :) In all seriousness, the term "trait" is not well-defined. Many Java developers are most familiar with traits as they are expressed in Scala, but Scala is far from the first language to have traits, either in name or in effect. For example, in Scala, traits are stateful (can have var variables); in Fortress they are pure behavior. Java's interfaces with default methods are stateless; does this mean they are not traits? (Hint: that was a trick question.) Again, in Scala, traits are composed through linearization; if class A extends traits X and Y , then the order in which X and Y are mixed in determines how conflicts between X and Y are resolved. In Java, this linearization mechanism is not present (it was rejected, in part, because it was too "un-Java-like".) The proximate reason for adding default methods to interfaces was to support interface evolution , but we were well aware that we were going beyond that. Whether you consider that to be "interface evolution++" or "traits--" is a matter of personal interpretation. So, to answer your question about safety ... so long as you stick to what the mechanism actually supports, rather than trying to wishfully stretch it to something it does not support, you should be fine. A key design goal was that, from the perspective of the client of an interface, default methods should be indistinguishable from "regular" interface methods. The default-ness of a method, therefore, is only interesting to the designer and implementor of the interface. Here are some use cases that are well within the design goals: #li Interface evolution. Here, we are adding a new method to an existing interface, which has a sensible default implementation in terms of existing methods on that interface. An example would be adding the forEach method to Collection , where the default implementation is written in terms of the iterator(args) method. #li "Optional" methods. Here, the designer of an interface is saying "Implementors need not implement this method if they are willing to live with the limitations in functionality that entails". For example, Iterator.remove was given a default which throws UnsupportedOperationException ; since the vast majority of implementations of Iterator have this behavior anyway, the default makes this method essentially optional. (If the behavior from AbstractCollection were expressed as defaults on Collection , we might do the same for the mutative methods.) #li Convenience methods. These are methods that are strictly for convenience, again generally implemented in terms of non-default methods on the class. The logger(args) method in your first example is a reasonable illustration of this. #li Combinators. These are compositional methods that instantiate new instances of the interface based on the current instance. For example, the methods Predicate.and(args) or Comparator.thenComparing(args) are examples of combinators. If you provide a default implementation, you should also provide some specification for the default (in the JDK, we use the @implSpec javadoc tag for this) to aid implementors in understanding whether they want to override the method or not. Some defaults, like convenience methods and combinators, are almost never overridden; others, like optional methods, are often overridden. You need to provide enough specification (not just documentation) about what the default promises to do, so the implementor can make a sensible decision about whether they need to override it.

Question-14846920
What are some of the situations where I can use Collections.emptyMap(args) ? The Documentation says I can use this method if I want my collection to be immutable. Why would I want an immutable empty collection? What is the point?

Question-16159203, answer-18258659
You have ordinary memory, the 'currentpos' reference and the Point object and its fields behind it, shared between 2 threads, without synchronisation. Thus, there is no defined ordering between the writes that happen to this memory in the main thread and the reads in the created thread (call it T). Main thread is doing the following writes (ignoring the initial setup of point, will result in p.x and p.y having default values): #li to p.x #li to p.y #li to currentpos Because there is nothing special about these writes in terms of synchronisation/barriers, the runtime is free to allow the T thread see them occur in any order (the main thread of course always sees writes and reads ordered according to programme order), and occur at any point between the reads in T. So T is doing: #li reads currentpos to p #li read p.x and p.y (in either order) #li compare, and take the branch #li read p.x and p.y (either order) and call System.out.println Given there's no ordering relationships between the writes in main, and the reads in T, there are clearly several ways this can produce your result, as T may see main's write to currentpos before the writes to currentpos.y or currentpos.x: #li It reads currentpos.x first, before the x write has occurred - gets 0, then reads currentpos.y before the y write has occurred - gets 0. Compare evals to true. The writes become visible to T. System.out.println is called. #li It reads currentpos.x first, after the x write has occurred, then reads currentpos.y before the y write has occurred - gets 0. Compare evals to true. Writes become visible to T... etc. #li It reads currentpos.y first, before the y write has occurred (0), then reads currentpos.x after the x write, evals to true. etc. and so on... There are a number of data races here. I suspect the flawed assumption here is thinking that the writes that result from this line are made visible across all the threads in the programme order of the thread executing it: currentPos = new Point(args); Java makes no such guarantee (it'd be terrible for performance). Something more must be added if your programme needs a guaranteed ordering of the writes relative to reads in other threads. Others have suggested making the x,y fields final, or alternatively making currentpos volatile. #li If you make the x,y fields final, then Java guarantees that the writes of their values will be seen to occur before the constructor returns, in all threads. Thus, as the assignment to currentpos is after the constructor, the T thread is guaranteed to see the writes in the correct order. #li If you make currentpos volatile, then Java guarantees that that this is a synchronisation point which will be total-ordered wrt other synchronisation points. As in main the writes to x and y must happen before the write to currentpos, then any read of currentpos in another thread must see also the writes of x, y that happened before. Using final has the advantage that it makes the fields immutable, and thus allows the values to be cached. Using volatile leads to synchronisation on every write and read of currentpos, which might hurt performance. See chapter 17 of the Java Language Spec for the gory details: #a (Initial answer assumed a weaker memory model, as I was not sure the JLS guaranteed volatile was sufficient. Answer edited to reflect comment from assylias, pointing out the Java model is stronger - happens-before is transitive - and so volatile on currentpos also suffices).

Question-15156857, answer-15157021
You must use doThrow(args).when(args).methodReturningVoid(args); and not doThrow(args).when(args); This is explained in the documentation

Question-18410035
Being somewhat new to the Java language I'm trying to familiarize myself with all the ways (or at least the non-pathological ones) that one might iterate through a list (or perhaps other collections) and the advantages or disadvantages of each. Given a List<T> list object, I know of the following ways to loop through all elements: Basic for loop (of course, there're equivalent while / do while loops as well) #pre Note: As @amarseillan pointed out, this form is a poor choice for iterating over List s because the actual implementation of the get method may not be as efficient as when using an Iterator . For example, LinkedList implementations must traverse all of the elements preceding i to get the i-th element. In the above example there's no way for the List implementation to "save its place" to make future iterations more efficient. For an ArrayList it doesn't really matter because the complexity/cost of get is constant time (O(1)) whereas for a LinkedList is it proportional to the size of the list (O(n)). For more information about the computational complexity of the built-in Collections implementations, check out this question . Enhanced for loop (nicely explained in this question ) #pre Iterator #pre EDIT: Added ListIterator ListIterator #pre EDIT: Added "functional-style" solution (thanks Dave Newton) Functional Java list.stream(args).map(args); // can apply a transformation function for e EDIT: Added map method from Java 8's Stream API (see @i_am_zero's answer) Iterable.forEach , Stream.forEach , ... In Java 8 collection classes that implement Iterable (for example all List s) now have a forEach method, which can be used instead of the for loop statement demonstrated above. (Here is another question that provides a good comparison.) #pre What other ways are there, if any? I feel like this has got to be a duplicate, but I haven't been able to find what I'm looking for, so I apologize for this question potentially being redundant. (BTW, my interest does not stem at all from a desire to optimize performance ; I just want to know what forms are available to me as a developer.) EDIT: Moved ListIterationExample.java to a suggested answer

Question-32323081, answer-32323641
First of all, you don' have to overload :D - overloading is never a necessity; use 2 different method names, e.g. foo and fooX Secondly, I don't see why you need 2 methods here. If you want to handle checked and unchecked exceptions differently, it can be done at runtime. To achieve "exception transparency", you can do #pre Finally, disambiguity can be achieved throw lambda return type; the compiler uses the return type as if using an argument type for choosing the most specific method. This gives us the idea to wrap the value together with the exception type, as Result<T> , a "monad" as they say. #pre

Question-24885223
I don't know whether I am asking the right question. I was exploring RecyclerView and I was surprised to see that RecyclerView does not have onItemClickListener(args) . Because RecyclerView extends #blockquote and ListView extends #blockquote . However I solved my problem by writing onClick in my RecyclerView.Adapter : #pre But still I want to know why Google removed onItemClickListener(args) ? Is there a performance issue or something else?

Question-14534767, answer-34073047
Another option is to use Apache Commons StrBuilder, which has the functionality that's lacking in StringBuilder. StrBuilder.appendLn()

Question-5374311, answer-17909839
The correct way to do this is: String[] stockArr = stock_list.toArray(args); I'd like to add to the other great answers here and explain how you could have used the Javadocs to answer your question. The Javadoc for toArray(args) (no arguments) is here . As you can see, this method returns an Object[] and not String[] which is an array of the runtime type of your list: #blockquote Right below that method, though, is the Javadoc for toArray(args) . As you can see, this method returns a T[] where T is the type of the array you pass in. At first this seems like what you're looking for, but it's unclear exactly why you're passing in an array (are you adding to it, using it for just the type, etc). The documentation makes it clear that the purpose of the passed array is essentially to define the type of array to return (which is exactly your use case): #blockquote Of course, an understanding of generics (as described in the other answers) is required to really understand the difference between these two methods. Nevertheless, if you first go to the Javadocs, you will usually find your answer and then see for yourself what else you need to learn (if you really do). Also note that reading the Javadocs here helps you to understand what the structure of the array you pass in should be. Though it may not really practically matter, you should not pass in an empty array like this: String [] stockArr = stockList.toArray(args); Because, from the doc, this implementation checks if the array is large enough to contain the collection; if not, it allocates a new array of the correct size and type (using reflection). There's no need for the extra overhead in creating a new array when you could easily pass in the size. As is usually the case, the Javadocs provide you with a wealth of information and direction. Hey wait a minute, what's reflection?

Question-21947452, answer-29434641
I performed tests on Eclipse vs Netbeans 8.0.2, both with Java version 1.8; I used System.nanoTime(args) for measurements. Eclipse: I got the same time on both cases - around 1.564 seconds . Netbeans: #li Using "#": 1.536 seconds #li Using "B": 44.164 seconds So, it looks like Netbeans has bad performance on print to console. After more research I realized that the problem is line-wrapping of the max buffer of Netbeans (it's not restricted to System.out.println command), demonstrated by this code: #pre The time results are less then 1 millisecond every iteration except every fifth iteration , when the time result is around 225 millisecond. Something like (in nanoseconds): #pre And so on.. Summary: #li Eclipse works perfectly with "B" #li Netbeans has a line-wrapping problem that can be solved (because the problem does not occur in eclipse)(without adding space after B ("B ")).

Question-20877086, answer-20889556
To complement the given answers, also take note of the following: #pre This code will also print: false As user Jay has claimed in a comment for the accepted answer, care must be taken when using operator == on objects, here you're checking if both references are the same, which is not, because they are different objets, although they represent the very same value. To compare objects, you should use the equals method instead: #pre This will print: true You may ask, But then why the first line printed true ? . Checking the source code for the Integer.valueOf method, you can see the following: #pre If the param is an integer between IntegerCache.low (defaulted to -128) and IntegerCache.high (calculated at runtime with minimum value 127) then a pre-allocated (cached) object is returned. So when you use 127 as parameter, you're getting two references to same cached object and getting true in the comparison of the references.

Question-6667243, answer-6667310
You can use Mode.mode1.name(args) however you often don't need to do this. Mode mode = System.out.println(args);

Question-14491966, answer-14492320
Your QuickRandom implementation hasn't really an uniform distribution. The frequencies are generally higher at the lower values while Math.random(args) has a more uniform distribution. Here's a SSCCE which shows that: #pre The average result looks like this: #pre If you repeat the test, you'll see that the QR distribution varies heavily, depending on the initial seeds, while the MR distribution is stable. Sometimes it reaches the desired uniform distribution, but more than often it doesn't. Here's one of the more extreme examples, it's even beyond the borders of the graph: #pre

Question-6271417, answer-6271668
I'm assuming this is happening for an anonymous class. When you create an anonymous class you actually create a class that extends the class whose name you got. The "cleaner" way to get the name you want is: If your class is an anonymous inner class, getSuperClass(args) should give you the class that it was created from. If you created it from an interface than you're sort of SOL because the best you can do is getInterfaces(args) which might give you more than one interface. The "hacky" way is to just get the name with getClassName(args) and use a regex to drop the $1 .

Question-27504925, answer-27505121
I'd like to point out this article . It seems as though arrays and objects follow different opcodes. I can't honestly summarize it more than that however it seems, arrays are simply not treated as Objects like we're normally used to so they don't inherit Object methods. Full credits to the author of that post as it's a very interesting read, both short & detailed. Upon further digging into the topic via multiple sources I've decided to give a more elaborate version of my previous answer. The first thing to note that instantiation of Objects and Arrays are very different within the JVM, their follow their respective bytecode. Object: Object instantiation follows a simple Opcode new which is a combination of two operands - indexbyte1 & indexbyte2 . Once instantiated the JVM pushes the reference to this object onto the stack . This occurs for all objects irrespective of their types. Arrays: Array Opcodes (regarding instantiation of an array) however are divided into three different codes. #blockquote newarray opcode is used when creating arrays that involve primitive datatypes ( byte short char int long float double boolean ) rather than object references. #blockquote anewarray opcode is used when creating arrays of object references #blockquote multianewarray instruction is used when allocating multi-dimensional arrays Object can be a class instance or an array. Take from Oracle Docs #blockquote BUT #blockquote This goes hand in hand with the information regarding the opcodes. Arrays are simply not developed to be class interfaces but are instead explicitly created by array creation expression thus naturally wouldn't implicitly be able to inherit and/or override Object . As we have seen, it has nothing to do with the fact that arrays may hold primitive datatypes. After giving it some thought though, it isn't very common to come across situations where one might want to toString(args) or equals(args) however was still a very interesting question to try and answer. Resources: Oracle-Docs chapter 4.3.1 Oracle-Docs chapter 15.10.1 Artima - UnderTheHood

Question-7348711, answer-7800008
Strictly speaking - you have no choice but calling either hostname(args) or - on Unix gethostname(args) . This is the name of your computer. Any attempt to determine the hostname by an IP address like this InetAddress.getLocalHost(args).getHostName(args) is bound to fail in some circumstances: #li The IP address might not resolve into any name. Bad DNS setup, bad system setup or bad provider setup may be the reason for this. #li A name in DNS can have many aliases called CNAMEs. These can only be resolved in one direction properly: name to address. The reverse direction is ambiguous. Which one is the "official" name? #li A host can have many different IP addresses - and each address can have many different names. Two common cases are: One ethernet port has several "logical" IP addresses or the computer has several ethernet ports. It is configurable whether they share an IP or have different IPs. This is called "multihomed". #li One Name in DNS can resolve to several IP Addresses. And not all of those addresses must be located on the same computer! (Usecase: A simple form of load-balancing) #li Let's not even start talking about dynamic IP addresses. Also don't confuse the name of an IP-address with the name of the host (hostname). A metaphor might make it clearer: #blockquote This illustrates it pretty much I think. The good news is: The real hostname is usually not necessary. In most cases any name which resolves into an IP address on this host will do. (The stranger might enter the city by Northgate, but helpful locals translate the "2nd left" part.) If the remaining corner cases you must use the definitive source of this configuration setting - which is the C function gethostname(args) . That function is also called by the program hostname .

Question-18532488
In many other languages, eg. Haskell, it is easy to repeat a value or function multiple times, eg. to get a list of 8 copies of the value 1: take 8(args) but I haven't found this yet in Java 8. Is there such a function in Java 8's JDK? Or alternatively something equivalent to a range like [1..8] It would seem an obvious replacement for a verbose statement in Java like #pre to have something like Range.from(args).forEach(args) though this particular example doesn't look much more concise actually... but hopefully it's more readable.

Question-5868369, answer-32542424
What you can do is scan the entire text using Scanner and go through the text line by line. Of course you should import the following: #pre Scanner basically scans all the text. The while loop is used to traverse through the entire text. The .hasNextLine(args) function is a boolean that returns true if there are still more lines in the text. The .nextLine(args) function gives you an entire line as a String which you can then use the way you want. Try System.out.println(args) to print the text. Side Note: .txt is the file type text.

Question-15430247, answer-15446006
I actually wrote a blog post on the topic 2 months ago. The article is for C#'s List<T> but Java's ArrayList has a very similar implementation. Since ArrayList is implemented using a dynamic array, it increases in size on demand. So the reason for the capacity constructor is for optimisation purposes. When one of these resizings operation occurs, the ArrayList copies the contents of the array into a new array that is twice the capacity of the old one. This operation runs in O(n) time. Example Here is an example of how the ArrayList would increase in size: #pre So the list starts with a capacity of 10 , when the 11th item is added it is increase by 50% + 1 to 16 . On the 17th item the ArrayList is increased again to 25 and so on. Now consider the example where we're creating a list where the desired capacity is already known as 1000000 . Creating the ArrayList without the size constructor will call ArrayList.add 1000000 times which takes O(1) normally or O(n) on resize. #blockquote Compare this using the constructor and then calling ArrayList.add which is guaranteed to run in O(1) . #blockquote Java vs C# Java is as above, starting at 10 and increasing each resize at 50% + 1 . C# starts at 4 and increases much more aggressively, doubling at each resize. The 1000000 adds example from above for C# uses 3097084 operations. References #li My blog post on C#'s List<T> #li Java's ArrayList source code

Question-5982447, answer-5982478
Use the Set#toArray(T[]) method taking a typed array argument of the same size. String[] GPXFILES1 = myset.toArray(args); A different size can also, but that would force the toArray(args) method to create a new array to return instead of reusing the provided argument, which may end up to be less efficient. See also the source code of AbstractCollection#toArray() .

Question-34509566, answer-34529067
Keep in mind that Java holds a pool of all string literals found in program, used for matching purposes among others, so any different string literal concatenation above will lead to the same object, to the same string literal. You can check out this useful article for more. On the other hand, the concatenation of a String object and a literal (case c + StringLiteral ) will lead to the creation of a as StringBuilder object at runtime, different to the literals found in pool.

Question-5192512, answer-22694891
I think many of the answers here may be missing a quality method included in StringBuilder : .delete(args) . I know this is a late reply; however, this should be made known (and explained a bit more thoroughly). Let's say you have a StringBuilder table - which you wish to modify, dynamically, throughout your program (one I am working on right now does this), e.g. StringBuilder table = new StringBuilder(args); If you are looping through the method and alter the content, use the content, then wish to discard the content to "clean up" the StringBuilder for the next iteration, you can delete it's contents, e.g. table.delete(args). start and end being the indices of the chars you wish to remove. Don't know the length in chars and want to delete the whole thing? table.delete(args); NOW, for the kicker. StringBuilders , as mentioned previously, take a lot of overhead when altered frequently (and can cause safety issues with regard to threading); therefore, use StringBuffer - same as StringBuilder (with a few exceptions) - if your StringBuilder is used for the purpose of interfacing with the user.

Question-15621083
I am working on some Java code which needs to be highly optimized as it will run in hot functions that are invoked at many points in my main program logic. Part of this code involves multiplying double variables by 10 raised to arbitrary non-negative int exponent s. One fast way (edit: but not the fastest possible, see Update 2 below) to get the multiplied value is to switch on the exponent : #pre The commented ellipses above indicate that the case int constants continue incrementing by 1, so there are really 19 case s in the above code snippet. Since I wasn't sure whether I would actually need all the powers of 10 in case statements 10 thru 18 , I ran some microbenchmarks comparing the time to complete 10 million operations with this switch statement versus a switch with only case s 0 thru 9 (with the exponent limited to 9 or less to avoid breaking the pared-down switch ). I got the rather surprising (to me, at least!) result that the longer switch with more case statements actually ran faster. On a lark, I tried adding even more case s which just returned dummy values, and found that I could get the switch to run even faster with around 22-27 declared case s (even though those dummy cases are never actually hit while the code is running). (Again, case s were added in a contiguous fashion by incrementing the prior case constant by 1 .) These execution time differences are not very significant: for a random exponent between 0 and 10 , the dummy padded switch statement finishes 10 million executions in 1.49 secs versus 1.54 secs for the unpadded version, for a grand total savings of 5ns per execution. So, not the kind of thing that makes obsessing over padding out a switch statement worth the effort from an optimization standpoint. But I still just find it curious and counter-intuitive that a switch doesn't become slower (or perhaps at best maintain constant O(1) time) to execute as more case s are added to it. #img These are the results I obtained from running with various limits on the randomly-generated exponent values. I didn't include the results all the way down to 1 for the exponent limit, but the general shape of the curve remains the same, with a ridge around the 12-17 case mark, and a valley between 18-28. All tests were run in JUnitBenchmarks using shared containers for the random values to ensure identical testing inputs. I also ran the tests both in order from longest switch statement to shortest, and vice-versa, to try and eliminate the possibility of ordering-related test problems. I've put my testing code up on a github repo if anyone wants to try to reproduce these results. So, what's going on here? Some vagaries of my architecture or micro-benchmark construction? Or is the Java switch really a little faster to execute in the 18 to 28 case range than it is from 11 up to 17 ? github test repo "switch-experiment" UPDATE: I cleaned up the benchmarking library quite a bit and added a text file in /results with some output across a wider range of possible exponent values. I also added an option in the testing code not to throw an Exception from default , but this doesn't appear to affect the results. UPDATE 2: Found some pretty good discussion of this issue from back in 2009 on the xkcd forum here: #a . The OP's discussion of using Array.binarySearch(args) gave me the idea for a simple array-based implementation of the exponentiation pattern above. There's no need for the binary search since I know what the entries in the array are. It appears to run about 3 times faster than using switch , obviously at the expense of some of the control flow that switch affords. That code has been added to the github repo also.

Question-23453287, answer-23456085
It will be hard to find and identify "THE" answer, for the resons mentioned in the comments from @EJP : There are roughly 2 (+/- 2) people in the world who can give the definite answer at all . And in doubt, the answer might just be something like "Supporting final default methods did not seem to be worth the effort of restructuring the internal call resolution mechanisms". This is speculation, of course, but it is at least backed by subtle evidences, like this Statement (by one of the two persons) in the OpenJDK mailing list : #blockquote and trivial facts like that a method is simply not considered to be a (really) final method when it is a default method, as currently implemented in the Method::is_final_method method in the OpenJDK. Further really "authorative" information is indeed hard to find, even with excessive websearches and by reading commit logs. I thought that it might be related to potential ambiguities during the resolution of interface method calls with the invokeinterface instruction and and class method calls, corresponding to the invokevirtual instruction: For the invokevirtual instruction, there may be a simple vtable lookup, because the method must either be inherited from a superclass, or implemented by the class directly. In contrast to that, an invokeinterface call must examine the respective call site to find out which interface this call actually refers to (this is explained in more detail in the InterfaceCalls page of the HotSpot Wiki). However, final methods do either not get inserted into the vtable at all, or replace existing entries in the vtable (see klassVtable.cpp. Line 333 ), and similarly, default methods are replacing existing entries in the vtable (see klassVtable.cpp, Line 202 ). So the actual reason (and thus, the answer) must be hidden deeper inside the (rather complex) method call resolution mechanisms, but maybe these references will nevertheless be considered as being helpful, be it only for others that manage to derive the actual answer from that.

Question-28459498, answer-28465634
I think there are very few differences between the two when you look closely enough. At it's face, an IEnumerable does appear to be a reusable construct: #pre However, the compiler is actually doing a little bit of work to help us out; it generates the following code: #pre Each time you would actually iterate over the enumerable, the compiler creates an enumerator. The enumerator is not reusable; further calls to MoveNext will just return false, and there is no way to reset it to the beginning. If you want to iterate over the numbers again, you will need to create another enumerator instance. To better illustrate that the IEnumerable has (can have) the same 'feature' as a Java Stream, consider a enumerable whose source of the numbers is not a static collection. For example, we can create an enumerable object which generates a sequence of 5 random numbers: #pre Now we have very similar code to the previous array-based enumerable, but with a second iteration over numbers : #pre The second time we iterate over numbers we will get a different sequence of numbers, which isn't reusable in the same sense. Or, we could have written the RandomNumberStream to thrown an exception if you try to iterate over it multiple times, making the enumerable actually unusable (like a Java Stream). Also, what does your enumerable-based quick sort mean when applied to a RandomNumberStream ? Conclusion So, the biggest difference is that .NET allows you to reuse an IEnumerable by implicitly creating a new IEnumerator in the background whenever it would need to access elements in the sequence. This implicit behavior is often useful (and 'powerful' as you state), because we can repeatedly iterate over a collection. But sometimes, this implicit behavior can actually cause problems. If your data source is not static, or is costly to access (like a database or web site), then a lot of assumptions about IEnumerable have to be discarded; reuse is not that straight-forward

Question-28818506, answer-28821352
It's not pretty, but this will work: return serviceA(args) .map(args).orElseGet(args) .map(args).orElseGet(args) .map(args).orElseGet(args); .map(args).orElseGet(args) is a fairly handy pattern for use with Optional . It means "If this Optional contains value v , give me func(args) , otherwise give me sup.get(args) ". In this case, we call serviceA(args) and get an Optional<T> . If that Optional contains value v , we want to get Optional.of(args) , but if it is empty, we want to get serviceB(args) . Rinse-repeat with more alternatives. Other uses of this pattern are #li .map(args).orElseGet(args) #li .map(args).orElseGet(args)

Question-31270759, answer-31273726
What if every functional interface provided by java.util.function was allowed to throw an exception? #pre We could use some default methods to provide the behavior you want. #li You could fallback to some default value or action #li Or you could try to perform another action which may throw an exception I've written a library which redefines most of the interfaces in java.util.function this way. I even provide a ThrowingStream which let's you use these new interfaces with the same API as a regular Stream . #pre ( Nothing is a RuntimeException that can never be thrown.) Your original example would become #pre

Question-11411022, answer-34052602
The best way is the clearest way: * Thread.currentThread(args) == Looper.getMainLooper(args).getThread(args) Or, if the runtime platform is API level 23 (Marshmallow 6.0) or higher: Looper.getMainLooper(args).isCurrentThread(args) See the Looper API . Note that calling Looper.getMainLooper(args) involves synchonization (see the source ). You might want to avoid the overhead by storing the return value and reusing it. * credit greg7gkb

Question-16232833, answer-16250729
change your return type to ResponseEntity<T> , then you can use below for 400 return new ResponseEntity<T>(args); and for correct request return new ResponseEntity<T>(args); UPDATE 1 after spring 4.1 there are helper methods in ResponseEntity could be used as return ResponseEntity.status(args).body(args); and return ResponseEntity.ok(args);

Question-25850328, answer-31838310
The main purpose of marker interfaces is to create special types where types themselves have no behavior of their own. #pre Here save method makes sure that only the objects of classes that implement the MarkerEntity interface are saved, for other types InvalidEntityFoundException is thrown. So here MarkerEntity marker interface is defining a type that adds special behavior to the classes implementing it. Though annotations can also used now to mark classes for some special treatments but marker annotations are replacement for naming pattern not for Marker interfaces. But marker annotations can't fully replace the marker interfaces because; marker interfaces are used to define type (as already explained above) where as marker annotations do not. Source for marker interface comment

Question-21163108, answer-21172732
The parallel streams use the default ForkJoinPool which by default has one less threads as you have processors , as returned by Runtime.getRuntime(args).availableProcessors(args) (so parallel streams use all your processors because they also use the main thread): #blockquote To change the way parallel streams are executed, you can either #li submit the parallel stream execution to your own ForkJoinPool: yourFJP.submit(args); or #li you can change the size of the common pool using system properties: System.setProperty(args) for a target parallelism of 20 threads. Example of the latter on my machine which has 8 processors. If I run the following program: #pre The output is: #blockquote So you can see that the parallel stream processes 8 items at a time, i.e. it uses 8 threads. However if I uncomment the commented line, the output is: #blockquote This time the parallel stream has used 20 threads and all 20 elements in the stream have been processed comcurrently.

Question-10786042
Say I have a URL http://example.com/query?q= and I have a query entered by the user such as: #blockquote I want the result to be a properly encoded URL: http://example.com/query?q=random%20word%20%A3500%20bank%20%24 What's the best way to achieve this? I tried URLEncoder and creating URI/URL objects but none of them come out quite right.

Question-29922296, answer-29922469
My guess is that enums are limited in size (i.e the size is not limited by language but limited by usage)and thus they don't need a native stream api. Streams are very good when you have to manipulate transform and recollect the elements in a stream; these are not common uses case for Enum (usually you iterate over enum values, but rarely you need to transform, map and collect them). If you need only to do an action over each elements perhaps you should expose only a forEach method #pre

Question-5868369, answer-5868454
You need to use the readLine(args) method in class BufferedReader . Create a new object from that class and operate this method on him and save it to a string. BufferReader API

Question-15202997, answer-37603567
this is best document I found describing getName(), getSimpleName(), getCanonicalName() #a #pre

Question-17828584, answer-17832168
I think the number displayed is the number of time the System.out.println call throws the Stackoverflow exception. It probably depend on the implementation of the println and the number of stacking call it is made in it. As an illustration: The main(args) call trigger the Stackoverflow exception at call i. The i-1 call of main catch the exception and call println which trigger a second Stackoverflow . cnt get increment to 1. The i-2 call of main catch now the exception and call println . In println a method is called triggering a 3rd exception. cnt get increment to 2. this continue until println can make all its needed call and finally display the value of cnt . This is then dependent of the actual implementation of println . For the JDK7 either it detect cycling call and throws the exception earlier either it keep some stack resource and throw the exception before reaching the limit to give some room for remediation logic either the println implementation doesn't make calls either the ++ operation is done after the println call thus is by pass by the exception.

Question-32175145, answer-32177563
The other answers have already answered your question - no, this is not possible with the Java's primitive wrapper classes. I'll try to address the "question behind the question": Is this possible with other classes? #blockquote This is actually a good question, and the answer is: Yes, it is possible to create such a situation, and yes, it would make Aristotle angry. Actually, I don't know if it would make Aristotle angry, not having known him, but it will certainly cause a lot of grief for whoever has to work with the code. The thing is: There is a contract associated with Object.equals(args) : #blockquote Javadocs for Object.equals Yes, when creating your own class, you can violate this contract. There is (unfortunately) nothing in the compiler or runtime stopping you. However, a lot of code relies on this contract, so if you violate it, any code that uses equals will probably fail in mysterious ways. One example: Java's own Collection classes ( java.util.Collection and friends) rely on equals . If an instance of a class that does not correctly implement equals is put into a collection, weird things happen, such as the collection sometimes containing the instance and sometimes not.

Question-4871051, answer-21274808
Use CodeSource#getLocation() . This works fine in JAR files as well. You can obtain CodeSource by ProtectionDomain#getCodeSource() and the ProtectionDomain in turn can be obtained by Class#getProtectionDomain() . #pre

Question-7520432, answer-35399386
The String pool (aka interning ) and Integer pool blur the difference further, and may allow you to use == for objects in some cases instead of .equals This can give you greater performance (?), at the cost of greater complexity. E.g.: #pre Complexity tradeoff: the following may surprise you: #pre I advise you to stay away from such micro-optimization, and always use .equals for objects, and == for primitives: #pre

Question-8579657, answer-26159918
invoke run(args) is executing on the calling thread, like any other method call. whereas Thread.start(args) creates a new thread. invoking run(args) is a programmatic bug.

Question-24631909, answer-24635657
Common features a) Both libraries use immutable types. Joda-Time also offers additional mutable types like MutableDateTime . b) Furthermore: Both libraries are inspired by the design study "TimeAndMoney" from Eric Evans or ideas from Martin Fowler about domain driven style so they strive more or less for a fluent programming style (although not always perfect ;-)). c) With both libraries we get a real calendar date type (called LocalDate ), a real wall time type (called LocalTime ) and the composition (called LocalDateTime ). That is a very big win compared with old java.util.Calendar and java.util.Date . d) Both libraries use a method-centric approach meaning they encourage the user to use getDayOfYear(args) instead of get(args) . This causes a lot of extra methods compared with java.util.Calendar (although latter is not type-safe at all due to excessive use of ints). Performance See the other answer by @OO7 pointing to the analysis of Mikhail Vorontsov although point 3 (exception catching) is probably obsolete - see this JDK-bug . The different performance (which is in general favour of JSR-310 ) is mainly due to the fact that the internal implementation of Joda-Time always use a machine-time-like long-primitive (in milliseconds). Null Joda-Time often use NULL as default for system timezone, default locale, current timestamp etc. while JSR-310 almost always rejects NULL values. Precision JSR-310 handles nanosecond precision while Joda-Time is limited to millisecond precision. Supported fields: An overview about supported fields in Java-8 (JSR-310) is given by some classes in the temporal-package (for example ChronoField and WeekFields ) while Joda-Time is rather weak on this area - see DateTimeFieldType . The biggest lack of Joda-Time is here the absence of localized week-related fields. A common feature of both field implementation design is that both are based on values of type long (no other types, not even enums). Enum JSR-310 offers enums like DayOfWeek or Month while Joda-Time does not offer this because it was mainly developed in years 2002-2004 before Java 5 . Zone API a) JSR-310 offers more timezone features than Joda-Time. Latter is not able to yield a programmatical access to the history of timezone offset transitions while JSR-310 is capable to do this. b) For your information: JSR-310 has moved its internal timezone repository to a new location and a different format. The old library folder lib/zi does not exist any more. Adjuster vs. Property JSR-310 has introduced the TemporalAdjuster -interface as a formalized way to externalize temporal calculations and manipulations, especially for library or framework-writers this is a nice and relative easy way to embed new extensions of JSR-310 (a kind of equivalent to static helper classes for former java.util.Date ). For most users however, this feature has very limited value because the burden to write code is still with the user. Built-in solutions based on the new TemporalAdjuster -concept are not so many, there is currently only the helper class TemporalAdjusters with a limited set of manipulations (and the enums Month or other temporal types). Joda-Time offers a field-package but practice has shown evidence that new field implementations are very hard to code. On the other side Joda-Time offers so-called properties which make some manipulations much easier and more elegant than in JSR-310, for example property.withMaximumValue() . Calendar systems JSR-310 offers 4 extra calendar systems. The most interesting one is Umalqura (used in Saudi Arabia). The other 3 are: Minguo (Taiwan), Japanese (only the modern calendar since 1871!) and ThaiBuddhist (only correct after 1940). Joda-Time offers an Islamic calendar based on calculatory base - not a sighting-based calendar like Umalqura. Thai-Buddhist is also offered by Joda-Time in a similar form, Minguo and the japanese one not. Otherwise Joda-Time offers coptic and ethiopic calendar, too (but without any support for internationalization). More interesting for Europeans: Joda-Time also offers a Gregorian , Julian and mixed-gregorian-julian calendar. However, the practical value for real historical calculations is limited because important features like different year starts in date history are not supported at all (the same criticism is valid for old java.util.GregorianCalendar ). Other calendars like Hebrew or Persian or Hindu are completely missing in both libraries. Epoch days JSR-310 has the class JulianFields while Joda-Time (version 2.0) offers some helper methods in the class DateTimeUtils . Clocks JSR-310 has no interface (a design mistake) but an abstract class java.time.Clock which can be used for any clock dependency injection. Joda-Time offers the interface MillisProvider and some helper methods in DateTimeUtils instead. So this way Joda-Time is also capable of supporting test-driven models with different clocks (mocking etc.). Duration arithmetic Both libraries support the calculation of time distances in one or more temporal units. However, when handling single-unit-durations the JSR-310-style is obviously nicer (and long-based instead of using int): JSR-310 => long days = ChronoUnit.DAYS.between(args); Joda-Time => int days = DAYS.daysBetween(args).getDays(args); Handling of multiple-unit-durations are also different. Even the calculation results can differ - see this closed Joda-Time issue . While JSR-310 use a very simple and limited approach to use just the classes Period (duration based on years, months and days) and Duration (based on seconds and nanoseconds), Joda-Time uses a more sophisticated way using the class PeriodType in order to control in which units a duration (Joda-Time call it "Period") shall be expressed. While the PeriodType -API is somehow awkward to use a similar way is not offered by JSR-310 at all. Especially it is not yet possible in JSR-310 to define mixed date and time durations (based on days and hours for example). So be warned if it comes to migration from one library to another. The libraries in discussion are incompatible - despite of partially same class names. Intervals JSR-310 does not support this feature while Joda-Time has limited support. See also this SO-answer . Formatting and Parsing Best way to compare both libraries is to view the equal-named classes DateTimeFormatterBuilder (JSR-310) and DateTimeFormatterBuilder (Joda-Time). The JSR-310-variant is a little bit more powerful (can also handle any kind of TemporalField provided the field implementor has managed to code some extension points like resolve() ). Most important difference is however - in my opinion: JSR-310 can much better parse timezone names (format pattern symbol z) while Joda-Time could not do this at all in its earlier versions and now only in a very limited way. Another advantage of JSR-310 is support for standalone month names which is important in languages like Russian or Polish etc. Joda-Time has no access to such resources - not even on Java-8 platforms. The pattern syntax in JSR-310 is also more flexible than in Joda-Time, allows for optional sections (using square brackets), is more orientated towards CLDR-standard and offers padding (letter symbol p) and more fields. Otherwise it should be noted that Joda-Time can format durations using PeriodFormatter . JSR-310 cannot do this. Hope this overview helps. All the gathered information is mainly there due to my efforts and investigations how to design and implement a better date-and-time library (nothing is perfect). Update from 2015-06-24: Meanwhile I have found the time to write and publish a tabular overview for different time libraries in Java. The tables also contain a comparison between Joda-Time v2.8.1 and Java-8 (JSR-310). It is more detailed than this post.

Question-5694385, answer-5694464
Rather than spoon-feed you code, here's how to look in the documentation . First, you're dealing with IO, so look in the java.io package . There are two classes that look interesting: FileFilter and FileNameFilter . When I clicked on the first, it showed me that there was a a listFiles(args) method in the File class. And the documentation for that method says: #blockquote Scrolling up in the File JavaDoc, I see the constructors. And that's really all I need to be able to create a File instance and call listFiles(args) on it. Scrolling still further, I can see some information about how files are named in different operating systems.

Question-12552863, answer-32302353
To concur with earlier comments: simplest is (2) to use Closeable resources and declare them in order in the try-with-resources clause. If you only have AutoCloseable, you can wrap them in another (nested) class that just checks that close is only called once (Facade Pattern), e.g. by having private bool isClosed; . In practice even Oracle just (1) chains the constructors and doesn't correctly handle exceptions partway through the chain. Alternatively, you can manually create a chained resource, using a static factory method; this encapsulates the chain, and handle cleanup if it fails part-way: #pre The complexity comes from handling multiple exceptions; otherwise it's just "close resources that you've acquired so far". A common practice seems to be to first initialize the variable that holds the object that holds the resource to null (here fileWriter ), and then include a null check in the cleanup, but that seems unnecessary: if the constructor fails, there's nothing to clean up, so we can just let that exception propagate, which simplifies the code a little. You could probably do this generically: #pre

Question-32294367, answer-32294898
#blockquote Let me ask a counterquestion: why do you think Thread.stop(args) has been deprecated for more than a decade? The reason why is precisely the negation of your statement above. To give two specific examples: you stop(args) a thread while it's executing something as innocuous-sounding as System.out.println(args) or Math.random(args) . Result: those two features are now broken for the entire JVM. The same pertains to any other synchronized code your application may execute. #blockquote The application may theoretically be coded such that absolutely no shared resource protected by locks is ever used; however that will only help to point out the exact extent to which Java threads are codependent. And the "independence" achieved will only pertain to the request-processing threads, not to all threads in such an application.

Question-24649842, answer-24649939
Try adding a Thread.sleep(args); call within your run(args) method... Basically it's the difference between scheduling something based on when the previous execution ends and when it (logically) starts . For example, suppose I schedule an alarm to go off with a fixed rate of once an hour, and every time it goes off, I have a cup of coffee, which takes 10 minutes. Suppose that starts at midnight, I'd have: #pre If I schedule with a fixed delay of one hour, I'd have: #pre Which one you want depends on your task.
Question-31965179, answer-35427268
There's a long list of things that have been changed in Hibernate 5: #li New bootstrap API so we can bootstrap a JPA environment programmatically without the need of a persistence.xml file . #li Starting in 5.0 Hibernate Spatial is part of the Hibernate project so we can handle GIS data too. #li The Java 8 Date and Time types are supported in domain model mappings. The mapping between the standard SQL Date/Time types and the supported Java 8 Date/Time class types looks as follows; #li DATE: java.time.LocalDate #li TIME: java.time.LocalTime , java.time.OffsetTime #li TIMESTAMP: java.time.Instant , java.time.LocalDateTime , java.time.OffsetDateTime and java.time.ZonedDateTime #li The bytecode enhancement mechanism was redesigned from scratch, and Hibernate features both a Maven and a Gradle plugin. There are three main aspects which we can enhance with bytecode instrumentation: #li Lazy initialization: Fields can be declared as LAZY and they will be fetched only when being accessed for the first time. #li Dirty checking: Entities are enhanced so that they can keep track of all the properties that get changed after being loaded in a Persistence Context. #li Bidirectional associations: It's possible to synchronize both sides of a bidirectional association automatically, even if the developer only updates a single side. #li Hibernate's native APIs ( Session , etc) have been updated to use generic typed. No need to cast when fetching entities. #li Hibernate 5.0 expends this to a broader set of types (e.g. UUID ). #li Second-level cache by reference. This feature enables direct storage of entity references into the second level cache for immutable entities. #li Starting with Hibernate 5.0, we have a completely new User Guide that was written from scratch.

Question-33477695, answer-33477803
The java.time API in general does have nanosecond precision. For example: #pre Output: 2015-11-02T12:38:00,123456789+0000 However, it's the clock value returned by OffsetDateTime.now(args) which is returning a value which only has milliseconds. From Clock implementation in Java 8: #blockquote So there's nothing inherently imprecise here - just the default implementation of Clock using System.currentTimeMillis(args) . You could potentially create your own more precise subclass. However, you should note that adding more precision without adding more accuracy probably isn't terribly useful. (There are times when it might be, admittedly...)

Question-17489250, answer-17489437
Java.lang.String is not just a class. It's an integral part of the core language. The compiler has syntactic sugar for it. For example, StringLiteral is like an abbreviation for new String(args) . When written StringLiteral the compiler optimizes identical strings to the same instance to save space. StringLiteral + 5 == StringLiteral ==> true The compiler has syntactic sugar for a lot of stuff, including not having to box/unbox between object versions and their native types, no parent means Object, default constructor, ...

Question-19418427, answer-19418553
If you take a look at this methods #pre and its decompiled with javap -c ClassWithTheseMethods versions you will see #pre and #pre So if Strings are not final compiler will have to use StringBuilder to concatenate str1 and str2 so String concat=str1+str2; will be compiled to String concat = new StringBuilder(args).append(args).toString(args); which means that concat will be created at runtime so will not come from String pool. Also if Strings are final then compiler can assume that they will never change so instead of using StringBuilder it can safely concatenate its values so String concat = str1 + str2; can be changed to String concat = StringLiteral + StringLiteral; and concatenated into String concat = StringLiteral; which means that concate will become sting literal which will be interned in string pool and then compared with same string literal from that pool in if statement.

Question-26791441, answer-26819171
This is not an easy problem. And the more search-replacement parameters you have, the trickier it gets. You have several options, scattered on the palette of ugly-elegant, efficient-wasteful: #li Use StringUtils.replaceEach from Apache Commons as @AlanHay recommended. This is a good option if you're free to add new dependencies in your project. You might get lucky: the dependency might be included already in your project #li Use a temporary placeholder as @Jeroen suggested, and perform the replacement in 2 steps: #li Replace all search patterns with a unique tag that doesn't exist in the original text #li Replace the placeholders with the real target replacement This is not a great approach, for several reasons: it needs to ensure that the tags used in the first step are really unique; it performs more string replacement operations than really necessary #li Build a regex from all the patterns and use the method with Matcher and StringBuffer as suggested by @arshajii . This is not terrible, but not that great either, as building the regex is kind of hackish, and it involves StringBuffer which went out of fashion a while ago in favor of StringBuilder . #li Use a recursive solution proposed by @mjolka , by splitting the string at the matched patterns, and recursing on the remaining segments. This is a fine solution, compact and quite elegant. Its weakness is the potentially many substring and concatenation operations, and the stack size limits that apply to all recursive solutions #li Split the text to words and use Java 8 streams to perform the replacements elegantly as @msandiford suggested, but of course that only works if you are ok with splitting at word boundaries, which makes it not suitable as a general solution Here's my version, based on ideas borrowed from Apache's implementation . It's neither simple nor elegant, but it works, and should be relatively efficient, without unnecessary steps. In a nutshell, it works like this: repeatedly find the next matching search pattern in the text, and use a StringBuilder to accumulate the unmatched segments and the replacements. #pre Unit tests: #pre

Question-30125296, answer-35035659
You can use reduce method: long creditAmountSum = result.stream(args).map(args).reduce(args);

Question-13291076, answer-13291166
name(args) is a "built-in" method of enum . It is final and you cannot change its implementation. It returns the name of enum constant as it is written, e.g. in upper case, without spaces etc. Compare MOBILE_PHONE_NUMBER and Mobile phone number . Which version is more readable? I believe the second one. This is the difference: name(args) always returns MOBILE_PHONE_NUMBER , toString(args) may be overriden to return Mobile phone number .

Question-22463062, answer-28324294
You can also use LocalDate.parse(args) or LocalDateTime.parse(args) on a String without providing it with a pattern, if the String is in ISO-8601 format . for example, #pre Output , #pre and use DateTimeFormatter only if you have to deal with other date patterns, For example, dd MMM uuuu represents the day of the month (two digits), three letters of the name of the month (Jan, Feb, Mar,...), and a four-digit year: #pre Output 04 Aug 2015 parses to 2015-08-04 also remember that the DateTimeFormatter object is bidirectional; it can both parse input and format output. #pre Output 2015-08-04 formats as 04 Aug 2015 (see complete list of Patterns for Formatting and Parsing DateFormatter ) #pre

Question-20331163, answer-20331243
Create a DateTimeFormatter using DateTimeFormat.forPattern(String) Using Joda time you would do it like this: #pre Also, if you wanted to use standard Java, you would do it like this: #pre

Question-26318569, answer-26319364
You're nesting mocking inside of mocking. You're calling getSomeList(args) , which does some mocking, before you've finished the mocking for MyMainModel . Mockito doesn't like it when you do this. Replace #pre with #pre To understand why this causes a problem, you need to know a little about how Mockito works, and also be aware in what order expressions and statements are evaluated in Java. Mockito can't read your source code, so in order to figure out what you are asking it to do, it relies a lot on static state. When you call a method on a mock object, Mockito records the details of the call in an internal list of invocations. The when method reads the last of these invocations off the list and records this invocation in the OngoingStubbing object it returns. The line Mockito.when(args).thenReturn(args); causes the following interactions with Mockito: #li Mock method mainModel.getList(args) is called, #li Static method when is called, #li Method thenReturn is called on the OngoingStubbing object returned by the when method. The thenReturn method can then instruct the mock it received via the OngoingStubbing method to handle any suitable call to the getList method to return someModelList . In fact, as Mockito can't see your code, you can also write your mocking as follows: #pre This style is somewhat less clear to read, especially since in this case the null has to be casted, but it generates the same sequence of interactions with Mockito and will achieve the same result as the line above. However, the line Mockito.when(args).thenReturn(args); causes the following interactions with Mockito: #li Mock method mainModel.getList(args) is called, #li Static method when is called, #li A new mock of SomeModel is created (inside getSomeList(args) ), #li Mock method model.getName(args) is called, At this point Mockito gets confused. It thought you were mocking mainModel.getList(args) , but now you're telling it you want to mock the model.getName(args) method. To Mockito, it looks like you're doing the following: #pre This looks silly to Mockito as it can't be sure what you're doing with mainModel.getList(args) . Note that we did not get to the thenReturn method call, as the JVM needs to evaluate the parameters to this method before it can call the method. In this case, this means calling the getSomeList(args) method. Generally it is a bad design decision to rely on static state, as Mockito does, because it can lead to cases where the Principle of Least Astonishment is violated. However, Mockito's design does make for clear and expressive mocking, even if it leads to astonishment sometimes. Finally, recent versions of Mockito add an extra line to the error message above. This extra line indicates you may be in the same situation as this question: #blockquote

Question-10904911, answer-10904956
What you want is the Arrays.toString(args) method: #pre There is a static Arrays.toString helper method for every different primitive java type; the one for int[] says this : #blockquote

Question-4645020
It is supposed to be generally preferable to use a StringBuilder for string concatenation in Java. Is this always the case? What I mean is this: Is the overhead of creating a StringBuilder object, calling the append(args) method and finally toString(args) already smaller then concatenating existing strings with the + operator for two strings, or is it only advisable for more (than two) strings? If there is such a threshold, what does it depend on (perhaps the string length, but in which way)? And finally, would you trade the readability and conciseness of the + concatenation for the performance of the StringBuilder in smaller cases like two, three or four strings? EDIT Explicit use of StringBuilder for regular concatenations is being mentioned as obsolete at obsolete java optimization tips as well as at java urban myths .

Question-28584669, answer-28584954
Because thats the standard. Infinity represents a number greater than or less than Double.MAX_VALUE/-Double.MAX_VALUE. NaN represents the outcome of an operation that didn't make sense. That is, the operation didn't possibly come out with a number. I would guess the logic is once a number gets big enough (infinity) and because of the limitation of floating point numbers, adding numbers to it won't change the outcome, so its 'like' infinity. So if you want to compare to really big numbers, at some point you might just say those two big numbers are close enough for all intents and purposes. But if you want to compare two things that both aren't numbers, you can't compare them so its false. At least you couldn't compare them as a primitive.

Question-5439529, answer-15357940
Or simply mystring.matches(args) though it would return true for numbers larger than an int

Question-32334319, answer-32334651
The API guarantees a stable sorting which Quicksort doesnâ€™t offer. However, when sorting primitive values by their natural order you wonâ€™t notice a difference as primitive values have no identity. Therefore, Quicksort is used for primitive arrays as it is slightly more efficient. For objects you may notice, when objects which are deemed equal according to their equals implementation or the provided Comparator change their order. Therefore, Quicksort is not an option. So a variant of MergeSort is used, the current Java versions use TimSort . This applies to both, Arrays.sort and Collections.sort , though with Java 8, the List itself may override the sort algorithms.

Question-28818506
I've been working with the new Optional type in Java 8 , and I've come across what seems like a common operation that isn't supported functionally: an "orElseOptional" Consider the following pattern: #pre There are many forms of this pattern, but it boils down to wanting an "orElse" on an optional that takes a function producing a new optional, called only if the current one does not exist. It's implementation would look like this: #pre I'm curious if there's a reason such a method doesn't exist, if I'm just using Optional in an unintended way, and what other ways people have come up with to deal with this case. I should say that I think that solutions involving custom utility classes/methods aren't elegant because people working with my code won't necessarily know they exist. Also, if anyone knows, will such a method be included in JDK 9, and where might I propose such a method? This seems like a pretty glaring omission to the API to me.

Question-29095967
I have this list ( List<T> ): [StringLiteral, StringLiteral, null, StringLiteral, null, StringLiteral, StringLiteral] And I'd like something like this: [[StringLiteral, StringLiteral], [StringLiteral], [StringLiteral, StringLiteral]] In other words I want to split my list in sublists using the null value as separator, in order to obtain a list of lists ( List<T> ). I'm looking for a Java 8 solution. I've tried with Collectors.partitioningBy but I'm not sure it is what I'm looking for. Thanks!

Question-20877086, answer-20877283
The Integer class has a static cache, that stores 256 special Integer objects - one for every value between -128 and 127. With that in mind, consider the difference between these three. new Integer(args); This (obviously) makes a brand new Integer object. Integer.parseInt(args); This returns an int primitive value after parsing the String . Integer.valueOf(args); This is more complex than the others. It starts off by parsing the String . Then, if the value is between -128 and 127, it returns the corresponding object from the static cache. If the value is outside of this range, then it invokes new Integer(args) and passes in the value, so that you get a new object. Now, consider the three expressions in the question. Integer.valueOf(args)==Integer.valueOf(args); This returns true, because the Integer whose value is 127 is retrieved twice from the static cache, and compared to itself. There's only one Integer object involved, so this returns true . Integer.valueOf(args)==Integer.valueOf(args); This returns false , because 128 is not in the static cache. So a new Integer is created for each side of the equality. Since there are two different Integer objects, and == for objects only returns true if both sides are the exact same object, this is going to be false . Integer.parseInt(args)==Integer.valueOf(args); This is comparing the primitive int value 128 on the left, with a newly created Integer object on the right. But because it doesn't make sense to compare an int to an Integer , Java will auto-unbox the Integer before doing the comparison; so you end up comparing an int to an int . Since the primitive 128 is equal to itself, this returns true .

Question-7520432, answer-27478241
== can be used in many object types but you can use Object.equals for any type , especially Strings and Google Map Markers.

Question-28459498, answer-28513908
I have some recollections from the early design of the Streams API that might shed some light on the design rationale. Back in 2012, we were adding lambdas to the language, and we wanted a collections-oriented or "bulk data" set of operations, programmed using lambdas, that would facilitate parallelism. The idea of lazily chaining operations together was well established by this point. We also didn't want the intermediate operations to store results. The main issues we needed to decide were what the objects in the chain looked like in the API and how they hooked up to data sources. The sources were often collections, but we also wanted to support data coming from a file or the network, or data generated on-the-fly, e.g., from a random number generator. There were many influences of existing work on the design. Among the more influential were Google's Guava library and the Scala collections library. (If anybody is surprised about the influence from Guava, note that Kevin Bourrillion , Guava lead developer, was on the JSR-335 Lambda expert group.) On Scala collections, we found this talk by Martin Odersky to be of particular interest: Future-Proofing Scala Collections: from Mutable to Persistent to Parallel . (Stanford EE380, 2011 June 1.) Our prototype design at the time was based around Iterable . The familiar operations filter , map , and so forth were extension (default) methods on Iterable . Calling one added an operation to the chain and returned another Iterable . A terminal operation like count would call iterator(args) up the chain to the source, and the operations were implemented within each stage's Iterator. Since these are Iterables, you can call the iterator(args) method more than once. What should happen then? If the source is a collection, this mostly works fine. Collections are Iterable, and each call to iterator(args) produces a distinct Iterator instance that is independent of any other active instances, and each traverses the collection independently. Great. Now what if the source is one-shot, like reading lines from a file? Maybe the first Iterator should get all the values but the second and subsequent ones should be empty. Maybe the values should be interleaved among the Iterators. Or maybe each Iterator should get all the same values. Then, what if you have two iterators and one gets farther ahead of the other? Somebody will have to buffer up the values in the second Iterator until they're read. Worse, what if you get one Iterator and read all the values, and only then get a second Iterator. Where do the values come from now? Is there a requirement for them all to be buffered up just in case somebody wants a second Iterator? Clearly, allowing multiple Iterators over a one-shot source raises a lot of questions. We didn't have good answers for them. We wanted consistent, predictable behavior for what happens if you call iterator(args) twice. This pushed us toward disallowing multiple traversals, making the pipelines one-shot. We also observed others bumping into these issues. In the JDK, most Iterables are collections or collection-like objects, which allow multiple traversal. It isn't specified anywhere, but there seemed to be an unwritten expectation that Iterables allow multiple traversal. A notable exception is the NIO DirectoryStream interface. Its specification includes this interesting warning: #blockquote [bold in original] This seemed unusual and unpleasant enough that we didn't want to create a whole bunch of new Iterables that might be once-only. This pushed us away from using Iterable. About this time, an article by Bruce Eckel appeared that described a spot of trouble he'd had with Scala. He'd written this code: #pre It's pretty straightforward. It parses lines of text into Registrant objects and prints them out twice. Except that it actually only prints them out once. It turns out that he thought that registrants was a collection, when in fact it's an iterator. The second call to foreach encounters an empty iterator, from which all values have been exhausted, so it prints nothing. This kind of experience convinced us that it was very important to have clearly predictable results if multiple traversal is attempted. It also highlighted the importance of distinguishing between lazy pipeline-like structures from actual collections that store data. This in turn drove the separation of the lazy pipeline operations into the new Stream interface and keeping only eager, mutative operations directly on Collections. Brian Goetz has explained the rationale for that. What about allowing multiple traversal for collection-based pipelines but disallowing it for non-collection-based pipelines? It's inconsistent, but it's sensible. If you're reading values from the network, of course you can't traverse them again. If you want to traverse them multiple times, you have to pull them into a collection explicitly. But let's explore allowing multiple traversal from collections-based pipelines. Let's say you did this: #pre (The into operation is now spelled collect(args) .) If source is a collection, then the first into(args) call will create a chain of Iterators back to the source, execute the pipeline operations, and send the results into the destination. The second call to into(args) will create another chain of Iterators, and execute the pipeline operations again . This isn't obviously wrong but it does have the effect of performing all the filter and map operations a second time for each element. I think many programmers would have been surprised by this behavior. As I mentioned above, we had been talking to the Guava developers. One of the cool things they have is an Idea Graveyard where they describe features that they decided not to implement along with the reasons. The idea of lazy collections sounds pretty cool, but here's what they have to say about it. Consider a List.filter(args) operation that returns a List : #blockquote To take a specific example, what's the cost of get(args) or size(args) on a List? For commonly used classes like ArrayList , they're O(1). But if you call one of these on a lazily-filtered list, it has to run the filter over the backing list, and all of a sudden these operations are O(n). Worse, it has to traverse the backing list on every operation. This seemed to us to be too much laziness. It's one thing to set up some operations and defer actual execution until you so "Go". It's another to set things up in such a way that hides a potentially large amount of recomputation. In proposing to disallow non-linear or "no-reuse" streams, Paul Sandoz described the potential consequences of allowing them as giving rise to "unexpected or confusing results." He also mentioned that parallel execution would make things even trickier. Finally, I'd add that a pipeline operation with side effects would lead to difficult and obscure bugs if the operation were unexpectedly executed multiple times, or at least a different number of times than the programmer expected. (But Java programmers don't write lambda expressions with side effects, do they? DO THEY??) So that's the basic rationale for the Java 8 Streams API design that allows one-shot traversal and that requires a strictly linear (no branching) pipeline. It provides consistent behavior across multiple different stream sources, it clearly separates lazy from eager operations, and it provides a straightforward execution model. With regard to IEnumerable , I am far from an expert on C# and .NET, so I would appreciate being corrected (gently) if I draw any incorrect conclusions. It does appear, however, that IEnumerable permits multiple traversal to behave differently with different sources; and it permits a branching structure of nested IEnumerable operations, which may result in some significant recomputation. While I appreciate that different systems make different tradeoffs, these are two characteristics that we sought to avoid in the design of the Java 8 Streams API. The quicksort example given by the OP is interesting, puzzling, and I'm sorry to say, somewhat horrifying. Calling QuickSort takes an IEnumerable and returns an IEnumerable , so no sorting is actually done until the final IEnumerable is traversed. What the call seems to do, though, is build up a tree structure of IEnumerables that reflects the partitioning that quicksort would do, without actually doing it. (This is lazy computation, after all.) If the source has N elements, the tree will be N elements wide at its widest, and it will be lg(N) levels deep. It seems to me -- and once again, I'm not a C# or .NET expert -- that this will cause certain innocuous-looking calls, such as pivot selection via ints.First(args) , to be more expensive than they look. At the first level, of course, it's O(1). But consider a partition deep in the tree, at the right-hand edge. To compute the first element of this partition, the entire source has to be traversed, an O(N) operation. But since the partitions above are lazy, they must be recomputed, requiring O(lg N) comparisons. So selecting the pivot would be an O(N lg N) operation, which is as expensive as an entire sort. But we don't actually sort until we traverse the returned IEnumerable . In the standard quicksort algorithm, each level of partitioning doubles the number of partitions. Each partition is only half the size, so each level remains at O(N) complexity. The tree of partitions is O(lg N) high, so the total work is O(N lg N). With the tree of lazy IEnumerables, at the bottom of the tree there are N partitions. Computing each partition requires a traversal of N elements, each of which requires lg(N) comparisons up the tree. To compute all the partitions at the bottom of the tree, then, requires O(N^2 lg N) comparisons. (Is this right? I can hardly believe this. Somebody please check this for me.) In any case, it is indeed cool that IEnumerable can be used this way to build up complicated structures of computation. But if it does increase the computational complexity as much as I think it does, it would seem that programming this way is something that should be avoided unless one is extremely careful.

Question-25606833, answer-25757572
There are several issues here. #li Any solution based on reading lines is going to process each character twice. Compilers for example don't do this, they read one character at a time and despatch on it directly. #li Any solution based on readLine(args) is going to create Strings. #li You are using different buffer sizes. #li You are using different I/O technologies. #li In some cases you are using character conversion, while in others you aren't. #li You're over-analyzing the file. You don't really care where the white space is, or how much of it there is, as long as it separates the numbers from each other. My solution: #pre

Question-9749746, answer-9749864
You are specifically asking about how they internally work , so here you are: No synchronization #pre It basically reads value from memory, increments it and puts back to memory. This works in single thread but nowadays, in the era of multi-core, multi-CPU, multi-level caches it won't work correctly. First of all it introduces race condition (several threads can read the value at the same time), but also visibility problems. The value might only be stored in " local " CPU memory (some cache) and not be visible for other CPUs/cores (and thus - threads). This is why many refer to local copy of a variable in a thread. It is very unsafe. Consider this popular but broken thread-stopping code: #pre Add volatile to stopped variable and it works fine - if any other thread modifies stopped variable via pleaseStop(args) method, you are guaranteed to see that change immediately in working thread's while(args) loop. BTW this is not a good way to interrupt a thread either, see: How to stop a thread that is running forever without any use and Stopping a specific java thread . AtomicInteger #pre The AtomicInteger class uses CAS ( compare-and-swap ) low-level CPU operations (no synchronization needed!) They allow you to modify a particular variable only if the present value is equal to something else (and is returned successfully). So when you execute getAndIncrement(args) it actually runs in a loop (simplified real implementation): #pre So basically: read; try to store incremented value; if not successful (the value is no longer equal to current ), read and try again. The compareAndSet(args) is implemented in native code (assembly). volatile without synchronization #pre This code is not correct. It fixes the visibility issue ( volatile makes sure other threads can see change made to counter ) but still has a race condition. This has been explained multiple times: pre/post-incrementation is not atomic. The only side effect of volatile is " flushing " caches so that all other parties see the freshest version of the data. This is too strict in most situations; that is why volatile is not default. volatile without synchronization (2) #pre The same problem as above, but even worse because i is not private . The race condition is still present. Why is it a problem? If, say, two threads run this code simultaneously, the output might be + 5 or + 10 . However, you are guaranteed to see the change. Multiple independent synchronized #pre Surprise, this code is incorrect as well. In fact, it is completely wrong. First of all you are synchronizing on i , which is about to be changed (moreover, i is a primitive, so I guess you are synchronizing on a temporary Integer created via autoboxing...) Completely flawed. You could also write: #pre No two threads can enter the same synchronized block with the same lock . In this case (and similarly in your code) the lock object changes upon every execution, so synchronized effectively has no effect. Even if you have used a final variable (or this ) for synchronization, the code is still incorrect. Two threads can first read i to temp synchronously (having the same value locally in temp ), then the first assigns a new value to i (say, from 1 to 6) and the other one does the same thing (from 1 to 6). The synchronization must span from reading to assigning a value. Your first synchronization has no effect (reading an int is atomic) and the second as well. In my opinion, these are the correct forms: #pre
Question-6416706, answer-6416788
As soon as you call contains , containsAll , equals , hashCode , remove , retainAll , size or toArray , you'd have to traverse the elements anyway. If you're occasionally only calling methods such as isEmpty or clear I suppose you'd be better of by creating the collection lazily. You could for instance have a backing ArrayList for storing previously iterated elements. I don't know of any such class in any library, but it should be a fairly simple exercise to write up.

Question-7348711, answer-20793241
Environment variables may also provide a useful means -- COMPUTERNAME on Windows, HOSTNAME on most modern Unix/Linux shells. See: #a I'm using these as "supplementary" methods to InetAddress.getLocalHost(args).getHostName(args) , since as several people point out, that function doesn't work in all environments. Runtime.getRuntime(args).exec(args) is another possible supplement. At this stage, I haven't used it. #pre

Question-22847105, answer-37354549
The way I think about it is that you use flatMap when the function you wanted to put inside of map(args) returns an Observable . In which case you might still try to use map(args) but it would be unpractical. Let me try to explain why. If in such case you decided to stick with map , you would get an Observable<T> . For example in your case, if we used an imaginary RxGson library, that returned an Observable<T> from it's toJson(args) method (instead of simply returning a String ) it would look like this: #pre At this point it would be pretty tricky to subscribe(args) to such an observable. Inside of it you would get an Observable<T> to which you would again need to subscribe(args) to get the value. Which is not practical or nice to look at. So to make it useful one idea is to "flatten" this observable of observables (you might start to see where the name _flat_Map comes from). RxJava provides a few ways to flatten observables and for sake of simplicity lets assume merge is what we want. Merge basically takes a bunch of observables and emits whenever any of them emits. (Lots of people would argue switch would be a better default. But if you're emitting just one value, it doesn't matter anyway.) So amending our previous snippet we would get: #pre This is a lot more useful, because subscribing to that (or mapping, or filtering, or...) you just get the String value. (Also, mind you, such variant of merge(args) does not exist in RxJava, but if you understand the idea of merge then I hope you also understand how that would work.) So basically because such merge(args) should probably only ever be useful when it succeeds a map(args) returning an observable and so you don't have to type this over and over again, flatMap(args) was created as a shorthand. It applies the mapping function just as a normal map(args) would, but later instead of emitting the returned values it also "flattens" (or merges) them. That's the general use case. It is most useful in a codebase that uses Rx allover the place and you've got many methods returning observables, which you want to chain with other methods returning observables. In your use case it happens to be useful as well, because map(args) can only transform one value emitted in onNext(args) into another value emitted in onNext(args) . But it cannot transform it into multiple values, no value at all or an error. And as akarnokd wrote in his answer (and mind you he's much smarter than me, probably in general, but at least when it comes to RxJava) you shouldn't throw exceptions from your map(args) . So instead you can use flatMap(args) and return Observable.just(args); when all goes well, but return Observable.error(args); when something fails. See his answer for a complete snippet: #a

Question-19416644, answer-19416665
One simple way is to use Float.NaN : #pre #pre You can do the same with Double.NaN . From JLS Â§15.21.1. Numerical Equality Operators == and != : #blockquote

Question-22718744, answer-22718904
This has been specified in the documentation of split(String regex, limit) . #blockquote In StringLiteral.split(args) you got a zero-width match at the beginning so the leading empty substring is not included in the resulting array. However in your second snippet when you split on StringLiteral you got a positive width match (1 in this case), so the empty leading substring is included as expected. (Removed irrelevant source code)

Question-5175728, answer-5175900
It depends on what form of date / time you want: #li If you want the date / time as a single numeric value, then System.currentTimeMillis(args) gives you that, expressed as the number of milliseconds after the UNIX epoch (as a Java long ). This value is a delta from a UTC time-point, and is independent of the local time-zone ... assuming that the system clock has been set correctly. #li If you want the date / time in a form that allows you to access the components (year, month, etc) numerically, you could use one of the following: #li new Date(args) gives you a Date object initialized with the current date / time. The problem is that the Date API methods are mostly flawed ... and deprecated. #li Calendar.getInstance(args) gives you a Calendar object initialized with the current date / time, using the default Locale and TimeZone . Other overloads allow you to use a specific Locale and/or TimeZone . Calendar works ... but the APIs are still cumbersome. #li new org.joda.time.DateTime(args) gives you a Joda-time object initialized with the current date / time, using the default time zone and chronology. There are lots of other Joda alternatives ... too many to describe here. #li in Java 8, calling LocalDateTime.now(args) and ZonedDateTime.now(args) will give you representations for the current date / time. Prior to Java 8, most people who know about these things recommended Joda-time as having (by far) the best Java APIs for doing things involving time point and duration calculations. With Java 8, this is no longer true. However, if you are already using Joda time in your codebase, there is no strong reason to migrate.

Question-28584669
Why doesn't infinity comparison follow the logic applied to NaNs? This code prints out false three times: #pre However, if I change Double.NaN to Double.POSITIVE_INFINITY , I get true for equality, but false for the greater-than and less-than comparisons: #pre This seems dangerous. Assuming that infinite values result from overflows, I imagine it's more likely that two variables that ended up as infinities wouldn't actually be equal in perfect arithmetic.

Question-20945049, answer-20959594
String is immutable, but through reflection you're allowed to change the String class. You've just redefined the String class as mutable in real-time. You could redefine methods to be public or private or static if you wanted.

Question-31696485
When using the Java 8 Optional class, there are two ways in which a value can be wrapped in an optional. #pre I understand Optional.ofNullable is the only safe way of using Optional , but why does Optional.of exist at all? Why not just use Optional.ofNullable and be on the safe side at all times?

Question-16148575, answer-18481387
If you code in Android, there is SparseArray , mapping integer to object.

Question-31445024, answer-31760309
Until the language specification mentions it, it is not guaranteed that autoboxing is equivalent to a call to the static valueOf methods. It is an implementation aspect, not part of the boxing conversion specification. An implementation is theoretically free to use another mechanism as long as it conforms to the rule you mentioned from the JLS. In practice, there are many Sun JDK bug reports (e.g. JDK-4990346 and JDK-6628737 ) that clearly imply that when autoboxing was introduced in Java 5, the intention was having the compiler to rely on valueOf as stated in JDK-6628737 : #blockquote But that's only for javac, not necessarily all compilers.

Question-5839359, answer-5839392
You're essentially running out of memory to run the process smoothly. Options that come to mind: #li Specify more memory like you mentioned, try something in between like -Xmx512m first #li Work with smaller batches of HashMap objects to process at once if possible #li If you have a lot of duplicate strings, use String.intern() on them before putting them into the HashMap #li Use the HashMap(int initialCapacity, float loadFactor) constructor to tune for your case

Question-31445024, answer-31445150
I first tought your question was a dupe of What code does the compiler generate for autoboxing? However, after your comment on @ElliottFrisch I realized it was different : #blockquote For other readers, assume that "behaves that way" means using valueOf . Remember that there are multiples compilers for Java. To be "legal" they must follow the contract given in the JLS . Therefore, as long as all the rules here are respected, there is no guarantee of how autoboxing is internally implemented. But I don't see any reason to not use valueOf , specially that it uses the cached values and is the recommended way as per this article by Joseph D. Darcy.

Question-33147339, answer-33147762
I found this explanation : #blockquote In Java 6, if you use the API as: #pre And newCount overflows (this becomes negative), if(args) will return false and you may mistakenly assume that the ArrayList was increased by len .

Question-27430092, answer-27430172
A possible use case is in testing primality of a given number (at test which in itself has many uses). The isProbablePrime algorithm will run much faster than an exact algorithm, so if the number fails isProbablePrime , then one need not go to the expense of running the more expensive algorithm.

Question-21242110
What is the best way to convert a java.util.Date object to the new JDK 8/JSR-310 java.time.LocalDate ? #pre

Question-11408427, answer-11408477
The + operator is usually replaced by a StringBuilder at compile time. Check this answer for more details on that matter.

Question-5769669, answer-5769679
You can use Double.parseDouble() to convert a String to a double : #pre For your case it looks like you want: #pre

Question-23218874, answer-23232560
For simple cases such as the one illustrated, they are mostly the same. However, there are a number of subtle differences that might be significant. One issue is with ordering. With Stream.forEach , the order is undefined . It's unlikely to occur with sequential streams, still, it's within the specification for Stream.forEach to execute in some arbitrary order. This does occur frequently in parallel streams. By contrast, Iterable.forEach is always executed in the iteration order of the Iterable , if one is specified. Another issue is with side effects. The action specified in Stream.forEach is required to be non-interfering . (See the java.util.stream package doc .) Iterable.forEach potentially has fewer restrictions. For the collections in java.util , Iterable.forEach will generally use that collection's Iterator , most of which are designed to be fail-fast and which will throw ConcurrentModificationException if the collection is structurally modified during the iteration. However, modifications that aren't structural are allowed during iteration. For example, the ArrayList class documentation says "merely setting the value of an element is not a structural modification." Thus, the action for ArrayList.forEach is allowed to set values in the underlying ArrayList without problems. The concurrent collections are yet again different. Instead of fail-fast, they are designed to be weakly consistent . The full definition is at that link. Briefly, though, consider ConcurrentLinkedDeque . The action passed to its forEach method is allowed to modify the underlying deque, even structurally, and ConcurrentModificationException is never thrown. However, the modification that occurs might or might not be visible in this iteration. (Hence the "weak" consistency.) Still another difference is visible if Iterable.forEach is iterating over a synchronized collection. On such a collection, Iterable.forEach takes the collection's lock once and holds it across all the calls to the action method. The Stream.forEach call uses the collection's spliterator, which does not lock, and which relies on the prevailing rule of non-interference. The collection backing the stream could be modified during iteration, and if it is, a ConcurrentModificationException or inconsistent behavior could result.

Question-22382453, answer-22384113
Made up example Imagine that you want to create the following sequence: 1, 2, 2, 3, 3, 3, 4, 4, 4, 4 etc. (in other words: 1x1, 2x2, 3x3 etc.) With flatMap it could look like: #pre where: #li IntStream.rangeClosed(args) creates a stream of int from 1 to 4, inclusive #li IntStream.iterate(args).limit(args) creates a stream of length i of int i - so applied to i = 4 it creates a stream: 4, 4, 4, 4 #li flatMap "flattens" the stream and "concatenates" it to the original stream With Java < 8 you would need two nested loops: #pre Real world example Let's say I have a List<T> where each TimeSeries is essentially a Map<T> . I want to get a list of all dates for which at least one of the time series has a value. flatMap to the rescue: list.stream(args).parallel(args) .flatMap(args) // for each TS, stream dates and flatmap .distinct(args) // remove duplicates .sorted(args) // sort ascending .collect(args); Not only is it readable, but if you suddenly need to process 100k elements, simply adding parallel(args) will improve performance without you writing any concurrent code.

Question-26375932, answer-26407637
It is an integer overflow. The int data type is 4 bytes, or 32 bits. Therefore, numbers larger than 2^(32 - 1) - 1 (2,147,483,647) cannot be stored in this data type. Your numerical values will be incorrect. For very large numbers, you will want to import and use the class java.math.BigInteger: #pre NOTE: For numerical values that are still too large for the int data type, but small enough to fit within 8 bytes (absolute value less than or equal to 2^(64 - 1) - 1), you should probably use the long primitive. HackerRank's practice problems (www.hackerrank.com), such as the Algorithms practice section, ( #a ) include some very good large-number questions that give good practice about how to think about the appropriate data type to use.

Question-12539365, answer-12562433
This is great question! I think the root cause of it is the following, we are using JUnit not only for unit testing. So the question should be splited up: #li Should I use Mockito.verify() in my integration (or any other higher-than-unit testing) testing? #li Should I use Mockito.verify() in my black-box unit-testing? #li Should I use Mockito.verify() in my white-box unit-testing? so if we will ignore higher-than-unit testing, the question can be rephrased " Using white-box unit-testing with Mockito.verify() creates great couple between unit test and my could implementation, can I make some "grey-box" unit-testing and what rules of thumb I should use for this ". Now, let's go through all of this step-by-step. *- Should I use Mockito.verify() in my integration (or any other higher-than-unit testing) testing?* I think the answer is clearly no, moreover you shouldn't use mocks for this. Your test should be as close to real application as possible. You are testing complete use case, not isolated part of the application. * black-box vs white-box unit-testing black-box state If you are using white-box approach what is you really doing, you're testing the behaviour of your unit. In this approach calling to Mockito.verify() is essential, you should verify that your unit behaves as you're expecting to. rules of thumbs for grey-box-testing The problem with white-box testing is it creates a high coupling. One possible solution is to do grey-box-testing, not white-box-testing. This is sort of combination of black&white box testing. You are really testing the behaviour of your unit like in white-box testing, but in general you make it implementation-agnostic when possible . When it is possible, you will just make a check like in black-box case, just asserts that output is what is your expected to be. So, the essence of your question is when it is possible. This is really hard. I don't have a good example, but I can give you to examples. In the case that was mentioned above with equals() vs equalsIgnoreCase() you shouldn't call Mockito.verify(), just assert the output. If you couldn't do it, break down your code to the smaller unit, until you can do it. On the other hand, suppose you have some @Service and you are writting @Web-Service that is essentially wrapper upon your @Service - it delegates all calls to the @Service (and making some extra error handling). In this case calling to Mockito.verify() is essential, you shouldn't duplicate all of your checks that you did for the @Serive, verifying that you're calling to @Service with correct parammeter list is sufficient.

Question-29922296, answer-29926133
I'd go for EnumSet . Because forEach(args) is also defined on Iterable , you can avoid creating the stream altogether: EnumSet.allOf(args).forEach(args); Or with a method reference: EnumSet.allOf(args).forEach(args); Still, the oldschool for-loop feels a bit simpler: #pre

Question-30081520, answer-30081600
From Objects.equals() : return(args) || (a != null && a.equals(args)); Very simple, self-explaining and elegant.

Question-27747562, answer-27747702
A List<T> could very well be an Item. See for example: #pre A cast tells the compiler: "I know you can't be sure that this is a object of type Item, but I know better than you, so please compile". The compiler will only refuse to compile that if it's impossible for the returned object to be an instance of Item (like, for example, Integer can't ever be a String ) At runtime, the type of the actual object returned by the method will be checked, and if it's not actually an object of type Item, you'll get a ClassCastException.

Question-32623834, answer-32652449
Another related point: you can make use of the constant pool to improve the performance of string comparisons in some circumstances, by using the String.intern() method. That method returns the instance of String with the same contents as the String on which it is invoked from the String constants pool, adding it it if is not yet present. In other words, after using intern(args) , all Strings with the same contents are guaranteed to be the same String instance as each other and as any String constants with those contents, meaning you can then use the equals operator ( == ) on them. This is just an example which is not very useful on its own, but it illustrates the point: #pre This little trick isn't worth designing your code around, but it is worth keeping in mind for the day when you notice a little more speed could be eked out of some bit of performance sensitive code by using the == operator on a string with judicious use of intern(args) .

Question-13950338, answer-17066803
Grant Vibration Permission Before you start implementing any vibration code, you have to give your application the permission to vibrate: <uses-permission android:name=StringLiteral/> Make sure to include this line in your AndroidManifest.xml file. Import the Vibration Library Most IDEs will do this for you, but here is the import statement if yours doesn't: import android.os.Vibrator; Make sure this in the activity where you want the vibration to occur. How to Vibrate for a Given Time In most circumstances, you'll be wanting to vibrate the device for a short, predetermined amount of time. You can achieve this by using the vibrate(args) method. Here is a quick example: #pre That's it, simple! How to Vibrate Indefinitely It may be the case that you want the device to continue vibrating indefinitely. For this, we use the vibrate(args) method: #pre When you're ready to stop the vibration, just call the cancel(args) method: v.cancel(args); How to use Vibration Patterns If you want a more bespoke vibration, you can attempt to create your own vibration patterns: #pre More Complex Vibrations There are multiple SDKs that offer a more comprehensive range of haptic feedback. One that I use for special effects is Immersion's Haptic Development Platform for Android . Troubleshooting If your device won't vibrate, first make sure that it can vibrate: #pre Secondly, please ensure that you've given your application the permission to vibrate! Refer back to the first point.

Question-31993377
Question How is it that for a scanner object the hasNextLine(args) method returns true while the hasNext(args) method returns false? Note: Based on the input file, the hasNext(args) method is returning the result as expected; the hasNextLine(args) does not seem to be returning the correct result. Code Here's the code I'm running that's creating the results below: #pre Input File The following is the actual content of the file that I'm passing to this scanner: #pre Result The following is the end of what's printed in the console when I run my code, and includes the portion I can't make sense of: #pre

Question-6841333, answer-20906129
As explained by others, there's a time discontinuity there. There are two possible timezone offsets for 1927-12-31 23:54:08 at Asia/Shanghai , but only one offset for 1927-12-31 23:54:07 . So, depending on which offset is used, there's either a one second difference or a 5 minutes and 53 seconds difference. This slight shift of offsets, instead of the usual one-hour daylight savings (summer time) we are used to, obscures the problem a bit. Note that the 2013a update of the timezone database moved this discontinuity a few seconds earlier, but the effect would still be observable. The new java.time package on Java 8 let use see this more clearly, and provide tools to handle it. Given: #pre Then durationAtEarlierOffset will be one second, while durationAtLaterOffset will be five minutes and 53 seconds. Also, these two offsets are the same: #pre But these two are different: #pre You can see the same problem comparing 1927-12-31 23:59:59 with 1928-01-01 00:00:00 , though, in this case, it is the earlier offset that produce the longer divergence, and it is the earlier date that has two possible offsets. Another way to approach this is to check whether there's a transition going on. We can do this like this: #pre You can check whether the transition is an overlap - in which case there's more than one valid offset for that date/time - or a gap - in which case that date/time is not valid for that zone id - by using the isOverlap(args) and isGap(args) methods on zot4 . I hope this helps people handle this sort of issue once Java 8 becomes widely available, or to those using Java 7 who adopt the JSR 310 backport.

Question-8172420, answer-8172439
You can use Character.toString(char) . Note that this method simply returns a call to String.valueOf(char) , which also works. As others have noted, string concatenation works as a shortcut as well: String s = StringLiteral + CharLiteral; But this compiles down to: String s = new StringBuilder(args).append(args).append(args).toString(args); which is less efficient because the StringBuilder is backed by a char[] (over-allocated by StringBuilder() to 16 ), only for that array to be defensively copied by the resulting String . String.valueOf(args) "gets in the back door" by wrapping the char in a single-element array and passing it to the package private constructor String(char[], boolean) , which avoids the array copy.

Question-31922866, answer-31923211
This advice is a variant of the "be as unspecific as possible regarding inputs and as specific as possible regarding outputs" rule of thumb. Usually if you have a method that takes a plain non-null value, you can map it over the Optional , so the plain version is strictly more unspecific regarding inputs. However there are a bunch of possible reasons why you would want to require an Optional argument nonetheless: #li you want your function to be used in conjunction with another API that returns an Optional #li Your function should return something other than an empty Optional if the given value is empty #li You think Optional is so awesome that whoever uses your API should be required to learn about it ;-)

Question-27683759, answer-27684042
In a nutshell, this creates an empty, immutable list of strings. Let's look at the expression bit by bit. Collections is the name of a class. From the Javadoc : #blockquote emptyList() is the name of a static method defined in the Collections class ( Javadoc ). It is a generic method, and the <String> in Collections.<String>emptyList(args) specifies the generic type argument. The method returns a List<T> , which in this case is List<T> : a list of strings. More specifically, it returns an empty , immutable list of strings.

Question-25056607, answer-25056821
Documentation: For: System.out.println(args); #blockquote It will simply return the entire string that's why it returns 1. For the second case, String.split will discard the , so the result will be empty. String.split silently discards trailing separators see guava StringsExplained too

Question-19757300, answer-35512247
Keeping this issue in mind I developed a small library for dealing with checked exceptions and lambdas. Custom adapters allow you to integrate with existing functional types: stream(args).map(args) //with a static import #a
Question-10796160, answer-10796174
You need test.split(args); split uses regular expression and in regex | is metacharacter representing OR operator. You need to escape that character using \ (written in String as StringLiteral since \ is also metacharacter in String literals and require another \ to escape it). You can also use test.split(args); and let Pattern.quote create escaped version of regex representing | .

Question-17489250, answer-17489394
It's a feature of the Java language. String literals in the source code is given special treatment. The language spec, here , simply says that a string literal is of String type

Question-8777257, answer-8777311
The Arrays.equals(args) : check if both arrays contain the same number of elements, and all corresponding pairs of elements in the two arrays are equal. The array1.equals(args) : compare the object to another object and return true only if the reference of the two object are equal as in the Object.equals(args)

Question-6271417, answer-29938300
Use this method,but be careful to make an object in your main. public static void setName(args){ Class setClass = obj.getClass(args); String className = setClass.getName(args); System.out.println(args); }

Question-8172420, answer-15633542
Nice question. I've got of the following five 6 methods to do it. #pre #blockquote String.valueOf(args) invokes new String(args) , which in turn sets the value char array. #pre On the other hand String.valueOf(args) invokes the following package private constructor. #pre Source code from String.java in Java 8 source code #blockquote #li Java :: How to convert primitive char to String in Java #li How to convert Char to String in Java with Example

Question-4818699, answer-4818783
The absolute simplest example I can think of is to make incrementing an atomic operation. With standard ints: #pre With AtomicInteger: #pre The latter is a very simple way to perform simple mutations effects (especially counting, or unique-indexing), without having to resort to synchronizing all access. More complex synchronization-free logic can be employed by using compareAndSet(args) as a type of optimistic locking - get the current value, compute result based on this, set this result iff value is still the input used to do the calculation, else start again - but the counting examples are very useful, and I'll often use AtomicIntegers for counting and VM-wide unique generators if there's any hint of multiple threads being involved, because they're so easy to work with I'd almost consider it premature optimisation to use plain ints . While you can almost always achieve the same synchronization guarantees with ints and appropriate synchronized declarations, the beauty of AtomicInteger is that the thread-safety is built into the actual object itself, rather than you needing to worry about the possible interleavings, and monitors held, of every method that happens to access the int value. It's much harder to accidentally violate threadsafety when calling getAndIncrement(args) than when returning i++ and remembering (or not) to acquire the correct set of monitors beforehand.

Question-21375659, answer-21375818
This isn't strictly an answer to your question, but if behind your question is a wish to have mutable strings that you can manipulate, you should check out the StringBuilder class, which implements many of the exact same methods that String has but also adds methods to change the current contents. Once you've built your string in such a way that you're content with it, you simply call toString(args) on it in order to convert it to an ordinary String that you can pass to library routines and other functions that only take String s. Also, both StringBuilder and String implements the CharSequence interface, so if you want to write functions in your own code that can use both mutable and immutable strings, you can declare them to take any CharSequence object.

Question-23674624
I'm looking at the docs for the IntStream , and I see an toArray method, but no way to go directly to a List<T> Surely there is a way to convert a Stream to a List ?

Question-29183904, answer-29972028
Use enum when you need its features. Don't avoid it strictly . Java enum is more powerful, but if you don't need its features, use constants, they occupy less space and they can be primitive itself. When to use enum: #li type checking - you can accept only listed values, and they are not continuous (see below what I call continuous here) #li method overloading - every enum constant has its own implementation of a method #pre #li more data - your one constant contains more than one information that cannot be put in one variable #li complicated data - your constant need methods to operate on the data When not to use enum: #li you can accept all values of one type, and your constants contain only these most used #li you can accept continuous data #pre #li for names (like in your example) #li for everything other that really doesn't need an enum Enum occupies more space #li a single reference to an enum constant occupy 4 bytes #li every enum constant occupy space that is a sum of its fields' sizes aligned to 8 bytes + overhead of the object #li the enum class itself occupy some space Constant occupies less space #li a constant doesn't have a reference so it's a pure data (even if it's a reference, then enum instance would be a reference to another reference) #li constants may be added to existing class - it's not necessary to add another class #li constants may be inlined; it brings extended compile-time features (such as null checking, finding dead code etc.)

Question-19431234, answer-23885950
Short answer: #pre Explanation: (based on this question about LocalDate ) Despite its name, java.util.Date represents an instant on the time-line, not a "date". The actual data stored within the object is a long count of milliseconds since 1970-01-01T00:00Z (midnight at the start of 1970 GMT/UTC). The equivalent class to java.util.Date in JSR-310 is Instant , thus there are convenient methods to provide the conversion to and fro: #pre A java.util.Date instance has no concept of time-zone. This might seem strange if you call toString(args) on a java.util.Date , because the toString is relative to a time-zone. However that method actually uses Java's default time-zone on the fly to provide the string. The time-zone is not part of the actual state of java.util.Date . An Instant also does not contain any information about the time-zone. Thus, to convert from an Instant to a local date-time it is necessary to specify a time-zone. This might be the default zone - ZoneId.systemDefault(args) - or it might be a time-zone that your application controls, such as a time-zone from user preferences. LocalDateTime has a convenient factory method that takes both the instant and time-zone: #pre In reverse, the LocalDateTime the time-zone is specified by calling the atZone(args) method. The ZonedDateTime can then be converted directly to an Instant : #pre Note that the conversion from LocalDateTime to ZonedDateTime has the potential to introduce unexpected behaviour. This is because not every local date-time exists due to Daylight Saving Time. In autumn/fall, there is an overlap in the local time-line where the same local date-time occurs twice. In spring, there is a gap, where an hour disappears. See the Javadoc of atZone(ZoneId) for more the definition of what the conversion will do. Summary, if you round-trip a java.util.Date to a LocalDateTime and back to a java.util.Date you may end up with a different instant due to Daylight Saving Time.

Question-20877086, answer-20877161
Integer objects caches between -128 and 127 of 256 Integer You should not compare object references with == or != . You should use . equals(..) instead, or better - use the primitive int rather than Integer. parseInt : Parses the string argument as a signed decimal integer. The characters in the string must all be decimal digits, except that the first character may be an ASCII minus sign '-' ('\u002D') to indicate a negative value. The resulting integer value is returned, exactly as if the argument and the radix 10 were given as arguments to the parseInt(java.lang.String, int) method. valueOf Returns an Integer object holding the value extracted from the specified String when parsed with the radix given by the second argument. The first argument is interpreted as representing a signed integer in the radix specified by the second argument, exactly as if the arguments were given to the parseInt(java.lang.String, int) method. The result is an Integer object that represents the integer value specified by the string. equivalent to new Integer(args) radix - the radix to be used in interpreting s so if you equal Integer.valueOf(args) for the integer inbetween -128 to 127 it returns true in your condition for lesser than -128 and greater than 127 it gives false

Question-32693704, answer-32752970
I will try to summarize three moreless reasonable versions which were proposed in comments. @Holger says : #blockquote This is the most easy thing to test. Let's compile such program: #pre Run it with java -verbose:class HashMapTest . This will print the class loading events as they occur. With JDK 1.8.0_60 I see more than 400 classes loaded: #pre As you can see, HashMap is loaded long before application code and Arrays is loaded only 14 classes after HashMap . The HashMap load is triggered by sun.reflect.Reflection initialization as it has HashMap static fields. The Arrays load is likely to be triggered by WeakHashMap load which actually has Arrays.fill in the clear(args) method. The WeakHashMap load is triggered by java.lang.ClassValue$ClassValueMap which extends WeakHashMap . The ClassValueMap is present in every java.lang.Class instance. So to me seems that without Arrays class the JDK cannot be initialized at all. Also the Arrays static initializer is very short, it only initializes the assertion mechanism. This mechanism is used in many other classes (including, for example, java.lang.Throwable which is loaded very early). No other static initialization steps are performed in java.util.Arrays . Thus @Holger version seems incorrect to me. Here we also found very interesting thing. The WeakHashMap.clear(args) still uses Arrays.fill . It's interesting when it appeared there, but unfortunately this goes to prehistoric times (it was already there in the very first public OpenJDK repository). Next, @MarcoTopolnik says : #blockquote It was actually surprising for me that Arrays.fill is not directly intrinsified (see intrinsic list generated by @apangin ). Seems that such loop can be recognized and vectorized by JVM without explicit intrinsic handling. So it's true that extra call can be not inlined in very specific cases (for example if MaxInlineLevel limit is reached). On the other hand it's very rare situation and it's only a single call, it's not a call inside loop, and it's a static, not virtual/interface call, thus the performance improvement could be only marginal and only in some specific scenarios. Not the thing the JVM developers usually care. Also it should be noted that even C1 'client' compiler (tier 1-3) is capable to inline Arrays.fill called, for example, in WeakHashMap.clear(args) , as inlining log ( -XX:+UnlockDiagnosticVMOptions -XX:+PrintCompilation -XX:+PrintInlining ) says: #pre Of course, it's also easily inlined by smart and powerful C2 'server' compiler. Thus I see no problems here. Seems that @Marco version is incorrect either. Finally we have a couple of comments from @StuartMarks (who is JDK developer, thus some official voice): #blockquote Indeed the HashMap.clear(args) contained the loop many years, was replaced with Arrays.fill on Apr 10th, 2013 and stayed less one half-a-year until Sept 4th when the discussed commit was introduced. The discussed commit was actually a major rewrite of the HashMap internals to fix JDK-8023463 issue. It was a long story about possibility to poison the HashMap with keys having duplicating hashcodes reducing HashMap search speed to linear making it vulnerable to DoS-attacks. The attempts to solve this were performed in JDK-7 including some randomization of String hashCode. So seems that the HashMap implementation was forked from the earlier commit, developed independently, then merged into the master branch overwriting several changes introduced in-between. We may support this hypothesis performing a diff. Take the version where Arrays.fill was removed (2013-09-04) and compare it with previous version (2013-07-30). The diff -U0 output has 4341 lines. Now let's diff against the version prior to one when Arrays.fill was added (2013-04-01). Now diff -U0 contains only 2680 lines. Thus the newer version actually more similar to the older than to immediate parent. Conclusion So to conclude I would agree with Stuart Marks. There were no concrete reason to remove Arrays.fill , it's just because the in-between change was overwritten by mistake. Using Arrays.fill is perfectly fine both in JDK code and in user applications and used, for example, in WeakHashMap . The Arrays class is loaded anyways pretty early during the JDK initialization, has very simple static initializer and Arrays.fill method can be easily inlined even by client compiler, so no performance drawback should be noted.

Question-7935858
I have prepared a simple code snippet in order to separate the erroneous portion from my web application. #pre I have tested it while building a web application JSF. I just want to know why in the above code temp.split(args) does not work. The statement, System.out.println(args); displays nothing on the console means that it doesn't go through the loop. When I change the argument of the temp.split(args) method to other characters, It works just fine as usual. What might be the problem?

Question-10631715, answer-30270403
There is a function called replaceAll(args) that can remove all whitespaces by replacing them with whatever you want. As an example #pre will give you: First:15.94, Second:16.01

Question-22463062
Java 8 added a new API for working with dates and times (JSR 310). I have date and time as string (e.g. StringLiteral ). How can I obtain a LocalDateTime instance from the given string? After I finished working with the LocalDateTime object: How can I then convert the LocalDateTime instance back to a string with the same format as shown above?

Question-24547673, answer-24547831
It's a curious omission. You would have to mark the field as transient and provide your own custom writeObject(args) method that wrote the get(args) result itself, and a readObject(args) method that restored the Optional by reading that result from the stream. Not forgetting to call defaultWriteObject(args) and defaultReadObject(args) respectively.

Question-12552863, answer-18496449
The first style is the one suggested by Oracle . BufferedWriter doesn't throw checked exceptions, so if any exception is thrown, the program is not expected to recover from it, making resource recover mostly moot. Mostly because it could happen in a thread, with the thread dieing but the program still continuing -- say, there was a temporary memory outage that wasn't long enough to seriously impair the rest of the program. It's a rather corner case, though, and if it happens often enough to make resource leak a problem, the try-with-resources is the least of your problems.

Question-27504925
The Java language specification specifies that #blockquote So, considering arrays are objects â€” why did the Java designers make the decision not to allow inherit and override from it, for example, toString() or equals(args) ? The current syntax wouldn't allow creating anonymous classes with an array as the base class, but I don't think that was the reason for their decision.

Question-7032070, answer-7032144
The source code for clear(args) : #pre The source code for removeAll(args) (As defined in AbstractCollection ): #pre clear(args) is much faster since it doesn't have to deal with all those extra method calls. And as Atrey points out, c.contains(args) increases the time complexity of removeAll to O(n^2) as opposed to clear 's O(n).

Question-12732422
I'm trying to add header for my request using HttpUrlConnection but the method setRequestProperty(args) doesn't seem working. The server side doesn't receive any request with my header. Can anyone help me? Thanks in advance. #pre

Question-32632364, answer-32633199
It shouldn't have compiled, according to JLS 7 . int can be compared to boxed numeric types, i.e. Byte, Short, Character, Integer, Long, Float, Double. But that is all. And if comparison is between int and say Float , Float will be unboxed first, so that the comparison is between float and int . It'll make no sense to do the other way around - box int then examine the identity of the Integer (with a Float no less).

Question-15655012, answer-15655071
If you make foo static, you must initialize it in the class constructor (or inline where you define it) like the following examples. Class constructor (not instance): #pre Inline: private static final List foo = new ArrayList(args); The problem here is not how the final modifier works, but rather how the static modifier works. The final modifier enforces an initialization of your reference by the time the call to your constructor completes (i.e. you must initialize it in the constructor). When you initialize an attribute in-line, it gets initialized before the code you have defined for the constructor is run, so you get the following outcomes: #li if foo is static , foo = new ArrayList(args) will be executed before the static{} constructor you have defined for your class is executed #li if foo is not static , foo = new ArrayList(args) will be executed before your constructor is run When you do not initilize an attribute in-line, the final modifier enforces that you initialize it and that you must do so in the constructor. If you also have a static modifier, the constructor you will have to initialize the attribute in is the class' initialization block : static{} . The error you get in your code is from the fact that static{} is run when the class is loaded, before the time you instantiate an object of that class. Thus, you will have not initialized foo when the class is created. Think of the static{} block as a constructor for an object of type Class . This is where you must do the initialization of your static final class attributes (if not done inline). Side note: The final modifier assures const-ness only for primitive types and references. When you declare a final object, what you get is a final reference to that object, but the object itself is not constant. What you are really achieving when declaring a final attribute is that, once you declare an object for your specific purpose (like the final List that you have declared), that and only that object will be used for that purpose: you will not be able to change List foo to another List , but you can still alter your List by adding/removing items (the List you are using will be the same, only with its contents altered).

Question-11774099, answer-11774137
iterate through the whole 65k chars and ask Character.isJavaIdentifierStart(args) . The answer is : "undertie" decimal 8255

Question-24630963, answer-32648397
I wrote a Collector which, unlike the default java one, does not crash when you have null values: #pre Just replace your Collectors.toMap(args) call to a call to this function and it'll fix the problem.

Question-27845223
I'm looking at a piece of Java code right now, and it takes a path as a String and gets its URL using URL resource = ClassLoader.getSystemClassLoader(args).getResource(args); , then calls String path = resource.getPath(args) and finally executes new File(args); . Oh, and there are also calls to URL url = resource.toURI(args); and String file = resource.getFile(args) . I'm totally confused right now - mostly because of the terminology, I guess. Can someone please walk me through the differences, or provide a few links to Dummy-proof material? Especially URI to URL and Resource to File ? To me, it feels like they should be the same thing, respectively... The difference between getFile(args) and getPath(args) is explained here: What's the difference between url.getFile() and getpath()? (Interestingly they both seem to return Strings, which probably adds a whole lot to my state of mind...) Now, if I have a locator that references a class or package in a jar file, will those two (i.e. path an file strings) differ? resource.toString(args) would give you jar:file:/C:/path/to/my.jar!/com/example/ , after all (note the exclamation mark). Is the difference between URI and URL in Java that the former doesn't encode spaces? Cf. Files, URIs, and URLs conflicting in Java (This answer explains the general, conceptual difference between the two terms fairly well: URIs identify and URLs locate; ) Lastly - and most importantly - why do I need File object; why isn't a Resource ( URL ) enough? (And is there a Resource object?) Sorry if this question is a bit unorganized; it just reflects the confusion I have... :)

Question-20129762
In Java 8 we have the class Stream<T> , which curiously have a method Iterator<T> iterator(args) So you would expect it to implement interface Iterable<T> , which requires exactly this method, but that's not the case. When I want to iterate over a Stream using a foreach loop, I have to do something like #pre Am I missing something here?

Question-32356762, answer-32370677
There is a small overhead in calling methods var an interface rather than directly on an object. This overhead is often no more than 1 or 2 processor instructions. The overhead of calling a method is even lower if the JIT knows that the method is final. This is not measurable for most code you and me right, but for the low level methods in java.utils may be used in some code where it is an issue. Also as has been pointed out in other answers, the concrete type of the object that is return (even when hidden behind an interface) effects the performance of code that uses it. This change in performance can be very great, so such an extent that the calling software fails to work. Clearly the authors of java.utils have no way to know what all the software that calls Collections.list() does with the result and no way to re-test this software if they change the implantation of Collections.list(). Therefore they are not going to change the implantation of Collections.list() to return a different type of List, even if the type system allowed it! When writing your own software, you (hopefully) have automated test that cover all your code and a good understand of how your code interrelates include know where performance is an issue. Being able to make a change to a method, without having to change the callers is of great value while the design of the software is changing. Therefore the two set of trade offs are very different.

Question-4576352, answer-4576367
using public String replaceAll(args) will work usage would be str.replace(args); executing StringLiteral.replaceAll(args); returns: lakjsdf xx

Question-31270759
Exceptions, especially checked ones, can severely interrupt the flow of program logic when the FP idiom is used in Java 8. Here is an arbitrary example: #pre The above code breaks when there's an exception for an unparseable string. But say I just want to replace that with a default value, much like I can with Optional : Stream.of(args).forEach(args); Of course, this still fails because Optional only handles null s. I would like something as follows: Stream.of(args).forEach(args); Note: this is a self-answered question.

Question-6271417, answer-6271520
Try using this.getClass(args).getCanonicalName(args) or this.getClass(args).getSimpleName(args) . If it's an anonymous class, use this.getClass.getSuperclass.getName(args)

Question-5031614, answer-5103360
We usually have two IDs in our entities: #li Is for persistence layer only (so that persistence provider and database can figure out relationships between objects). #li Is for our application needs ( equals(args) and hashCode(args) in particular) Take a look: #pre EDIT: to clarify my point regarding calls to setUuid(args) method. Here's a typical scenario: #pre When I run my tests and see the log output I fix the problem: #pre Alternatively, one can provide a separate constructor: #pre So my example would look like this: #pre I use a default constructor and a setter, but you may find two-constructors approach more suitable for you.

Question-4812570
How can I get the e.printStackTrace(args) and store it into a String variable? I want to use the string generated by e.printStackTrace(args) later in my program. I'm still new to Java so I'm not too familiar with StringWriter that I think will be the solution. Or if you have any other ideas please let me know. Thanks

Question-31316581, answer-31327420
If type inference produces a single upper bound for a type variable, typically the upper bound is chosen as the solution. For example, if T<<Number , the solution is T=Number . Although Integer , Float etc. could also satisfy the constraint, there's no good reason to choose them over Number . That was also the case for throws T in java 5-7: T<<Throwable => T=Throwable . (Sneaky throw solutions all had explicit <RuntimeException> type arguments, otherwise <Throwable> is inferred.) In java8, with the introduction of lambda, this becomes problematic. Consider this case #pre If we invoke with an empty lambda, what would T be inferred as? invoke(args); The only constraint on T is an upper bound Throwable . In earlier stage of java8, T=Throwable would be inferred. See this report I filed. But that is pretty silly, to infer Throwable , a checked exception, out of an empty block. A solution was proposed in the report (which is apparently adopted by JLS) - #pre i.e. if the upper bound is Exception or Throwable , choose RuntimeException as the solution. In this case, there is a good reason to choose a particular subtype of the upper bound.

Question-12576156, answer-12576394
By specifying the the my.list.of.strings=ABC,CDE,EFG in .properties file and using @Value(args) private String[] myString; You can get the arrays of strings. And using CollectionUtils.addAll(args) , you can get the list of strings.

Question-5778658, answer-5778863
An OutputStream is one where you write data to. If some module exposes an OutputStream , the expectation is that there is something at the other end that is reading. Something that exposes an InputStream on the other hand is indicating that you will need to listen to this stream, and there will be data that you can read. So it is possible to connect an InputStream to an OutputStream InputStream----read---> intermediateBytes[n] ----write----> OutputStream As someone metioned, this is what the copy(args) method from IOUtils lets you do. It does not make sense to go the other way... hopefully this makes some sense UPDATE: Of course the more I think of this, the more I can see how this actually would be a requirement. I know some of the comments mentioned Piped input/ouput streams, but there is another possibility. If the output stream that is exposed is a ByteArrayOutputStream , then you can always get the full contents by calling the toByteArray(args) method. Then you can create an input stream wrapper by using the ByteArrayInputStream sub-class. These two are pseudo-streams, they both basically just wrap an array of bytes. Using the streams this way, therefore, is technically possible, but to me it is still very strange...

Question-20001427, answer-20001866
Usually, one would call the reduce method using Math.max(args) as follows: #pre That requires a lot of syntax for just calling Math.max . That's where lambda expressions come into play. Since Java 8 it is allowed to do the same thing in a much shorter way: reduce(args); How does this work? The java compiler "detects", that you want to implement a method that accepts two int s and returns one int . This is equivalent to the formal parameters of the one and only method of interface IntBinaryOperator (the parameter of method reduce you want to call). So the compiler does the rest for you - it just assumes you want to implement IntBinaryOperator . But as Math.max(args) itself fulfills the formal requirements of IntBinaryOperator , it can be used directly. Because Java 7 does not have any syntax that allows a method itself to be passed as an argument (you can only pass method results, but never method references), the :: syntax was introduced in Java 8 to reference methods: reduce(args); Note that this will be interpreted by the compiler, not by the JVM at runtime! Although it produces different bytecodes for all three code snippets, they are semantically equal, so the last two can be considered to be short (and probably more efficient) versions of the IntBinaryOperator implementation above! (See also Translation of Lambda Expressions )

Question-28319064, answer-29000802
There is a third option - using stream(args).toArray(args) - see comments under why didn't stream have a toList method . It turns out to be slower than forEach() or collect(), and less expressive. It might be optimised in later JDK builds, so adding it here just in case. assuming List<T> myFinalList = Arrays.asList(args); with a micro-micro benchmark, 1M entries, 20% nulls and simple transform in doSomething() #pre the results are parallel: #pre sequential: #pre parallel without nulls and filter (so the stream is SIZED ): toArrays has the best performance in such case, and .forEach(args) fails with "indexOutOfBounds" on the recepient ArrayList, had to replace with .forEachOrdered(args) #pre

Question-13291076, answer-13291108
Use name(args) when you want to make a comparison or use the hardcoded value for some internal use in your code. Use toString(args) when you want to present information to a user (including a developper looking at a log). Never rely in your code on toString(args) giving a specific value. Never test it against a specific string. If your code breaks when someone correctly changes the toString(args) return, then it was already broken. From the javadoc (emphasis mine) : #blockquote

Question-11821801, answer-36827191
From oracle documentation page about ReentrantLock : #blockquote #li A ReentrantLock is owned by the thread last successfully locking, but not yet unlocking it. A thread invoking lock will return, successfully acquiring the lock, when the lock is not owned by another thread. The method will return immediately if the current thread already owns the lock. #li The constructor for this class accepts an optional fairness parameter. When set true, under contention, locks favor granting access to the longest-waiting thread . Otherwise this lock does not guarantee any particular access order. ReentrantLock key features as per this article #li Ability to lock interruptibly. #li Ability to timeout while waiting for lock. #li Power to create fair lock. #li API to get list of waiting thread for lock. #li Flexibility to try for lock without blocking. You can use ReentrantReadWriteLock.ReadLock, ReentrantReadWriteLock.WriteLock to further acquire control on granular locking on read and write operations. Have a look at this article by Benjamen on usage of different type of ReentrantLocks

Question-8098953, answer-8103083
The first thing to keep in mind is that Java ternary operators have a "type", and that this is what the compiler will determine and consider no matter what the actual/real types of the second or third parameter are. Depending on several factors the ternary operator type is determined in different ways as illustrated in the Java Language Specification 15.26 In the question above we should consider the last case: #blockquote This is by far the most complex case once you take a look at applying capture conversion (Â§5.1.10) and most of all at lub(T1, T2) . In plain English and after an extreme simplification we can describe the process as calculating the "Least Common Superclass" (yes, think of the LCM) of the second and third parameters. This will give us the ternary operator "type". Again, what I just said is an extreme simplification (consider classes that implement multiple common interfaces). For example, if you try the following: #pre You'll notice that resulting type of the conditional expression is java.util.Date since it's the "Least Common Superclass" for the Timestamp / Time pair. Since null can be autoboxed to anything, the "Least Common Superclass" is the Integer class and this will be the return type of the conditional expression (ternary operator) above. The return value will then be a null pointer of type Integer and that is what will be returned by the ternary operator. At runtime, when the Java Virtual Machine unboxes the Integer a NullPointerException is thrown. This happens because the JVM attempts to invoke the function null.intValue(args) , where null is the result of autoboxing. In my opinion (and since my opinion is not in the Java Language Specification many people will find it wrong anyway) the compiler does a poor job in evaluating the expression in your question. Given that you wrote true ? param1 : param2 the compiler should determine right away that the first parameter - null - will be returned and it should generate a compiler error. This is somewhat similar to when you write while(args){} etc... and the compiler complains about the code underneath the loop and flags it with Unreachable Statements . Your second case is pretty straightforward and this answer is already too long... ;) CORRECTION: After another analysis I believe that I was wrong to say that a null value can be boxed/autoboxed to anything. Talking about the class Integer, explicit boxing consists in invoking the new Integer(args) constructor or maybe the Integer.valueOf(args); (I found this version somewhere). The former would throw a NumberFormatException (and this does not happen) while the second would just not make sense since an int cannot be null ...

Question-21488056, answer-35074360
I have written a complete utility class (inspired by Askar's proposal) that can take Java 8 lambda expression and turn them (if applicable) into any typed standard Java 8 lambda defined in the package java.util.function . You can for example do: #li asPredicate(args).negate(args) #li asBiPredicate(args).negate(args) Because there would be numerous ambiguities if all the static methods would be named just as(args) , I opted to call the method "as" followed by the returned type. This gives us full control of the lambda interpretation. Below is the first part of the (somewhat large) utility class revealing the pattern used. Have a look at the complete class here (at gist). #pre

Question-26548660, answer-26548894
You can use a Callback to get onSuccess and onError events. Just add a new Callback to your request like so: Picasso.with(args) .load(args) .into(args); Then you can perform any alterations and modifications in the onSuccess callback.

Question-22694884, answer-22695031
Technically there's an ugly 'workaround' that involves peek(args) and an AtomicInteger , but really you shouldn't be using that. What I do in these cases is just collecting it in a list, like this: #pre I am not aware of a way to do this in the API, meanwhile I will work on another example involving a custom element. Update , You should create your own Collector for this: #pre What it does is: #li It mimicks the Collectors.toList(args) collector. #li It applies an extra finisher at the end, that throws an exception, or if no exception, returns the first element of the list. Used as: User resultUser = users.stream(args) .filter(args) .collect(args); You can then customize this singletonCollector as much as you want, for example give the exception as argument in the constructor, tweak it to allow two values, and more. New update , I revised my old answer once more for singletonCollector(args) , it can actually be obtained like this: #pre

Question-28276423, answer-28276469
It will be fine if you only close the last stream - the close call will be send to the underlying streams, too.

