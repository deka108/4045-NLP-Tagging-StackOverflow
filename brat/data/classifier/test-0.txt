Question-34172978, answer-34173040
Since there are only 4 elements that pass the filter, limit(args) never reaches 10 elements, so the Stream pipeline keeps generating new elements and feeding them to the filter, trying to reach 10 elements that pass the filter, but since only the first 4 elements pass the filter, the processing never ends (at least until i overflows). The Stream pipeline is not smart enough to know that no more elements can pass the filter, so it keeps processing new elements.

Question-6667243, answer-6667354
Enum is just a little bit special class. Enums can store additional fields, implement methods etc. For example #pre Now you can say: System.out.println(args) and see output: a

Question-27908213, answer-27908402
Although there is no explicit guarantee of this, the end result is bound to be such that the comparison always succeeds for enum constants with identical names: #pre The reason for this is that Java compiler constructs subclasses of Enum in such a way that they end up calling Enum 's sole protected constructor, passing it the name of enum value: protected Enum(args); The name is embedded into the generated code in the form of a string literal. According to String documentation, #blockquote This amounts to an implicit guarantee of your expression succeeding when names of enum constants are identical. However, I would not rely on this behavior, and use equals(args) instead, because anyone reading my code would be scratching his head, thinking that I made a mistake.

Question-10631715, answer-32362691
For completeness, using the Guava library, you'd do: Splitter.on(args).split(args) Another example: #pre Splitter.split(args) returns an Iterable, so if you need a List, wrap it in Lists.newArrayList(args) as above. Otherwise just go with the Iterable, for example: #pre Note how trimResults(args) handles all your trimming needs without having to tweak regexes for corner cases , as with String.split(args) . If your project uses Guava already, this should be your preferred solution. See Splitter documentation in Guava User Guide or the javadocs for more configuration options.

Question-10977992, answer-17939167
There are two differences: #li We can use Iterator to traverse Set and List and also Map type of Objects. While a ListIterator can be used to traverse for List-type Objects, but not for Set-type of Objects. That is, we can get a Iterator object by using Set and List, see here: By using Iterator we can retrieve the elements from Collection Object in forward direction only. Methods in Iterator: #li hasNext(args) #li next(args) #li remove(args) #pre #li But we get ListIterator object only from the List interface, see here: where as a ListIterator allows you to traverse in either directions (Both forward and backward). So it has two more methods like hasPrevious(args) and previous(args) other than those of Iterator. Also, we can get indexes of the next or previous elements (using nextIndex(args) and previousIndex(args) respectively ) Methods in ListIterator: #li hasNext() #li next() #li previous() #li hasPrevious() #li remove() #li nextIndex() #li previousIndex() ListIterator listiterator = List.listIterator(args); i.e., we can't get ListIterator object from Set interface.

Question-9749746, answer-9749864
You are specifically asking about how they internally work , so here you are: No synchronization #pre It basically reads value from memory, increments it and puts back to memory. This works in single thread but nowadays, in the era of multi-core, multi-CPU, multi-level caches it won't work correctly. First of all it introduces race condition (several threads can read the value at the same time), but also visibility problems. The value might only be stored in " local " CPU memory (some cache) and not be visible for other CPUs/cores (and thus - threads). This is why many refer to local copy of a variable in a thread. It is very unsafe. Consider this popular but broken thread-stopping code: #pre Add volatile to stopped variable and it works fine - if any other thread modifies stopped variable via pleaseStop(args) method, you are guaranteed to see that change immediately in working thread's while(args) loop. BTW this is not a good way to interrupt a thread either, see: How to stop a thread that is running forever without any use and Stopping a specific java thread . AtomicInteger #pre The AtomicInteger class uses CAS ( compare-and-swap ) low-level CPU operations (no synchronization needed!) They allow you to modify a particular variable only if the present value is equal to something else (and is returned successfully). So when you execute getAndIncrement(args) it actually runs in a loop (simplified real implementation): #pre So basically: read; try to store incremented value; if not successful (the value is no longer equal to current ), read and try again. The compareAndSet(args) is implemented in native code (assembly). volatile without synchronization #pre This code is not correct. It fixes the visibility issue ( volatile makes sure other threads can see change made to counter ) but still has a race condition. This has been explained multiple times: pre/post-incrementation is not atomic. The only side effect of volatile is " flushing " caches so that all other parties see the freshest version of the data. This is too strict in most situations; that is why volatile is not default. volatile without synchronization (2) #pre The same problem as above, but even worse because i is not private . The race condition is still present. Why is it a problem? If, say, two threads run this code simultaneously, the output might be + 5 or + 10 . However, you are guaranteed to see the change. Multiple independent synchronized #pre Surprise, this code is incorrect as well. In fact, it is completely wrong. First of all you are synchronizing on i , which is about to be changed (moreover, i is a primitive, so I guess you are synchronizing on a temporary Integer created via autoboxing...) Completely flawed. You could also write: #pre No two threads can enter the same synchronized block with the same lock . In this case (and similarly in your code) the lock object changes upon every execution, so synchronized effectively has no effect. Even if you have used a final variable (or this ) for synchronization, the code is still incorrect. Two threads can first read i to temp synchronously (having the same value locally in temp ), then the first assigns a new value to i (say, from 1 to 6) and the other one does the same thing (from 1 to 6). The synchronization must span from reading to assigning a value. Your first synchronization has no effect (reading an int is atomic) and the second as well. In my opinion, these are the correct forms: #pre
Question-32693704
I noticed something strange in the implementation of HashMap.clear(args) . This is how it looked in OpenJDK 7u40 : #pre And this is how it looks as of OpenJDK 8u40 : #pre I understand that now the table can be null for empty an map, thus the additional check and caching in a local variable is required. But why was Arrays.fill(args) replaced with a for-loop? It seems that the change was introduced in this commit . Unfortunately I found no explanation for why a plain for loop might be better than Arrays.fill(args) . Is it faster? Or safer?

Question-27845223
I'm looking at a piece of Java code right now, and it takes a path as a String and gets its URL using URL resource = ClassLoader.getSystemClassLoader(args).getResource(args); , then calls String path = resource.getPath(args) and finally executes new File(args); . Oh, and there are also calls to URL url = resource.toURI(args); and String file = resource.getFile(args) . I'm totally confused right now - mostly because of the terminology, I guess. Can someone please walk me through the differences, or provide a few links to Dummy-proof material? Especially URI to URL and Resource to File ? To me, it feels like they should be the same thing, respectively... The difference between getFile(args) and getPath(args) is explained here: What's the difference between url.getFile() and getpath()? (Interestingly they both seem to return Strings, which probably adds a whole lot to my state of mind...) Now, if I have a locator that references a class or package in a jar file, will those two (i.e. path an file strings) differ? resource.toString(args) would give you jar:file:/C:/path/to/my.jar!/com/example/ , after all (note the exclamation mark). Is the difference between URI and URL in Java that the former doesn't encode spaces? Cf. Files, URIs, and URLs conflicting in Java (This answer explains the general, conceptual difference between the two terms fairly well: URIs identify and URLs locate; ) Lastly - and most importantly - why do I need File object; why isn't a Resource ( URL ) enough? (And is there a Resource object?) Sorry if this question is a bit unorganized; it just reflects the confusion I have... :)

Question-10786042, answer-10786112
URLEncoder should be the way to go. You only need to keep in mind to encode only the individual query string parameter name and/or value, not the entire URL, for sure not the query string parameter separator character & nor the parameter name-value separator character = . #pre Note that spaces in query parameters are represented by + , not %20 , which is legitimately valid. The %20 is usually to be used to represent spaces in URI itself (the part before the URI-query string separator character ? ), not in query string (the part after ? ). Also note that there are two encode(args) methods. One without charset argument and another with. The one without charset argument is deprecated. Never use it and always specify the charset argument. The javadoc even explicitly recommends to use the UTF-8 encoding, as mandated by RFC3986 and W3C . #blockquote See also: #li What every web developer must know about URL encoding

Question-8777257, answer-8777292
The equals(args) of arrays is inherited from Object , so it does not look at the contents of the arrrays, it only considers each array equal to itself. The Arrays.equals(args) methods do compare the arrays' contents. There's overloads for all primitive types, and the one for objects uses the objects' own equals(args) methods.

Question-29494800, answer-29500496
First of all, the cast in that line ((Object)newType == (Object)Object[].class) are absobuletly needed. Removing them will result in a compilation error : #pre Now to answer your question What is this line checking ? It simply verify if the given array is of object type, which is part of the answer for your other question Why Array.newInstance not good enough for both cases? In the first case, we already know that the array is of Object type so there is no point in calling the newInstance method to retrieve the correct type, this would only result in performance loss. As for your final example, Integer[] nums = Arrays.copyOf(args) That it does compile, it is true. Because the given arguments to the method are all valids. It will certainly fail at runtime; what would be the expected output of converting "a" to Integer type ? Now, when to use copyOf ? When you already know the both types, and already know that they are valid together. It main usage is to return a copy but truncated or padded with [null/default values] to the original array.

Question-32356762, answer-32357149
Disclaimer: I am not a JDK author. I agree that it's correct to write your own code to interfaces, but if you're going return a mutable collection to a third party, it's important to let the third party know what sort of List they're getting back. LinkedList and ArrayList are very different, performance wise, for various operations. For example, removing the first element of an ArrayList is O(args) , but removing the first element of a LinkedList is O(args) . By fully specifying the return type, the JDK authors are communicating extra information , in unambiguous code, about what sort of object they're giving back to you, so you can write your code to use this method properly. If you really need a LinkedList , you know that you have to specify one here. Finally, the main reason to code to an interface over an implementation is if you think that the implementation will change. The JDK authors probably figure they are never going to change this method; it's never going to return a LinkedList or a Collections.UnmodifiableList . However, in most cases, you would probably still do: List<T> list = Collections.list(args);

Question-6667243, answer-25575077
You could override the toString(args) method for each enum value. Example: #pre Usage: #pre

Question-13195797, answer-13195890
FileUtils.cleanDirectory(args); There is this method available in the same file. This will also recursively deletes all sub-folders and files under them. Docs: org.apache.commons.io.FileUtils.cleanDirectory

Question-25056607, answer-25056878
We can take a look into the source code of java.util.regex.Pattern which is behind String.split . Way down the rabbit hole the method public String[] split(args) is invoked. Input StringLiteral For input StringLiteral this method is called as String[] parts = split(args); The intersting part of this method is : #pre And that is what happens: new String[] {input.toString()} is returned . Input StringLiteral For input StringLiteral the intersting part is #pre Here resultSize == 0 and limit == 0 so new String[0] is returned .

Question-21375659, answer-21375818
This isn't strictly an answer to your question, but if behind your question is a wish to have mutable strings that you can manipulate, you should check out the StringBuilder class, which implements many of the exact same methods that String has but also adds methods to change the current contents. Once you've built your string in such a way that you're content with it, you simply call toString(args) on it in order to convert it to an ordinary String that you can pass to library routines and other functions that only take String s. Also, both StringBuilder and String implements the CharSequence interface, so if you want to write functions in your own code that can use both mutable and immutable strings, you can declare them to take any CharSequence object.

Question-20877086, answer-20877161
Integer objects caches between -128 and 127 of 256 Integer You should not compare object references with == or != . You should use . equals(..) instead, or better - use the primitive int rather than Integer. parseInt : Parses the string argument as a signed decimal integer. The characters in the string must all be decimal digits, except that the first character may be an ASCII minus sign '-' ('\u002D') to indicate a negative value. The resulting integer value is returned, exactly as if the argument and the radix 10 were given as arguments to the parseInt(java.lang.String, int) method. valueOf Returns an Integer object holding the value extracted from the specified String when parsed with the radix given by the second argument. The first argument is interpreted as representing a signed integer in the radix specified by the second argument, exactly as if the arguments were given to the parseInt(java.lang.String, int) method. The result is an Integer object that represents the integer value specified by the string. equivalent to new Integer(args) radix - the radix to be used in interpreting s so if you equal Integer.valueOf(args) for the integer inbetween -128 to 127 it returns true in your condition for lesser than -128 and greater than 127 it gives false

Question-18723596
String x = (String) null; Why there is no exception in this statement? #pre It prints null . But .toString(args) method should throw a null pointer exception.

Question-8579657, answer-8579702
If you just invoke run(args) directly, it's executed on the calling thread, just like any other method call. Thread.start(args) is required to actually create a new thread so that the runnable's run method is executed in parallel.

Question-32623834, answer-32652449
Another related point: you can make use of the constant pool to improve the performance of string comparisons in some circumstances, by using the String.intern() method. That method returns the instance of String with the same contents as the String on which it is invoked from the String constants pool, adding it it if is not yet present. In other words, after using intern(args) , all Strings with the same contents are guaranteed to be the same String instance as each other and as any String constants with those contents, meaning you can then use the equals operator ( == ) on them. This is just an example which is not very useful on its own, but it illustrates the point: #pre This little trick isn't worth designing your code around, but it is worth keeping in mind for the day when you notice a little more speed could be eked out of some bit of performance sensitive code by using the == operator on a string with judicious use of intern(args) .

Question-26684562, answer-26684710
Both map and flatMap can be applied to a Stream<T> and they both return a Stream<T> . The difference is that the map operation produces one output value for each input value, whereas the flatMap operation produces an arbitrary number (zero or more) values for each input value. This is reflected in the arguments to each operation. The map operation takes a Function , which is called for each value in the input stream and produces one result value, which is sent to the output stream. The flatMap operation takes a function that conceptually wants to consume one value and produce an arbitrary number of values. However, in Java, it's cumbersome for a method to return an arbitrary number of values, since methods can return only zero or one value. One could imagine an API where the mapper function for flatMap takes a value and returns an array or a List of values, which are then sent to the output. Given that this is the streams library, a particularly apt way to represent an arbitrary number of return values is for the mapper function itself to return a stream! The values from the stream returned by the mapper are drained from the stream and are passed to the output stream. The "clumps" of values returned by each call to the mapper function are not distinguished at all in the output stream, thus the output is said to have been "flattened." Typical use is for the mapper function of flatMap to return Stream.empty(args) if it wants to send zero values, or something like Stream.of(args) if it wants to return several values. But of course any stream can be returned.

Question-7348711, answer-7353473
InetAddress.getLocalHost(args).getHostName(args) is better (as explained by Nick), but still not very good One host can be known under many different hostnames. Usually you'll be looking for the hostname your host has in a specific context. For example, in a web application, you might be looking for the hostname used by whoever issued the request you're currently handling. How to best find that one depends on which framework you're using for your web application. In some kind of other internet-facing service, you'll want the hostname your service is available through from the 'outside'. Due to proxies, firewalls etc this might not even be a hostname on the machine your service is installed on - you might try to come up with a reasonable default, but you should definitely make this configurable for whoever installs this.

Question-32312876, answer-32313069
This is possible using the mergeFunction parameter of Collectors.toMap(keyMapper, valueMapper, mergeFunction) : #pre mergeFunction is a function that operates on two values associated with the same key. adress1 corresponds to the first address that was encountered when collecting elements and adress2 corresponds to the second address encountered: this lambda just tells to keep the first address and ignores the second.

Question-15336477, answer-15336606
It got deprecated in version 4.3-alpha1 which you use because of the LATEST version specification. If you take a look at the javadoc of the class, it tells you what to use instead: HttpClientBuilder . In the latest stable version ( 4.2.3 ) the DefaultHttpClient is not deprecated yet.

Question-7520432
I wanted to clarify if I understand this correctly: #li == -> is a reference comparison, i.e. both objects point to the same memory location #li .equals(args) -> evaluates to the comparison of values in the objects Am I correct in my understanding ?

Question-18532488
In many other languages, eg. Haskell, it is easy to repeat a value or function multiple times, eg. to get a list of 8 copies of the value 1: take 8(args) but I haven't found this yet in Java 8. Is there such a function in Java 8's JDK? Or alternatively something equivalent to a range like [1..8] It would seem an obvious replacement for a verbose statement in Java like #pre to have something like Range.from(args).forEach(args) though this particular example doesn't look much more concise actually... but hopefully it's more readable.

Question-31922866, answer-31922994
I think that is because you usually write your functions to manipulate data, and then lift it to Optional using map and similar functions. This adds the default Optional behavior to it. Of course, there might be cases, when it is necessary to write your own auxilary function that works on Optional .

Question-22561614, answer-22561690
Comparator is a functional interface , and Integer::max complies with that interface (after autoboxing/unboxing is taken into consideration). It takes two int values and returns an int - just as you'd expect a Comparator<T> to (again, squinting to ignore the Integer/int difference). However, I wouldn't expect it to do the right thing, given that Integer.max doesn't comply with the semantics of Comparator.compare . And indeed it doesn't really work in general. For example, make one small change: #pre ... and now the max value is -20 and the min value is -1. Instead, both calls should use Integer::compare : #pre

Question-27747562, answer-27747702
A List<T> could very well be an Item. See for example: #pre A cast tells the compiler: "I know you can't be sure that this is a object of type Item, but I know better than you, so please compile". The compiler will only refuse to compile that if it's impossible for the returned object to be an instance of Item (like, for example, Integer can't ever be a String ) At runtime, the type of the actual object returned by the method will be checked, and if it's not actually an object of type Item, you'll get a ClassCastException.

Question-26791441, answer-26796725
Swapping Only One Occurrence If there is only one occurrence of each of the swapable strings in the input, you can do the following: Before proceeding to any replace, get the indices of the occurrences of the words. After that we only replace the word found at these indexes, and not all occurrences. This solution uses StringBuilder and does not produce intermediate String s like String.replace(args) . One thing to note: if the swapable words have different lengths, after the first replace the second index might change (if the 1st word occurs before the 2nd) exactly with the difference of the 2 lengths. So aligning the second index will ensure this works even if we're swapping words with different lengths. #pre Swapping Arbitrary Number of Occurrences Analogous to the previous case we will first collect the indexes (occurrences) of the words, but in this case it will a list of integers for each word, not just one int . For this we will use the following utility method: #pre And using this we will replace the words with the other one by decreasing index (which might require to alternate between the 2 swapable words) so that we won't even have to correct the indices after a replace: #pre

Question-32693704, answer-32749756
I'm going to shoot in the dark here... My guess is that it might have been changed in order to prepare the ground for Specialization (aka generics over primitive types). Maybe (and I insist on maybe ), this change is meant to make transition to Java 10 easier, in the event of specialization being part of the JDK. If you look at the State of the Specialization document , Language restrictions section, it says the following: #blockquote (Emphasis is mine). And ahead in the Specializer transformations section, it says: #blockquote Later on, near the end of the document, in the Further investigation section, it says: #blockquote Now, regarding the change... If the Arrays.fill(args) method is going to be specialized, then its signature should change to Arrays.fill(args) . However this case is specifically listed in the (already mentioned) Language restrictions section (it would violate the emphasized items). So maybe someone decided that it would be better to not use it from the HashMap.clear(args) method, especially if value is null .

Question-18410035, answer-37409771
In Java 8 collection classes that implement Iterable (for example all lists) now have forEach method: Arrays.asList(args).forEach(args); The above example makes use of method-reference introduced in Java 8. We can also iterate over a list using Stream as: Arrays.asList(args).stream(args).forEach(args); The advantage with later option is that we can also make use of parallel streams wherever appropriate. If the objective is only to print the items irrespective of the order then we can use parallel stream as: Arrays.asList(args).parallelStream(args).forEach(args);

Question-14014086, answer-20784007
Ken's answer is basically right but I'd like to chime in on the "why would you want to use one over the other?" part of your question. Basics The base interface you choose for your repository has two main purposes. First, you allow the Spring Data repository infrastructure to find your interface and trigger the proxy creation so that you inject instances of the interface into clients. The second purpose is to pull in as much functionality as needed into the interface without having to declare extra methods. The common interfaces The Spring Data core library ships with two base interfaces that expose a dedicated set of functionalities: #li CrudRepository - CRUD methods #li PagingAndSortingRepository - methods for pagination and sorting (extends CrudRepository ) Store-specific interfaces The individual store modules (e.g. for JPA or MongoDB) expose store-specific extensions of these base interfaces to allow access to store-specific functionality like flushing or dedicated batching that take some store specifics into account. An example for this is deleteInBatch(args) of JpaRepository which is different from delete(args) as it uses a query to delete the given entities which is more performant but comes with the side effect of not triggering the JPA-defined cascades (as the spec defines it). We generally recommend not to use these base interfaces as they expose the underlying persistence technology to the clients and thus tighten the coupling between them and the repository. Plus, you get a bit away from the original definition of a repository which is basically "a collection of entities". So if you can, stay with PagingAndSortingRepository . Custom repository base interfaces The downside of directly depending on one of the provided base interfaces is two-fold. Both of them might be considered as theoretical but I think they're important to be aware of: #li Depending on a a Spring Data repository interface couples your repository interface to the library. I don't think this is a particular issue as you'll probably use abstractions like Page or Pageable in your code anyway. Spring Data is not any different from any other general purpose library like commons-lang or Guava. As long as it provides reasonable benefit, it's just fine. #li By extending e.g. CrudRepository , you expose a complete set of persistence method at once. This is probably fine in most circumstances as well but you might run into situations where you'd like to gain more fine-grained control over the methods expose, e.g. to create a ReadOnlyRepository that doesn't include the save(args) and delete(args) methods of CrudRepository . The solution to both of these downsides is to craft your own base repository interface or even a set of them. In a lot of applications we've seen something like this: #pre The first repository interface is some general purpose base interface that actually only fixes point 1 but also ties the ID type to be Long for consistency. The second interface usually has all the find…(…) methods copied from CrudRepository and PagingAndSortingRepository but does not expose the manipulating ones. Read more on that approach in the reference documentation . Summary - tl;dr The repository abstraction allows you to pickt the base repository totally driven by you architectural and functional needs. Use the ones provided out of the box if they suit, craft your own repository base interfaces if necessary. Stay away from the store specific repository interfaces unless unavoidable.

Question-32164385, answer-32164423
#blockquote The only way is to read the code unfortunately. #blockquote The common convention is to pass an object which cannot be modified, using a wrapper if needed. This ensure the class cannot modify the object. List<T> readOnly = Collections.unmodifiableList(args); If the object is Cloneable, you can also use clone(args) but another common approach is to use a copy. List<T> readOnly = new ArrayList<T>(args); If you care about such behaviour, unit tests can show whether a method modifies an object or not. If you have unit tests already, it is usually one or two lines extra to check for this.

Question-5031614, answer-26826084
#li If you have a business key , then you should use that for equals / hashCode . #li If you don't have a business key, you should not leave it with the default Object equals and hashCode implementations because that does not work after you merge and entity. #li You can use the entity identifier as suggested in this post . The only catch is that you need to use a hashCode implementation that always return the same value, like this: #pre

Question-28818506, answer-32653133
This is looks like a good fit for pattern matching and a more traditional Option interface with Some and None implementations (such as those in Javaslang , FunctionalJava ) or a lazy Maybe implementation in cyclops-react .I'm the author of this library. With cyclops-react you can also use structural pattern matching on JDK types. For Optional you can match on the present and absent cases via the visitor pattern . it would look something like this - #pre

Question-31965179, answer-35427268
There's a long list of things that have been changed in Hibernate 5: #li New bootstrap API so we can bootstrap a JPA environment programmatically without the need of a persistence.xml file . #li Starting in 5.0 Hibernate Spatial is part of the Hibernate project so we can handle GIS data too. #li The Java 8 Date and Time types are supported in domain model mappings. The mapping between the standard SQL Date/Time types and the supported Java 8 Date/Time class types looks as follows; #li DATE: java.time.LocalDate #li TIME: java.time.LocalTime , java.time.OffsetTime #li TIMESTAMP: java.time.Instant , java.time.LocalDateTime , java.time.OffsetDateTime and java.time.ZonedDateTime #li The bytecode enhancement mechanism was redesigned from scratch, and Hibernate features both a Maven and a Gradle plugin. There are three main aspects which we can enhance with bytecode instrumentation: #li Lazy initialization: Fields can be declared as LAZY and they will be fetched only when being accessed for the first time. #li Dirty checking: Entities are enhanced so that they can keep track of all the properties that get changed after being loaded in a Persistence Context. #li Bidirectional associations: It's possible to synchronize both sides of a bidirectional association automatically, even if the developer only updates a single side. #li Hibernate's native APIs ( Session , etc) have been updated to use generic typed. No need to cast when fetching entities. #li Hibernate 5.0 expends this to a broader set of types (e.g. UUID ). #li Second-level cache by reference. This feature enables direct storage of entity references into the second level cache for immutable entities. #li Starting with Hibernate 5.0, we have a completely new User Guide that was written from scratch.

Question-24651403, answer-24651855
OK, first of all, your setExits(args) method will not work as intended, chained if-elseif will maximally execute 1 branch of code, for example: #pre Even if e contains both N and W , only bexits[0] will be set. Also this method will only add exits (for example calling setExits(args) will not delete any existing exits. I would change that method to: #pre Also, i definetly wouldn't remember that north is on index 0, west in on 1, ... so a common practice is to name your indexes using final static constants: #pre Then you can write in your setExits method: #pre (much more readible) Finally, if you want your code even more well-arranged, you can make a Exits class representing avaliable exits, and backed by boolean array. Then on place where you create your String, you could create this class instead and save yourself work with generating and then parsing a string. EDIT: as @gexicide answers, there is a really handy class EnumSet which would be probably better for representing the exits than bollean array.

Question-10827872
What's the difference between java.lang.String 's replace(args) and replaceAll(args) methods, other than later uses regex? For simple substitutions like, replace . with / , is there any difference?

Question-28770822, answer-28853754
TLDR : Jump to the conclusion #blockquote A brief history of @Native I made some search on the mailing lists. I found some interesting things. At first an annotation ( 1 2 ) javax.tools.annotation.ForceNativeHeader was introduced to #blockquote It is used by com.sun.tools.javac.processing.NativeapiVisitor . By looking at the code we can see that the native header is generated if the class declare some native methods or if the class is annotated @ForceNativeHeader . Later this annotation was renamed to GenerateNativeHeader ( 1 2 ). Then this annotation was added to several types (especially Integer and Long ) with an interresting comment: #pre But by adding this annotation it add a problematic dependency from base module to the module containing javax.tools. So the annotation were removed from Integer and Long and these files were explicitly added to the build process since the header were no more automatically generated... a "(hopefully temporary) hack" . So a new annotation java.lang.annotation.Native was created and used in Integer and Long . The annotation was set a TargetType FIELD . #blockquote All the purpose of this stuff is: #blockquote It is the case of Integer and Long this was a part of the JEP 139: Enhance javac to Improve Build Speed : #blockquote A basic experimentation I made a basic experimentation on the JDK. I clone the open-jdk forest and i successfully build it. As expected the header files where generated for Integer and Long (thanks to @Native ) and for Float and Double (thanks to their native methods) but not for Byte , Short ... #pre Then i tried to remove the @Native from the Integer fields and i tried to build again the jdk but i get an error: #pre logically since the header have not been generated. I have also confirmed that java_lang_Integer.h is included in several c and cpp files : #pre like Long #pre like Float #pre and like Double #pre but neither Short find . \( -name StringLiteral -o -name StringLiteral \) -exec grep StringLiteral {} \; -print nor Byte , nor Character . Conclusion Among all these types, only Integer , Long , Float , Double are used in the native source code of the jdk . And only the Integer and Long fields are annotated with @Native because they have no native methods (as opposed to Float and Double )

Question-14491966, answer-14492320
Your QuickRandom implementation hasn't really an uniform distribution. The frequencies are generally higher at the lower values while Math.random(args) has a more uniform distribution. Here's a SSCCE which shows that: #pre The average result looks like this: #pre If you repeat the test, you'll see that the QR distribution varies heavily, depending on the initial seeds, while the MR distribution is stable. Sometimes it reaches the desired uniform distribution, but more than often it doesn't. Here's one of the more extreme examples, it's even beyond the borders of the graph: #pre

Question-12552863, answer-12619799
I would say don't use ARM and go on with Closeable. Use method like, #pre Also you should consider calling close of BufferedWriter as it is not just delegating the close to FileWriter , but it does some cleanup like flushBuffer .

Question-29140402, answer-38628203
In intellij you can auto generate toString method by pressing alt+inset and then selecting toString() here is an out put for a test class: #pre As you can see, it generates a String by concatenating, several attributes of the class, for primitives it will print their values and for reference types it will use their class type (in this case to string method of Test2).

Question-13291076, answer-13291108
Use name(args) when you want to make a comparison or use the hardcoded value for some internal use in your code. Use toString(args) when you want to present information to a user (including a developper looking at a log). Never rely in your code on toString(args) giving a specific value. Never test it against a specific string. If your code breaks when someone correctly changes the toString(args) return, then it was already broken. From the javadoc (emphasis mine) : #blockquote

Question-28818506, answer-28833677
The cleanest “try services” approach given the current API would be: Optional<T> o = Stream.<Supplier<T>>of(args) .map(args) .filter(args) .map(args) .findFirst(args); The important aspect is not the (constant) chain of operations you have to write once but how easy it is to add another service (or modify the list of services is general). Here, adding or removing a single ()->serviceX(args) is enough. Due to the lazy evaluation of streams, no service will be invoked if a preceding service returned a non-empty Optional .

Question-22847105, answer-37354549
The way I think about it is that you use flatMap when the function you wanted to put inside of map(args) returns an Observable . In which case you might still try to use map(args) but it would be unpractical. Let me try to explain why. If in such case you decided to stick with map , you would get an Observable<T> . For example in your case, if we used an imaginary RxGson library, that returned an Observable<T> from it's toJson(args) method (instead of simply returning a String ) it would look like this: #pre At this point it would be pretty tricky to subscribe(args) to such an observable. Inside of it you would get an Observable<T> to which you would again need to subscribe(args) to get the value. Which is not practical or nice to look at. So to make it useful one idea is to "flatten" this observable of observables (you might start to see where the name _flat_Map comes from). RxJava provides a few ways to flatten observables and for sake of simplicity lets assume merge is what we want. Merge basically takes a bunch of observables and emits whenever any of them emits. (Lots of people would argue switch would be a better default. But if you're emitting just one value, it doesn't matter anyway.) So amending our previous snippet we would get: #pre This is a lot more useful, because subscribing to that (or mapping, or filtering, or...) you just get the String value. (Also, mind you, such variant of merge(args) does not exist in RxJava, but if you understand the idea of merge then I hope you also understand how that would work.) So basically because such merge(args) should probably only ever be useful when it succeeds a map(args) returning an observable and so you don't have to type this over and over again, flatMap(args) was created as a shorthand. It applies the mapping function just as a normal map(args) would, but later instead of emitting the returned values it also "flattens" (or merges) them. That's the general use case. It is most useful in a codebase that uses Rx allover the place and you've got many methods returning observables, which you want to chain with other methods returning observables. In your use case it happens to be useful as well, because map(args) can only transform one value emitted in onNext(args) into another value emitted in onNext(args) . But it cannot transform it into multiple values, no value at all or an error. And as akarnokd wrote in his answer (and mind you he's much smarter than me, probably in general, but at least when it comes to RxJava) you shouldn't throw exceptions from your map(args) . So instead you can use flatMap(args) and return Observable.just(args); when all goes well, but return Observable.error(args); when something fails. See his answer for a complete snippet: #a

Question-9510125, answer-9511880
validate(args) : In Swing when you create Component, it is not valid i.e. it's valid property is false . A component is said to be valid, when it's width, height, location and stuff has been determined. This is usually done by calling their validate(args) method, directly or indirectly. When we call validate(args) on containers, it will validate the container (if it is invalid) by calling its doLayout(args) method, which typically will invoke the LayoutManager . Now each child placed on this container will be validated recursively, so that the entire tree will be laid out and will become valid. revalidate(args) : revalidate(args) is to be called when you change an attribute that would affect their width/height and call repaint() when you change an attribute that would affect their appearance. For Example, If your JFrame contains a JPanel , now at certain point of time you removed that JPanel and inserted a new one in it's place, depending on the contents of the newly placed JPanel , the size of the components inside the JPanel as well as The CONTAINER itself (by virtue of the layout manager used by it), changes. Which pushes it to the invalidate state. So in order to validate this change, you have to explicitly call revalidate(args) . invalidate(args) : This thing is something, I had never used, so might be not much of the info I can give. But seems like the scenario presented above, can give a bit of hint, as to what happens in invalidate(args) .

Question-28818506
I've been working with the new Optional type in Java 8 , and I've come across what seems like a common operation that isn't supported functionally: an "orElseOptional" Consider the following pattern: #pre There are many forms of this pattern, but it boils down to wanting an "orElse" on an optional that takes a function producing a new optional, called only if the current one does not exist. It's implementation would look like this: #pre I'm curious if there's a reason such a method doesn't exist, if I'm just using Optional in an unintended way, and what other ways people have come up with to deal with this case. I should say that I think that solutions involving custom utility classes/methods aren't elegant because people working with my code won't necessarily know they exist. Also, if anyone knows, will such a method be included in JDK 9, and where might I propose such a method? This seems like a pretty glaring omission to the API to me.

Question-20358883
Is there a Utility method somewhere that can do this in 1 line? I can't find it anywhere in Collections , or List . #pre I don't want to re-invent the wheel unless I plan on putting fancy rims on it. Well... the type can be T , and not String . but you get the point. (with all the null checking, safety checks...etc)

Question-29140402
I have a class defined as follows: #pre I tried to print an instance of my class: System.out.println(args); but I got the following output: com.foo.Person@2f92e0f4 . A similar thing happened when I tried to print an array of Person objects: #pre I got the output: [Lcom.foo.Person;@28a418fc What does this output mean? How do I change this output so it contains the name of my person? And how do I print collections of my objects? Note : this is intended as a canonical Q&A about this subject.

Question-7935858, answer-7935881
The documentation on split() says: #blockquote (Emphasis mine.) A dot is a special character in regular expression syntax. Use Pattern.quote() on the parameter to split() if you want the split to be on a literal string pattern: String[] words = temp.split(args);
Question-26548660, answer-26548894
You can use a Callback to get onSuccess and onError events. Just add a new Callback to your request like so: Picasso.with(args) .load(args) .into(args); Then you can perform any alterations and modifications in the onSuccess callback.

Question-32820722, answer-32820940
An IntFunction<T> is a function int -> R . An IntUnaryOperator is a function int -> int . Thus an IntFunction<T> is a function that takes an int as parameter and return a function that takes an int as parameter and return an int . #pre Maybe it is more clear if you use anonymous classes to "decompose" the lambda: #pre

Question-32175145, answer-32177563
The other answers have already answered your question - no, this is not possible with the Java's primitive wrapper classes. I'll try to address the "question behind the question": Is this possible with other classes? #blockquote This is actually a good question, and the answer is: Yes, it is possible to create such a situation, and yes, it would make Aristotle angry. Actually, I don't know if it would make Aristotle angry, not having known him, but it will certainly cause a lot of grief for whoever has to work with the code. The thing is: There is a contract associated with Object.equals(args) : #blockquote Javadocs for Object.equals Yes, when creating your own class, you can violate this contract. There is (unfortunately) nothing in the compiler or runtime stopping you. However, a lot of code relies on this contract, so if you violate it, any code that uses equals will probably fail in mysterious ways. One example: Java's own Collection classes ( java.util.Collection and friends) rely on equals . If an instance of a class that does not correctly implement equals is put into a collection, weird things happen, such as the collection sometimes containing the instance and sometimes not.

Question-28818506, answer-28818627
Perhaps this is what you're after: Get value from one Optional or another Otherwise, you may want to have a look at Optional.orElseGet . Here's an example of what I think that you're after: result = Optional.ofNullable(args);

Question-11774099, answer-11774137
iterate through the whole 65k chars and ask Character.isJavaIdentifierStart(args) . The answer is : "undertie" decimal 8255

Question-34172978, answer-34173110
Flipping the limit and the filter clauses has different behaviors. If you put the limit first, the stream will first generate 10 integers [1..10], and then filter them leaving only those smaller than 5. In the original ordering, with the filter applied first, integers are generated and filtered until you reach 10 elements. This isn't an infinite operator, as i in the supplier will eventually overflow, but it will take a while, especially on a slow computer, to reach MAX_INT .

Question-26791441, answer-26791826
Search for the first word to be replaced. If it's in the string, recurse on the the part of the string before the occurrence, and on the part of the string after the occurrence. Otherwise, continue with the next word to be replaced. A naive implementation might look like this #pre Sample usage: #pre Output: Once upon a foo, there was a bar and a baz. A less-naive version: #pre Unfortunately, Java's String has no indexOf(args) method. I've omitted the implementation of indexOf here as I'm not certain it's correct, but it can be found on ideone , along with some rough timings of various solutions posted here.

Question-34172978
#pre Counter to my expectation, the collect call never returns. Setting limit before filter produces the expected result. Why?

Question-29333689, answer-29337734
My intuition in Python is to use the collections.Counter as a multiset: #pre So we have a list of integers from 0-99 twice except for 66. #pre Which gets the least common (last item) from a list sorted by frequency. Such a function would be: #pre And usage: #pre This is a generalized solution that works for any number of items.

Question-14833008, answer-14833098
"." is a special character in java. You have to use "\." to escape this character : final String extensionRemoved = filename.split(args)[0]; I hope this helps

Question-4871051, answer-4871135
Current working directory is defined differently in different Java implementations For certain prior to Java 7 there was no consistent way to get the working directory. You could work around this by launching Java with -D and defining a variable to hold the info Something like java -Dcom.mycompany.workingDir=StringLiteral That's not quite right, but you get the idea. Then System.getProperty(args) ...

Question-22718744, answer-22718904
This has been specified in the documentation of split(String regex, limit) . #blockquote In StringLiteral.split(args) you got a zero-width match at the beginning so the leading empty substring is not included in the resulting array. However in your second snippet when you split on StringLiteral you got a positive width match (1 in this case), so the empty leading substring is included as expected. (Removed irrelevant source code)

Question-4709175, answer-4709284
#blockquote You can use an Enum to represent a smallish fixed set of constants or an internal class mode while increasing readability. Also, Enums can enforce a certain rigidity when used in method parameters. They offer the interesting possibility of passing information to a constructor like in the Planets example on Oracle's site and, as you've discovered, also allow a simple way to create a singleton pattern. ex: Locale.setDefault(args) reads better than Locale.setDefault(args) and enforces the use of fixed set of values shown in an IDE when you add the . separator instead of all integers.

Question-29280857, answer-29282558
As you have mentioned there will be 1000-10000 concurrent transaction you expecting at a time than you can store accounts on which some transaction is going on and handle concurrency One Solution is to allow system to create only one object of particulate account id, means that if you want to make a transaction between account "123" and "456" than your thread will create account object and in that constructor of account class we will check if any other object of account is there with particulate account id, if other object of account is there with same account id means that some transaction is going on with particulate account id so you have to wait to get the account object. So we can do transaction between "123" and "456" and at same time we can do transaction between "abc" and "xyz" but if at same time some other thread will try to create object of account "123" than system will say please wait for reference you can see below code Please note : #li dont forgote to remove your account id from locks map by call to freeAccount(BigDecimal accId) from LockHolder class #li I have used HasMap instand of list because list will not be a good choice when you are randomly removing element from it(or when frequently you are updating it) #pre

Question-28319064, answer-29000802
There is a third option - using stream(args).toArray(args) - see comments under why didn't stream have a toList method . It turns out to be slower than forEach() or collect(), and less expressive. It might be optimised in later JDK builds, so adding it here just in case. assuming List<T> myFinalList = Arrays.asList(args); with a micro-micro benchmark, 1M entries, 20% nulls and simple transform in doSomething() #pre the results are parallel: #pre sequential: #pre parallel without nulls and filter (so the stream is SIZED ): toArrays has the best performance in such case, and .forEach(args) fails with "indexOutOfBounds" on the recepient ArrayList, had to replace with .forEachOrdered(args) #pre

Question-17489250, answer-17489334
Text inside double quotes creates a literal String object. String myString = StringLiteral; The code above creates a String object, using double quotes.

Question-8881291, answer-14060804
#li Strings are immutable in Java if you store password as plain text it will be available in memory until Garbage collector clears it and since Strings are used in String pool for re-usability there is pretty high chance that it will be remain in memory for long duration, which pose a security threat. Since any one who has access to memory dump can find the password in clear text #li Java recommendation using getPassword(args) method of JPasswordField which returns a char[] and deprecated getText(args) method which returns password in clear text stating security reason. #li toString() there is always a risk of printing plain text in log file or console but if use Array you won't print contents of array instead its memory location get printed. #pre #blockquote Final thoughts: Though using char[] is not just enough you need to erase content to be more secure. I also suggest working with hash'd or encrypted password instead of plaintext and clearing it from memory as soon as authentication is completed.

Question-5769669, answer-5769679
You can use Double.parseDouble() to convert a String to a double : #pre For your case it looks like you want: #pre

Question-8725387, answer-8725550
Think of it like this: the List interface has methods like add(args) , set(args) . The contract is that once you added an element at position X you will find it there unless you add or remove elements before it. If any list implementation would store elements in some order other than based on the index, the above list methods would make no sense.

Question-23114015
I am wondering why the Iterable interface does not provide the stream(args) and parallelStream(args) methods. Consider the following class: #pre It is an implementation of a Hand as you can have cards in your hand while playing a Trading Card Game. Essentially it wraps a List<T> , ensures a maximum capacity and offers some other useful features. It is better as implementing it directly as a List<T> . Now, for convienience I thought it would be nice to implement Iterable<T> , such that you can use enhanced for-loops if you want to loop over it. (My Hand class also provides a get(args) method, hence the Iterable<T> is justified in my opinion.) The Iterable interface provides the following (left out javadoc): #pre Now can you obtain a stream with: Stream<T> stream = StreamSupport.stream(args); So onto the real question: #li Why does Iterable<T> not provide a default methods that implement stream(args) and parallelStream(args) , I see nothing that would make this impossible or unwanted? A related question I found is the following though: Why does Stream<T> not implement Iterable<T>? Which is oddly enough suggesting it to do it somewhat the other way around.

Question-12146298
I would like to know what is the cleanest and best way to perform form validation of user inputs. I have seen some developers implement org.springframework.validation.Validator . A question about that: I saw it validates a class. Does the class have to be filled manually with the values from the user input, and then passed to the validator? I am confused about the cleanest and best way to validate the user input. I know about the traditional method of using request.getParameter(args) and then manually checking for nulls , but I don't want to do all the validation in my Controller . Some good advice on this area will be greatly appreciated. I am not using Hibernate in this application.

Question-19757300, answer-35512247
Keeping this issue in mind I developed a small library for dealing with checked exceptions and lambdas. Custom adapters allow you to integrate with existing functional types: stream(args).map(args) //with a static import #a
Question-6094575, answer-6094602
Yes, something like: #pre That will only work for a single string parameter of course, but you can modify it pretty easily. Note that the class name has to be a fully-qualified one, i.e. including the namespace. For nested classes, you need to use a dollar (as that's what the compiler uses). For example: #pre To obtain the Class object for that, you'd need Class.forName(args) .

Question-17828584, answer-17842210
After digging around for a while, I can't say that I find the answer, but I think it's quite close now. First, we need to know when a StackOverflowError will be thrown. In fact, the stack for a java thread stores frames, which containing all the data needed for invoking a method and resume. According to Java Language Specifications for JAVA 6 , when invoking a method, #blockquote Second, we should make it clear what is " there is not sufficient memory available to create such an activation frame ". According to Java Virtual Machine Specifications for JAVA 6 , #blockquote So, when a frame is created, there should be enough heap space to create a stack frame and enough stack space to store the new reference which point to the new stack frame if the frame is heap allocated. Now let's go back to the question. From the above, we can know that when a method is execute, it may just costs the same amount of stack space. And invoking System.out.println (may) needs 5 level of method invocation, so 5 frames need to be created. Then when StackOverflowError is thrown out, it has to go back 5 times to get enough stack space to store 5 frames' references. Hence 4 is print out. Why not 5? Because you use cnt++ . Change it to ++cnt , and then you will get 5. And you will notice that when the size of stack go to a high level, you will get 50 sometimes. That is because the amount of available heap space need to be taken into consideration then. When the stack's size is too large, maybe heap space will run out before stack. And (maybe) the actual size of stack frames of System.out.println is about 51 times of main , therefore it goes back 51 times and print 50.

Question-27949213, answer-27949581
Imagine you have a phone book, which contains people, which have a String firstName and a String lastName . And it happens that in your phone book, 100,000 people have the same firstName = StringLiteral . Because you get the data from a database or a file those strings are not interned so your JVM memory contains the char array {CharLiteral, CharLiteral, CharLiteral, CharLiteral} 100 thousand times, one per John string. Each of these arrays takes, say, 20 bytes of memory so those 100k Johns take up 2 MB of memory. With deduplication, the JVM will realise that "John" is duplicated many times and make all those John strings point to the same underlying char array, decreasing the memory usage from 2MB to 20 bytes. You can find a more detailed explanation in the JEP . In particular: #blockquote

Question-8098953, answer-8103083
The first thing to keep in mind is that Java ternary operators have a "type", and that this is what the compiler will determine and consider no matter what the actual/real types of the second or third parameter are. Depending on several factors the ternary operator type is determined in different ways as illustrated in the Java Language Specification 15.26 In the question above we should consider the last case: #blockquote This is by far the most complex case once you take a look at applying capture conversion (§5.1.10) and most of all at lub(T1, T2) . In plain English and after an extreme simplification we can describe the process as calculating the "Least Common Superclass" (yes, think of the LCM) of the second and third parameters. This will give us the ternary operator "type". Again, what I just said is an extreme simplification (consider classes that implement multiple common interfaces). For example, if you try the following: #pre You'll notice that resulting type of the conditional expression is java.util.Date since it's the "Least Common Superclass" for the Timestamp / Time pair. Since null can be autoboxed to anything, the "Least Common Superclass" is the Integer class and this will be the return type of the conditional expression (ternary operator) above. The return value will then be a null pointer of type Integer and that is what will be returned by the ternary operator. At runtime, when the Java Virtual Machine unboxes the Integer a NullPointerException is thrown. This happens because the JVM attempts to invoke the function null.intValue(args) , where null is the result of autoboxing. In my opinion (and since my opinion is not in the Java Language Specification many people will find it wrong anyway) the compiler does a poor job in evaluating the expression in your question. Given that you wrote true ? param1 : param2 the compiler should determine right away that the first parameter - null - will be returned and it should generate a compiler error. This is somewhat similar to when you write while(args){} etc... and the compiler complains about the code underneath the loop and flags it with Unreachable Statements . Your second case is pretty straightforward and this answer is already too long... ;) CORRECTION: After another analysis I believe that I was wrong to say that a null value can be boxed/autoboxed to anything. Talking about the class Integer, explicit boxing consists in invoking the new Integer(args) constructor or maybe the Integer.valueOf(args); (I found this version somewhere). The former would throw a NumberFormatException (and this does not happen) while the second would just not make sense since an int cannot be null ...

Question-31188231, answer-31190722
We can draw a parallel with abstract class. An abstract class is intended to be subclassed so that the abstract methods can be implemented. The abstract class itself contains concrete methods that invoke the abstract methods. The abstract class is free to evolve by adding more concrete methods; and this practice may break subclasses. Therefore the exact problem you described existed even before Java8. The problem is much more manifested on Collection APIs because there are a lot of subclasses out in the wild. While the leading motivation of default method was to add some useful methods to existing Collection APIs without breaking subclasses, they had to exercise great self-control of doing it too much, for fear of breaking subclasses. A default method is added only if it's absolutely necessary. The real question here is, why List.sort is considered absolutely necessary. I think that is debatable. Regardless of why default method was introduced in the 1st place, it is now a great tool for API designers, and we ought to treat it the same as concrete methods in abstract classes - they need to be designed carefully up front; and new ones must be introduced with great caution.

Question-8725387, answer-8725453
Since all lists are already "sorted" by the order the items were added (FIFO ordering), you can "resort" them with another ordering, including the natural ordering of elements, using java.util.Collections.sort(args) . EDIT: Lists as data structures are based in what is interesting is the ordering in which the items where inserted. Sets do not have that information. If you want to order by addition time, use List . If you want to order by other criteria, use SortedSet .

Question-30081520
I am aware that it is better to call the equals method over using the == operator (see this question ). I want two strings to compare as equal if they are both null or if they represent the same string. Unfortunately the equals method will throw an NPE if the strings are null . My code is currently: #pre This is inelegant. What is the correct way to perform this test?

Question-12317668
According to the JLS, an int array should be filled by zeros just after initialization. However, I am faced with a situation where it is not. Such a behavior occurs first in JDK 7u4 and also occurs in all later updates (I use 64-bit implementation). The following code throws exception: #pre The exception occurs after the JVM performs compilation of the code block and does not arise with -Xint flag. Additionally, the Arrays.fill(args) statement (as all other statements in this code) is necessary, and the exception does not occurs if it is absent. It is clear that this possible bug is bounded with some JVM optimization. Any ideas for the reason of such a behavior? Update: I see this behavior on HotSpot 64-bit server VM, Java version from 1.7.0_04 to 1.7.0_10 on Gentoo Linux, Debian Linux (both kernel 3.0 version) and MacOS Lion. This error can always be reproduced with the code above. I did not test this problem with a 32-bit JDK or on Windows. I already sent a bug report to the Oracle (bug id 7196857) and it will appear in public Oracle bug database in few days. Update: Oracle published this bug at their public bug database: #a

Question-29922296, answer-29922831
Three questions: three-part answer: Is it okay from a design point of view? Absolutely. Nothing wrong with it. If you need to do lots of iterating over your enum, the stream API is the clean way to go and hiding the boiler plate behind a little method is fine. Although I’d consider OldCumudgeon ’s version even better. Is it okay from a performance point of view? It most likely doesn’t matter. Most of the time, enums are not that big. Therefore, whatever overhead there is for one method or the other probably doesn’t matter in 99.9% of the cases. Of course, there are the 0.1% where it does. In that case: measure properly, with your real-world data and consumers. If I had to bet, I’d expect the for each loop to be faster, since it maps more directly to the memory model, but don’t guess when talking performance, and don’t tune before there is actual need for tuning. Write your code in a way that is correct first, easy to read second and only then worry about performance of code style. Why aren’t Enums properly integrated into the Stream API? If you compare Java’s Stream API to the equivalent in many other languages, it appears seriously limited. There are various pieces that are missing (reusable Streams and Optionals as Streams, for example). On the other hand, implementing the Stream API was certainly a huge change for the API. It was postponed multiple times for a reason. So I guess Oracle wanted to limit the changes to the most important use cases. Enums aren’t used that much anyway. Sure, every project has a couple of them, but they’re nothing compared to the number of Lists and other Collections. Even when you have an Enum, in many cases you won’t ever iterate over it. Lists and Sets, on the other hand, are probably iterated over almost every time. I assume that these were the reasons why the Enums didn’t get their own adapter to the Stream world. We’ll see whether more of this gets added in future versions. And until then you always can use Arrays.stream .

Question-28724850
Running the following stream example in Java8: System.out.println(args); yields: /a/b/c/d/e/f Which is - of course - no surprise. Due to #a it shouldn't matter whether the stream is executed sequentially or parallel: #blockquote AFAIK reduce(args) is deterministic and (s1, s2) -> s1 + StringLiteral + s2 is associative, so that adding parallel(args) should yield the same result: System.out.println(args); However the result on my machine is: /a//b//c//d//e//f What's wrong here? BTW: using (the preferred) .collect(args) instead of reduce(args) yields the same result a/b/c/d/e/f for sequential and parallel execution. JVM details: #pre

Question-22694884, answer-39385411
As Collectors.toMap(args) uses a throwing merger to handle multiple entries with the same key it is easy: #pre You will get a IllegalStateException for duplicate keys. But at the end I am not sure if the code would not be even more readable using an if .

Question-8881291
In Swing, the password field has a getPassword(args) (returns char[] ) method instead of the usual getText(args) (returns String ) method. Similarly, I have come across a suggestion not to use String to handle passwords. Why does String pose a threat to security when it comes to passwords? It feels inconvenient to use char[] .

Question-4772425, answer-4772461
Use LocalDateTime#parse() (or ZonedDateTime#parse() if the string happens to contain a time zone part) to parse a String in a certain pattern into a LocalDateTime . #pre Use LocalDateTime#format() (or ZonedDateTime#format() ) to format a LocalDateTime into a String in a certain pattern. #pre Or , when you're not on Java 8 yet, use SimpleDateFormat#parse() to parse a String in a certain pattern into a Date . #pre Use SimpleDateFormat#format() to format a Date into a String in a certain pattern. #pre See also: #li Java string to date conversion Update : as per your failed attempt: the patterns are case sensitive . Read the java.text.SimpleDateFormat javadoc what the individual parts stands for. So stands for example M for months and m for minutes. Also, years exist of four digits yyyy , not five yyyyy . Look closer at the code snippets I posted here above.

Question-8275499, answer-8275508
Just use TheClassName.class instead of getClass(args) .

Question-34509566, answer-34509655
As you said internally the last concatenation is done to something similar to String e = new StringBuilder(args).append(args).append(args).toString(args); the implementation of toString(args) of StringBuilder creates a new String . Here is the implementation. #pre Comparing strings using == instead of .equals(args) returns true only if both strings are the same . In this case they are not the same because the second string is created as a new object of type String . The other concatenations are performed directly by the compiler so no new String is created.

Question-18448671, answer-26937769
Though one answer is accepted and this is an old one, I thought posting this answer as it does not use Iterator #pre

Question-32714194, answer-32714222
+ is implemented in java compilers . The compiler replaces String + String with either compile time constants or StringBuilder code. Note that this applies to primitives too. i.e, int i=1+2 could get directly replaced to int i=3 during compilation itself.

Question-31419029, answer-31419077
If you look at the implementation of HashMap , the constructor looks like: #pre And init(args) looks like: #pre So initialCapacity doesn't actually get used to create an array. Where does it get used? Look at the put(args) method. #pre When doing a put, the array is actually created. I didn't show inflateTable(args) but it does some math and initializes the array.

Question-15156857, answer-15157021
You must use doThrow(args).when(args).methodReturningVoid(args); and not doThrow(args).when(args); This is explained in the documentation

Question-15621083
I am working on some Java code which needs to be highly optimized as it will run in hot functions that are invoked at many points in my main program logic. Part of this code involves multiplying double variables by 10 raised to arbitrary non-negative int exponent s. One fast way (edit: but not the fastest possible, see Update 2 below) to get the multiplied value is to switch on the exponent : #pre The commented ellipses above indicate that the case int constants continue incrementing by 1, so there are really 19 case s in the above code snippet. Since I wasn't sure whether I would actually need all the powers of 10 in case statements 10 thru 18 , I ran some microbenchmarks comparing the time to complete 10 million operations with this switch statement versus a switch with only case s 0 thru 9 (with the exponent limited to 9 or less to avoid breaking the pared-down switch ). I got the rather surprising (to me, at least!) result that the longer switch with more case statements actually ran faster. On a lark, I tried adding even more case s which just returned dummy values, and found that I could get the switch to run even faster with around 22-27 declared case s (even though those dummy cases are never actually hit while the code is running). (Again, case s were added in a contiguous fashion by incrementing the prior case constant by 1 .) These execution time differences are not very significant: for a random exponent between 0 and 10 , the dummy padded switch statement finishes 10 million executions in 1.49 secs versus 1.54 secs for the unpadded version, for a grand total savings of 5ns per execution. So, not the kind of thing that makes obsessing over padding out a switch statement worth the effort from an optimization standpoint. But I still just find it curious and counter-intuitive that a switch doesn't become slower (or perhaps at best maintain constant O(1) time) to execute as more case s are added to it. #img These are the results I obtained from running with various limits on the randomly-generated exponent values. I didn't include the results all the way down to 1 for the exponent limit, but the general shape of the curve remains the same, with a ridge around the 12-17 case mark, and a valley between 18-28. All tests were run in JUnitBenchmarks using shared containers for the random values to ensure identical testing inputs. I also ran the tests both in order from longest switch statement to shortest, and vice-versa, to try and eliminate the possibility of ordering-related test problems. I've put my testing code up on a github repo if anyone wants to try to reproduce these results. So, what's going on here? Some vagaries of my architecture or micro-benchmark construction? Or is the Java switch really a little faster to execute in the 18 to 28 case range than it is from 11 up to 17 ? github test repo "switch-experiment" UPDATE: I cleaned up the benchmarking library quite a bit and added a text file in /results with some output across a wider range of possible exponent values. I also added an option in the testing code not to throw an Exception from default , but this doesn't appear to affect the results. UPDATE 2: Found some pretty good discussion of this issue from back in 2009 on the xkcd forum here: #a . The OP's discussion of using Array.binarySearch(args) gave me the idea for a simple array-based implementation of the exponentiation pattern above. There's no need for the binary search since I know what the entries in the array are. It appears to run about 3 times faster than using switch , obviously at the expense of some of the control flow that switch affords. That code has been added to the github repo also.

Question-6652687
#blockquote Is there a convenience method to strip any leading or trailing spaces from a Java String? Something like: #pre Result: no spaces:keep this myString.replace(args) would replace the space between keep and this. Thanks

Question-29183904, answer-29972028
Use enum when you need its features. Don't avoid it strictly . Java enum is more powerful, but if you don't need its features, use constants, they occupy less space and they can be primitive itself. When to use enum: #li type checking - you can accept only listed values, and they are not continuous (see below what I call continuous here) #li method overloading - every enum constant has its own implementation of a method #pre #li more data - your one constant contains more than one information that cannot be put in one variable #li complicated data - your constant need methods to operate on the data When not to use enum: #li you can accept all values of one type, and your constants contain only these most used #li you can accept continuous data #pre #li for names (like in your example) #li for everything other that really doesn't need an enum Enum occupies more space #li a single reference to an enum constant occupy 4 bytes #li every enum constant occupy space that is a sum of its fields' sizes aligned to 8 bytes + overhead of the object #li the enum class itself occupy some space Constant occupies less space #li a constant doesn't have a reference so it's a pure data (even if it's a reference, then enum instance would be a reference to another reference) #li constants may be added to existing class - it's not necessary to add another class #li constants may be inlined; it brings extended compile-time features (such as null checking, finding dead code etc.)

Question-18723596, answer-18723704
You can cast null to any reference type. You can also call methods which handle a null as an argument, e.g. System.out.println(args) does, but you cannot reference a null value and call a method on it. BTW There is a tricky situation where it appears you can call static methods on null values. #pre

Question-27482579, answer-27483288
#blockquote No . It will never throw a compilation error. This is much similar to what a simple getter and setter does or a copy constructor does. Remember we can access private members using this. #pre Your testPrivate method accepts an instance of MyClass. Since testPrivate is a method inside MyClass , it will have access to private properties. #pre Methods defined inside the class will always have access to it's private members, through this. and instance variable. But if you define testPrivate outside of MyClass then, you won't have access to private members. There you will have to use a method or a setter or a getter.

Question-20363719, answer-25453317
If your key is NOT guaranteed to be unique for all elements in the list, you should convert it to a Map<String, List<T> instead of a Map<T> Map<T> result = choices.stream(args).collect(args);

Question-28276423, answer-28276493
You can close the outer most stream, in fact you don't need to retain all the streams wrapped and you can use Java 7 try-with-resources. #pre If you subscribe to YAGNI, or you-aint-gonna-need-it, you should be only adding code you actually need. You shouldn't be adding code you imagine you might need but in reality doesn't do anything useful. Take this example and imagine what could possibly go wrong if you didn't do this and what the impact would be? #pre Lets start with FileOutputStream which calls open to do all the real work. /** * Opens a file, with the specified name, for overwriting or appending. * @param name name of file to be opened * @param append whether the file is to be opened in append mode */ private native void open(args) throws FileNotFoundException; If the file is not found, there is no underlying resource to close, so closing it won't make any difference. If The file exists, it should be throwing a FileNotFoundException. So there is nothing to be gained by trying to close the resource from this line alone. The reason you need to close the file is when the file is opened successfully, but you later get an error. Lets look at the next stream GZIPOutputStream There is code which can throw an exception #pre This writes the header of the file. Now it would be very unusual for you to be able to open a file for writing but not be able to write even 8 bytes to it, but lets imagine this could happen and we don't close the file afterwards. What does happen to a file if it is not closed? You don't get any unflushed writes, they are discarded and in this case, there is no successfully written bytes to the stream which isn't buffered at this point anyway. But a file which is not closed doesn't live forever, instead FileOutputStream has #pre If you don't close a file at all, it gets closed anyway, just not immediately (and like I said, data which is left in a buffer will be lost this way, but there is none at this point) What is the consequence of not closing the file immediately? Under normal conditions, you potentially lose some data, and you potentially run out of file descriptors. But if you have a system where you can create files but you can't write anything to them, you have a bigger problem. i.e. it hard to imagine why you are repeatedly trying to create this file despite the fact you are failing. Both OutputStreamWriter and BufferedWriter don't throw IOException in their constructors, so it not clear what problem they would cause. In The case of BufferedWriter, you could get an OutOfMemoryError. In this case it will immediately trigger a GC, which as we have seen will close the file anyway.

Question-5031614, answer-5103360
We usually have two IDs in our entities: #li Is for persistence layer only (so that persistence provider and database can figure out relationships between objects). #li Is for our application needs ( equals(args) and hashCode(args) in particular) Take a look: #pre EDIT: to clarify my point regarding calls to setUuid(args) method. Here's a typical scenario: #pre When I run my tests and see the log output I fix the problem: #pre Alternatively, one can provide a separate constructor: #pre So my example would look like this: #pre I use a default constructor and a setter, but you may find two-constructors approach more suitable for you.

Question-32693704, answer-32852619
Because it's much faster! I ran some thorough benchmarking tests on cut down versions of the two methods: #pre operating on arrays of various sizes containing random values. Here are the (typical) results: #pre And here are the results when operating over an array filled with nulls (so garbage collection issues are eradicated): #pre The numbers are in nanoseconds, (sd) is 1 standard deviation expressed as a percentage of the result (fyi, a "normally distributed" population has an SD of 68), vs is the JDK 8 timing relative to JDK 7. It is interesting that not only is it significantly faster, but the deviation is also slightly narrower, which means that the JDK 8 implementation gives slightly more consistent performance. The tests were run on jdk 1.8.0_45 over a large (millions) number of times on arrays populated with random Integer objects. To remove out-lying numbers, on each set of results the fastest and slowest 3% of timings were discarded. Garbage collection was requested and the thread yielded and slept just prior to running each invocation of the method. JVM warm up was done on the first 20% of work and those results were discarded.

Question-16324831
Why do Double.parseDouble(null) and Integer.parseInt(null) throw different exceptions? Is this a historical accident or intentional? The documentation clearly states two types of exceptions for Double.parseDouble(...) and one for Integer.parseInt() , but it seems inconsistent: Integer.parseInt(args); // throws java.lang.NumberFormatException: null However Double.parseDouble(args); // throws java.lang.NullPointerException

Question-12539365, answer-12562433
This is great question! I think the root cause of it is the following, we are using JUnit not only for unit testing. So the question should be splited up: #li Should I use Mockito.verify() in my integration (or any other higher-than-unit testing) testing? #li Should I use Mockito.verify() in my black-box unit-testing? #li Should I use Mockito.verify() in my white-box unit-testing? so if we will ignore higher-than-unit testing, the question can be rephrased " Using white-box unit-testing with Mockito.verify() creates great couple between unit test and my could implementation, can I make some "grey-box" unit-testing and what rules of thumb I should use for this ". Now, let's go through all of this step-by-step. *- Should I use Mockito.verify() in my integration (or any other higher-than-unit testing) testing?* I think the answer is clearly no, moreover you shouldn't use mocks for this. Your test should be as close to real application as possible. You are testing complete use case, not isolated part of the application. * black-box vs white-box unit-testing black-box state If you are using white-box approach what is you really doing, you're testing the behaviour of your unit. In this approach calling to Mockito.verify() is essential, you should verify that your unit behaves as you're expecting to. rules of thumbs for grey-box-testing The problem with white-box testing is it creates a high coupling. One possible solution is to do grey-box-testing, not white-box-testing. This is sort of combination of black&white box testing. You are really testing the behaviour of your unit like in white-box testing, but in general you make it implementation-agnostic when possible . When it is possible, you will just make a check like in black-box case, just asserts that output is what is your expected to be. So, the essence of your question is when it is possible. This is really hard. I don't have a good example, but I can give you to examples. In the case that was mentioned above with equals() vs equalsIgnoreCase() you shouldn't call Mockito.verify(), just assert the output. If you couldn't do it, break down your code to the smaller unit, until you can do it. On the other hand, suppose you have some @Service and you are writting @Web-Service that is essentially wrapper upon your @Service - it delegates all calls to the @Service (and making some extra error handling). In this case calling to Mockito.verify() is essential, you shouldn't duplicate all of your checks that you did for the @Serive, verifying that you're calling to @Service with correct parammeter list is sufficient.

Question-23756966
While investigating for a little debate w.r.t. using StringLiteral + n and Integer.toString(int) to convert an integer primitive to a string I wrote this JMH microbenchmark: #pre I ran it with the default JMH options with both Java VMs that exist on my Linux machine (up-to-date Mageia 4 64-bit, Intel i7-3770 CPU, 32GB RAM). The first JVM was the one supplied with Oracle JDK 8u5 64-bit: #pre With this JVM I got pretty much what I expected: #pre I.e. using the StringBuilder class is slower due to the additional overhead of creating the StringBuilder object and appending an empty string. Using String.format(args) is even slower, by an order of magnitude or so. The distribution-provided compiler, on the other hand, is based on OpenJDK 1.7: #pre The results here were interesting : #pre Why does StringBuilder.append(args) appear so much faster with this JVM? Looking at the StringBuilder class source code revealed nothing particularly interesting - the method in question is almost identical to Integer#toString(args) . Interestingly enough, appending the result of Integer.toString(args) (the stringBuilder2 microbenchmark) does not appear to be faster. Is this performance discrepancy an issue with the testing harness? Or does my OpenJDK JVM contain optimizations that would affect this particular code (anti)-pattern? EDIT: For a more straight-forward comparison, I installed Oracle JDK 1.7u55: #pre The results are similar to those of OpenJDK: #pre It seems that this is a more general Java 7 vs Java 8 issue. Perhaps Java 7 had more aggressive string optimizations? EDIT 2 : For completeness, here are the string-related VM options for both of these JVMs: For Oracle JDK 8u5: #pre For OpenJDK 1.7: #pre The UseStringCache option was removed in Java 8 with no replacement, so I doubt that makes any difference. The rest of the options appear to have the same settings. EDIT 3: A side-by-side comparison of the source code of the AbstractStringBuilder , StringBuilder and Integer classes from the src.zip file of reveals nothing noteworty. Apart from a whole lot of cosmetic and documentation changes, Integer now has some support for unsigned integers and StringBuilder has been slightly refactored to share more code with StringBuffer . None of these changes seem to affect the code paths used by StringBuilder#append(args) , although I may have missed something. A comparison of the assembly code generated for IntStr#integerToString(args) and IntStr#stringBuilder0(args) is far more interesting. The basic layout of the code generated for IntStr#integerToString(args) was similar for both JVMs, although Oracle JDK 8u5 seemed to be more aggressive w.r.t. inlining some calls within the Integer#toString(args) code. There was a clear correspondence with the Java source code, even for someone with minimal assembly experience. The assembly code for IntStr#stringBuilder0(args) , however, was radically different. The code generated by Oracle JDK 8u5 was once again directly related to the Java source code - I could easily recognise the same layout. On the contrary, the code generated by OpenJDK 7 was almost unrecognisable to the untrained eye (like mine). The new StringBuilder(args) call was seemingly removed, as was the creation of the array in the StringBuilder constructor. Additionaly, the disassembler plugin was not able to provide as many references to the source code as it did in JDK 8. I assume that this is either the result of a much more aggressive optimization pass in OpenJDK 7, or more probably the result of inserting hand-written low-level code for certain StringBuilder operations. I am unsure why this optimization does not happen in my JVM 8 implementation or why the same optimizations were not implemented for Integer#toString(args) in JVM 7. I guess someone familiar with the related parts of the JRE source code would have to answer these questions...

Question-16232833
I'm using Spring MVC for a simple JSON API, with @ResponseBody based approach like the following. (I already have a service layer producing JSON directly.) #pre Question is, in the given scenario, what is the simplest, cleanest way to respond with a HTTP 400 error ? I did come across approaches like: return new ResponseEntity(args); ...but I can't use it here since my method's return type is String, not ResponseEntity.

Question-15655012, answer-15656208
This is favorite interview question . Interviewer tries to find out here, how much you understand about behavior of objects with respect to constructors, methods, class variables(static variables), instance variables. #pre In above case we have defined Test constructor and setFoo method. About constructor: Constructor can be invoked only one time per object creation by using new keyword. Programmer cannot invoke constructor many times because constructor are designed so. About method: Method can be invoked as many time as programmer wants and compiler knows it programmer may invoke method zero or multiple time. Scenario 1 private final List foo; // 1 foo is an instance variable. When we create Test class' object then instance variable foo will be copied inside object of Test class. If we assign foo inside constructor then compiler know that Constructor will be invoked only one time. so there is no problem to assign it inside constructor. If we assign foo inside method then compiler knows that method may be invoked multiple time. So value will have to be changed multiple time which is not allowed for final variable. You can assign value to the final variable only one time. So compiler decides constructor is good choice! Scenario 2 private static final List foo = new ArrayList(args); foo is now static variable. When we create object of Test class then foo will not be copied to the object of Test class because foo is static. Now foo is not the property of each object. This is the property of Test class. But foo can be seen by many objects and if every object which is created by using new keyword which ultimately invoke Test constructor then value will be changed at the time of multiple object creation (Remember static foo is not copied in every object now but is shared between multiple objects.) Scenario 3 t.foo.add(args); // Modification-2 Above Modification-2 is from your question. In above case you are not changing first referenced object but you are adding contents inside foo which is allowed. Compiler complains if you try to assign new ArrayList(args) object to the foo reference variable. Rule is that if you have initialized object to final reference variable then you cannot change it to refer different ArrayList object. (in this case ArrayList) final class cannot be subclassed final methods cannot be overridden. (This method is in superclass) final methods can override. (Read this in grammatical way. This method is in subclass)

Question-15430247, answer-15446006
I actually wrote a blog post on the topic 2 months ago. The article is for C#'s List<T> but Java's ArrayList has a very similar implementation. Since ArrayList is implemented using a dynamic array, it increases in size on demand. So the reason for the capacity constructor is for optimisation purposes. When one of these resizings operation occurs, the ArrayList copies the contents of the array into a new array that is twice the capacity of the old one. This operation runs in O(n) time. Example Here is an example of how the ArrayList would increase in size: #pre So the list starts with a capacity of 10 , when the 11th item is added it is increase by 50% + 1 to 16 . On the 17th item the ArrayList is increased again to 25 and so on. Now consider the example where we're creating a list where the desired capacity is already known as 1000000 . Creating the ArrayList without the size constructor will call ArrayList.add 1000000 times which takes O(1) normally or O(n) on resize. #blockquote Compare this using the constructor and then calling ArrayList.add which is guaranteed to run in O(1) . #blockquote Java vs C# Java is as above, starting at 10 and increasing each resize at 50% + 1 . C# starts at 4 and increases much more aggressively, doubling at each resize. The 1000000 adds example from above for C# uses 3097084 operations. References #li My blog post on C#'s List<T> #li Java's ArrayList source code

Question-6684665, answer-12685471
The kind of output you are seeing from your byte array ( [B@405217f8 ) is also an output for a zero length byte array (ie new byte[0] ). It looks like this string is a reference to the array rather than a description of the contents of the array like we might expect from a regular collection's toString(args) method. As with other respondents, I would point you to the String constructors that accept a byte[] parameter to construct a string from the contents of a byte array. You should be able to read raw bytes from a socket's InputStream if you want to obtain bytes from a TCP connection. If you have already read those bytes as a String (using an InputStreamReader ), then, the string can be converted to bytes using the getBytes(args) function. Be sure to pass in your desired character set to both the String constructor and getBytes(args) functions, and this will only work if the byte data can be converted to characters by the InputStreamReader . If you want to deal with raw bytes you should really avoid using this stream reader layer.

Question-29333689
The following is taken from a job interview: #blockquote I thought about using an HashSet, but it might complicate everything... Any ideas of a simple solution?

Question-6667243, answer-6667307
mode1.name(args) or String.valueOf(args) . It doesn't get better than that, I'm afraid

Question-7488643, answer-7488683
You can first split them using String.split(args) , and then convert the returned String array to an ArrayList using Arrays.asList(args)

Question-8725387, answer-34405789
Set and Map are non-linear data structure. List is linear data structure. The tree data structure SortedSet and SortedMap interfaces implements TreeSet and TreeMap respectively using used Red-Black tree implementation algorithm. So it ensure that there are no duplicated items (or keys in case of Map ). #li Tree by definition cannot contain duplicates. #li In List we can have duplicates, so there is no TreeList . So if we want to sort the list we have to use java.util.Collections.sort(args) .

Question-7348711, answer-7353205
InetAddress.getLocalHost(args).getHostName(args) is the more portable way. exec(args) actually calls out to the operating system to execute the hostname command. Here are a couple other related answers on SO: #li Java current machine name and logged in user? #li Get DNS name of local machine as seen by a remote machine EDIT: You should take a look at A.H.'s answer or Arnout Engelen's answer for details on why this might not work as expected, depending on your situation. As an answer for this person who specifically requested portable, I still think getHostName(args) is fine, but they bring up some good points that should be considered.

Question-5785745, answer-34845194
You can also use Arrays.copyOfRange . Example : #pre This method is similar to Arrays.copyOf , but it's more flexible. Both of them use System.arraycopy under the hood. See : #li #a #li #a #li #a

Question-14846920
What are some of the situations where I can use Collections.emptyMap(args) ? The Documentation says I can use this method if I want my collection to be immutable. Why would I want an immutable empty collection? What is the point?

Question-14846920, answer-14846943
It is, in my personal experience admittedly, very useful in cases where an API requires a collection of parameters, but you have nothing to provide. For example you may have an API that looks something like this, and does not allow null references: public ResultSet executeQuery(args); If you have a query that doesn't take any parameters, it's certainly a bit wasteful to create a HashMap, which involves allocating an array, when you could just pass in the 'Empty Map' which is effectively a constant, the way it's implemented in java.util.Collections .

Question-14376807, answer-22092971
For those looking for a general strategy for reading and writing a string to file: First, get a file object You'll need the storage path. For the internal storage, use: File path = context.getFilesDir(args); For the external storage (SD card), use: File path = context.getExternalFilesDir(args); Then create your file object: File file = new File(args); Write a string to the file #pre Or with Google Guava Files.write(args); Read the file to a string #pre Or if you are using Google Guava String contents = Files.toString(args); For completeness I'll mention String contents = new Scanner(args).useDelimiter(args).next(args); which requires no libraries, but benchmarks 50% - 400% slower than the other options (in various tests on my Nexus 5). Notes For each of these strategies, you'll be asked to catch an IOException. The default character encoding on Android is UTF-8. If you are using external storage, you'll need to add to your manifest either: <uses-permission android:name=StringLiteral/> or <uses-permission android:name=StringLiteral/> Write permission implies read permission, so you don't need both.

Question-25168062
Why is i++ not atomic in Java? To get a bit deeper in Java I tried to count how often the loop in threads are executed. So I used a private static int total = 0; in the main class. I have two threads. #li Thread 1: Prints System.out.println(args); #li Thread 2: Prints System.out.println(args); And I count the lines printed by thread 1 and thread 2. But the lines of thread 1 + lines of thread 2 don't match the total number of lines printed out. Here is my code: #pre

Question-10827872, answer-22578124
Old thread I know but I am sort of new to Java and discover one of it's strange things. I have used String.replaceAll(args) but get unpredictable results. Something like this mess up the string: sUrl = sUrl.replaceAll(args).replaceAll(args); So I designed this function to get around the weird problem: #pre Which make you able to do: #pre

Question-14534767, answer-14534798
It should be r.append(args); But I recommend you to do as below, r.append(args); System.getProperty(args) gives you system-dependent newline in java. Also from Java 7 there's a method that returns the value directly: System.lineSeparator()

Question-32623834, answer-32624143
You just changed the String of String constant pool Mario to Luigi which was referenced by multiple String s, so every referencing literal Mario is now Luigi . Field stringValue = String.class.getDeclaredField(args); You have fetched the char[] named value field from class String stringValue.setAccessible(args); Make it accessible. stringValue.set(args); You changed original String field to Luigi . But original is Mario the String literal and literal belongs to the String pool and all are interned . Which means all the literals which has same content refers to the same memory address. #pre Basically you have changed the Mario of String pool which got reflected in all the referencing fields. If you create String Object (i.e. new String(args) ) instead of literal you will not face this behavior because than you will have two different Mario s .

Question-10066590
With Mockito, I want to verify(args) a method call with byte[] in its argument list, but I didn't find how to write this. myMethod(args) I just want something like anyByteArray(args) , how to do that with Mockito ?

Question-30384955, answer-30385343
This happens because of the way capture conversion works: #blockquote Note the end bit. So, what this means is that, given a type like this: #pre Only "outside" wildcards are captured. The Map key wildcard is captured, but the List element wildcard is not. This is why, for example, we can add to a List<T> , but not a List<T> . The placement of the wildcard is what matters. Carrying this over to TbinList , if we have an ArrayList<T> , the wildcard is in a place where it does not get captured, but if we have a TbinList<T> , the wildcard is in a place where it gets captured. As I alluded to in the comments, one very interesting test is this: ArrayList<T> test3 = new TbinList<T>(args); We get this error: #pre So there's no way to make it work as-is. One of the class declarations needs to be changed. Additionally, think about it this way. Suppose we had: #pre And since a wildcard allows subtyping, we can do this: TbinList<T> test4 = new TbinList<T>(args); Should we be able to add a Tbin<T> to test4 ? No, this would be heap pollution. We might end up with Derived2 s floating around in a TbinList<T> .

Question-32632364, answer-32633199
It shouldn't have compiled, according to JLS 7 . int can be compared to boxed numeric types, i.e. Byte, Short, Character, Integer, Long, Float, Double. But that is all. And if comparison is between int and say Float , Float will be unboxed first, so that the comparison is between float and int . It'll make no sense to do the other way around - box int then examine the identity of the Integer (with a Float no less).

Question-32175145, answer-32175224
Since equals(...) is not a final method of Object , yes, it is very well be possible in a different situation . #pre This question, however, specifically says that these are primitive wrappers (e.g. Integer , Boolean , etc.) and since these classes are final, you cannot extend them, thus a.equals(args) will always return true .

Question-6841333, answer-20906129
As explained by others, there's a time discontinuity there. There are two possible timezone offsets for 1927-12-31 23:54:08 at Asia/Shanghai , but only one offset for 1927-12-31 23:54:07 . So, depending on which offset is used, there's either a one second difference or a 5 minutes and 53 seconds difference. This slight shift of offsets, instead of the usual one-hour daylight savings (summer time) we are used to, obscures the problem a bit. Note that the 2013a update of the timezone database moved this discontinuity a few seconds earlier, but the effect would still be observable. The new java.time package on Java 8 let use see this more clearly, and provide tools to handle it. Given: #pre Then durationAtEarlierOffset will be one second, while durationAtLaterOffset will be five minutes and 53 seconds. Also, these two offsets are the same: #pre But these two are different: #pre You can see the same problem comparing 1927-12-31 23:59:59 with 1928-01-01 00:00:00 , though, in this case, it is the earlier offset that produce the longer divergence, and it is the earlier date that has two possible offsets. Another way to approach this is to check whether there's a transition going on. We can do this like this: #pre You can check whether the transition is an overlap - in which case there's more than one valid offset for that date/time - or a gap - in which case that date/time is not valid for that zone id - by using the isOverlap(args) and isGap(args) methods on zot4 . I hope this helps people handle this sort of issue once Java 8 becomes widely available, or to those using Java 7 who adopt the JSR 310 backport.

Question-18532488, answer-33142346
Once a repeat function is somewhere defined as #pre You can use it now and then this way, e.g.: repeat.accept(args); To get and equivalent to Haskell's take 8(args) You could write #pre

Question-26791441, answer-26791724
Use the replaceEach() method from Apache Commons StringUtils : StringUtils.replaceEach(args)

Question-33147339
I was reading Java's ArrayList source code and noticed some comparisons in if-statements. In Java 7, the method grow(int) uses if(args) newCapacity = minCapacity; In Java 6, grow didn't exist. The method ensureCapacity(int) however uses if(args) newCapacity = minCapacity; What was the reason behind the change? Was it a performance issue or just a style? I could imagine that comparing against zero is faster, but performing a complete subtraction just to check whether it's negative seems a bit overkill to me. Also in terms of bytecode, this would involve two instructions ( ISUB and IF_ICMPGE ) instead of one ( IFGE ).

Question-13102045, answer-15046253
It does that because input.nextInt(args); doesn't capture the newline. you could do like the others proposed by adding an input.nextLine(args); underneath. Alternatively you can do it C# style and parse a nextLine to an integer like so: int number = Integer.parseInt(args); Doing this works just as well, and it saves you a line of code.

Question-19998454, answer-19998652
This is being described in this article . Think about forEach of Collections. List<T> list = … list.forEach(args); #blockquote

Question-14534767, answer-34073047
Another option is to use Apache Commons StrBuilder, which has the functionality that's lacking in StringBuilder. StrBuilder.appendLn()

Question-7348711, answer-20793241
Environment variables may also provide a useful means -- COMPUTERNAME on Windows, HOSTNAME on most modern Unix/Linux shells. See: #a I'm using these as "supplementary" methods to InetAddress.getLocalHost(args).getHostName(args) , since as several people point out, that function doesn't work in all environments. Runtime.getRuntime(args).exec(args) is another possible supplement. At this stage, I haven't used it. #pre

Question-22409102, answer-22409270
You can use Float.floatToIntBits to convert it to an int and look at the bit pattern: #pre

Question-29183904
I used to define a set of related constants like Bundle keys together in an interface like below: #pre This provides me a nicer way to group related constants together and used them by making a static import (not implements). I know Android framework also uses the constants in same way like Toast.LENTH_LONG , View.GONE . However, I often feel that the Java Enums provide much better and powerful way to represent the constant. But is there a performence issue in using enums on Android ? With a bit of research I ended up in confusion. From this question "Avoid Enums Where You Only Need Ints” removed from Android's performance tips? it's clear that Google has removed "Avoid enums" from its performance tips, but from it's official training docs Be aware of memory overhead section it clearly says: "Enums often require more than twice as much memory as static constants. You should strictly avoid using enums on Android." Is this still holds good? (say in Java versions after 1.6) One more issue that I observed is to send enums across intents using Bundle I should send them by serializing (i.e putSerializable(args) , that I think an expensive operation compared to primitive putString(args) method, eventhough enums provides it for free). Can someone please clarify which one is the best way to represent the same in Android ? Should I strictly avoid using enums on Android ?

Question-29229373, answer-33839551
In my free StreamEx library I introduced the short-circuiting collectors. When collecting sequential stream with short-circuiting collector (like MoreCollectors.first() ) exactly one element is consumed from the source. Internally it's implemented in quite dirty way: using a custom exception to break the control flow. Using my library your sample could be rewritten in this way: #pre The result is the following: #pre

Question-14491966, answer-14513598
java.util.Random is not much different, a basic LCG described by Knuth. However it has main 2 main advantages/differences: #li thread safe - each update is a CAS which is more expensive than a simple write and needs a branch (even if perfectly predicted single threaded). Depending on the CPU it could be significant difference. #li undisclosed internal state - this is very important for anything non-trivial. You wish the random numbers not to be predictable. Below it's the main routine generating 'random' integers in java.util.Random. #pre If you remove the AtomicLong and the undisclosed sate (i.e. using all bits of the long ), you'd get more performance than the double multiplication/modulo. Last note: Math.random should not be used for anything but simple tests, it's prone to contention and if you have even a couple of threads calling it concurrently the performance degrades. One little known historical feature of it is the introduction of CAS in java - to beat an infamous benchmark (first by IBM via intrinsics and then Sun made "CAS from Java")

Question-11359187, answer-11359320
#li java.util.logging was introduced in Java 1.4. There were uses for logging before that, that's why many other logging APIs exist. Those APIs where used heavily before Java 1.4 and thus had a great marketshare that didn't just drop to 0 when 1.4 was release. #li JUL didn't start out all that great, many of the things you mentioned where a lot worse in 1.4 and only got better in 1.5 (and I guess in 6 as well, but I'm not too sure). #li JUL isn't well suited for multiple applications with different configurations in the same JVM (think multiple web applications that should not interact). Tomcat needs to jump through some hoops to get that working (effectively re-implementing JUL if I understood that correctly). #li You can't always influence what logging framework your libraries use. Therefore using SLF4J (which is actually just a very thin API layer above other libraries) helps keeping a somewhat consistent picture of the entire logging world (so you can decide the underlying logging framework while still having library logging in the same system). #li Libraries can't easily change. If a previous version of a library used to use logging-library-X it can't easily switch to logging-library-Y (for example JUL), even if the latter is clearly superious: any user of that library would need to learn the new logging framework and (at least) reconfigure their logging. That's a big no-no, especially when it brings no apparent gain to most people. Having said all that I think JUL is at least a valid alternative to other logging frameworks these days.

Question-23453287, answer-23456085
It will be hard to find and identify "THE" answer, for the resons mentioned in the comments from @EJP : There are roughly 2 (+/- 2) people in the world who can give the definite answer at all . And in doubt, the answer might just be something like "Supporting final default methods did not seem to be worth the effort of restructuring the internal call resolution mechanisms". This is speculation, of course, but it is at least backed by subtle evidences, like this Statement (by one of the two persons) in the OpenJDK mailing list : #blockquote and trivial facts like that a method is simply not considered to be a (really) final method when it is a default method, as currently implemented in the Method::is_final_method method in the OpenJDK. Further really "authorative" information is indeed hard to find, even with excessive websearches and by reading commit logs. I thought that it might be related to potential ambiguities during the resolution of interface method calls with the invokeinterface instruction and and class method calls, corresponding to the invokevirtual instruction: For the invokevirtual instruction, there may be a simple vtable lookup, because the method must either be inherited from a superclass, or implemented by the class directly. In contrast to that, an invokeinterface call must examine the respective call site to find out which interface this call actually refers to (this is explained in more detail in the InterfaceCalls page of the HotSpot Wiki). However, final methods do either not get inserted into the vtable at all, or replace existing entries in the vtable (see klassVtable.cpp. Line 333 ), and similarly, default methods are replacing existing entries in the vtable (see klassVtable.cpp, Line 202 ). So the actual reason (and thus, the answer) must be hidden deeper inside the (rather complex) method call resolution mechanisms, but maybe these references will nevertheless be considered as being helpful, be it only for others that manage to derive the actual answer from that.

Question-12552863, answer-16229988
My solution is to do a "extract method" refactoring, as following: #pre printToFile can be written either #pre or #pre For class lib designers, I will suggest them extend the AutoClosable interface with an additional method to suppress the close. In this case we can then manually control the close behavior. For language designers, the lesson is that adding a new feature could mean adding a lot others. In this Java case, obviously ARM feature will work better with a resource ownership transfer mechanism. UPDATE Originally the code above requires @SuppressWarning since the BufferedWriter inside the function requires close(args) . As suggested by a comment, if flush(args) to be called before close the writer, we need to do so before any return (implicit or explicit) statements inside the try block. There is currently no way to ensure the caller doing this I think, so this must be documented for writeFileWriter . UPDATE AGAIN The above update makes @SuppressWarning unnecessary since it require the function to return the resource to the caller, so itself does not necessary being closed. Unfortunately, this pull us back to the beginning of the situation: the warning is now moved back to the caller side. So to properly solve this, we need a customised AutoClosable that whenever it closes, the underline BufferedWriter shall be flush(args) ed. Actually, this shows us another way to bypass the warning, since the BufferWriter is never closed in either way.

Question-32820722, answer-32820984
Let's rewrite that lambda expression with parentheses to make it more clear: IntFunction<T> curriedAdd = a -> (b -> (a + b)); So we are declaring a function taking an int which returns a Function . More specifically, the function returned takes an int and returns an int (the sum of the two elements): this can be represented as an IntUnaryOperator . Therefore, curriedAdd is a function taking an int and returning an IntUnaryOperator , so it can be represented as IntFunction<IntUnaryOperator> .

Question-32714194, answer-32714537
While currently most of Java compilers using StringBuilder chain, it's not specified that it should be always in this way. In particular there's a proposal to change this drastically in Java-9 replacing with single invokedynamic call and introduce new metafactory which will generate an appropriate MethodHandle in runtime to perform concatenation.

Question-8430805, answer-22332291
Sudheesh B Nair 's has a nice (and accepted) answer on the question, which i think should have a better alternative such as; What's wrong with measuring time passed and checking if TIME_INTERVAL miliseconds (say 2000) passed since the last back press. The following sample code uses System.currentTimeMillis(args); to store the time onBackPressed(args) is called; #pre Back on accepted answer critique ; Using a flag to indicate if it was pressed in last TIME_INTERVAL (say 2000) milliseconds and set - reset is via Handler 's postDelayed(args) method was the first thing to come in my mind. But the postDelayed(args) action should be cancelled when activity is closing, removing the Runnable . In order to remove the Runnable , it must not be declared anonymous , and be declared as member along with the Handler aswell. Then removeCallbacks(args) method of Handler can be called appropriately. The following sample is the demonstration; #pre Thanks to @NSouth for contributing; In order to prevent toast message appearing even after the application is closed, Toast can be declared as a member - say mExitToast - and can be cancelled via mExitToast.cancel(args); just before super.onBackPressed(args); call.

Question-9481865
I am trying to develop a system where there are different nodes that are run on different system or on different ports on the same system. Now all the nodes create a Socket with a target IP as the IP of a special node known as a bootstrapping node. The nodes then create their own ServerSocket and start listening for connections. The bootstrapping node maintains a list of Nodes and returns them on being quired. Now what I need is the node must register its IP to the bootstrapping node. I tried using cli.getInetAddress(args) once the client connects to the ServerSocket of bootstrapping node but that didn't work. #li I need the client to register its PPP IP if available; #li Otherwise the LAN IP if available; #li Otherwise it must register 127.0.0.1 assuming its the same computer. Please help me with this. EDIT using the code: System.out.println(args); or System.out.println(args); My PPP Connection IP address is: 117.204.44.192 but the above returns me 192.168.1.2 EDIT2 I am using the following code: #pre I am able to get all the IP addresses associated all NetworkInterface s, but how do I distinguish them?? This is the output I am getting: #pre

Question-29494800, answer-29502668
#blockquote It's checking simple equality (likely for the purpose of a micro-optimization, but more on that later). The unusual casting is necessary because Class<T> (the type of Object[].class ) and Class<T> are incomparable types. Basically, for an equality comparison with == to compile, one of the sides has to be a subtype or supertype of the other. I.e. we can't do: #pre The rules for generic types are a bit more complicated and there are a few cases where a comparison doesn't compile, but it may still evaluate to true. The reason Class<T> is not a supertype of Class<T> , despite Object[] being a supertype of all object array types, is that Java generics are invariant without the presence of a wildcard. Another way to do the comparison would be: (newType == (Class<T>)Object[].class) #blockquote #li new Object[...] creates an array the normal way, of a type that is statically known. Remember, the code has just checked that T[] is Object[] . #li Array.newInstance(args) uses reflection to dynamically create an array of the Class type passed in. #blockquote An operation using reflection is generally slower than its non-reflective counterpart. The reflection tutorial says: #blockquote Java SE is filled with micro-optimization like this. The writers of SE try to squeeze everything they can out of it. But I wouldn't be worried about a performance hit in this case: newInstance and copyOf are HotSpot intrinsics . This means that ideally calls to these methods get replaced with machine-specific assembly. Anecdotally, I ran some tests and found the difference between new Object[...] and Array.newInstance(args) to be negligible. The code in the question is probably a relic, although it may still be useful on less well-equipped JVMs. Reflection can also be disabled in certain contexts with strict security (such as an applet), but not typically for a normal desktop application. #blockquote In general, you will probably never use this overload. This overload is only useful if you want to change the type of the array. #li Widening: #pre #li Narrowing: #pre It's more typical to use Arrays.copyOf(T[], int) .

Question-25850328, answer-25850622
a. I have always seen them as a design pattern and nothing JVM-Special I have used that pattern in several situations. c. I beleive that using Annotations to mark something is a better solution then using marker interfaces. Simply because Interfaces are in the first place aimed to define common interfaces of Types / Classes. They are part of the class-hierachy. Annotations are aimed to provide Meta-Informations to Code, and I think that marker are meta-informations. So they are exactly for that use-case.

Question-19235606
I am having trouble understanding the Stream interface in Java 8, especially where it has to do with the Spliterator and Collector interfaces. My problem is that I simply can't understand yet the Spliterator and the Collector interfaces, and as a result the Stream interface is still somewhat obscure to me. What exactly is a Spliterator and a Collector , and how can I use them? If I am willing to write my own Spliterator or Collector (and probably my own Stream in that process), what should I do and not do? I read some examples scattered around the web, but since everything here is stil new and subject to changes, examples and tutorials are still very sparse.

Question-29494800
I have trouble understanding the source code of Arrays.copyOf . #pre #li what is this line checking? (Object)newType == (Object)Object[].class #li What are the differences between (T[]) new Object[newLength] and (T[]) Array.newInstance(args) . why Array.newInstance not good enough for both cases? #li This following line compiles, but crashes at run time (as expected). When should I use this method? Integer[] nums = Arrays.copyOf(args)

Question-12468764, answer-24537575
I've found a very nice and concise solution, especially useful when you cannot modify enum classes as it was in my case. Then you should provide a custom ObjectMapper with a certain feature enabled. Those features are available since Jackson 1.6. So you only need to write toString(args) method in your enum. #pre There are more enum-related features available, see here: #a #a

Question-30081520, answer-30081600
From Objects.equals() : return(args) || (a != null && a.equals(args)); Very simple, self-explaining and elegant.

Question-32323081, answer-32323305
Any lambda which could be accepted as a Supplier<T> can also be accepted as a ThrowingSupplier<T> . The following compiles: #pre Given the above, you probably don't need this, but if foo must accept a non-throwing Supplier<T> , you can always wrap the Exception-throwing method in a method which launders it into an unchecked Exception: #pre

Question-18777989, answer-18778228
You made a good summery of the practical differences in use and implementation but did not say anything about the difference in meaning. An interface is a description of the behaviour an implementing class will have. The implementing class ensures, that it will have these methods that can be used on it. It is basically a contract or a promise the class has to make. An abstract class is a basis for different subclasses that share behaviour which does not need to be repeatedly be created. Subclasses must complete the behaviour and have the option to override predefine behaviour (as long as it is not defined as final or private ). You will find good examples in the java.util package which includes interfaces like List and abstract classes like AbstractList which already implements the interface. The official documentation describes the AbstractList as follows: #blockquote

Question-10631715, answer-30270403
There is a function called replaceAll(args) that can remove all whitespaces by replacing them with whatever you want. As an example #pre will give you: First:15.94, Second:16.01

Question-10904911, answer-10904956
What you want is the Arrays.toString(args) method: #pre There is a static Arrays.toString helper method for every different primitive java type; the one for int[] says this : #blockquote

Question-15430247
The usual constructor of ArrayList is: ArrayList<T> list = new ArrayList<T>(args); But there is also an overloaded constructor with a parameter for its initial capacity: ArrayList<T> list = new ArrayList<T>(args); Why is it useful to create an ArrayList with an initial capacity when we can append to it as we please?

Question-18532488, answer-24296741
Here's another technique I ran across the other day: Collections.nCopies(args) .stream(args) .forEach(args); The Collections.nCopies call creates a List containing n copies of whatever value you provide. In this case it's the boxed Integer value 1. Of course it doesn't actually create a list with n elements; it creates a "virtualized" list that contains only the value and the length, and any call to get within range just returns the value. The nCopies method has been around since the Collections Framework was introduced way back in JDK 1.2. Of course, the ability to create a stream from its result was added in Java SE 8. Big deal, another way to do the same thing in about the same number of lines. However, this technique is faster than the IntStream.generate and IntStream.iterate approaches, and surprisingly, it's also faster than the IntStream.range approach. For iterate and generate the result is perhaps not too surprising. The streams framework (really, the Spliterators for these streams) is built on the assumption that the lambdas will potentially generate different values each time, and that they will generate an unbounded number of results. This makes parallel splitting particularly difficult. The iterate method is also problematic for this case because each call requires the result of the previous one. So the streams using generate and iterate don't do very well for generating repeated constants. The relatively poor performance of range is surprising. This too is virtualized, so the elements don't actually all exist in memory, and the size is known up front. This should make for a fast and easily parallelizable spliterator. But it surprisingly didn't do very well. Perhaps the reason is that range has to compute a value for each element of the range and then call a function on it. But this function just ignores its input and returns a constant, so I'm surprised this isn't inlined and killed. The Collections.nCopies technique has to do boxing/unboxing in order to handle the values, since there are no primitive specializations of List . Since the value is the same every time, it's basically boxed once and that box is shared by all n copies. I suspect boxing/unboxing is highly optimized, even intrinsified, and it can be inlined well. Here's the code: #pre And here are the JMH results: (2.8GHz Core2Duo) #pre There is a fair amount of variance in the ncopies version, but overall it seems comfortably 20x faster than the range version. (I'd be quite willing to believe that I've done something wrong, though.) I'm surprised at how well the nCopies technique works. Internally it doesn't do very much special, with the stream of the virtualized list simply being implemented using IntStream.range ! I had expected that it would be necessary to create a specialized spliterator to get this to go fast, but it already seems to be pretty good.

Question-25606833, answer-25757572
There are several issues here. #li Any solution based on reading lines is going to process each character twice. Compilers for example don't do this, they read one character at a time and despatch on it directly. #li Any solution based on readLine(args) is going to create Strings. #li You are using different buffer sizes. #li You are using different I/O technologies. #li In some cases you are using character conversion, while in others you aren't. #li You're over-analyzing the file. You don't really care where the white space is, or how much of it there is, as long as it separates the numbers from each other. My solution: #pre

Question-27908213, answer-27908294
The Oracle documentation about Enum says (first line): #blockquote If this is true then, yes, your enum1.name(args) == enum2.name(args) is guaranteed to be true if the names are the same. Also, in the method name(args) javadoc: #blockquote For example, if you had two enums, Days and MyDays , where SUNDAY is a common value, == between the enum object values, SUNDAY will return true as you are comparing two strings - see the working example in #a . #pre

Question-28276423, answer-28276469
It will be fine if you only close the last stream - the close call will be send to the underlying streams, too.

Question-27747562
In the following code, a dowcast to an apparently incompatible type passes compilation: #pre Item and List<T> are disparate types so the cast can never succeed. Why did the compiler allow this?

Question-10827872, answer-10827945
The replace(args) method is overloaded to accept both a primitive char and a CharSequence as arguments. Now as far as the performance is concerned, the replace(args) method is a bit faster than replaceAll(args) because the later first compiles the regex pattern and then matches before finally replacing whereas the former simply matches for the provided argument and replaces. Since we know the regex pattern matching is a bit more complex and consequently slower, then preferring replace(args) over replaceAll(args) is suggested whenever possible. For example, for simple substitutions like you mentioned, it is better to use: replace(args); instead of: replaceAll(args); Note: the above conversion method arguments are system-dependent.

Question-22694884, answer-22695031
Technically there's an ugly 'workaround' that involves peek(args) and an AtomicInteger , but really you shouldn't be using that. What I do in these cases is just collecting it in a list, like this: #pre I am not aware of a way to do this in the API, meanwhile I will work on another example involving a custom element. Update , You should create your own Collector for this: #pre What it does is: #li It mimicks the Collectors.toList(args) collector. #li It applies an extra finisher at the end, that throws an exception, or if no exception, returns the first element of the list. Used as: User resultUser = users.stream(args) .filter(args) .collect(args); You can then customize this singletonCollector as much as you want, for example give the exception as argument in the constructor, tweak it to allow two values, and more. New update , I revised my old answer once more for singletonCollector(args) , it can actually be obtained like this: #pre

Question-8275499, answer-8275761
getClass(args) method is defined in Object class with the following signature: #blockquote Since it is not defined as static , you can not call it within a static code block. See these answers for more information: Q1 , Q2 , Q3 . If you're in a static context, then you have to use the class literal expression to get the Class, so you basically have to do like: #blockquote This type of expression is called Class Literals and they are explained in Java Language Specification Book as follows: #blockquote You can also find information about this subject on API documentation for Class.

Question-26791441, answer-26819171
This is not an easy problem. And the more search-replacement parameters you have, the trickier it gets. You have several options, scattered on the palette of ugly-elegant, efficient-wasteful: #li Use StringUtils.replaceEach from Apache Commons as @AlanHay recommended. This is a good option if you're free to add new dependencies in your project. You might get lucky: the dependency might be included already in your project #li Use a temporary placeholder as @Jeroen suggested, and perform the replacement in 2 steps: #li Replace all search patterns with a unique tag that doesn't exist in the original text #li Replace the placeholders with the real target replacement This is not a great approach, for several reasons: it needs to ensure that the tags used in the first step are really unique; it performs more string replacement operations than really necessary #li Build a regex from all the patterns and use the method with Matcher and StringBuffer as suggested by @arshajii . This is not terrible, but not that great either, as building the regex is kind of hackish, and it involves StringBuffer which went out of fashion a while ago in favor of StringBuilder . #li Use a recursive solution proposed by @mjolka , by splitting the string at the matched patterns, and recursing on the remaining segments. This is a fine solution, compact and quite elegant. Its weakness is the potentially many substring and concatenation operations, and the stack size limits that apply to all recursive solutions #li Split the text to words and use Java 8 streams to perform the replacements elegantly as @msandiford suggested, but of course that only works if you are ok with splitting at word boundaries, which makes it not suitable as a general solution Here's my version, based on ideas borrowed from Apache's implementation . It's neither simple nor elegant, but it works, and should be relatively efficient, without unnecessary steps. In a nutshell, it works like this: repeatedly find the next matching search pattern in the text, and use a StringBuilder to accumulate the unmatched segments and the replacements. #pre Unit tests: #pre

Question-29280857, answer-29382161
As stated previously, you should lock on both accounts, always in the same order. The key part, however, is ensuring both high granularity and singularity across the VM instance. This can be done using String.intern() : #pre

Question-6684665, answer-6684852
What Arrays.toString(args) does is create a string representation of each individual byte in your byteArray. Please check the API documentation Arrays API To convert your response string back to the original byte array, you have to use split(args) or something and convert it into a collection and then convert each individual item in there to a byte to recreate your byte array.

Question-23674624
I'm looking at the docs for the IntStream , and I see an toArray method, but no way to go directly to a List<T> Surely there is a way to convert a Stream to a List ?

Question-16324831, answer-16324963
Note: everything in this post is in the source of Java7-b147 Double.parseDouble(args) goes into a Sun library (in sun.misc.FloatingDecimal ) the first important thing that happens is: #pre Integer.parseInt(args) is done manually in the Integer class. The first important thing that happens is: #pre I would guess there are two different authors.

Question-31188231
It has generally been the case the Java source code has been forward compatible. Until Java 8, as far as I know, both compiled classes and source have been forward compatible with later JDK/JVM releases. [Update: this is not correct, see comments re 'enum', etc, below.] However, with the addition of default methods in Java 8 this appears to no longer be the case. For example, a library I have been using has an implementation of java.util.List which includes a List<T> sort(args) . This method returns a copy of the contents of the list sorted. This library, deployed as a jar file dependency, worked fine in a project being built using JDK 1.8. However, later I had occasion to recompile the library itself using JDK 1.8 and I found the library no longer compiles: the List -implementing class with its own sort(args) method now conflicts with the Java 8 java.util.List.sort(args) default method. The Java 8 sort(args) default method sorts the list in place (returns void ); my library's sort(args) method - since it returns a new sorted list - has an incompatible signature. So my basic question is: #li Doesn't JDK 1.8 introduce a forward incompatibility for Java source code due to default methods? Also: #li Is this the first such forward incompatible change? #li Was this considered or discussed when default methods where designed and implemented? Is it documented anywhere? #li Was the (admittedly small) inconvenience discounted versus the benefits? The following is an example of some code that compiles and runs under 1.7 and runs under 1.8 - but does not compile under 1.8: #pre The following shows this code being compiled (or failing to) and being run. #pre

Question-5839359, answer-5839392
You're essentially running out of memory to run the process smoothly. Options that come to mind: #li Specify more memory like you mentioned, try something in between like -Xmx512m first #li Work with smaller batches of HashMap objects to process at once if possible #li If you have a lot of duplicate strings, use String.intern() on them before putting them into the HashMap #li Use the HashMap(int initialCapacity, float loadFactor) constructor to tune for your case

Question-5455794, answer-5455820
How about replaceAll(args) . Refer here .

Question-32693704, answer-32744190
There is no actual difference in the functionality between the 2 version's loop. Arrays.fill does the exact same thing. So the choice to use it or not may not necessarily be considered a mistake. It is left up to the developer to decide when it comes to this kind of micromanagement. There are 2 separate concerns for each approach: #li using the Arrays.fill makes the code less verbose and more readable. #li looping directly in the HashMap code (like version 8) peformance wise is actually a better option. While the overhead that inserting the Arrays class is negligible it may become less so when it comes to something as widespread as HashMap where every bit of performance enhancement has a large effect(imagine the tiniest footprint reduce of a HashMap in fullblown webapp). Take into consideration the fact that the Arrays class was used only for this one loop. The change is small enough that it doesn't make the clear method less readable. The precise reason can't be found out without asking the developer who actually did this, however i suspect it's either a mistake or a small enhancement. better option. My opinion is it can be considered an enhancement, even if only by accident.

Question-8189466, answer-23592535
I had that same problem but in case that I was adding en element into iterated list. I made it this way #pre Now everything goes fine because you don't create any iterator over your list, you iterate over it "manually". And condition i < integerList.size(args) will never fool you because when you remove/add something into List size of the List decrement/increment.. Hope it helps, for me that was solution.

Question-15336477
All I'm trying to do is download some JSON and deserialize it into an object. I haven't got as far as downloading the JSON yet. Almost every single HttpClient example I can find, including those on the apache site looks something like... #pre However, Netbeans tells me that DefaultHttpClient is deprecated. I've tried googling for DefaultHttpClient deprecated and as many other variations as I can think of and can't find any useful results, so I'm obviously missing something. What is the correct Java7 way to download the contents of a webpage? Is there really no decent Http Client as part of the language? I find that hard to believe. My Maven dependency for this is... #pre

Question-15430247, answer-15432106
This is to avoid possible efforts for reallocation for every single object. int newCapacity = (oldCapacity * 3)/2 + 1; internally new Object[] is created. JVM needs effort to create new Object[] when you add element in the arraylist. If you don't have above code(any algo you think) for reallocation then every time when you invoke arraylist.add(args) then new Object[] has to be created which is pointless and we are loosing time for increasing size by 1 for each and every objects to be added. So it is better to increase size of Object[] with following formula. (JSL has used forcasting formula given below for dynamically growing arraylist instead of growing by 1 every time. Because to grow it takes effort by JVM) int newCapacity = (oldCapacity * 3)/2 + 1;

Question-14491966, answer-14495128
If the Math.Random(args) function calls the operating system to get the time of day, then you cannot compare it to your function. Your function is a PRNG, whereas that function is striving for real random numbers. Apples and oranges. Your PRNG may be fast, but it does not have enough state information to achieve a long period before it repeats (and its logic is not sophisticated enough to even achieve the periods that are possible with that much state information). Period is the length of the sequence before your PRNG begins to repeat itself. This happens as soon as the PRNG machine makes a state transition to a state which is identical to some past state. From there, it will repeat the transitions which began in that state. Another problem with PRNG's can be a low number of unique sequences, as well as degenerate convergence on a particular sequence which repeats. There can also be undesirable patterns. For instance, suppose that a PRNG looks fairly random when the numbers are printed in decimal, but an inspection of the values in binary shows that bit 4 is simply toggling between 0 and 1 on each call. Oops! Take a look at the Mersenne Twister and other algorithms. There are ways to strike a balance between the period length and CPU cycles. One basic approach (used in the Mersenne Twister) is to cycle around in the state vector. That is to say, when a number is being generated, it is not based on the entire state, just on a few words from the state array subject to a few bit operations. But at each step, the algorithm also moves around in the array, scrambling the contents a little bit at a time.

Question-16635398, answer-31707746
One of most upleasing functional forEach 's limitations is lack of checked exceptions support. One possible workaround is to replace terminal forEach with plain old foreach loop: #pre Here is list of most popular questions with other workarounds on checked exception handling within lambdas and streams: Java 8 Lambda function that throws exception? Java 8: Lambda-Streams, Filter by Method with Exception How can I throw CHECKED exceptions from inside Java 8 streams? Java 8: Mandatory checked exceptions handling in lambda expressions. Why mandatory, not optional?

Question-29328785, answer-29330741
It's not so hard to track down the reason for the odd behavior. The divide call goes to #pre This, internally, delegates to another divide method, based on the rounding mode: #pre In this case, the last call applies. Note that the intVal (which is a BigInteger that is stored in the BigDecimal ) is passed directly to this method as the first argument: #pre Finally, the path to the second divideAndRound is taken here, again passing the dividend on (which was the intVal of the original BigDecimal ), ending up with this code: #pre And this is where the error is introduced: The mdivididend is a mutable BigInteger , that was created as a mutable view on the mag array of the BigInteger that is stored in the BigDecimal x from the original call. The division modifies the mag field, and thus, the state of the (now not-so-immutable) BigDecimal . This is clearly a bug in the implementation of one of the divide methods. I already started tracking the change sets of the OpenJDK, but have not yet spotted the definite culprit. ( Edit: See updates below ) (A side note: Calling x.toString(args) before doing the division does not really avoid , but only hide the bug: It causes a string cache of the correct state to be created internally. The right value is printed, but the internal state is still wrong - which is concerning, to say the least...) #blockquote

Question-7520432, answer-7521675
Just remember that .equals(args) has to be implemented by the class you are trying to compare. Otherwise, there isn't much of a point; the version of the method for the Object class does the same thing as the comparison operation: Object#equals . The only time you really want to use the comparison operator for objects is wen you are comparing Enums. This is because there is only one instance of an Enum value at a time. For instance, given the enum enum FooEnum {A, B, C} You will never have more than one instance of A at a time, and the same for B and C . This means that you can actually write a method like so: #pre And you will have no problems whatsoever.

Question-28459498, answer-28460301
Stream s are built around Spliterator s which are stateful, mutable objects. They don’t have a “reset” action and in fact, requiring to support such rewind action would “take away much power”. How would Random.ints() be supposed to handle such a request? On the other hand, for Stream s which have a retraceable origin, it is easy to construct an equivalent Stream to be used again. Just put the steps made to construct the Stream into a reusable method. Keep in mind that repeating these steps is not an expensive operation as all these steps are lazy operations; the actual work starts with the terminal operation and depending on the actual terminal operation entirely different code might get executed. It would be up to you, the writer of such a method, to specify what calling the method twice implies: does it reproduce exactly the same sequence, as streams created for an unmodified array or collection do, or does it produce a stream with a similar semantics but different elements like a stream of random ints or a stream of console input lines, etc. By the way, to avoid confusion, a terminal operation consumes the Stream which is distinct from closing the Stream as calling close(args) on the stream does (which is required for streams having associated resources like, e.g. produced by Files.lines(args) ). It seems that a lot of confusion stems from misguiding comparison of IEnumerable with Stream . An IEnumerable represents the ability to provide an actual IEnumerator , so its like an Iterable in Java. In contrast, a Stream is a kind of iterator and comparable to an IEnumerator so it’s wrong to claim that this kind of data type can be used multiple times in .NET, the support for IEnumerator.Reset is optional. The examples discussed here rather use the fact that an IEnumerable can be used to fetch new IEnumerator s and that works with Java’s Collection s as well; you can get a new Stream . If the Java developers decided to add the Stream operations to Iterable directly, with intermediate operations returning another Iterable , it was really comparable and it could work the same way. However, the developers decided against it and the decision is discussed in this question . The biggest point is the confusion about eager Collection operations and lazy Stream operations. By looking at the .NET API, I (yes, personally) find it justified. While it looks reasonable looking at IEnumerable alone, a particular Collection will have lots of methods manipulating the Collection directly and lots of methods returning a lazy IEnumerable , while the particular nature of a method isn’t always intuitively recognizable. The worst example I found (within the few minutes I looked at it) is List.Reverse() whose name matches exactly the name of the inherited (is this the right terminus for extension methods?) Enumerable.Reverse() while having an entirely contradicting behavior. Of course, these are two distinct decisions. The first one to make Stream a type distinct from Iterable / Collection and the second to make Stream a kind of one time iterator rather than another kind of iterable. But these decision were made together and it might be the case that separating these two decision never was considered. It wasn’t created with being comparable to .NET’s in mind. The actual API design decision was to add an improved type of iterator, the Spliterator . Spliterator s can be provided by the old Iterable s (which is the way how these were retrofitted) or entirely new implementations. Then, Stream was added as a high-level front-end to the rather low level Spliterator s. That’s it. You may discuss about whether a different design would be better, but that’s not productive, it won’t change, given the way they are designed now. There is another implementation aspect you have to consider. Stream s are not immutable data structures. Each intermediate operation may return a new Stream instance encapsulating the old one but it may also manipulate its own instance instead and return itself (that doesn’t preclude doing even both for the same operation). Commonly known examples are operations like parallel or unordered which do not add another step but manipulate the entire pipeline). Having such a mutable data structure and attempts to reuse (or even worse, using it multiple times at the same time) doesn’t play well… For completeness, here is your quicksort example translated to the Java Stream API. It shows that it does not really “take away much power”. #pre It can be used like #pre You can write it even more compact as #pre

Question-26791441, answer-26877910
What I can only share is my own method. You can use a temporary String temp = StringLiteral; or String.Format(args); This is my example code created in console application via c# -"Idea Only, Not Exact Answer" . #pre Or you can also use the String.Format(args); #pre Output: time upon a Once, there was a bar and a foo.

Question-17781150, answer-17781376
Like the others have mentioned, this is only fulfilled by Integer.MIN_VALUE . As for proof, let me offer an easier to understand explanation other than in binary (although it is still rooted in that). Note that Integer.MIN_VALUE is equal to -2^31 or -2147483648 and Integer.MAX_VALUE is equal to 2^31-1 or 2147483647 . -Integer.MIN_VALUE is 2^31 , which is now too large for an Integer (since it is past MAX_VALUE ) thus causing an Integer overflow, making it Integer.MIN_VALUE again. It's the only Integer that does this since MIN_VALUE is the only number with no negative equivalent aside from 0.

Question-20945049, answer-20945268
In Java, if two string primitive variables are initialized to the same literal, it assigns the same reference to both variables: #pre #blockquote That is the reason the comparison returns true. The third string is created using substring(args) which makes a new string instead of pointing to the same. #blockquote When you access a string using reflection, you get the actual pointer: #pre So change to this will change the string holding a pointer to it, but as s3 is created with a new string due to substring(args) it would not change. #blockquote

Question-14846920, answer-14847046
Most of the time we use a constructor to create a new empty map . But the Collections methods offer a couple of advantages to create an empty map using static method java.util.Collections.emptyMap(args) #blockquote

